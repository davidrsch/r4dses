# Bases de datos {#sec-import-databases}

```{r}
#| results: "asis"
#| echo: false
source("_common.R")
status("complete")
```

## Introducción

Una gran cantidad de datos reside en las bases de datos, por lo que es esencial que sepa cómo acceder a ellos.
A veces, puede pedirle a alguien que descargue una instantánea en un `.csv` para usted, pero esto se vuelve doloroso rápidamente: cada vez que necesite hacer un cambio, tendrá que comunicarse con otro ser humano.
Desea poder acceder directamente a la base de datos para obtener los datos que necesita, cuando los necesita.

En este capítulo, primero aprenderá los conceptos básicos del paquete DBI: cómo usarlo para conectarse a una base de datos y luego recuperar datos con una consulta SQL[^databases-1].
**SQL**, abreviatura de **s**tructured **q**uery **l**language, es la lingua franca de las bases de datos y es un lenguaje importante que deben aprender todos los científicos de datos.
Dicho esto, no vamos a comenzar con SQL, sino que le enseñaremos dbplyr, que puede traducir su código dplyr a SQL.
Usaremos eso como una forma de enseñarle algunas de las características más importantes de SQL.
No se convertirá en un maestro de SQL al final del capítulo, pero podrá identificar los componentes más importantes y entender lo que hacen.

[^databases-1]: SQL es pronunciado "s"-"q"-"l" o "sequel".

### Requisitos previos

En este capítulo, presentaremos DBI y dbplyr.
DBI es una interfaz de bajo nivel que se conecta a bases de datos y ejecuta SQL; dbplyr es una interfaz de alto nivel que traduce su código dplyr a consultas SQL y luego las ejecuta con DBI.

```{r}
#| label: setup
#| message: false
library(DBI)
library(dbplyr)
library(tidyverse)
```

## Bases de datos básicos

En el nivel más simple, puede pensar en una base de datos como una colección de marcos de datos, llamados **tablas** en la terminología de la base de datos.
Al igual que un marco de datos, una tabla de base de datos es una colección de columnas con nombre, donde cada valor en la columna es del mismo tipo.
Hay tres diferencias de alto nivel entre los marcos de datos y las tablas de la base de datos:

-   Las tablas de la base de datos se almacenan en el disco y pueden tener un tamaño arbitrario.
    Los marcos de datos se almacenan en la memoria y están fundamentalmente limitados (aunque ese límite sigue siendo bastante grande para muchos problemas).

-   Las tablas de bases de datos casi siempre tienen índices.
    Al igual que el índice de un libro, el índice de una base de datos permite encontrar rápidamente filas de interés sin tener que mirar cada una de ellas.
    Los marcos de datos y los tibbles no tienen índices, pero las tablas de datos sí, que es una de las razones por las que son tan rápidos.

-   La mayoría de las bases de datos clásicas están optimizadas para recopilar datos rápidamente, no para analizar los datos existentes.
    Estas bases de datos se denominan **orientadas a filas** porque los datos se almacenan fila por fila, en lugar de columna por columna como R.
    Más recientemente, ha habido mucho desarrollo de bases de datos **orientadas a columnas** que hacen que el análisis de los datos existentes sea mucho más rápido.

Las bases de datos se ejecutan mediante sistemas de administración de bases de datos (**DBMS** para abreviar), que vienen en tres formas básicas:

-   **Cliente-servidor** Los DBMS se ejecutan en un poderoso servidor central, que usted conecta desde su computadora (el cliente). Son excelentes para compartir datos con varias personas en una organización. Los DBMS cliente-servidor populares incluyen PostgreSQL, MariaDB, SQL Server y Oracle.
-   Los DBMS de **Cloud**, como Snowflake, RedShift de Amazon y BigQuery de Google, son similares a los DBMS del servidor del cliente, pero se ejecutan en la nube. Esto significa que pueden manejar fácilmente conjuntos de datos extremadamente grandes y pueden proporcionar automáticamente más recursos informáticos según sea necesario.
-   Los DBMS **en proceso**, como SQLite o duckdb, se ejecutan completamente en su computadora. Son excelentes para trabajar con grandes conjuntos de datos en los que usted es el usuario principal.

## Conexión a una base de datos

Para conectarse a la base de datos desde R, utilizará un par de paquetes:

-   Siempre usará DBI (**d**ata**b**ase **i**nterface) porque proporciona un conjunto de funciones genéricas que se conectan a la base de datos, cargan datos, ejecutan consultas SQL, etc.

-   También utilizará un paquete diseñado para el DBMS al que se está conectando.
    Este paquete traduce los comandos DBI genéricos a los específicos necesarios para un DBMS dado.
    Por lo general, hay un paquete para cada DBMS, p.
    RPostgres para Postgres y RMariaDB para MySQL.

Si no puede encontrar un paquete específico para su DBMS, generalmente puede usar el paquete odbc en su lugar.
Esto usa el protocolo ODBC soportado por muchos DBMS.
odbc requiere un poco más de configuración porque también necesitará instalar un controlador ODBC e indicarle al paquete odbc dónde encontrarlo.

Concretamente, crea una conexión a la base de datos usando `DBI::dbConnect()`.
El primer argumento selecciona DBMS[^databases-2], luego el segundo argumento y los subsiguientes describen cómo conectarse a él (es decir, dónde reside y las credenciales que necesita para acceder a él).
El siguiente código muestra un par de ejemplos típicos:

[^databases-2]: Por lo general, esta es la única función que usará del paquete del cliente, por lo que recomendamos usar `::` para extraer esa función, en lugar de cargar el paquete completo con `library()`.

```{r}
#| eval: false
con <- DBI::dbConnect(
  RMariaDB::MariaDB(), 
  username = "foo"
)
con <- DBI::dbConnect(
  RPostgres::Postgres(), 
  hostname = "databases.mycompany.com", 
  port = 1234
)
```

Los detalles precisos de la conexión varían mucho de DBMS a DBMS, por lo que lamentablemente no podemos cubrir todos los detalles aquí.
Esto significa que tendrás que investigar un poco por tu cuenta.
Por lo general, puede preguntar a los otros científicos de datos de su equipo o hablar con su DBA (**d**ata**b**ase **a**administrador).
La configuración inicial a menudo requerirá un poco de manipulación (y tal vez un poco de google) para hacerlo bien, pero generalmente solo necesitará hacerlo una vez.

### En este libro

Configurar un DBMS cliente-servidor o en la nube sería una molestia para este libro, por lo que en su lugar usaremos un DBMS en proceso que vive completamente en un paquete R: duckdb.
Gracias a la magia de DBI, la única diferencia entre usar duckdb y cualquier otro DBMS es cómo te conectarás a la base de datos.
Esto hace que sea excelente para enseñar porque puede ejecutar fácilmente este código y tomar fácilmente lo que aprende y aplicarlo en otro lugar.

Conectarse a duckdb es particularmente simple porque los valores predeterminados crean una base de datos temporal que se elimina cuando sale de R.
Eso es excelente para aprender porque garantiza que comenzará desde cero cada vez que reinicie R:

```{r}
con <- DBI::dbConnect(duckdb::duckdb())
```

duckdb es una base de datos de alto rendimiento diseñada en gran medida para las necesidades de un científico de datos.
Lo usamos aquí porque es muy fácil de usar, pero también es capaz de manejar gigabytes de datos a gran velocidad.
Si desea utilizar duckdb para un proyecto de análisis de datos real, también deberá proporcionar el argumento `dbdir` para crear una base de datos persistente y decirle a duckdb dónde guardarla.
Asumiendo que estás usando un proyecto (@sec-workflow-scripts-projects), es razonable guardarlo en el directorio `duckdb` del proyecto actual:

```{r}
#| eval: false
con <- DBI::dbConnect(duckdb::duckdb(), dbdir = "duckdb")
```

### Cargar algunos datos {#sec-load-data}

Dado que esta es una base de datos nueva, debemos comenzar agregando algunos datos.
Aquí agregaremos conjuntos de datos `mpg` y `diamonds` de ggplot2 usando `DBI::dbWriteTable()`.
El uso más simple de `dbWriteTable()` necesita tres argumentos: una conexión de base de datos, el nombre de la tabla para crear en la base de datos y un marco de datos de datos.

```{r}
dbWriteTable(con, "mpg", ggplot2::mpg)
dbWriteTable(con, "diamonds", ggplot2::diamonds)
```

Si está utilizando duckdb en un proyecto real, le recomendamos que aprenda sobre `duckdb_read_csv()` y `duckdb_register_arrow()`.
Estos le brindan formas potentes y eficaces de cargar rápidamente datos directamente en duckdb, sin tener que cargarlos primero en R.
También mostraremos una técnica útil para cargar varios archivos en una base de datos en @sec-save-database.

### DBI básico

Puede comprobar que los datos se cargan correctamente utilizando un par de otras funciones de DBI: `dbListTable()` enumera todas las tablas de la base de datos[^databases-3] y `dbReadTable()` recupera el contenido de una tabla.

[^databases-3]: Al menos, todas las tablas que tiene permiso para ver.

```{r}
dbListTables(con)

con |> 
  dbReadTable("diamonds") |> 
  as_tibble()
```

`dbReadTable()` devuelve un `data.frame` por lo que usamos `as_tibble()` para convertirlo en un tibble para que se imprima bien.

Si ya conoce SQL, puede usar `dbGetQuery()` para obtener los resultados de ejecutar una consulta en la base de datos:

```{r}
sql <- "
  SELECT carat, cut, clarity, color, price 
  FROM diamonds 
  WHERE price > 15000
"
as_tibble(dbGetQuery(con, sql))
```

Si nunca ha visto SQL antes, ¡no se preocupe!
En breve aprenderás más al respecto.
Pero si lo lee detenidamente, puede adivinar que selecciona cinco columnas del conjunto de datos de diamantes y todas las filas donde el `precio` es mayor que 15,000.

## dbplyr básico

Ahora que nos conectamos a una base de datos y cargamos algunos datos, podemos comenzar a aprender sobre dbplyr.
dbplyr es un **backend** de dplyr, lo que significa que sigues escribiendo código dplyr pero el backend lo ejecuta de manera diferente.
En esto, dbplyr se traduce a SQL; otros backends incluyen [dtplyr](https://dtplyr.tidyverse.org) que se traduce en [data.table](https://r-datatable.com), y [multidplyr](https://multidplyr.tidyverse.org) que ejecuta su código en múltiples núcleos.

Para usar dbplyr, primero debe usar `tbl()` para crear un objeto que represente una tabla de base de datos:

```{r}
diamonds_db <- tbl(con, "diamonds")
diamonds_db
```

::: callout-note
Hay otras dos formas comunes de interactuar con una base de datos.
Primero, muchas bases de datos corporativas son muy grandes, por lo que necesita cierta jerarquía para mantener todas las tablas organizadas.
En ese caso, es posible que deba proporcionar un esquema, o un catálogo y un esquema, para elegir la tabla que le interesa.:

```{r}
#| eval: false
diamonds_db <- tbl(con, in_schema("sales", "diamonds"))
diamonds_db <- tbl(con, in_catalog("north_america", "sales", "diamonds"))
```

Otras veces, es posible que desee utilizar su propia consulta SQL como punto de partida:

```{r}
#| eval: false
diamonds_db <- tbl(con, sql("SELECT * FROM diamonds"))
```
:::

Este objeto es **perezoso**; cuando usa verbos dplyr en él, dplyr no hace ningún trabajo: solo registra la secuencia de operaciones que desea realizar y solo las realiza cuando es necesario.
Por ejemplo, tome la siguiente canalización:

```{r}
big_diamonds_db <- diamonds_db |> 
  filter(price > 15000) |> 
  select(carat:clarity, price)

big_diamonds_db
```

Puede decir que este objeto representa una consulta de base de datos porque imprime el nombre de DBMS en la parte superior y, aunque le dice el número de columnas, normalmente no sabe el número de filas.
Esto se debe a que encontrar el número total de filas generalmente requiere ejecutar la consulta completa, algo que estamos tratando de evitar.

Puede ver el código SQL generado por la función dbplyr `show_query()`.
Si conoce dplyr, ¡esta es una excelente manera de aprender SQL!
Escriba algo de código dplyr, obtenga dbplyr para traducirlo a SQL y luego intente averiguar cómo coinciden los dos idiomas.

```{r}
big_diamonds_db |>
  show_query()
```

Para recuperar todos los datos en R, llama a `collect()`.
Detrás de escena, esto genera el SQL, llama a `dbGetQuery()` para obtener los datos, luego convierte el resultado en un tibble:

```{r}
big_diamonds <- big_diamonds_db |> 
  collect()
big_diamonds
```

Por lo general, usará dbplyr para seleccionar los datos que desea de la base de datos, realizando filtrado y agregación básicos utilizando las traducciones que se describen a continuación.
Luego, una vez que esté listo para analizar los datos con funciones que son exclusivas de R, `collect()` los datos para obtener un tibble en memoria y continuar su trabajo con código R puro.

## SQL

El resto del capítulo le enseñará un poco de SQL a través de la lente de dbplyr.
Es una introducción bastante no tradicional a SQL, pero esperamos que lo ponga rápidamente al día con los conceptos básicos.
Afortunadamente, si entiende dplyr, está en un buen lugar para aprender SQL rápidamente porque muchos de los conceptos son los mismos.

Exploraremos la relación entre dplyr y SQL usando un par de viejos amigos del paquete nycflights13: `flights` y `planes`.
Estos conjuntos de datos son fáciles de ingresar a nuestra base de datos de aprendizaje porque dbplyr viene con una función que copia las tablas de nycflights13 a nuestra base de datos:

```{r}
dbplyr::copy_nycflights13(con)
flights <- tbl(con, "flights")
planes <- tbl(con, "planes")
```

```{r}
#| echo: false
options(dplyr.strict_sql = TRUE)
```

### SQL básico

Los componentes de nivel superior de SQL se denominan **declaraciones**.
Las declaraciones comunes incluyen `CREATE` para definir nuevas tablas, `INSERT` para agregar datos y `SELECT` para recuperar datos.
Nos centraremos en las declaraciones `SELECT`, también llamadas **consultas**, porque son casi exclusivamente lo que usará como científico de datos.

Una consulta se compone de **cláusulas**.
Hay cinco cláusulas importantes: `SELECT`, `FROM`, `WHERE`, `ORDER BY` y `GROUP BY`. Cada consulta debe tener las cláusulas `SELECT`[^databases-4] y `FROM`[^databases-5] y la consulta más simple es `SELECT * FROM table`, que selecciona todas las columnas de la tabla especificada
. Esto es lo que genera dbplyr para una tabla sin adulterar
:

[^databases-4]: De manera confusa, según el contexto, `SELECT` es una declaración o una cláusula.
    Para evitar esta confusión, generalmente usaremos la consulta en lugar de la instrucción `SELECT`.

[^databases-5]: Ok, técnicamente, solo se requiere `SELECT`, ya que puedes escribir consultas como `SELECT 1+1` para realizar cálculos básicos.
    Pero si quieres trabajar con datos (¡como siempre lo haces!) también necesitarás una cláusula `FROM`.

```{r}
flights |> show_query()
planes |> show_query()
```

`WHERE` y `ORDER BY` controlan qué filas se incluyen y cómo se ordenan:

```{r}
flights |> 
  filter(dest == "IAH") |> 
  arrange(dep_delay) |>
  show_query()
```

`GROUP BY` convierte la consulta en un resumen, lo que hace que se produzca la agregación:

```{r}
flights |> 
  group_by(dest) |> 
  summarize(dep_delay = mean(dep_delay, na.rm = TRUE)) |> 
  show_query()
```

Hay dos diferencias importantes entre los verbos dplyr y las cláusulas SELECT:

-   En SQL, el caso no importa: puede escribir `select`, `SELECT` o incluso `SeLeCt`. En este libro nos apegaremos a la convención común de escribir palabras clave de SQL en mayúsculas para distinguirlas de los nombres de tablas o variables.
-   En SQL, el orden importa: siempre debe escribir las cláusulas en el orden `SELECT`, `FROM`, `WHERE`, `GROUP BY`, `ORDER BY`. De manera confusa, este orden no coincide con la evaluación real de las cláusulas, que es primero `FROM`, luego `WHERE`, `GROUP BY`, `SELECT` y `ORDER BY`.

Las siguientes secciones exploran cada cláusula con más detalle.

::: callout-note
Tenga en cuenta que, si bien SQL es un estándar, es extremadamente complejo y ninguna base de datos lo sigue exactamente.
Si bien los componentes principales en los que nos centraremos en este libro son muy similares entre los DBMS, existen muchas variaciones menores.
Afortunadamente, dbplyr está diseñado para manejar este problema y genera diferentes traducciones para diferentes bases de datos.
No es perfecto, pero está mejorando continuamente, y si encuentra un problema, puede presentar un problema [en GitHub](https://github.com/tidyverse/dbplyr/issues/) para ayudarnos a hacerlo mejor.
:::

### SELECT

The `SELECT` clause is the workhorse of queries and performs the same job as `select()`, `mutate()`, `rename()`, `relocate()`, and, as you'll learn in the next section, `summarize()`.

`select()`, `rename()`, and `relocate()` have very direct translations to `SELECT` as they just affect where a column appears (if at all) along with its name:

```{r}
planes |> 
  select(tailnum, type, manufacturer, model, year) |> 
  show_query()

planes |> 
  select(tailnum, type, manufacturer, model, year) |> 
  rename(year_built = year) |> 
  show_query()

planes |> 
  select(tailnum, type, manufacturer, model, year) |> 
  relocate(manufacturer, model, .before = type) |> 
  show_query()
```

This example also shows you how SQL does renaming.
In SQL terminology renaming is called **aliasing** and is done with `AS`.
Note that unlike `mutate()`, the old name is on the left and the new name is on the right.

::: callout-note
In the examples above note that `"year"` and `"type"` are wrapped in double quotes.
That's because these are **reserved words** in duckdb, so dbplyr quotes them to avoid any potential confusion between column/table names and SQL operators.

When working with other databases you're likely to see every variable name quotes because only a handful of client packages, like duckdb, know what all the reserved words are, so they quote everything to be safe.

``` sql
SELECT "tailnum", "type", "manufacturer", "model", "year"
FROM "planes"
```

Some other database systems use backticks instead of quotes:

``` sql
SELECT `tailnum`, `type`, `manufacturer`, `model`, `year`
FROM `planes`
```
:::

The translations for `mutate()` are similarly straightforward: each variable becomes a new expression in `SELECT`:

```{r}
flights |> 
  mutate(
    speed = distance / (air_time / 60)
  ) |> 
  show_query()
```

We'll come back to the translation of individual components (like `/`) in @sec-sql-expressions.

### FROM

The `FROM` clause defines the data source.
It's going to be rather uninteresting for a little while, because we're just using single tables.
You'll see more complex examples once we hit the join functions.

### GROUP BY

`group_by()` is translated to the `GROUP BY`[^databases-6] clause and `summarize()` is translated to the `SELECT` clause:

[^databases-6]: This is no coincidence: the dplyr function name was inspired by the SQL clause.

```{r}
diamonds_db |> 
  group_by(cut) |> 
  summarize(
    n = n(),
    avg_price = mean(price, na.rm = TRUE)
  ) |> 
  show_query()
```

We'll come back to what's happening with translation `n()` and `mean()` in @sec-sql-expressions.

### WHERE

`filter()` is translated to the `WHERE` clause:

```{r}
flights |> 
  filter(dest == "IAH" | dest == "HOU") |> 
  show_query()

flights |> 
  filter(arr_delay > 0 & arr_delay < 20) |> 
  show_query()
```

There are a few important details to note here:

-   `|` becomes `OR` and `&` becomes `AND`.
-   SQL uses `=` for comparison, not `==`. SQL doesn't have assignment, so there's no potential for confusion there.
-   SQL uses only `''` for strings, not `""`. In SQL, `""` is used to identify variables, like R's ``` `` ```.

Another useful SQL operator is `IN`, which is very close to R's `%in%`:

```{r}
flights |> 
  filter(dest %in% c("IAH", "HOU")) |> 
  show_query()
```

SQL uses `NULL` instead of `NA`.
`NULL`s behave similarly to `NA`s.
The main difference is that while they're "infectious" in comparisons and arithmetic, they are silently dropped when summarizing.
dbplyr will remind you about this behavior the first time you hit it:

```{r}
flights |> 
  group_by(dest) |> 
  summarize(delay = mean(arr_delay))
```

If you want to learn more about how NULLs work, you might enjoy "[*Three valued logic*](https://modern-sql.com/concept/three-valued-logic)" by Markus Winand.

In general, you can work with `NULL`s using the functions you'd use for `NA`s in R:

```{r}
flights |> 
  filter(!is.na(dep_delay)) |> 
  show_query()
```

This SQL query illustrates one of the drawbacks of dbplyr: while the SQL is correct, it isn't as simple as you might write by hand.
In this case, you could drop the parentheses and use a special operator that's easier to read:

``` sql
WHERE "dep_delay" IS NOT NULL
```

Note that if you `filter()` a variable that you created using a summarize, dbplyr will generate a `HAVING` clause, rather than a `WHERE` clause.
This is a one of the idiosyncrasies of SQL: `WHERE` is evaluated before `SELECT` and `GROUP BY`, so SQL needs another clause that's evaluated afterwards.

```{r}
diamonds_db |> 
  group_by(cut) |> 
  summarize(n = n()) |> 
  filter(n > 100) |> 
  show_query()
```

### ORDER BY

Ordering rows involves a straightforward translation from `arrange()` to the `ORDER BY` clause:

```{r}
flights |> 
  arrange(year, month, day, desc(dep_delay)) |> 
  show_query()
```

Notice how `desc()` is translated to `DESC`: this is one of the many dplyr functions whose name was directly inspired by SQL.

### Subqueries

Sometimes it's not possible to translate a dplyr pipeline into a single `SELECT` statement and you need to use a subquery.
A **subquery** is just a query used as a data source in the `FROM` clause, instead of the usual table.

dbplyr typically uses subqueries to work around limitations of SQL.
For example, expressions in the `SELECT` clause can't refer to columns that were just created.
That means that the following (silly) dplyr pipeline needs to happen in two steps: the first (inner) query computes `year1` and then the second (outer) query can compute `year2`.

```{r}
flights |> 
  mutate(
    year1 = year + 1,
    year2 = year1 + 1
  ) |> 
  show_query()
```

You'll also see this if you attempted to `filter()` a variable that you just created.
Remember, even though `WHERE` is written after `SELECT`, it's evaluated before it, so we need a subquery in this (silly) example:

```{r}
flights |> 
  mutate(year1 = year + 1) |> 
  filter(year1 == 2014) |> 
  show_query()
```

Sometimes dbplyr will create a subquery where it's not needed because it doesn't yet know how to optimize that translation.
As dbplyr improves over time, these cases will get rarer but will probably never go away.

### Joins

If you're familiar with dplyr's joins, SQL joins are very similar.
Here's a simple example:

```{r}
flights |> 
  left_join(planes |> rename(year_built = year), by = "tailnum") |> 
  show_query()
```

The main thing to notice here is the syntax: SQL joins use sub-clauses of the `FROM` clause to bring in additional tables, using `ON` to define how the tables are related.

dplyr's names for these functions are so closely connected to SQL that you can easily guess the equivalent SQL for `inner_join()`, `right_join()`, and `full_join()`:

``` sql
SELECT flights.*, "type", manufacturer, model, engines, seats, speed
FROM flights
INNER JOIN planes ON (flights.tailnum = planes.tailnum)

SELECT flights.*, "type", manufacturer, model, engines, seats, speed
FROM flights
RIGHT JOIN planes ON (flights.tailnum = planes.tailnum)

SELECT flights.*, "type", manufacturer, model, engines, seats, speed
FROM flights
FULL JOIN planes ON (flights.tailnum = planes.tailnum)
```

You're likely to need many joins when working with data from a database.
That's because database tables are often stored in a highly normalized form, where each "fact" is stored in a single place and to keep a complete dataset for analysis you need to navigate a complex network of tables connected by primary and foreign keys.
If you hit this scenario, the [dm package](https://cynkra.github.io/dm/), by Tobias Schieferdecker, Kirill Müller, and Darko Bergant, is a life saver.
It can automatically determine the connections between tables using the constraints that DBAs often supply, visualize the connections so you can see what's going on, and generate the joins you need to connect one table to another.

### Other verbs

dbplyr also translates other verbs like `distinct()`, `slice_*()`, and `intersect()`, and a growing selection of tidyr functions like `pivot_longer()` and `pivot_wider()`.
The easiest way to see the full set of what's currently available is to visit the dbplyr website: <https://dbplyr.tidyverse.org/reference/>.

### Exercises

1.  What is `distinct()` translated to?
    How about `head()`?

2.  Explain what each of the following SQL queries do and try recreate them using dbplyr.

    ``` sql
    SELECT * 
    FROM flights
    WHERE dep_delay < arr_delay

    SELECT *, distance / (airtime / 60) AS speed
    FROM flights
    ```

## Function translations {#sec-sql-expressions}

So far we've focused on the big picture of how dplyr verbs are translated to the clauses of a query.
Now we're going to zoom in a little and talk about the translation of the R functions that work with individual columns, e.g. what happens when you use `mean(x)` in a `summarize()`?

To help see what's going on, we'll use a couple of little helper functions that run a `summarize()` or `mutate()` and show the generated SQL.
That will make it a little easier to explore a few variations and see how summaries and transformations can differ.

```{r}
summarize_query <- function(df, ...) {
  df |> 
    summarize(...) |> 
    show_query()
}
mutate_query <- function(df, ...) {
  df |> 
    mutate(..., .keep = "none") |> 
    show_query()
}
```

Let's dive in with some summaries!
Looking at the code below you'll notice that some summary functions, like `mean()`, have a relatively simple translation while others, like `median()`, are much more complex.
The complexity is typically higher for operations that are common in statistics but less common in databases.

```{r}
flights |> 
  group_by(year, month, day) |>  
  summarize_query(
    mean = mean(arr_delay, na.rm = TRUE),
    median = median(arr_delay, na.rm = TRUE)
  )
```

The translation of summary functions becomes more complicated when you use them inside a `mutate()` because they have to turn into so-called **window** functions.
In SQL, you turn an ordinary aggregation function into a window function by adding `OVER` after it:

```{r}
flights |> 
  group_by(year, month, day) |>  
  mutate_query(
    mean = mean(arr_delay, na.rm = TRUE),
  )
```

In SQL, the `GROUP BY` clause is used exclusively for summaries so here you can see that the grouping has moved to the `PARTITION BY` argument to `OVER`.

Window functions include all functions that look forward or backwards, like `lead()` and `lag()` which look at the "previous" or "next" value respectively:

```{r}
flights |> 
  group_by(dest) |>  
  arrange(time_hour) |> 
  mutate_query(
    lead = lead(arr_delay),
    lag = lag(arr_delay)
  )
```

Here it's important to `arrange()` the data, because SQL tables have no intrinsic order.
In fact, if you don't use `arrange()` you might get the rows back in a different order every time!
Notice for window functions, the ordering information is repeated: the `ORDER BY` clause of the main query doesn't automatically apply to window functions.

Another important SQL function is `CASE WHEN`. It's used as the translation of `if_else()` and `case_when()`, the dplyr function that it directly inspired.
Here are a couple of simple examples:

```{r}
flights |> 
  mutate_query(
    description = if_else(arr_delay > 0, "delayed", "on-time")
  )
flights |> 
  mutate_query(
    description = 
      case_when(
        arr_delay < -5 ~ "early", 
        arr_delay < 5 ~ "on-time",
        arr_delay >= 5 ~ "late"
      )
  )
```

`CASE WHEN` is also used for some other functions that don't have a direct translation from R to SQL.
A good example of this is `cut()`:

```{r}
flights |> 
  mutate_query(
    description =  cut(
      arr_delay, 
      breaks = c(-Inf, -5, 5, Inf), 
      labels = c("early", "on-time", "late")
    )
  )
```

dbplyr also translates common string and date-time manipulation functions, which you can learn about in `vignette("translation-function", package = "dbplyr")`.
dbplyr's translations are certainly not perfect, and there are many R functions that aren't translated yet, but dbplyr does a surprisingly good job covering the functions that you'll use most of the time.

## Summary

In this chapter you learned how to access data from databases.
We focused on dbplyr, a dplyr "backend" that allows you to write the dplyr code you're familiar with, and have it be automatically translated to SQL.
We used that translation to teach you a little SQL; it's important to learn some SQL because it's *the* most commonly used language for working with data and knowing some will it easier for you to communicate with other data folks who don't use R.
If you've finished this chapter and would like to learn more about SQL.
We have two recommendations:

-   [*SQL for Data Scientists*](https://sqlfordatascientists.com) by Renée M. P. Teate is an introduction to SQL designed specifically for the needs of data scientists, and includes examples of the sort of highly interconnected data you're likely to encounter in real organizations.
-   [*Practical SQL*](https://www.practicalsql.com) by Anthony DeBarros is written from the perspective of a data journalist (a data scientist specialized in telling compelling stories) and goes into more detail about getting your data into a database and running your own DBMS.

In the next chapter, we'll learn about another dplyr backend for working with large data: arrow.
Arrow is designed for working with large files on disk, and is a natural complement to databases.
