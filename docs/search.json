[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R para la Ciencia de Datos (2e)",
    "section": "",
    "text": "Bienvenida\nEste es el sitio web de la segunda edición de “R para la Ciencia de Datos”. Este libro le enseñará cómo hacer ciencia de datos con R: aprenderá cómo obtener sus datos en R, convertirlos en la estructura más útil, transformarlos y visualizarlos.\nEn este libro, encontrará ejercicios prácticos para aprender las habilidades necesarias para la ciencia de datos. Así como un químico aprende a limpiar tubos de ensayo y a abastecer un laboratorio, usted aprenderá a limpiar datos, dibujar diagramas y mucho más. Estas son las habilidades que hacen que exista la ciencia de datos y aquí encontrará las mejores prácticas para realizar estas tareas con R. Aprenderá a usar la gramática de los gráficos, la programación literaria y la investigación reproducible para ahorrar tiempo. También aprenderá a administrar los recursos cognitivos para facilitar los descubrimientos al discutir, visualizar y explorar datos.\nEste sitio web es y será siempre gratuito, bajo la licencia de CC BY-NC-ND 3.0 License. Si desea una copia física del libro, puede pedir una en Amazon. Si aprecia leer el libro gratis y desea retribuir, haga una donación a Kākāpō Recovery: el kākāpō (que aparece en la portada de R4DS) es un loro nativo de Nueva Zelanda en peligro de extinsión; solo quedan 248.\nSi habla otro idioma es posible que le interesen las traducciones disponibles gratuitamente de la primera edición:\nPuede encontrar respuestas sugeridas a los ejercicios en el libro en https://mine-cetinkaya-rundel.github.io/r4ds-solutions.\nTenga en cuenta que R4DS utiliza un Código de conducta del colaborador. Al contribuir a este libro, usted acepta cumplir con sus términos.",
    "crumbs": [
      "Bienvenida"
    ]
  },
  {
    "objectID": "index.html#acknowledgements",
    "href": "index.html#acknowledgements",
    "title": "R for Data Science (2e)",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nR4DS is hosted by https://www.netlify.com as part of their support of open source software and communities."
  },
  {
    "objectID": "index.html#agradecimientos",
    "href": "index.html#agradecimientos",
    "title": "R para la Ciencia de Datos (2e)",
    "section": "Agradecimientos",
    "text": "Agradecimientos\nR4DS está alojado por https://www.netlify.com como parte de su apoyo a las comunidades y el software de código abierto.",
    "crumbs": [
      "Bienvenida"
    ]
  },
  {
    "objectID": "whole-game.html",
    "href": "whole-game.html",
    "title": "El Juego Completo",
    "section": "",
    "text": "Nuestro objetivo en esta parte del libro es brindarle una descripción general rápida de las principales herramientas de la ciencia de datos: importar, ordenar, transformar y visualizar datos, así como se muestra en Figure 1. Queremos mostrarle el “juego completo” de la ciencia de datos brindándole lo suficiente de todas las piezas principales para que pueda abordar conjuntos de datos reales, aunque simples. Las últimas partes del libro abordarán cada uno de estos temas con mayor profundidad, aumentando la gama de desafíos de la ciencia de datos que puede abordar.\n\n\n\n\nFigure 1: En esta sección del libro, aprenderá a importar, ordenar, transformar y visualizar datos.\n\n\n\n\nCinco capítulos se centran en las herramientas de la ciencia de datos:\n\nLa visualización es un excelente lugar para comenzar con la programación en R, porque la recompensa es muy clara: puedes hacer diagramas elegantes e informativos que te ayuden a comprender los datos. En Chapter 2, se sumergirá en la visualización, aprenderá la estructura básica de un gráfico ggplot2 y técnicas poderosas para convertir datos en gráficos.\nPor lo general, la visualización por sí sola no es suficiente, por lo que en Chapter 4, aprenderá los verbos clave que le permiten seleccionar variables importantes, filtrar observaciones clave, crear nuevas variables y calcular resúmenes.\nEn Chapter 6, aprenderá sobre los datos ordenados, una forma consistente de almacenar sus datos que facilita la transformación, la visualización y el modelado. Aprenderá los principios subyacentes y cómo poner sus datos en una forma ordenada.\nAntes de que pueda transformar y visualizar sus datos, primero debe obtener sus datos en R. En Chapter 8 aprenderá los conceptos básicos para obtener archivos .csv en R.\n\nEntre estos capítulos se encuentran otros cuatro capítulos que se centran en su flujo de trabajo de R. En Chapter 3, Chapter 5 y Chapter 7 aprenderá buenas prácticas de flujo de trabajo para escribir y organizar su código R. Estos te prepararán para el éxito a largo plazo, ya que te darán las herramientas para mantenerte organizado cuando abordes proyectos reales. Finalmente, Chapter 9 le enseñará cómo obtener ayuda y seguir aprendiendo."
  },
  {
    "objectID": "EDA.html#introduction",
    "href": "EDA.html#introduction",
    "title": "12  Exploratory data analysis",
    "section": "\n12.1 Introduction",
    "text": "12.1 Introduction\nThis chapter will show you how to use visualization and transformation to explore your data in a systematic way, a task that statisticians call exploratory data analysis, or EDA for short. EDA is an iterative cycle. You:\n\nGenerate questions about your data.\nSearch for answers by visualizing, transforming, and modelling your data.\nUse what you learn to refine your questions and/or generate new questions.\n\nEDA is not a formal process with a strict set of rules. More than anything, EDA is a state of mind. During the initial phases of EDA you should feel free to investigate every idea that occurs to you. Some of these ideas will pan out, and some will be dead ends. As your exploration continues, you will home in on a few particularly productive areas that you’ll eventually write up and communicate to others.\nEDA is an important part of any data analysis, even if the questions are handed to you on a platter, because you always need to investigate the quality of your data. Data cleaning is just one application of EDA: you ask questions about whether your data meets your expectations or not. To do data cleaning, you’ll need to deploy all the tools of EDA: visualization, transformation, and modelling.\n\n12.1.1 Prerequisites\nIn this chapter we’ll combine what you’ve learned about dplyr and ggplot2 to interactively ask questions, answer them with data, and then ask new questions.\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "EDA.html#questions",
    "href": "EDA.html#questions",
    "title": "12  Exploratory data analysis",
    "section": "\n12.2 Questions",
    "text": "12.2 Questions\n\n“There are no routine statistical questions, only questionable statistical routines.” — Sir David Cox\n\n\n“Far better an approximate answer to the right question, which is often vague, than an exact answer to the wrong question, which can always be made precise.” — John Tukey\n\nYour goal during EDA is to develop an understanding of your data. The easiest way to do this is to use questions as tools to guide your investigation. When you ask a question, the question focuses your attention on a specific part of your dataset and helps you decide which graphs, models, or transformations to make.\nEDA is fundamentally a creative process. And like most creative processes, the key to asking quality questions is to generate a large quantity of questions. It is difficult to ask revealing questions at the start of your analysis because you do not know what insights can be gleaned from your dataset. On the other hand, each new question that you ask will expose you to a new aspect of your data and increase your chance of making a discovery. You can quickly drill down into the most interesting parts of your data—and develop a set of thought-provoking questions—if you follow up each question with a new question based on what you find.\nThere is no rule about which questions you should ask to guide your research. However, two types of questions will always be useful for making discoveries within your data. You can loosely word these questions as:\n\nWhat type of variation occurs within my variables?\nWhat type of covariation occurs between my variables?\n\nThe rest of this chapter will look at these two questions. We’ll explain what variation and covariation are, and we’ll show you several ways to answer each question. To make the discussion easier, let’s define some terms:\n\nA variable is a quantity, quality, or property that you can measure.\nA value is the state of a variable when you measure it. The value of a variable may change from measurement to measurement.\nAn observation is a set of measurements made under similar conditions (you usually make all of the measurements in an observation at the same time and on the same object). An observation will contain several values, each associated with a different variable. We’ll sometimes refer to an observation as a data point.\nTabular data is a set of values, each associated with a variable and an observation. Tabular data is tidy if each value is placed in its own “cell”, each variable in its own column, and each observation in its own row.\n\nSo far, all of the data that you’ve seen has been tidy. In real-life, most data isn’t tidy, so we’ll come back to these ideas again in ?sec-rectangling."
  },
  {
    "objectID": "EDA.html#variation",
    "href": "EDA.html#variation",
    "title": "12  Exploratory data analysis",
    "section": "\n12.3 Variation",
    "text": "12.3 Variation\nVariation is the tendency of the values of a variable to change from measurement to measurement. You can see variation easily in real life; if you measure any continuous variable twice, you will get two different results. This is true even if you measure quantities that are constant, like the speed of light. Each of your measurements will include a small amount of error that varies from measurement to measurement. Variables can also vary if you measure across different subjects (e.g. the eye colors of different people) or different times (e.g. the energy levels of an electron at different moments). Every variable has its own pattern of variation, which can reveal interesting information about how that variable varies between measurements on the same observation as well as across observations. The best way to understand that pattern is to visualize the distribution of the variable’s values, which you’ve learned about in Chapter 2.\nWe’ll start our exploration by visualizing the distribution of weights (carat) of ~54,000 diamonds from the diamonds dataset. Since carat is a numerical variable, we can use a histogram:\n\nggplot(diamonds, aes(x = carat)) +\n  geom_histogram(binwidth = 0.5)\n\n\n\n\nNow that you can visualize variation, what should you look for in your plots? And what type of follow-up questions should you ask? We’ve put together a list below of the most useful types of information that you will find in your graphs, along with some follow-up questions for each type of information. The key to asking good follow-up questions will be to rely on your curiosity (What do you want to learn more about?) as well as your skepticism (How could this be misleading?).\n\n12.3.1 Typical values\nIn both bar charts and histograms, tall bars show the common values of a variable, and shorter bars show less-common values. Places that do not have bars reveal values that were not seen in your data. To turn this information into useful questions, look for anything unexpected:\n\nWhich values are the most common? Why?\nWhich values are rare? Why? Does that match your expectations?\nCan you see any unusual patterns? What might explain them?\n\nAs an example, the histogram below suggests several interesting questions:\n\nWhy are there more diamonds at whole carats and common fractions of carats?\nWhy are there more diamonds slightly to the right of each peak than there are slightly to the left of each peak?\n\n\nsmaller <- diamonds |> \n  filter(carat < 3)\n\nggplot(smaller, aes(x = carat)) +\n  geom_histogram(binwidth = 0.01)\n\n\n\n\nClusters of similar values suggest that subgroups exist in your data. To understand the subgroups, ask:\n\nHow are the observations within each cluster similar to each other?\nHow are the observations in separate clusters different from each other?\nHow can you explain or describe the clusters?\nWhy might the appearance of clusters be misleading?\n\nThe histogram below shows the length (in minutes) of 272 eruptions of the Old Faithful Geyser in Yellowstone National Park. Eruption times appear to be clustered into two groups: there are short eruptions (of around 2 minutes) and long eruptions (4-5 minutes), but little in between.\n\nggplot(faithful, aes(x = eruptions)) + \n  geom_histogram(binwidth = 0.25)\n\n\n\n\nMany of the questions above will prompt you to explore a relationship between variables, for example, to see if the values of one variable can explain the behavior of another variable. We’ll get to that shortly.\n\n12.3.2 Unusual values\nOutliers are observations that are unusual; data points that don’t seem to fit the pattern. Sometimes outliers are data entry errors; other times outliers suggest important new science. When you have a lot of data, outliers are sometimes difficult to see in a histogram. For example, take the distribution of the y variable from the diamonds dataset. The only evidence of outliers is the unusually wide limits on the x-axis.\n\nggplot(diamonds, aes(x = y)) + \n  geom_histogram(binwidth = 0.5)\n\n\n\n\nThere are so many observations in the common bins that the rare bins are very short, making it very difficult to see them (although maybe if you stare intently at 0 you’ll spot something). To make it easy to see the unusual values, we need to zoom to small values of the y-axis with coord_cartesian():\n\nggplot(diamonds, aes(x = y)) + \n  geom_histogram(binwidth = 0.5) +\n  coord_cartesian(ylim = c(0, 50))\n\n\n\n\ncoord_cartesian() also has an xlim() argument for when you need to zoom into the x-axis. ggplot2 also has xlim() and ylim() functions that work slightly differently: they throw away the data outside the limits.\nThis allows us to see that there are three unusual values: 0, ~30, and ~60. We pluck them out with dplyr:\n\nunusual <- diamonds |> \n  filter(y < 3 | y > 20) |> \n  select(price, x, y, z) |>\n  arrange(y)\nunusual\n#> # A tibble: 9 × 4\n#>   price     x     y     z\n#>   <int> <dbl> <dbl> <dbl>\n#> 1  5139  0      0    0   \n#> 2  6381  0      0    0   \n#> 3 12800  0      0    0   \n#> 4 15686  0      0    0   \n#> 5 18034  0      0    0   \n#> 6  2130  0      0    0   \n#> 7  2130  0      0    0   \n#> 8  2075  5.15  31.8  5.12\n#> 9 12210  8.09  58.9  8.06\n\nThe y variable measures one of the three dimensions of these diamonds, in mm. We know that diamonds can’t have a width of 0mm, so these values must be incorrect. We might also suspect that measurements of 32mm and 59mm are implausible: those diamonds are over an inch long, but don’t cost hundreds of thousands of dollars!\nIt’s good practice to repeat your analysis with and without the outliers. If they have minimal effect on the results, and you can’t figure out why they’re there, it’s reasonable to omit them, and move on. However, if they have a substantial effect on your results, you shouldn’t drop them without justification. You’ll need to figure out what caused them (e.g. a data entry error) and disclose that you removed them in your write-up.\n\n12.3.3 Exercises\n\nExplore the distribution of each of the x, y, and z variables in diamonds. What do you learn? Think about a diamond and how you might decide which dimension is the length, width, and depth.\nExplore the distribution of price. Do you discover anything unusual or surprising? (Hint: Carefully think about the binwidth and make sure you try a wide range of values.)\nHow many diamonds are 0.99 carat? How many are 1 carat? What do you think is the cause of the difference?\nCompare and contrast coord_cartesian() vs. xlim() or ylim() when zooming in on a histogram. What happens if you leave binwidth unset? What happens if you try and zoom so only half a bar shows?"
  },
  {
    "objectID": "EDA.html#sec-missing-values-eda",
    "href": "EDA.html#sec-missing-values-eda",
    "title": "12  Exploratory data analysis",
    "section": "\n12.4 Unusual values",
    "text": "12.4 Unusual values\nIf you’ve encountered unusual values in your dataset, and simply want to move on to the rest of your analysis, you have two options.\n\n\nDrop the entire row with the strange values:\n\ndiamonds2 <- diamonds |> \n  filter(between(y, 3, 20))\n\nWe don’t recommend this option because just because one measurement is invalid, doesn’t mean all the measurements are. Additionally, if you have low quality data, by time that you’ve applied this approach to every variable you might find that you don’t have any data left!\n\n\nInstead, we recommend replacing the unusual values with missing values. The easiest way to do this is to use mutate() to replace the variable with a modified copy. You can use the if_else() function to replace unusual values with NA:\n\ndiamonds2 <- diamonds |> \n  mutate(y = ifelse(y < 3 | y > 20, NA, y))\n\n\n\nif_else() has three arguments. The first argument test should be a logical vector. The result will contain the value of the second argument, yes, when test is TRUE, and the value of the third argument, no, when it is false. Alternatively to if_else(), use case_when(). case_when() is particularly useful inside mutate when you want to create a new variable that relies on a complex combination of existing variables or would otherwise require multiple if_else() statements nested inside one another. You will learn more about logical vectors in ?sec-logicals.\nIt’s not obvious where you should plot missing values, so ggplot2 doesn’t include them in the plot, but it does warn that they’ve been removed:\n\nggplot(diamonds2, aes(x = x, y = y)) + \n  geom_point()\n#> Warning: Removed 9 rows containing missing values (`geom_point()`).\n\n\n\n\nTo suppress that warning, set na.rm = TRUE:\n\nggplot(diamonds2, aes(x = x, y = y)) + \n  geom_point(na.rm = TRUE)\n\nOther times you want to understand what makes observations with missing values different to observations with recorded values. For example, in nycflights13::flights1, missing values in the dep_time variable indicate that the flight was cancelled. So you might want to compare the scheduled departure times for cancelled and non-cancelled times. You can do this by making a new variable with is.na().\n\nnycflights13::flights |> \n  mutate(\n    cancelled = is.na(dep_time),\n    sched_hour = sched_dep_time %/% 100,\n    sched_min = sched_dep_time %% 100,\n    sched_dep_time = sched_hour + (sched_min / 60)\n  ) |> \n  ggplot(aes(x = sched_dep_time)) + \n  geom_freqpoly(aes(color = cancelled), binwidth = 1/4)\n\n\n\n\nHowever this plot isn’t great because there are many more non-cancelled flights than cancelled flights. In the next section we’ll explore some techniques for improving this comparison.\n\n12.4.1 Exercises\n\nWhat happens to missing values in a histogram? What happens to missing values in a bar chart? Why is there a difference in how missing values are handled in histograms and bar charts?\nWhat does na.rm = TRUE do in mean() and sum()?"
  },
  {
    "objectID": "EDA.html#covariation",
    "href": "EDA.html#covariation",
    "title": "12  Exploratory data analysis",
    "section": "\n12.5 Covariation",
    "text": "12.5 Covariation\nIf variation describes the behavior within a variable, covariation describes the behavior between variables. Covariation is the tendency for the values of two or more variables to vary together in a related way. The best way to spot covariation is to visualize the relationship between two or more variables.\n\n12.5.1 A categorical and a numerical variable\nFor example, let’s explore how the price of a diamond varies with its quality (measured by cut) using geom_freqpoly():\n\nggplot(diamonds, aes(x = price)) + \n  geom_freqpoly(aes(color = cut), binwidth = 500, linewidth = 0.75)\n\n\n\n\nThe default appearance of geom_freqpoly() is not that useful for that sort of comparison because the height is given by the count and the overall counts of cut in differ so much, making it hard to see the differences in the shapes of their distributions:\n\nggplot(diamonds, aes(x = cut)) + \n  geom_bar()\n\n\n\n\nTo make the comparison easier we need to swap what is displayed on the y-axis. Instead of displaying count, we’ll display the density, which is the count standardized so that the area under each frequency polygon is one.\n\nggplot(diamonds, aes(x = price, y = after_stat(density))) + \n  geom_freqpoly(aes(color = cut), binwidth = 500, linewidth = 0.75)\n\n\n\n\nNote that we’re mapping the density the y, but since density is not a variable in the diamonds dataset, we need to first calculate it. We use the after_stat() function to do so.\nThere’s something rather surprising about this plot - it appears that fair diamonds (the lowest quality) have the highest average price! But maybe that’s because frequency polygons are a little hard to interpret - there’s a lot going on in this plot.\nA visually simpler plot for exploring this relationship is using side-by-side boxplots.\n\nggplot(diamonds, aes(x = cut, y = price)) +\n  geom_boxplot()\n\n\n\n\nWe see much less information about the distribution, but the boxplots are much more compact so we can more easily compare them (and fit more on one plot). It supports the counter-intuitive finding that better quality diamonds are cheaper on average! In the exercises, you’ll be challenged to figure out why.\ncut is an ordered factor: fair is worse than good, which is worse than very good and so on. Many categorical variables don’t have such an intrinsic order, so you might want to reorder them to make a more informative display. One way to do that is with the fct_reorder() function.\nFor example, take the class variable in the mpg dataset. You might be interested to know how highway mileage varies across classes:\n\nggplot(mpg, aes(x = class, y = hwy)) +\n  geom_boxplot()\n\n\n\n\nTo make the trend easier to see, we can reorder class based on the median value of hwy:\n\nggplot(mpg,\n       aes(x = fct_reorder(class, hwy, median), y = hwy)) +\n  geom_boxplot()\n\n\n\n\nIf you have long variable names, geom_boxplot() will work better if you flip it 90°. You can do that by exchanging the x and y aesthetic mappings.\n\nggplot(mpg,\n       aes(x = hwy, y = fct_reorder(class, hwy, median))) +\n  geom_boxplot()\n\n\n\n\n\n12.5.1.1 Exercises\n\nUse what you’ve learned to improve the visualization of the departure times of cancelled vs. non-cancelled flights.\nWhat variable in the diamonds dataset is most important for predicting the price of a diamond? How is that variable correlated with cut? Why does the combination of those two relationships lead to lower quality diamonds being more expensive?\nInstead of exchanging the x and y variables, add coord_flip() as a new layer to the vertical boxplot to create a horizontal one. How does this compare to using exchanging the variables?\nOne problem with boxplots is that they were developed in an era of much smaller datasets and tend to display a prohibitively large number of “outlying values”. One approach to remedy this problem is the letter value plot. Install the lvplot package, and try using geom_lv() to display the distribution of price vs. cut. What do you learn? How do you interpret the plots?\nCompare and contrast geom_violin() with a faceted geom_histogram(), or a colored geom_freqpoly(). What are the pros and cons of each method?\nIf you have a small dataset, it’s sometimes useful to use geom_jitter() to see the relationship between a continuous and categorical variable. The ggbeeswarm package provides a number of methods similar to geom_jitter(). List them and briefly describe what each one does.\n\n12.5.2 Two categorical variables\nTo visualize the covariation between categorical variables, you’ll need to count the number of observations for each combination of levels of these categorical variables. One way to do that is to rely on the built-in geom_count():\n\nggplot(diamonds, aes(x = cut, y = color)) +\n  geom_count()\n\n\n\n\nThe size of each circle in the plot displays how many observations occurred at each combination of values. Covariation will appear as a strong correlation between specific x values and specific y values.\nAnother approach for exploring the relationship between these variables is computing the counts with dplyr:\n\ndiamonds |> \n  count(color, cut)\n#> # A tibble: 35 × 3\n#>   color cut           n\n#>   <ord> <ord>     <int>\n#> 1 D     Fair        163\n#> 2 D     Good        662\n#> 3 D     Very Good  1513\n#> 4 D     Premium    1603\n#> 5 D     Ideal      2834\n#> 6 E     Fair        224\n#> # … with 29 more rows\n\nThen visualize with geom_tile() and the fill aesthetic:\n\ndiamonds |> \n  count(color, cut) |>  \n  ggplot(aes(x = color, y = cut)) +\n  geom_tile(aes(fill = n))\n\n\n\n\nIf the categorical variables are unordered, you might want to use the seriation package to simultaneously reorder the rows and columns in order to more clearly reveal interesting patterns. For larger plots, you might want to try the heatmaply package, which creates interactive plots.\n\n12.5.2.1 Exercises\n\nHow could you rescale the count dataset above to more clearly show the distribution of cut within color, or color within cut?\nHow does the segmented bar chart change if color is mapped to the x aesthetic and cut is mapped to the fill aesthetic? Calculate the counts that fall into each of the segments.\nUse geom_tile() together with dplyr to explore how average flight delays vary by destination and month of year. What makes the plot difficult to read? How could you improve it?\nWhy is it slightly better to use aes(x = color, y = cut) rather than aes(x = cut, y = color) in the example above?\n\n12.5.3 Two numerical variables\nYou’ve already seen one great way to visualize the covariation between two numerical variables: draw a scatterplot with geom_point(). You can see covariation as a pattern in the points. For example, you can see an exponential relationship between the carat size and price of a diamond.\n\nggplot(diamonds, aes(x = carat, y = price)) +\n  geom_point()\n\n\n\n\nScatterplots become less useful as the size of your dataset grows, because points begin to overplot, and pile up into areas of uniform black (as above). You’ve already seen one way to fix the problem: using the alpha aesthetic to add transparency.\n\nggplot(diamonds, aes(x = carat, y = price)) + \n  geom_point(alpha = 1 / 100)\n\n\n\n\nBut using transparency can be challenging for very large datasets. Another solution is to use bin. Previously you used geom_histogram() and geom_freqpoly() to bin in one dimension. Now you’ll learn how to use geom_bin2d() and geom_hex() to bin in two dimensions.\ngeom_bin2d() and geom_hex() divide the coordinate plane into 2d bins and then use a fill color to display how many points fall into each bin. geom_bin2d() creates rectangular bins. geom_hex() creates hexagonal bins. You will need to install the hexbin package to use geom_hex().\n\nggplot(smaller, aes(x = carat, y = price)) +\n  geom_bin2d()\n\n# install.packages(\"hexbin\")\nggplot(smaller, aes(x = carat, y = price)) +\n  geom_hex()\n\n\n\n\nAnother option is to bin one continuous variable so it acts like a categorical variable. Then you can use one of the techniques for visualizing the combination of a categorical and a continuous variable that you learned about. For example, you could bin carat and then for each group, display a boxplot:\n\nggplot(smaller, aes(x = carat, y = price)) + \n  geom_boxplot(aes(group = cut_width(carat, 0.1)))\n\n\n\n\ncut_width(x, width), as used above, divides x into bins of width width. By default, boxplots look roughly the same (apart from number of outliers) regardless of how many observations there are, so it’s difficult to tell that each boxplot summaries a different number of points. One way to show that is to make the width of the boxplot proportional to the number of points with varwidth = TRUE.\nAnother approach is to display approximately the same number of points in each bin. That’s the job of cut_number():\n\nggplot(smaller, aes(x = carat, y = price)) + \n  geom_boxplot(aes(group = cut_number(carat, 20)))\n\n\n\n\n\n12.5.3.1 Exercises\n\nInstead of summarizing the conditional distribution with a boxplot, you could use a frequency polygon. What do you need to consider when using cut_width() vs. cut_number()? How does that impact a visualization of the 2d distribution of carat and price?\nVisualize the distribution of carat, partitioned by price.\nHow does the price distribution of very large diamonds compare to small diamonds? Is it as you expect, or does it surprise you?\nCombine two of the techniques you’ve learned to visualize the combined distribution of cut, carat, and price.\n\nTwo dimensional plots reveal outliers that are not visible in one dimensional plots. For example, some points in the plot below have an unusual combination of x and y values, which makes the points outliers even though their x and y values appear normal when examined separately.\n\nggplot(diamonds, aes(x = x, y = y)) +\n  geom_point() +\n  coord_cartesian(xlim = c(4, 11), ylim = c(4, 11))\n\n\n\n\nWhy is a scatterplot a better display than a binned plot for this case?"
  },
  {
    "objectID": "EDA.html#patterns-and-models",
    "href": "EDA.html#patterns-and-models",
    "title": "12  Exploratory data analysis",
    "section": "\n12.6 Patterns and models",
    "text": "12.6 Patterns and models\nPatterns in your data provide clues about relationships. If a systematic relationship exists between two variables it will appear as a pattern in the data. If you spot a pattern, ask yourself:\n\nCould this pattern be due to coincidence (i.e. random chance)?\nHow can you describe the relationship implied by the pattern?\nHow strong is the relationship implied by the pattern?\nWhat other variables might affect the relationship?\nDoes the relationship change if you look at individual subgroups of the data?\n\nA scatterplot of Old Faithful eruption lengths versus the wait time between eruptions shows a pattern: longer wait times are associated with longer eruptions. The scatterplot also displays the two clusters that we noticed above.\n\nggplot(faithful, aes(x = eruptions, y = waiting)) + \n  geom_point()\n\n\n\n\nPatterns provide one of the most useful tools for data scientists because they reveal covariation. If you think of variation as a phenomenon that creates uncertainty, covariation is a phenomenon that reduces it. If two variables covary, you can use the values of one variable to make better predictions about the values of the second. If the covariation is due to a causal relationship (a special case), then you can use the value of one variable to control the value of the second.\nModels are a tool for extracting patterns out of data. For example, consider the diamonds data. It’s hard to understand the relationship between cut and price, because cut and carat, and carat and price are tightly related. It’s possible to use a model to remove the very strong relationship between price and carat so we can explore the subtleties that remain. The following code fits a model that predicts price from carat and then computes the residuals (the difference between the predicted value and the actual value). The residuals give us a view of the price of the diamond, once the effect of carat has been removed. Note that instead of using the raw values of price and carat, we log transform them first, and fit a model to the log-transformed values. Then, we exponentiate the residuals to put them back in the scale of raw prices.\n\nlibrary(tidymodels)\n\ndiamonds <- diamonds |>\n  mutate(\n    log_price = log(price),\n    log_carat = log(carat)\n  )\n\ndiamonds_fit <- linear_reg() |>\n  fit(log_price ~ log_carat, data = diamonds)\n\ndiamonds_aug <- augment(diamonds_fit, new_data = diamonds) |>\n  mutate(.resid = exp(.resid))\n\nggplot(diamonds_aug, aes(x = carat, y = .resid)) + \n  geom_point()\n\n\n\n\nOnce you’ve removed the strong relationship between carat and price, you can see what you expect in the relationship between cut and price: relative to their size, better quality diamonds are more expensive.\n\nggplot(diamonds_aug, aes(x = cut, y = .resid)) + \n  geom_boxplot()\n\n\n\n\nWe’re not discussing modelling in this book because understanding what models are and how they work is easiest once you have tools of data wrangling and programming in hand."
  },
  {
    "objectID": "EDA.html#summary",
    "href": "EDA.html#summary",
    "title": "12  Exploratory data analysis",
    "section": "\n12.7 Summary",
    "text": "12.7 Summary\nIn this chapter you’ve learned a variety of tools to help you understand the variation within your data. You’ve seen technique that work with a single variable at a time and with a pair of variables. This might seem painful restrictive if you have tens or hundreds of variables in your data, but they’re foundation upon which all other techniques are built.\nIn the next chapter, we’ll tackle our final piece of workflow advice: how to get help when you’re stuck."
  },
  {
    "objectID": "intro.html#lo-que-vas-a-aprender",
    "href": "intro.html#lo-que-vas-a-aprender",
    "title": "1  Introducción",
    "section": "\n1.1 Lo que vas a aprender",
    "text": "1.1 Lo que vas a aprender\nLa ciencia de datos es un campo amplio, y no hay forma de que puedas dominarlo todo leyendo un solo libro. Este libro tiene como objetivo brindarle una base sólida en las herramientas más importantes y el conocimiento suficiente para encontrar los recursos para aprender más cuando sea necesario. Nuestro modelo de los pasos de un proyecto típico de ciencia de datos se parece a Figura 1.1.\n\n\n\n\nFigura 1.1: En nuestro modelo del proceso de ciencia de datos, comienza con la importación de datos y ordenando. Luego, comprende sus datos con un ciclo iterativo de transformar, visualizar y modelar. Terminas el proceso comunicando sus resultados a otros humanos.\n\n\n\nPrimero, debe importar sus datos a R. Esto generalmente significa que toma datos almacenados en un archivo, base de datos o interfaz de programación de aplicaciones web (API) y los carga en un marco de datos en R. Si no puede llevar sus datos a R, ¡no puede hacer ciencia de datos en ellos!\nUna vez que haya importado sus datos, es una buena idea ordenarlos. Ordenar sus datos significa almacenarlos en una forma consistente que coincida con la semántica del conjunto de datos con la forma en que se almacenan. En resumen, cuando sus datos están ordenados, cada columna es una variable y cada fila es una observación. Los datos ordenados son importantes porque una estructura coherente le permite centrar sus esfuerzos en responder preguntas sobre los datos, sin luchar para obtener los datos en la forma correcta para diferentes funciones.\nUna vez que tenga datos ordenados, el próximo paso común es transformarlos. La transformación incluye la reducción de las observaciones de interés (como todas las personas en una ciudad o todos los datos del último año), la creación de nuevas variables que son funciones de las variables existentes (como la velocidad de cálculo a partir de la distancia y el tiempo) y el cálculo de un conjunto de estadísticas de resumen. (como la mediana o la media). Juntos, ordenar y transformar se denominan disputar (o manipular) porque obtener sus datos en una forma en la que es natural trabajar con ellos a menudo se siente como una pelea.\nUna vez que tenga datos ordenados con las variables que necesita, hay dos motores principales de generación de conocimiento: visualización y modelado. Estos tienen fortalezas y debilidades complementarias, por lo que cualquier análisis de datos real iterará entre ellos muchas veces.\nLa visualización es una actividad fundamentalmente humana. Una buena visualización le mostrará cosas que no esperaba o le generará nuevas preguntas sobre los datos. Una buena visualización también podría indicar que está haciendo la pregunta incorrecta o que necesita recopilar datos diferentes. Las visualizaciones pueden sorprenderlo, pero no se escalan particularmente bien porque requieren que un ser humano las interprete.\nLos modelos son herramientas complementarias a la visualización. Una vez que haya hecho sus preguntas lo suficientemente precisas, puede usar un modelo para responderlas. Los modelos son una herramienta fundamentalmente matemática o computacional, por lo que generalmente se escalan bien. ¡Incluso cuando no lo hacen, por lo general es más barato comprar más computadoras que comprar más cerebros! Pero todo modelo hace suposiciones y, por su propia naturaleza, un modelo no puede cuestionar sus propias suposiciones. Eso significa que un modelo no puede sorprenderte fundamentalmente.\nEl último paso de la ciencia de datos es la comunicación, una parte absolutamente crítica de cualquier proyecto de análisis de datos. No importa qué tan bien sus modelos y visualización lo hayan llevado a comprender los datos, a menos que también pueda comunicar sus resultados a otros.\nAlrededor de todas estas herramientas está la programación. La programación es una herramienta transversal que utiliza en casi todas las partes de un proyecto de ciencia de datos. No necesita ser un programador experto para ser un científico de datos exitoso, pero aprender más sobre programación vale la pena porque convertirse en un mejor programador le permite automatizar tareas comunes y resolver nuevos problemas con mayor facilidad.\nUsará estas herramientas en todos los proyectos de ciencia de datos, pero no son suficientes para la mayoría de los proyectos. Hay una regla aproximada de 80-20 en juego; puede abordar aproximadamente el 80 % de cada proyecto con las herramientas que aprenderá en este libro, pero necesitará otras herramientas para abordar el 20 % restante. A lo largo de este libro, le indicaremos los recursos donde puede obtener más información."
  },
  {
    "objectID": "intro.html#cómo-está-organizado-este-libro",
    "href": "intro.html#cómo-está-organizado-este-libro",
    "title": "1  Introducción",
    "section": "\n1.2 Cómo está organizado este libro",
    "text": "1.2 Cómo está organizado este libro\nLa descripción anterior de las herramientas de la ciencia de datos está organizada aproximadamente según el orden en que las usa en un análisis (aunque, por supuesto, las repetirá varias veces). En nuestra experiencia, sin embargo, aprender a importar y ordenar datos primero no es óptimo porque el 80 % del tiempo es rutinario y aburrido, y el otro 20 % del tiempo es raro y frustrante. ¡Ese es un mal lugar para comenzar a aprender un nuevo tema! En su lugar, comenzaremos con la visualización y transformación de datos que ya se han importado y ordenado. De esa manera, cuando ingiere y ordena sus propios datos, su motivación se mantendrá alta porque sabe que el esfuerzo vale la pena.\nDentro de cada capítulo, tratamos de adherirnos a un patrón concistente: comience con algunos ejemplos motivadores para que pueda ver el panorama general y luego profundice en los detalles. Cada sección del libro está emparejada con ejercicios para ayudarte a practicar lo que has aprendido. Aunque puede ser tentador saltarse los ejercicios, no hay mejor manera de aprender que practicar con problemas reales."
  },
  {
    "objectID": "intro.html#lo-que-no-aprenderás",
    "href": "intro.html#lo-que-no-aprenderás",
    "title": "1  Introducción",
    "section": "\n1.3 Lo que no aprenderás",
    "text": "1.3 Lo que no aprenderás\nHay varios temas importantes que este libro no cubre. Creemos que es importante concentrarse despiadadamente en lo esencial para que pueda ponerse en marcha lo más rápido posible. Eso significa que este libro no puede cubrir todos los temas importantes.\n\n1.3.1 Modelado\nEl modelado es muy importante para la ciencia de datos, pero es un gran tema y, lamentablemente, no tenemos el espacio para darle la cobertura que se merece aquí. Para obtener más información sobre modelado, recomendamos Tidy Modeling with R de nuestros colegas Max Kuhn y Julia Silge. Este libro le enseñará la familia de paquetes tidymodels que, como puede adivinar por el nombre, comparten muchas convenciones con los paquetes tidyverse que usamos en este libro.\n\n1.3.2 Big data\nEste libro se enfoca orgullosamente y principalmente en pequeños conjuntos de datos en memoria. Este es el lugar correcto para comenzar porque no puede abordar big data a menos que tenga experiencia con small data. Las herramientas que aprenderá a lo largo de la mayor parte de este libro manejarán fácilmente cientos de megabytes de datos y, con un poco de cuidado, normalmente puede usarlas para trabajar con unos pocos gigabytes de datos. También le mostraremos cómo obtener datos de bases de datos y archivos de parquet, los cuales se usan a menudo para almacenar big data. No necesariamente podrá trabajar con todo el conjunto de datos, pero eso no es un problema porque solo necesita un subconjunto o submuestra para responder la pregunta que le interesa.\nSi trabaja habitualmente con datos más grandes (10-100 Gb, digamos), le recomendamos obtener más información sobre [data.table] (https://github.com/Rdatatable/data.table). No lo enseñamos aquí porque usa una interfaz diferente a tidyverse y requiere que aprendas algunas convenciones diferentes. Sin embargo, es increíblemente más rápido y vale la pena invertir algo de tiempo en aprenderlo si está trabajando con grandes datos.\n\n1.3.3 Python, Julia, y amigos\nEn este libro, no aprenderá nada sobre Python, Julia o cualquier otro lenguaje de programación útil para la ciencia de datos. Esto no se debe a que pensemos que estas herramientas son malas. ¡No lo son! Y en la práctica, la mayoría de los equipos de ciencia de datos usan una combinación de lenguajes, a menudo al menos R y Python.\nPero creemos firmemente que es mejor dominar una herramienta a la vez, y R es un excelente lugar para comenzar."
  },
  {
    "objectID": "intro.html#requisitos-previos",
    "href": "intro.html#requisitos-previos",
    "title": "1  Introducción",
    "section": "\n1.4 Requisitos previos",
    "text": "1.4 Requisitos previos\nHemos hecho algunas suposiciones sobre lo que ya sabe para aprovechar al máximo este libro. En general, debe tener conocimientos numéricos, y es útil si ya tiene algo de experiencia en programación básica. Si nunca ha programado antes, es posible que encuentre que Hands on Programming with R por Garrett puede ser un valioso complemento de este libro.\nNecesita cuatro cosas para ejecutar el código de este libro: R, RStudio, una colección de paquetes de R llamada tidyverse y un puñado de otros paquetes. Los paquetes son las unidades fundamentales del código de R reproducible. Incluyen funciones reutilizables, documentación que describe cómo usarlas y datos de muestra.\n\n1.4.1 R\nPara descargar R, vaya a CRAN la red comprensiva de archivos de R (por sus siglas en inglés: comprehensive R archive network), https://cloud.r-project.org. Una nueva versión principal de R sale una vez al año y hay 2 o 3 lanzamientos menores cada año. Es una buena idea actualizar regularmente. La actualización puede ser un poco complicada, especialmente para las versiones principales que requieren que vuelva a instalar todos sus paquetes, pero posponerlo solo empeora las cosas. Recomendamos R 4.2.0 o posterior para este libro.\n\n1.4.2 RStudio\nRStudio es un entorno de desarrollo integrado, o IDE, para programación R, que puede descargar desde https://posit.co/download/rstudio-desktop/. RStudio se actualiza un par de veces al año y le avisará automáticamente cuando haya una nueva versión disponible para que no tenga que volver a comprobarlo. Es una buena idea actualizar regularmente para aprovechar las últimas y mejores funciones. Para este libro, asegúrese de tener al menos RStudio 2022.02.0.\nCuando inicie RStudio, Figura 1.2, verá dos regiones clave en la interfaz: el panel de la consola y el panel de salida. Por ahora, todo lo que necesita saber es que escribe el código R en el panel de la consola y presiona enter para ejecutarlo. ¡Aprenderás más a medida que avancemos!1\n\n\n\n\nFigura 1.2: El IDE de RStudio tiene dos regiones clave: escriba el código R en el panel de la consola a la izquierda y busque gráficos en el panel de salida a la derecha.\n\n\n\n\n1.4.3 tidyverse\nTambién deberá instalar algunos paquetes de R. Un paquete de R es una colección de funciones, datos y documentación que amplía las capacidades de R básico. El uso de paquetes es clave para el uso exitoso de R. La mayoría de los paquetes que aprenderás en este libro forman parte del llamado tidyverse. Todos los paquetes en tidyverse comparten una filosofía común de datos y programación R y están diseñados para trabajar juntos.\nPuedes instalar el tidyverse completo con una sola línea de código:\n\ninstall.packages(\"tidyverse\")\n\nEn su computadora, escriba esa línea de código en la consola y luego presione Intro para ejecutarlo. R descargará los paquetes de CRAN y los instalará en su computadora.\nNo podrá usar las funciones, objetos o archivos de ayuda en un paquete hasta que lo cargue con library(). Una vez que haya instalado un paquete, puede cargarlo usando la función library():\n\nlibrary(tidyverse)\n#&gt; ── Attaching core tidyverse packages ───────────────────── tidyverse 2.0.0 ──\n#&gt; ✔ dplyr     1.1.3     ✔ readr     2.1.4\n#&gt; ✔ forcats   1.0.0     ✔ stringr   1.5.0\n#&gt; ✔ ggplot2   3.4.3     ✔ tibble    3.2.1\n#&gt; ✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n#&gt; ✔ purrr     1.0.2     \n#&gt; ── Conflicts ─────────────────────────────────────── tidyverse_conflicts() ──\n#&gt; ✖ dplyr::filter() masks stats::filter()\n#&gt; ✖ dplyr::lag()    masks stats::lag()\n#&gt; ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nEsto le dice que tidyverse carga nueve paquetes: dplyr, forcats, ggplot2, lubridate, purrr, readr, stringr, tibble, tidyr. Estos se consideran el núcleo del tidyverse porque los usará en casi todos los análisis.\nLos paquetes en tidyverse cambian con bastante frecuencia. Puedes ver si hay actualizaciones disponibles ejecutando tidyverse_update().\n\n1.4.4 Otros paquetes\nHay muchos otros paquetes excelentes que no forman parte de tidyverse porque resuelven problemas en un dominio diferente o están diseñados con un conjunto diferente de principios subyacentes. Esto no los hace mejores o peores, simplemente diferentes. En otras palabras, el complemento del tidyverse no es el desordenado sino muchos otros universos de paquetes interrelacionados. A medida que aborde más proyectos de ciencia de datos con R, aprenderá nuevos paquetes y nuevas formas de pensar sobre los datos.\nUsaremos muchos paquetes de fuera del tidyverse en este libro. Por ejemplo, usaremos los siguientes paquetes porque proporcionan conjuntos de datos interesantes para que trabajemos en el proceso de aprendizaje de R:\n\ninstall.packages(\n  c(\"arrow\", \"babynames\", \"curl\", \"duckdb\", \"gapminder\",\n    \"ggrepel\", \"ggridges\", \"ggthemes\", \"hexbin\", \"janitor\", \"Lahman\",\n    \"leaflet\", \"maps\", \"nycflights13\", \"openxlsx\", \"palmerpenguins\",\n    \"repurrrsive\", \"tidymodels\", \"writexl\")\n  )\n\nTambién usaremos una selección de otros paquetes para ejemplos únicos. No necesita instalarlos ahora, solo recuerde que cada vez que vea un error como este:\n\nlibrary(ggrepel)\n#&gt; Error in library(ggrepel) : there is no package called ‘ggrepel’\n\nDebe ejecutar install.packages(\"ggrepel\") para instalar el paquete."
  },
  {
    "objectID": "intro.html#ejecutando-código-de-r",
    "href": "intro.html#ejecutando-código-de-r",
    "title": "1  Introducción",
    "section": "\n1.5 Ejecutando código de R",
    "text": "1.5 Ejecutando código de R\nLa sección anterior le mostró varios ejemplos de ejecución de código R. El código en el libro se ve así:\n\n1 + 2\n#&gt; [1] 3\n\nSi ejecuta el mismo código en su consola local, se verá así:\n&gt; 1 + 2\n[1] 3\nHay dos diferencias principales. En su consola, escribe después de &gt;, llamado prompt; no mostramos el aviso en el libro. En el libro, la salida se comenta con #&gt;; en su consola, aparece directamente después de su código. Estas dos diferencias significan que si está trabajando con una versión electrónica del libro, puede copiar fácilmente el código del libro y colocarlo en la consola.\nA lo largo del libro, usamos un conjunto consistente de convenciones para referirnos al código:\n\nLas funciones se muestran en una fuente de código y van seguidas de paréntesis, como sum() o mean().\nOtros objetos R (como datos o argumentos de funciones) están en una fuente de código, sin paréntesis, como flights o x.\nA veces, para dejar claro de qué paquete proviene un objeto, usaremos el nombre del paquete seguido de dos puntos, como dplyr::mutate() o nycflights13::flights. Este también es un código R válido."
  },
  {
    "objectID": "intro.html#reconocimientos",
    "href": "intro.html#reconocimientos",
    "title": "1  Introducción",
    "section": "\n1.6 Reconocimientos",
    "text": "1.6 Reconocimientos\nEste libro no es solo el producto de Hadley, Mine y Garrett, sino que es el resultado de muchas conversaciones (en persona y en línea) que hemos tenido con muchas personas en la comunidad de R. Estamos increíblemente agradecidos por todas las conversaciones que hemos tenido con todos ustedes; ¡muchas gracias!\nEste libro fue escrito abiertamente, y muchas personas contribuyeron a través de solicitudes de extracción. Un agradecimiento especial a todos 259 de ustedes que contribuyeron con mejoras a través de solicitudes de extracción de GitHub (en orden alfabético por nombre de usuario):"
  },
  {
    "objectID": "intro.html#colofón",
    "href": "intro.html#colofón",
    "title": "1  Introducción",
    "section": "\n1.7 Colofón",
    "text": "1.7 Colofón\nUna versión en línea de este libro está disponible en https://r4ds.hadley.nz. Continuará evolucionando entre las reimpresiones del libro físico. El código fuente del libro está disponible en https://github.com/hadley/r4ds. El libro funciona con Quarto, lo que facilita la escritura de libros que combinan texto y código ejecutable."
  },
  {
    "objectID": "base-R.html#introduction",
    "href": "base-R.html#introduction",
    "title": "28  A field guide to base R",
    "section": "\n28.1 Introduction",
    "text": "28.1 Introduction\nTo finish off the programming section, we’re going to give you a quick tour of the most important base R functions that we don’t otherwise discuss in the book. These tools are particularly useful as you do more programming and will help you read code you’ll encounter in the wild.\nThis is a good place to remind you that the tidyverse is not the only way to solve data science problems. We teach the tidyverse in this book because tidyverse packages share a common design philosophy, increasing the consistency across functions, and making each new function or package a little easier to learn and use. It’s not possible to use the tidyverse without using base R, so we’ve actually already taught you a lot of base R functions: from library() to load packages, to sum() and mean() for numeric summaries, to the factor, date, and POSIXct data types, and of course all the basic operators like +, -, /, *, |, &, and !. What we haven’t focused on so far is base R workflows, so we will highlight a few of those in this chapter.\nAfter you read this book, you’ll learn other approaches to the same problems using base R, data.table, and other packages. You’ll undoubtedly encounter these other approaches when you start reading R code written by others, particularly if you’re using StackOverflow. It’s 100% okay to write code that uses a mix of approaches, and don’t let anyone tell you otherwise!\nIn this chapter, we’ll focus on four big topics: subsetting with [, subsetting with [[ and $, the apply family of functions, and for loops. To finish off, we’ll briefly discuss two essential plotting functions.\n\n28.1.1 Prerequisites\nThis package focuses on base R so doesn’t have any real prerequisites, but we’ll load the tidyverse in order to explain some of the differences.\n\nlibrary(tidyverse)\n#> Warning: package 'tibble' was built under R version 4.2.3\n#> Warning: package 'readr' was built under R version 4.2.3\n#> Warning: package 'dplyr' was built under R version 4.2.3"
  },
  {
    "objectID": "base-R.html#sec-subset-many",
    "href": "base-R.html#sec-subset-many",
    "title": "28  A field guide to base R",
    "section": "\n28.2 Selecting multiple elements with [\n",
    "text": "28.2 Selecting multiple elements with [\n\n[ is used to extract sub-components from vectors and data frames, and is called like x[i] or x[i, j]. In this section, we’ll introduce you to the power of [, first showing you how you can use it with vectors, then how the same principles extend in a straightforward way to two-dimensional (2d) structures like data frames. We’ll then help you cement that knowledge by showing how various dplyr verbs are special cases of [.\n\n28.2.1 Subsetting vectors\nThere are five main types of things that you can subset a vector with, i.e., that can be the i in x[i]:\n\n\nA vector of positive integers. Subsetting with positive integers keeps the elements at those positions:\n\nx <- c(\"one\", \"two\", \"three\", \"four\", \"five\")\nx[c(3, 2, 5)]\n#> [1] \"three\" \"two\"   \"five\"\n\nBy repeating a position, you can actually make a longer output than input, making the term “subsetting” a bit of a misnomer.\n\nx[c(1, 1, 5, 5, 5, 2)]\n#> [1] \"one\"  \"one\"  \"five\" \"five\" \"five\" \"two\"\n\n\n\nA vector of negative integers. Negative values drop the elements at the specified positions:\n\nx[c(-1, -3, -5)]\n#> [1] \"two\"  \"four\"\n\n\n\nA logical vector. Subsetting with a logical vector keeps all values corresponding to a TRUE value. This is most often useful in conjunction with the comparison functions.\n\nx <- c(10, 3, NA, 5, 8, 1, NA)\n\n# All non-missing values of x\nx[!is.na(x)]\n#> [1] 10  3  5  8  1\n\n# All even (or missing!) values of x\nx[x %% 2 == 0]\n#> [1] 10 NA  8 NA\n\nUnlike filter(), NA indices will be included in the output as NAs.\n\n\nA character vector. If you have a named vector, you can subset it with a character vector:\n\nx <- c(abc = 1, def = 2, xyz = 5)\nx[c(\"xyz\", \"def\")]\n#> xyz def \n#>   5   2\n\nAs with subsetting with positive integers, you can use a character vector to duplicate individual entries.\n\nNothing. The final type of subsetting is nothing, x[], which returns the complete x. This is not useful for subsetting vectors, but as we’ll see shortly, it is useful when subsetting 2d structures like tibbles.\n\n28.2.2 Subsetting data frames\nThere are quite a few different ways1 that you can use [ with a data frame, but the most important way is to select rows and columns independently with df[rows, cols]. Here rows and cols are vectors as described above. For example, df[rows, ] and df[, cols] select just rows or just columns, using the empty subset to preserve the other dimension.\nHere are a couple of examples:\n\ndf <- tibble(\n  x = 1:3, \n  y = c(\"a\", \"e\", \"f\"), \n  z = runif(3)\n)\n\n# Select first row and second column\ndf[1, 2]\n#> # A tibble: 1 × 1\n#>   y    \n#>   <chr>\n#> 1 a\n\n# Select all rows and columns x and y\ndf[, c(\"x\" , \"y\")]\n#> # A tibble: 3 × 2\n#>       x y    \n#>   <int> <chr>\n#> 1     1 a    \n#> 2     2 e    \n#> 3     3 f\n\n# Select rows where `x` is greater than 1 and all columns\ndf[df$x > 1, ]\n#> # A tibble: 2 × 3\n#>       x y         z\n#>   <int> <chr> <dbl>\n#> 1     2 e     0.834\n#> 2     3 f     0.601\n\nWe’ll come back to $ shortly, but you should be able to guess what df$x does from the context: it extracts the x variable from df. We need to use it here because [ doesn’t use tidy evaluation, so you need to be explicit about the source of the x variable.\nThere’s an important difference between tibbles and data frames when it comes to [. In this book, we’ve mainly used tibbles, which are data frames, but they tweak some behaviors to make your life a little easier. In most places, you can use “tibble” and “data frame” interchangeably, so when we want to draw particular attention to R’s built-in data frame, we’ll write data.frame. If df is a data.frame, then df[, cols] will return a vector if col selects a single column and a data frame if it selects more than one column. If df is a tibble, then [ will always return a tibble.\n\ndf1 <- data.frame(x = 1:3)\ndf1[, \"x\"]\n#> [1] 1 2 3\n\ndf2 <- tibble(x = 1:3)\ndf2[, \"x\"]\n#> # A tibble: 3 × 1\n#>       x\n#>   <int>\n#> 1     1\n#> 2     2\n#> 3     3\n\nOne way to avoid this ambiguity with data.frames is to explicitly specify drop = FALSE:\n\ndf1[, \"x\" , drop = FALSE]\n#>   x\n#> 1 1\n#> 2 2\n#> 3 3\n\n\n28.2.3 dplyr equivalents\nSeveral dplyr verbs are special cases of [:\n\n\nfilter() is equivalent to subsetting the rows with a logical vector, taking care to exclude missing values:\n\ndf <- tibble(\n  x = c(2, 3, 1, 1, NA), \n  y = letters[1:5], \n  z = runif(5)\n)\ndf |> filter(x > 1)\n\n# same as\ndf[!is.na(df$x) & df$x > 1, ]\n\nAnother common technique in the wild is to use which() for its side-effect of dropping missing values: df[which(df$x > 1), ].\n\n\narrange() is equivalent to subsetting the rows with an integer vector, usually created with order():\n\ndf |> arrange(x, y)\n\n# same as\ndf[order(df$x, df$y), ]\n\nYou can use order(decreasing = TRUE) to sort all columns in descending order or -rank(col) to sort columns in decreasing order individually.\n\n\nBoth select() and relocate() are similar to subsetting the columns with a character vector:\n\ndf |> select(x, z)\n\n# same as\ndf[, c(\"x\", \"z\")]\n\n\n\nBase R also provides a function that combines the features of filter() and select()2 called subset():\n\ndf |> \n  filter(x > 1) |> \n  select(y, z)\n#> # A tibble: 2 × 2\n#>   y           z\n#>   <chr>   <dbl>\n#> 1 a     0.157  \n#> 2 b     0.00740\n\n\n# same as\ndf |> subset(x > 1, c(y, z))\n\nThis function was the inspiration for much of dplyr’s syntax.\n\n28.2.4 Exercises\n\n\nCreate functions that take a vector as input and return:\n\nThe elements at even-numbered positions.\nEvery element except the last value.\nOnly even values (and no missing values).\n\n\nWhy is x[-which(x > 0)] not the same as x[x <= 0]? Read the documentation for which() and do some experiments to figure it out."
  },
  {
    "objectID": "base-R.html#sec-subset-one",
    "href": "base-R.html#sec-subset-one",
    "title": "28  A field guide to base R",
    "section": "\n28.3 Selecting a single element with $ and [[\n",
    "text": "28.3 Selecting a single element with $ and [[\n\n[, which selects many elements, is paired with [[ and $, which extract a single element. In this section, we’ll show you how to use [[ and $ to pull columns out of data frames, discuss a couple more differences between data.frames and tibbles, and emphasize some important differences between [ and [[ when used with lists.\n\n28.3.1 Data frames\n[[ and $ can be used to extract columns out of a data frame. [[ can access by position or by name, and $ is specialized for access by name:\n\ntb <- tibble(\n  x = 1:4,\n  y = c(10, 4, 1, 21)\n)\n\n# by position\ntb[[1]]\n#> [1] 1 2 3 4\n\n# by name\ntb[[\"x\"]]\n#> [1] 1 2 3 4\ntb$x\n#> [1] 1 2 3 4\n\nThey can also be used to create new columns, the base R equivalent of mutate():\n\ntb$z <- tb$x + tb$y\ntb\n#> # A tibble: 4 × 3\n#>       x     y     z\n#>   <int> <dbl> <dbl>\n#> 1     1    10    11\n#> 2     2     4     6\n#> 3     3     1     4\n#> 4     4    21    25\n\nThere are several other base R approaches to creating new columns including with transform(), with(), and within(). Hadley collected a few examples at https://gist.github.com/hadley/1986a273e384fb2d4d752c18ed71bedf.\nUsing $ directly is convenient when performing quick summaries. For example, if you just want to find the size of the biggest diamond or the possible values of cut, there’s no need to use summarize():\n\nmax(diamonds$carat)\n#> [1] 5.01\n\nlevels(diamonds$cut)\n#> [1] \"Fair\"      \"Good\"      \"Very Good\" \"Premium\"   \"Ideal\"\n\ndplyr also provides an equivalent to [[/$ that we didn’t mention in Chapter 4: pull(). pull() takes either a variable name or variable position and returns just that column. That means we could rewrite the above code to use the pipe:\n\ndiamonds |> pull(carat) |> mean()\n#> [1] 0.7979397\n\ndiamonds |> pull(cut) |> levels()\n#> [1] \"Fair\"      \"Good\"      \"Very Good\" \"Premium\"   \"Ideal\"\n\n\n28.3.2 Tibbles\nThere are a couple of important differences between tibbles and base data.frames when it comes to $. Data frames match the prefix of any variable names (so-called partial matching) and don’t complain if a column doesn’t exist:\n\ndf <- data.frame(x1 = 1)\ndf$x\n#> [1] 1\ndf$z\n#> NULL\n\nTibbles are more strict: they only ever match variable names exactly and they will generate a warning if the column you are trying to access doesn’t exist:\n\ntb <- tibble(x1 = 1)\n\ntb$x\n#> Warning: Unknown or uninitialised column: `x`.\n#> NULL\ntb$z\n#> Warning: Unknown or uninitialised column: `z`.\n#> NULL\n\nFor this reason we sometimes joke that tibbles are lazy and surly: they do less and complain more.\n\n28.3.3 Lists\n[[ and $ are also really important for working with lists, and it’s important to understand how they differ from [. Lets illustrate the differences with a list named l:\n\nl <- list(\n  a = 1:3, \n  b = \"a string\", \n  c = pi, \n  d = list(-1, -5)\n)\n\n\n\n[ extracts a sub-list. It doesn’t matter how many elements you extract, the result will always be a list.\n\nstr(l[1:2])\n#> List of 2\n#>  $ a: int [1:3] 1 2 3\n#>  $ b: chr \"a string\"\n\nstr(l[1])\n#> List of 1\n#>  $ a: int [1:3] 1 2 3\n\nstr(l[4])\n#> List of 1\n#>  $ d:List of 2\n#>   ..$ : num -1\n#>   ..$ : num -5\n\nLike with vectors, you can subset with a logical, integer, or character vector.\n\n\n[[ and $ extract a single component from a list. They remove a level of hierarchy from the list.\n\nstr(l[[1]])\n#>  int [1:3] 1 2 3\n\nstr(l[[4]])\n#> List of 2\n#>  $ : num -1\n#>  $ : num -5\n\nstr(l$a)\n#>  int [1:3] 1 2 3\n\n\n\nThe difference between [ and [[ is particularly important for lists because [[ drills down into the list while [ returns a new, smaller list. To help you remember the difference, take a look at the unusual pepper shaker shown in Figure 28.1. If this pepper shaker is your list pepper, then, pepper[1] is a pepper shaker containing a single pepper packet. If we suppose this pepper shaker is a list called pepper, then pepper[1] is a pepper shaker containing a single pepper packet. pepper[2] would look the same, but would contain the second packet. pepper[1:2] would be a pepper shaker containing two pepper packets. pepper[[1]] would extract the pepper packet itself.\n\n\n\n\nFigure 28.1: (Left) A pepper shaker that Hadley once found in his hotel room. (Middle) pepper[1]. (Right) pepper[[1]]\n\n\n\n\nThis same principle applies when you use 1d [ with a data frame: df[\"x\"] returns a one-column data frame and df[[\"x\"]] returns a vector.\n\n28.3.4 Exercises\n\nWhat happens when you use [[ with a positive integer that’s bigger than the length of the vector? What happens when you subset with a name that doesn’t exist?\nWhat would pepper[[1]][1] be? What about pepper[[1]][[1]]?"
  },
  {
    "objectID": "base-R.html#apply-family",
    "href": "base-R.html#apply-family",
    "title": "28  A field guide to base R",
    "section": "\n28.4 Apply family",
    "text": "28.4 Apply family\nIn Chapter 27, you learned tidyverse techniques for iteration like dplyr::across() and the map family of functions. In this section, you’ll learn about their base equivalents, the apply family. In this context apply and map are synonyms because another way of saying “map a function over each element of a vector” is “apply a function over each element of a vector”. Here we’ll give you a quick overview of this family so you can recognize them in the wild.\nThe most important member of this family is lapply(), which is very similar to purrr::map()3. In fact, because we haven’t used any of map()’s more advanced features, you can replace every map() call in Chapter 27 with lapply().\nThere’s no exact base R equivalent to across() but you can get close by using [ with lapply(). This works because under the hood, data frames are lists of columns, so calling lapply() on a data frame applies the function to each column.\n\ndf <- tibble(a = 1, b = 2, c = \"a\", d = \"b\", e = 4)\n\n# First find numeric columns\nnum_cols <- sapply(df, is.numeric)\nnum_cols\n#>     a     b     c     d     e \n#>  TRUE  TRUE FALSE FALSE  TRUE\n\n# Then transform each column with lapply() then replace the original values\ndf[, num_cols] <- lapply(df[, num_cols, drop = FALSE], \\(x) x * 2)\ndf\n#> # A tibble: 1 × 5\n#>       a     b c     d         e\n#>   <dbl> <dbl> <chr> <chr> <dbl>\n#> 1     2     4 a     b         8\n\nThe code above uses a new function, sapply(). It’s similar to lapply() but it always tries to simplify the result, hence the s in its name, here producing a logical vector instead of a list. We don’t recommend using it for programming, because the simplification can fail and give you an unexpected type, but it’s usually fine for interactive use. purrr has a similar function called map_vec() that we didn’t mention in Chapter 27.\nBase R provides a stricter version of sapply() called vapply(), short for vector apply. It takes an additional argument that specifies the expected type, ensuring that simplification occurs the same way regardless of the input. For example, we could replace the sapply() call above with this vapply() where we specify that we expect is.numeric() to return a logical vector of length 1:\n\nvapply(df, is.numeric, logical(1))\n#>     a     b     c     d     e \n#>  TRUE  TRUE FALSE FALSE  TRUE\n\nThe distinction between sapply() and vapply() is really important when they’re inside a function (because it makes a big difference to the function’s robustness to unusual inputs), but it doesn’t usually matter in data analysis.\nAnother important member of the apply family is tapply() which computes a single grouped summary:\n\ndiamonds |> \n  group_by(cut) |> \n  summarize(price = mean(price))\n#> # A tibble: 5 × 2\n#>   cut       price\n#>   <ord>     <dbl>\n#> 1 Fair      4359.\n#> 2 Good      3929.\n#> 3 Very Good 3982.\n#> 4 Premium   4584.\n#> 5 Ideal     3458.\n\ntapply(diamonds$price, diamonds$cut, mean)\n#>      Fair      Good Very Good   Premium     Ideal \n#>  4358.758  3928.864  3981.760  4584.258  3457.542\n\nUnfortunately tapply() returns its results in a named vector which requires some gymnastics if you want to collect multiple summaries and grouping variables into a data frame (it’s certainly possible to not do this and just work with free floating vectors, but in our experience that just delays the work). If you want to see how you might use tapply() or other base techniques to perform other grouped summaries, Hadley has collected a few techniques in a gist.\nThe final member of the apply family is the titular apply(), which works with matrices and arrays. In particular, watch out for apply(df, 2, something), which is a slow and potentially dangerous way of doing lapply(df, something). This rarely comes up in data science because we usually work with data frames and not matrices."
  },
  {
    "objectID": "base-R.html#for-loops",
    "href": "base-R.html#for-loops",
    "title": "28  A field guide to base R",
    "section": "\n28.5 For loops",
    "text": "28.5 For loops\nfor loops are the fundamental building block of iteration that both the apply and map families use under the hood. for loops are powerful and general tools that are important to learn as you become a more experienced R programmer. The basic structure of a for loop looks like this:\n\nfor (element in vector) {\n  # do something with element\n}\n\nThe most straightforward use of for loops is to achieve the same affect as walk(): call some function with a side-effect on each element of a list. For example, in Section 27.4.1 instead of using walk:\n\npaths |> walk(append_file)\n\nWe could have used a for loop:\n\nfor (path in paths) {\n  append_file(path)\n}\n\nThings get a little trickier if you want to save the output of the for loop, for example reading all of the excel files in a directory like we did in Chapter 27:\n\npaths <- dir(\"data/gapminder\", pattern = \"\\\\.xlsx$\", full.names = TRUE)\nfiles <- map(paths, readxl::read_excel)\n\nThere are a few different techniques that you can use, but we recommend being explicit about what the output is going to look like upfront. In this case, we’re going to want a list the same length as paths, which we can create with vector():\n\nfiles <- vector(\"list\", length(paths))\n\nThen instead of iterating over the elements of paths, we’ll iterate over their indices, using seq_along() to generate one index for each element of paths:\n\nseq_along(paths)\n#>  [1]  1  2  3  4  5  6  7  8  9 10 11 12\n\nUsing the indices is important because it allows us to link to each position in the input with the corresponding position in the output:\n\nfor (i in seq_along(paths)) {\n  files[[i]] <- readxl::read_excel(paths[[i]])\n}\n\nTo combine the list of tibbles into a single tibble you can use do.call() + rbind():\n\ndo.call(rbind, files)\n#> # A tibble: 1,704 × 5\n#>   country     continent lifeExp      pop gdpPercap\n#>   <chr>       <chr>       <dbl>    <dbl>     <dbl>\n#> 1 Afghanistan Asia         28.8  8425333      779.\n#> 2 Albania     Europe       55.2  1282697     1601.\n#> 3 Algeria     Africa       43.1  9279525     2449.\n#> 4 Angola      Africa       30.0  4232095     3521.\n#> 5 Argentina   Americas     62.5 17876956     5911.\n#> 6 Australia   Oceania      69.1  8691212    10040.\n#> # ℹ 1,698 more rows\n\nRather than making a list and saving the results as we go, a simpler approach is to build up the data frame piece-by-piece:\n\nout <- NULL\nfor (path in paths) {\n  out <- rbind(out, readxl::read_excel(path))\n}\n\nWe recommend avoiding this pattern because it can become very slow when the vector is very long. This is the source of the persistent canard that for loops are slow: they’re not, but iteratively growing a vector is."
  },
  {
    "objectID": "base-R.html#plots",
    "href": "base-R.html#plots",
    "title": "28  A field guide to base R",
    "section": "\n28.6 Plots",
    "text": "28.6 Plots\nMany R users who don’t otherwise use the tidyverse prefer ggplot2 for plotting due to helpful features like sensible defaults, automatic legends, and a modern look. However, base R plotting functions can still be useful because they’re so concise — it takes very little typing to do a basic exploratory plot.\nThere are two main types of base plot you’ll see in the wild: scatterplots and histograms, produced with plot() and hist() respectively. Here’s a quick example from the diamonds dataset:\n\n# Left\nhist(diamonds$carat)\n\n# Right\nplot(diamonds$carat, diamonds$price)\n\n\n\n\n\n\n\n\n\n\n\nNote that base plotting functions work with vectors, so you need to pull columns out of the data frame using $ or some other technique."
  },
  {
    "objectID": "base-R.html#summary",
    "href": "base-R.html#summary",
    "title": "28  A field guide to base R",
    "section": "\n28.7 Summary",
    "text": "28.7 Summary\nIn this chapter, we’ve shown you a selection of base R functions useful for subsetting and iteration. Compared to approaches discussed elsewhere in the book, these functions tend to have more of a “vector” flavor than a “data frame” flavor because base R functions tend to take individual vectors, rather than a data frame and some column specification. This often makes life easier for programming and so becomes more important as you write more functions and begin to write your own packages.\nThis chapter concludes the programming section of the book. You’ve made a solid start on your journey to becoming not just a data scientist who uses R, but a data scientist who can program in R. We hope these chapters have sparked your interest in programming and that you’re looking forward to learning more outside of this book."
  },
  {
    "objectID": "communicate.html",
    "href": "communicate.html",
    "title": "Communicate",
    "section": "",
    "text": "So far, you’ve learned the tools to get your data into R, tidy it into a form convenient for analysis, and then understand your data through transformation, and visualization. However, it doesn’t matter how great your analysis is unless you can explain it to others: you need to communicate your results.\n\n\n\n\nFigure 1: Communication is the final part of the data science process; if you can’t communicate your results to other humans, it doesn’t matter how great your analysis is.\n\n\n\n\nCommunication is the theme of the following two chapters:\n\nIn Chapter 29, you will learn about Quarto, a tool for integrating prose, code, and results. You can use Quarto for analyst-to-analyst communication as well as analyst-to-decision-maker communication. Thanks to the power of Quarto formats, you can even use the same document for both purposes.\nIn Chapter 30, you’ll learn a little about the many other varieties of outputs you can produce using Quarto, including dashboards, websites, and books.\n\nThese chapters focus mostly on the technical mechanics of communication, not the really hard problems of communicating your thoughts to other humans. However, there are lot of other great books about communication, which we’ll point you to at the end of each chapter."
  },
  {
    "objectID": "quarto.html#introduction",
    "href": "quarto.html#introduction",
    "title": "29  Quarto",
    "section": "\n29.1 Introduction",
    "text": "29.1 Introduction\nQuarto provides a unified authoring framework for data science, combining your code, its results, and your prose. Quarto documents are fully reproducible and support dozens of output formats, like PDFs, Word files, presentations, and more.\nQuarto files are designed to be used in three ways:\n\nFor communicating to decision-makers, who want to focus on the conclusions, not the code behind the analysis.\nFor collaborating with other data scientists (including future you!), who are interested in both your conclusions, and how you reached them (i.e. the code).\nAs an environment in which to do data science, as a modern-day lab notebook where you can capture not only what you did, but also what you were thinking.\n\nQuarto is a command line interface tool, not an R package. This means that help is, by-and-large, not available through ?. Instead, as you work through this chapter, and use Quarto in the future, you should refer to the Quarto documentation.\nIf you’re an R Markdown user, you might be thinking “Quarto sounds a lot like R Markdown”. You’re not wrong! Quarto unifies the functionality of many packages from the R Markdown ecosystem (rmarkdown, bookdown, distill, xaringan, etc.) into a single consistent system as well as extends it with native support for multiple programming languages like Python and Julia in addition to R. In a way, Quarto reflects everything that was learned from expanding and supporting the R Markdown ecosystem over a decade.\n\n29.1.1 Prerequisites\nYou need the Quarto command line interface (Quarto CLI), but you don’t need to explicitly install it or load it, as RStudio automatically does both when needed."
  },
  {
    "objectID": "quarto.html#quarto-basics",
    "href": "quarto.html#quarto-basics",
    "title": "29  Quarto",
    "section": "\n29.2 Quarto basics",
    "text": "29.2 Quarto basics\nEste es un archivo Quarto, un archivo de texto sin formato que tiene la extensión .qmd:\n\n---\ntitle: \"Diamond sizes\"\ndate: 2022-09-12\nformat: html\n---\n\n```{r}\n#| label: setup\n#| include: false\n\nlibrary(tidyverse)\n\nsmaller &lt;- diamonds |&gt; \n  filter(carat &lt;= 2.5)\n```\n\nWe have data about `r nrow(diamonds)` diamonds.\nOnly `r nrow(diamonds) - nrow(smaller)` are larger than 2.5 carats.\nThe distribution of the remainder is shown below:\n\n```{r}\n#| label: plot-smaller-diamonds\n#| echo: false\n\nsmaller |&gt; \n  ggplot(aes(x = carat)) + \n  geom_freqpoly(binwidth = 0.01)\n```\n\nContiene tres tipos importantes de contenido:\n\nUn encabezado YAML (opcional) rodeado de ---s.\n\nPorciones de código R rodeadas por ```.\nTexto mezclado con formato de texto simple como #título y _cursiva_.\n\nFigura 29.1 muestra un documento .qmd en RStudio con interfaz de notebook donde el código y la salida están intercalados. Puede ejecutar cada fragmento de código haciendo clic en el ícono Ejecutar (parece un botón de reproducción en la parte superior del fragmento), o presionando Cmd/Ctrl + Shift + Enter. RStudio ejecuta el código y muestra los resultados en línea con el código.\n\n\n\n\n\n\n\nFigura 29.1: Un documento de Quarto en RStudio. Código y salida intercalados en el documento, con la salida de la gráfica apareciendo justo debajo del código.\n\n\n\n\nSi no le gusta ver sus gráficos y resultados en su documento y prefiere utilizar la consola y los paneles de gráficos de RStudio, puede hacer clic en el icono de engranaje junto a “Render” y cambiar a “Chunk Output in Console”, como se muestra en Figura 29.2.\n\n\n\n\n\n\n\nFigura 29.2: Un documento Quarto en RStudio con la salida del gráfico en el panel Gráficos.\n\n\n\n\nPara generar un informe completo que contenga todo el texto, el código y los resultados, haga clic en “Render” o presione Cmd/Ctrl + Shift + K. También puede hacer esto mediante programación con quarto::quarto_render(\"diamond-sizes.qmd\"). Esto mostrará el informe en el panel del visor como se muestra en Figura 29.3 y creará un archivo HTML.\n\n\n\n\n\n\n\nFigura 29.3: Un documento de Quarto en RStudio con el documento renderizado en el panel del View.\n\n\n\n\nCuando renderiza el documento, Quarto envía el archivo .qmd a knitr, https://yihui.org/knitr/, que ejecuta todos los fragmentos de código y crea un nuevo documento de markdown (.md) que incluye el código y su salida. El archivo markdown generado por knitr luego es procesado por pandoc, https://pandoc.org, que es responsable de crear el archivo terminado. Este proceso se muestra en Figura 29.4. La ventaja de este flujo de trabajo de dos pasos es que puede crear una amplia gama de formatos de salida, como aprenderá en Capítulo 30.\n\n\n\n\n\n\n\nFigura 29.4: Diagrama del flujo de trabajo de Quarto de qmd, a knitr, a md, a pandoc, a la salida en formato PDF, MS Word o HTML.\n\n\n\n\nPara comenzar con su propio archivo .qmd, seleccione File &gt; New File &gt; Quarto Document… en la barra de menú. RStudio lanzará un asistente que puede usar para completar previamente su archivo con contenido útil que le recuerda cómo funcionan las funciones clave de Quarto\nLas siguientes secciones se sumergen en los tres componentes de un documento Quarto con más detalles: el texto markdown, los fragmentos de código y el encabezado YAML.\n\n29.2.1 Ejercicios\n\nCrear un nuevo documento Quarto usando File &gt; New File &gt; Quarto Document. Lee las instrucciones. Practique ejecutar los fragmentos individualmente. Luego renderice el documento haciendo clic en el botón apropiado y luego usando el atajo de teclado apropiado. Verifique que puede modificar el código, volver a ejecutarlo y ver el resultado modificado.\nCree un nuevo documento Quarto para cada uno de los tres formatos integrados: HTML, PDF y Word. Renderice cada uno de los tres documentos. ¿Cómo difieren las salidas? ¿Cómo difieren las entradas? (Es posible que deba instalar LaTeX para generar la salida en PDF; RStudio le indicará si es necesario).",
    "crumbs": [
      "Comunicar",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#visual-editor",
    "href": "quarto.html#visual-editor",
    "title": "29  Quarto",
    "section": "\n29.3 Visual editor",
    "text": "29.3 Visual editor\nThe Visual editor in RStudio provides a WYSIWYM interface for authoring Quarto documents. Under the hood, prose in Quarto documents (.qmd files) is written in Markdown, a lightweight set of conventions for formatting plain text files. In fact, Quarto uses Pandoc markdown (a slightly extended version of Markdown that Quarto understands), including tables, citations, cross-references, footnotes, divs/spans, definition lists, attributes, raw HTML/TeX, and more as well as support for executing code cells and viewing their output inline. While Markdown is designed to be easy to read and write, as you will see in Section 29.4, it still requires learning new syntax. Therefore, if you’re new to computational documents like .qmd files but have experience using tools like Google Docs or MS Word, the easiest way to get started with Quarto in RStudio is the visual editor.\nIn the visual editor you can either use the buttons on the menu bar to insert images, tables, cross-references, etc. or you can use the catch-all ⌘ / shortcut to insert just about anything. If you are at the beginning of a line (as shown in Figure 29.5), you can also enter just / to invoke the shortcut.\n\n\n\n\nFigure 29.5: Quarto visual editor.\n\n\n\n\nInserting images and customizing how they are displayed is also facilitated with the visual editor. You can either paste an image from your clipboard directly into the visual editor (and RStudio will place a copy of that image in the project directory and link to it) or you can use the visual editor’s Insert > Figure / Image menu to browse to the image you want to insert or paste it’s URL. In addition, using the same menu you can resize the image as well as add a caption, alternative text, and a link.\nThe visual editor has many more features that we haven’t enumerated here that you might find useful as you gain experience authoring with it.\nMost importantly, while the visual editor displays your content with formatting, under the hood, it saves your content in plain Markdown and you can switch back and forth between the visual and source editors to view and edit your content using either tool.\n\n29.3.1 Exercises\n\nRe-create the document in Figure 29.5 using the visual editor.\nUsing the visual editor, insert a code chunk using the Insert menu and then the insert anything tool.\nUsing the visual editor, figure out how to:\n\nAdd a footnote.\nAdd a horizontal rule.\nAdd a block quote.\n\n\nIn the visual editor, go to Insert > Citation and insert a citation to the paper titled Welcome to the Tidyverse using its DOI (digital object identifier), which is 10.21105/joss.01686. Render the document and observe how the reference shows up in the document. What change do you observe in the YAML of your document?"
  },
  {
    "objectID": "quarto.html#sec-source-editor",
    "href": "quarto.html#sec-source-editor",
    "title": "29  Quarto",
    "section": "\n29.4 Editor Source",
    "text": "29.4 Editor Source\nTambién puede editar documentos Quarto usando el editor de origen en RStudio, sin la ayuda del editor visual. Mientras que el editor visual les resultará familiar a quienes tengan experiencia escribiendo en herramientas como Google docs, el editor de código fuente les resultará familiar a quienes tengan experiencia escribiendo scripts R o documentos R Markdown. El editor de código fuente también puede ser útil para depurar cualquier error de sintaxis de Quarto, ya que a menudo es más fácil detectarlos en texto sin formato.\nLa siguiente guía muestra cómo usar Markdown de Pandoc para crear documentos Quarto en el editor de código fuente.\n\n## Text formatting\n\n*italic* **bold** ~~strikeout~~ `code`\n\nsuperscript^2^ subscript~2~\n\n[underline]{.underline} [small caps]{.smallcaps}\n\n## Headings\n\n# 1st Level Header\n\n## 2nd Level Header\n\n### 3rd Level Header\n\n## Lists\n\n-   Bulleted list item 1\n\n-   Item 2\n\n    -   Item 2a\n\n    -   Item 2b\n\n1.  Numbered list item 1\n\n2.  Item 2.\n    The numbers are incremented automatically in the output.\n\n## Links and images\n\n&lt;http://example.com&gt;\n\n[linked phrase](http://example.com)\n\n![optional caption text](quarto.png){fig-alt=\"Quarto logo and the word quarto spelled in small case letters\"}\n\n## Tables\n\n| First Header | Second Header |\n|--------------|---------------|\n| Content Cell | Content Cell  |\n| Content Cell | Content Cell  |\n\nLa mejor manera de aprender estos es simplemente probarlos. Tomará algunos días, pero pronto se convertirán en una segunda naturaleza y no necesitará pensar en ellos. Si lo olvida, puede acceder a una práctica hoja de referencia con Help &gt; Markdown Quick Reference.\n\n29.4.1 Ejercicios\n\nPractica lo que has aprendido creando un breve CV. El título debe ser su nombre y debe incluir encabezados para (al menos) educación o empleo. Cada una de las secciones debe incluir una lista con viñetas de trabajos/títulos. Resalta el año en negrita.\n\nCon el editor de código fuente y la referencia rápida de Markdown, descubra cómo:\n\nAñadir una nota al pie.\nAgregue una regla horizontal.\n\n\nAgregue una cita en bloque.\n\n\nCopie y pegue el contenido de diamond-sizes.qmd de https://github.com/hadley/r4ds/tree/main/quarto en un documento R Quarto local. Comprueba que puedes ejecutarlo, luego agrega texto después del polígono de frecuencia que describe sus características más llamativas.\nCree un documento en un documento de Google o MS Word (o busque un documento que haya creado anteriormente) con algún contenido, como encabezados, hipervínculos, texto formateado, etc. Copie el contenido de este documento y péguelo en un documento Quarto en el editor visual. Luego, cambie al editor de código fuente e inspeccione el código fuente.",
    "crumbs": [
      "Comunicar",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#code-chunks",
    "href": "quarto.html#code-chunks",
    "title": "29  Quarto",
    "section": "\n29.5 Code chunks",
    "text": "29.5 Code chunks\nTo run code inside a Quarto document, you need to insert a chunk. There are three ways to do so:\n\nThe keyboard shortcut Cmd + Option + I / Ctrl + Alt + I.\nThe “Insert” button icon in the editor toolbar.\nBy manually typing the chunk delimiters ```{r} and ```.\n\nWe’d recommend you learn the keyboard shortcut. It will save you a lot of time in the long run!\nYou can continue to run the code using the keyboard shortcut that by now (we hope!) you know and love: Cmd/Ctrl + Enter. However, chunks get a new keyboard shortcut: Cmd/Ctrl + Shift + Enter, which runs all the code in the chunk. Think of a chunk like a function. A chunk should be relatively self-contained, and focused around a single task.\nThe following sections describe the chunk header which consists of ```{r}, followed by an optional chunk label and various other chunk options, each on their own line, marked by #|.\n\n29.5.1 Chunk label\nChunks can be given an optional label, e.g.\n\n```{r}\n#| label: simple-addition\n\n1 + 1\n```\n#> [1] 2\n\nThis has three advantages:\n\n\nYou can more easily navigate to specific chunks using the drop-down code navigator in the bottom-left of the script editor:\n\n\n\n\n\n\nGraphics produced by the chunks will have useful names that make them easier to use elsewhere. More on that in Section 29.6.\nYou can set up networks of cached chunks to avoid re-performing expensive computations on every run. More on that in Section 29.8.\n\nYour chunk labels should be short but evocative and should not contain spaces. We recommend using dashes (-) to separate words (instead of underscores, _) and avoiding other special characters in chunk labels.\nYou are generally free to label your chunk however you like, but there is one chunk name that imbues special behavior: setup. When you’re in a notebook mode, the chunk named setup will be run automatically once, before any other code is run.\nAdditionally, chunk labels cannot be duplicated. Each chunk label must be unique.\n\n29.5.2 Chunk options\nChunk output can be customized with options, fields supplied to chunk header. Knitr provides almost 60 options that you can use to customize your code chunks. Here we’ll cover the most important chunk options that you’ll use frequently. You can see the full list at https://yihui.name/knitr/options.\nThe most important set of options controls if your code block is executed and what results are inserted in the finished report:\n\neval: false prevents code from being evaluated. (And obviously if the code is not run, no results will be generated). This is useful for displaying example code, or for disabling a large block of code without commenting each line.\ninclude: false runs the code, but doesn’t show the code or results in the final document. Use this for setup code that you don’t want cluttering your report.\necho: false prevents code, but not the results from appearing in the finished file. Use this when writing reports aimed at people who don’t want to see the underlying R code.\nmessage: false or warning: false prevents messages or warnings from appearing in the finished file.\nresults: hide hides printed output; fig-show: hide hides plots.\nerror: true causes the render to continue even if code returns an error. This is rarely something you’ll want to include in the final version of your report, but can be very useful if you need to debug exactly what is going on inside your .qmd. It’s also useful if you’re teaching R and want to deliberately include an error. The default, error: false causes rendering to fail if there is a single error in the document.\n\nEach of these chunk options get added to the header of the chunk, following #|, e.g. in the following chunk the result is not printed since eval is set to false.\n\n```{r}\n#| label: simple-multiplication\n#| eval: false\n\n2 * 2\n```\n\nThe following table summarizes which types of output each option suppresses:\n\n\n\n\n\n\n\n\n\n\n\nOption\nRun code\nShow code\nOutput\nPlots\nMessages\nWarnings\n\n\n\neval: false\nX\n\nX\nX\nX\nX\n\n\ninclude: false\n\nX\nX\nX\nX\nX\n\n\necho: false\n\nX\n\n\n\n\n\n\nresults: hide\n\n\nX\n\n\n\n\n\nfig-show: hide\n\n\n\nX\n\n\n\n\nmessage: false\n\n\n\n\nX\n\n\n\nwarning: false\n\n\n\n\n\nX\n\n\n\n29.5.3 Global options\nAs you work more with knitr, you will discover that some of the default chunk options don’t fit your needs and you want to change them.\nYou can do this by adding the preferred options in the document YAML, under execute. For example, if you are preparing a report for an audience who does not need to see your code but only your results and narrative, you might set echo: false at the document level. That will hide the code by default, so only showing the chunks you deliberately choose to show (with echo: true). You might consider setting message: false and warning: false, but that would make it harder to debug problems because you wouldn’t see any messages in the final document.\ntitle: \"My report\"\nexecute:\n  echo: false\nSince Quarto is designed to be multi-lingual (works with R as well as other languages like Python, Julia, etc.), all of the knitr options are not available at the document execution level since some of them only work with knitr and not other engines Quarto uses for running code in other languages (e.g. Jupyter). You can, however, still set these as global options for your document under the knitr field, under opts_chunk. For example, when writing books and tutorials we set:\ntitle: \"Tutorial\"\nknitr:\n  opts_chunk:\n    comment: \"#>\"\n    collapse: true\nThis uses our preferred comment formatting and ensures that the code and output are kept closely entwined.\n\n29.5.4 Inline code\nThere is one other way to embed R code into a Quarto document: directly into the text, with: `r `. This can be very useful if you mention properties of your data in the text. For example, the example document used at the start of the chapter had:\n\nWe have data about `r nrow(diamonds)` diamonds. Only `r nrow(diamonds) - nrow(smaller)` are larger than 2.5 carats. The distribution of the remainder is shown below:\n\nWhen the report is rendered, the results of these computations are inserted into the text:\n\nWe have data about 53940 diamonds. Only 126 are larger than 2.5 carats. The distribution of the remainder is shown below:\n\nWhen inserting numbers into text, format() is your friend. It allows you to set the number of digits so you don’t print to a ridiculous degree of accuracy, and a big.mark to make numbers easier to read. You might combine these into a helper function:\n\ncomma <- function(x) format(x, digits = 2, big.mark = \",\")\ncomma(3452345)\n#> [1] \"3,452,345\"\ncomma(.12358124331)\n#> [1] \"0.12\"\n\n\n29.5.5 Exercises\n\nAdd a section that explores how diamond sizes vary by cut, color, and clarity. Assume you’re writing a report for someone who doesn’t know R, and instead of setting echo: false on each chunk, set a global option.\nDownload diamond-sizes.qmd from https://github.com/hadley/r4ds/tree/main/quarto. Add a section that describes the largest 20 diamonds, including a table that displays their most important attributes.\nModify diamonds-sizes.qmd to use label_comma() to produce nicely formatted output. Also include the percentage of diamonds that are larger than 2.5 carats."
  },
  {
    "objectID": "quarto.html#sec-figures",
    "href": "quarto.html#sec-figures",
    "title": "29  Quarto",
    "section": "\n29.6 Figuras",
    "text": "29.6 Figuras\nLas figuras en un documento Quarto se pueden incrustar (por ejemplo, un archivo PNG o JPEG) o generarse como resultado de un fragmento de código.\nPara incrustar una imagen de un archivo externo, puede usar el menú Insertar en el Editor visual en RStudio y seleccionar Figura/Imagen. Esto abrirá un menú emergente donde puede buscar la imagen que desea insertar, así como agregarle un texto alternativo o un título y ajustar su tamaño. En el editor visual también puede simplemente pegar una imagen de su portapapeles en su documento y RStudio colocará una copia de esa imagen en su carpeta de proyecto.\nSi incluye un fragmento de código que genera una figura (por ejemplo, incluye una llamada ggplot()), la figura resultante se incluirá automáticamente en su documento Quarto.\n\n29.6.1 Tamaño de la figura\nEl mayor desafío de los gráficos Quarto es conseguir que las figuras tengan el tamaño y la forma adecuados. Hay cinco opciones principales que controlan el tamaño de la figura: fig-width, fig-height, fig-asp, out-width y out-height. El tamaño de la imagen es un desafío porque hay dos tamaños (el tamaño de la figura creada por R y el tamaño en el que se inserta en el documento de salida) y varias formas de especificar el tamaño (es decir, alto, ancho y relación de aspecto: seleccione dos de tres).\nRecomendamos tres de las cinco opciones:\n\nLas gráficas tienden a ser más agradables estéticamente si tienen un ancho uniforme. Para hacer cumplir esto, configure fig-width: 6 (6”) y fig-asp: 0.618 (la proporción áurea) en los valores predeterminados. Luego, en los fragmentos individuales, solo ajuste fig-asp.\n\nControle el tamaño de salida con out-width y configúrelo en un porcentaje del ancho del cuerpo del documento de salida. Sugerimos out-width: \"70%\" y fig-align: center.\nEso le da a las gráficas espacio para respirar, sin ocupar demasiado espacio.\n\nPara colocar varias gráficas en una sola fila, establezca layout-ncol en 2 para dos gráficas, 3 para tres gráficas, etc. Esto establece efectivamente out-width en “50%” para cada una de sus parcelas si layout-ncol es 2, “33%” si layout-ncol es 3, etc. Dependiendo de lo que esté tratando de ilustrar (por ejemplo, mostrar datos o mostrar variaciones de gráficos), también puede modificar fig-width, como se explica a continuación.\n\nSi encuentra que tiene que entrecerrar los ojos para leer el texto en su gráfica, necesita modificar fig-width. Si fig-width es más grande que el tamaño de la figura en el documento final, el texto será demasiado pequeño; si fig-width es más pequeño, el texto será demasiado grande. A menudo necesitarás hacer un poco de experimentación para encontrar la proporción correcta entre el fig-width y el ancho final en tu documento. Para ilustrar el principio, las siguientes tres gráficas tienen un ancho de figura de 4, 6 y 8 respectivamente:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSi desea asegurarse de que el tamaño de la fuente sea consistente en todas sus figuras, cada vez que configure out-width, también deberá ajustar fig-width para mantener la misma proporción con su out-width predeterminado. Por ejemplo, si su fig-width predeterminado es 6 y out-width es “70%”, cuando establezca out-width: \"50%\", deberá establecer fig-width en 4.3 (6 * 0.5 / 0.7).\nEl dimensionamiento y escalado de figuras es un arte y una ciencia, y hacer las cosas bien puede requerir un enfoque iterativo de prueba y error. Puede obtener más información sobre el tamaño de la figura en la publicación del blog sobre cómo tomar el control de la escala de la gráfica.\n\n29.6.2 Otras opciones importantes\nAl mezclar código y texto, como en este libro, puede configurar fig-show: hold para que los gráficos se muestren después del código. Esto tiene el agradable efecto secundario de obligarte a dividir grandes bloques de código con sus explicaciones.\nPara agregar un título a la gráfica, use fig-cap. En Quarto, esto cambiará la figura de en línea a “floating”.\nSi está produciendo una salida en PDF, el tipo de gráfico predeterminado es PDF. Este es un buen valor predeterminado porque los archivos PDF son gráficos vectoriales de alta calidad. Sin embargo, pueden producir gráficos muy grandes y lentos si muestra miles de puntos. En ese caso, configure fig-format: \"png\" para forzar el uso de PNG. Son de calidad ligeramente inferior, pero serán mucho más compactos.\nEs una buena idea nombrar fragmentos de código que produzcan figuras, incluso si no etiqueta otros fragmentos de forma rutinaria. La etiqueta de fragmento se usa para generar el nombre de archivo del gráfico en el disco, por lo que nombrar sus fragmentos hace que sea mucho más fácil seleccionar gráficos y reutilizarlos en otras circunstancias (es decir, si desea colocar rápidamente un solo gráfico en un correo electrónico).\n\n29.6.3 Ejercicios\n\nAbra diamond-sizes.qmd en el editor visual, busque una imagen de un diamante, cópiela y péguela en el documento. Haga doble clic en la imagen y agregue un título. Cambie el tamaño de la imagen y renderice su documento. Observe cómo se guarda la imagen en su directorio de trabajo actual.\nEdite la etiqueta del fragmento de código en diamond-sizes.qmd que genera un gráfico que comience con el sufijo fig- y agregue un título a la figura con la opción de fragmento fig-cap. Luego, edite el texto sobre el fragmento de código para agregar una referencia cruzada a la figura con Insert &gt; Cross Reference.\n\nCambie el tamaño de la figura con las siguientes opciones de fragmento, una a la vez, renderice su documento y describa cómo cambia la figura.\n\nfig-width: 10\nfig-height: 3\nout-width: \"100%\"\nout-width: \"20%\"",
    "crumbs": [
      "Comunicar",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#tables",
    "href": "quarto.html#tables",
    "title": "29  Quarto",
    "section": "\n29.7 Tables",
    "text": "29.7 Tables\nSimilar to figures, you can include two types of tables in a Quarto document. They can be markdown tables that you create directly in your Quarto document (using the Insert Table menu) or they can be tables generated as a result of a code chunk. In this section we will focus on the latter, tables generated via computation.\nBy default, Quarto prints data frames and matrices as you’d see them in the console:\n\nmtcars[1:5, ]\n#>                    mpg cyl disp  hp drat    wt  qsec vs am gear carb\n#> Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\n#> Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\n#> Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\n#> Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\n#> Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\n\nIf you prefer that data be displayed with additional formatting you can use the knitr::kable() function. The code below generates Table 29.1.\n\nknitr::kable(mtcars[1:5, ], )\n\n\n\nTable 29.1: A knitr kable.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmpg\ncyl\ndisp\nhp\ndrat\nwt\nqsec\nvs\nam\ngear\ncarb\n\n\n\nMazda RX4\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\nMazda RX4 Wag\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\nDatsun 710\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\nHornet 4 Drive\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\nHornet Sportabout\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\n\n\n\n\nRead the documentation for ?knitr::kable to see the other ways in which you can customize the table. For even deeper customization, consider the gt, huxtable, reactable, kableExtra, xtable, stargazer, pander, tables, and ascii packages. Each provides a set of tools for returning formatted tables from R code.\n\n29.7.1 Exercises\n\nOpen diamond-sizes.qmd in the visual editor, insert a code chunk, and add a table with knitr::kable() that shows the first 5 rows of the diamonds data frame.\nDisplay the same table with gt::gt() instead.\nAdd a chunk label that starts with the suffix tbl- and add a caption to the table with the chunk option tbl-cap. Then, edit the text above the code chunk to add a cross-reference to the table with Insert > Cross Reference."
  },
  {
    "objectID": "quarto.html#sec-caching",
    "href": "quarto.html#sec-caching",
    "title": "29  Quarto",
    "section": "\n29.8 Almacenamiento en caché",
    "text": "29.8 Almacenamiento en caché\nNormalmente, cada renderizado de un documento comienza desde cero. Esto es excelente para la reproducibilidad, porque garantiza que haya capturado todos los cálculos importantes en el código. Sin embargo, puede ser doloroso si tiene algunos cálculos que toman mucho tiempo. La solucion es cache: true.\nPuede habilitar el caché de Knitr a nivel de documento para almacenar en caché los resultados de todos los cálculos en un documento usando las opciones estándar de YAML:\n---\ntitle: \"My Document\"\nexecute: \n  cache: true\n---\nTambién puede habilitar el almacenamiento en caché a nivel de fragmento para almacenar en caché los resultados del cálculo en un fragmento específico:\n\n```{r}\n#| cache: true\n\n# código para cálculos largos...\n```\n\nCuando se establece, esto guardará la salida del fragmento en un archivo con un nombre especial en el disco. En ejecuciones posteriores, knitr verificará si el código ha cambiado y, si no es así, reutilizará los resultados almacenados en caché.\nEl sistema de almacenamiento en caché debe usarse con cuidado, ya que, de manera predeterminada, se basa solo en el código, no en sus dependencias. Por ejemplo, aquí el fragmento processed_data depende del fragmento raw-data:\n```{r}\n#| label: raw-data\n#| cache: true\n\nrawdata &lt;- readr::read_csv(\"a_very_large_file.csv\")\n```\n```{r}\n#| label: processed_data\n#| cache: true\n\nprocessed_data &lt;- rawdata |&gt; \n  filter(!is.na(import_var)) |&gt; \n  mutate(new_variable = complicated_transformation(x, y, z))\n```\nAlmacenar en caché el fragmento processed_data significa que se volverá a ejecutar si se cambia la canalización de dplyr, pero no se volverá a ejecutar si cambia la llamada read_csv(). Puede evitar ese problema con la opción de fragmento dependson:\n```{r}\n#| label: processed-data\n#| cache: true\n#| dependson: \"raw-data\"\n\nprocessed_data &lt;- rawdata |&gt; \n  filter(!is.na(import_var)) |&gt; \n  mutate(new_variable = complicated_transformation(x, y, z))\n```\ndependson debe contener un vector de caracteres de cada fragmento del que depende el fragmento almacenado en caché. Knitr actualizará los resultados del fragmento en caché cada vez que detecte que una de sus dependencias ha cambiado.\nTenga en cuenta que los fragmentos no se actualizarán si un_archivo_muy_grande.csv cambia, porque el almacenamiento en caché de knitr solo rastrea los cambios dentro del archivo .qmd. Si también desea realizar un seguimiento de los cambios en ese archivo, puede usar la opción cache.extra. Esta es una expresión R arbitraria que invalidará el caché cada vez que cambie. Una buena función para usar es file.mtime(): regresa cuando fue modificada por última vez. Entonces puedes escribir:\n```{r}\n#| label: raw-data\n#| cache: true\n#| cache.extra: !expr file.mtime(\"a_very_large_file.csv\")\n\nrawdata &lt;- readr::read_csv(\"un_archivo_muy_grande.csv\")\n```\nSeguimos el consejo de David Robinson para nombrar estos fragmentos: cada fragmento lleva el nombre del objeto principal que crea. Esto facilita la comprensión de la especificación dependson.\nA medida que sus estrategias de almacenamiento en caché se vuelven progresivamente más complicadas, es una buena idea borrar regularmente todos sus cachés con knitr::clean_cache().\n\n29.8.1 Ejercicios\n\nConfigure una red de fragmentos donde d dependa de c y b, y tanto b como c dependan de a. Haga que cada fragmento imprima lubridate::now(), configure cache: true y luego verifique su comprensión del almacenamiento en caché.",
    "crumbs": [
      "Comunicar",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#yaml-header",
    "href": "quarto.html#yaml-header",
    "title": "30  Quarto",
    "section": "\n30.9 YAML header",
    "text": "30.9 YAML header\nYou can control many other “whole document” settings by tweaking the parameters of the YAML header. You might wonder what YAML stands for: it’s “YAML Ain’t Markup Language”, which is designed for representing hierarchical data in a way that’s easy for humans to read and write. Quarto uses it to control many details of the output. Here we’ll discuss three: self-contained documents, document parameters, and bibliographies.\n\n30.9.1 Self-contained\nHTML documents typically have a number of external dependencies (e.g. images, CSS style sheets, JavaScript, etc.) and, by default, Quarto places these dependencies in a _files folder in the same directory as your .qmd file. If you publish the HTML file on a hosting platform (e.g. QuartoPub, https://quartopub.com/), the dependencies in this directory are published with your document and hence are available in the published report. However, if you want to email the report to a colleague, you might prefer to have a single, self-contained, HTML document that embeds all of its dependencies. You can do this by specifying the embed-resources option:\nBy default these dependencies are placed in a _files directory alongside your document. For example, if you render report.qmd to HTML:\nformat:\n  html:\n    embed-resources: true\nThe resulting file will be self-contained, such that it will need no external files and no internet access to be displayed properly by a browser.\n\n30.9.2 Parameters\nQuarto documents can include one or more parameters whose values can be set when you render the report. Parameters are useful when you want to re-render the same report with distinct values for various key inputs. For example, you might be producing sales reports per branch, exam results by student, or demographic summaries by country. To declare one or more parameters, use the params field.\nThis example uses a my_class parameter to determine which class of cars to display:\n\n---\noutput: html_document\nparams:\n  my_class: \"suv\"\n---\n\n```{r}\n#| label: setup\n#| include: false\n\nlibrary(tidyverse)\n\nclass <- mpg |> filter(class == params$my_class)\n```\n\n# Fuel economy for `r params$my_class`s\n\n```{r}\n#| message: false\n\nggplot(class, aes(x = displ, y = hwy)) + \n  geom_point() + \n  geom_smooth(se = FALSE)\n```\n\nAs you can see, parameters are available within the code chunks as a read-only list named params.\nYou can write atomic vectors directly into the YAML header. You can also run arbitrary R expressions by prefacing the parameter value with !r. This is a good way to specify date/time parameters.\nparams:\n  start: !r lubridate::ymd(\"2015-01-01\")\n  snapshot: !r lubridate::ymd_hms(\"2015-01-01 12:30:00\")\n\n30.9.3 Bibliographies and Citations\nQuarto can automatically generate citations and a bibliography in a number of styles. The most straightforward way of adding citations and bibliographies to a Quarto document is using the visual editor in RStudio.\nTo add a citation using the visual editor, go to Insert > Citation. Citations can be inserted from a variety of sources:\n\nDOI (Document Object Identifier) references.\nZotero personal or group libraries.\nSearches of Crossref, DataCite, or PubMed.\nYour document bibliography (a .bib file in the directory of your document)\n\nUnder the hood, the visual mode uses the standard Pandoc markdown representation for citations (e.g. [@citation]).\nIf you add a citation using one of the first three methods, the visual editor will automatically create a bibliography.bib file for you and add the reference to it. It will also add a bibliography field to the document YAML. As you add more references, this file will get populated with their citations. You can also directly edit this file using many common bibliography formats including BibLaTeX, BibTeX, EndNote, Medline.\nTo create a citation within your .qmd file in the source editor, use a key composed of ‘@’ + the citation identifier from the bibliography file. Then place the citation in square brackets. Here are some examples:\nSeparate multiple citations with a `;`: Blah blah [@smith04; @doe99].\n\nYou can add arbitrary comments inside the square brackets: \nBlah blah [see @doe99, pp. 33-35; also @smith04, ch. 1].\n\nRemove the square brackets to create an in-text citation: @smith04 \nsays blah, or @smith04 [p. 33] says blah.\n\nAdd a `-` before the citation to suppress the author's name: \nSmith says blah [-@smith04].\nWhen Quarto renders your file, it will build and append a bibliography to the end of your document. The bibliography will contain each of the cited references from your bibliography file, but it will not contain a section heading. As a result it is common practice to end your file with a section header for the bibliography, such as # References or # Bibliography.\nYou can change the style of your citations and bibliography by referencing a CSL (citation style language) file in the csl field:\nbibliography: rmarkdown.bib\ncsl: apa.csl\nAs with the bibliography field, your csl file should contain a path to the file. Here we assume that the csl file is in the same directory as the .qmd file. A good place to find CSL style files for common bibliography styles is https://github.com/citation-style-language/styles."
  },
  {
    "objectID": "quarto.html#workflow",
    "href": "quarto.html#workflow",
    "title": "29  Quarto",
    "section": "\n29.9 Workflow",
    "text": "29.9 Workflow\nEarlier, we discussed a basic workflow for capturing your R code where you work interactively in the console, then capture what works in the script editor. Quarto brings together the console and the script editor, blurring the lines between interactive exploration and long-term code capture. You can rapidly iterate within a chunk, editing and re-executing with Cmd/Ctrl + Shift + Enter. When you’re happy, you move on and start a new chunk.\nQuarto is also important because it so tightly integrates prose and code. This makes it a great analysis notebook because it lets you develop code and record your thoughts. An analysis notebook shares many of the same goals as a classic lab notebook in the physical sciences. It:\n\nRecords what you did and why you did it. Regardless of how great your memory is, if you don’t record what you do, there will come a time when you have forgotten important details. Write them down so you don’t forget!\nSupports rigorous thinking. You are more likely to come up with a strong analysis if you record your thoughts as you go, and continue to reflect on them. This also saves you time when you eventually write up your analysis to share with others.\nHelps others understand your work. It is rare to do data analysis by yourself, and you’ll often be working as part of a team. A lab notebook helps you share not only what you’ve done, but why you did it with your colleagues or lab mates.\n\nMuch of the good advice about using lab notebooks effectively can also be translated to analysis notebooks. We’ve drawn on our own experiences and Colin Purrington’s advice on lab notebooks (https://colinpurrington.com/tips/lab-notebooks) to come up with the following tips:\n\nEnsure each notebook has a descriptive title, an evocative file name, and a first paragraph that briefly describes the aims of the analysis.\n\nUse the YAML header date field to record the date you started working on the notebook:\ndate: 2016-08-23\nUse ISO8601 YYYY-MM-DD format so that’s there no ambiguity. Use it even if you don’t normally write dates that way!\n\nIf you spend a lot of time on an analysis idea and it turns out to be a dead end, don’t delete it! Write up a brief note about why it failed and leave it in the notebook. That will help you avoid going down the same dead end when you come back to the analysis in the future.\nGenerally, you’re better off doing data entry outside of R. But if you do need to record a small snippet of data, clearly lay it out using tibble::tribble().\nIf you discover an error in a data file, never modify it directly, but instead write code to correct the value. Explain why you made the fix.\nBefore you finish for the day, make sure you can render the notebook. If you’re using caching, make sure to clear the caches. That will let you fix any problems while the code is still fresh in your mind.\nIf you want your code to be reproducible in the long-run (i.e. so you can come back to run it next month or next year), you’ll need to track the versions of the packages that your code uses. A rigorous approach is to use renv, https://rstudio.github.io/renv/index.html, which stores packages in your project directory. A quick and dirty hack is to include a chunk that runs sessionInfo() — that won’t let you easily recreate your packages as they are today, but at least you’ll know what they were.\nYou are going to create many, many, many analysis notebooks over the course of your career. How are you going to organize them so you can find them again in the future? We recommend storing them in individual projects, and coming up with a good naming scheme."
  },
  {
    "objectID": "quarto.html#learning-more",
    "href": "quarto.html#learning-more",
    "title": "30  Quarto",
    "section": "\n30.11 Learning more",
    "text": "30.11 Learning more\nQuarto is still relatively young, and is still growing rapidly. The best place to stay on top of innovations is the official Quarto website: https://quarto.org.\nThere are two important topics that we haven’t covered here: collaboration and the details of accurately communicating your ideas to other humans. Collaboration is a vital part of modern data science, and you can make your life much easier by using version control tools, like Git and GitHub. We recommend “Happy Git with R”, a user friendly introduction to Git and GitHub from R users, by Jenny Bryan. The book is freely available online: https://happygitwithr.com.\nWe have also not touched on what you should actually write in order to clearly communicate the results of your analysis. To improve your writing, we highly recommend reading either Style: Lessons in Clarity and Grace by Joseph M. Williams & Joseph Bizup, or The Sense of Structure: Writing from the Reader’s Perspective by George Gopen. Both books will help you understand the structure of sentences and paragraphs, and give you the tools to make your writing more clear. (These books are rather expensive if purchased new, but they’re used by many English classes so there are plenty of cheap second-hand copies). George Gopen also has a number of short articles on writing at https://www.georgegopen.com/the-litigation-articles.html. They are aimed at lawyers, but almost everything applies to data scientists too."
  },
  {
    "objectID": "quarto-formats.html#introduction",
    "href": "quarto-formats.html#introduction",
    "title": "30  Quarto formats",
    "section": "\n30.1 Introduction",
    "text": "30.1 Introduction\nSo far, you’ve seen Quarto used to produce HTML documents. This chapter gives a brief overview of some of the many other types of output you can produce with Quarto.\nThere are two ways to set the output of a document:\n\n\nPermanently, by modifying the YAML header:\ntitle: \"Diamond sizes\"\nformat: html\n\n\nTransiently, by calling quarto::quarto_render() by hand:\n\nquarto::quarto_render(\"diamond-sizes.qmd\", output_format = \"docx\")\n\nThis is useful if you want to programmatically produce multiple types of output since the output_format argument can also take a list of values.\n\nquarto::quarto_render(\"diamond-sizes.qmd\", output_format = c(\"docx\", \"pdf\"))"
  },
  {
    "objectID": "quarto-formats.html#output-options",
    "href": "quarto-formats.html#output-options",
    "title": "30  Quarto formats",
    "section": "\n30.2 Output options",
    "text": "30.2 Output options\nQuarto offers a wide range of output formats. You can find the complete list at https://quarto.org/docs/output-formats/all-formats.html. Many formats share some output options (e.g. toc: true for including a table of contents), but others have options that are format specific (e.g. code-fold: true collapses code chunks into a <details> tag for HTML output so the user can display it on demand, it’s not applicable in a PDF or Word document).\nTo override the default options, you need to use an expanded format field. For example, if you wanted to render an html with a floating table of contents, you’d use:\nformat:\n  html:\n    toc: true\n    toc_float: true\nYou can even render to multiple outputs by supplying a list of formats:\nformat:\n  html:\n    toc: true\n    toc_float: true\n  pdf: default\n  docx: default\nNote the special syntax (pdf: default) if you don’t want to override any default options.\nTo render to all formats specified in the YAML of a document, you can use output_format = \"all\".\n\nquarto::quarto_render(\"diamond-sizes.qmd\", output_format = \"all\")"
  },
  {
    "objectID": "quarto-formats.html#documents",
    "href": "quarto-formats.html#documents",
    "title": "30  Quarto formats",
    "section": "\n30.3 Documents",
    "text": "30.3 Documents\nThe previous chapter focused on the default html output. There are several basic variations on that theme, generating different types of documents. For example:\n\npdf makes a PDF with LaTeX (an open-source document layout system), which you’ll need to install. RStudio will prompt you if you don’t already have it.\ndocx for Microsoft Word (.docx) documents.\nodt for OpenDocument Text (.odt) documents.\nrtf for Rich Text Format (.rtf) documents.\ngfm for a GitHub Flavored Markdown (.md) document.\nipynb for Jupyter Notebooks (.ipynb).\n\nRemember, when generating a document to share with decision-makers, you can turn off the default display of code by setting global options in document YAML:\nexecute:\n  echo: false\nFor html documents another option is to make the code chunks hidden by default, but visible with a click:\nformat:\n  html:\n    code: true"
  },
  {
    "objectID": "quarto-formats.html#presentations",
    "href": "quarto-formats.html#presentations",
    "title": "30  Quarto formats",
    "section": "\n30.4 Presentations",
    "text": "30.4 Presentations\nYou can also use Quarto to produce presentations. You get less visual control than with a tool like Keynote or PowerPoint, but automatically inserting the results of your R code into a presentation can save a huge amount of time. Presentations work by dividing your content into slides, with a new slide beginning at each second (##) level header. Additionally, first (#) level headers indicate the beginning of a new section with a section title slide that is, by default, centered in the middle.\nQuarto supports a variety of presentation formats, including:\n\nrevealjs - HTML presentation with revealjs\npptx - PowerPoint presentation\nbeamer - PDF presentation with LaTeX Beamer.\n\nYou can read more about creating presentations with Quarto at https://quarto.org/docs/presentations."
  },
  {
    "objectID": "quarto-formats.html#dashboards",
    "href": "quarto-formats.html#dashboards",
    "title": "31  Quarto formats",
    "section": "\n31.5 Dashboards",
    "text": "31.5 Dashboards\nDashboards are a useful way to communicate information visually and quickly. A dashboard-like look can be achieved with Quarto using document layout options like sidebars, tabsets, multi-column layouts, etc.\nFor example, you can produce this dashboard:\n\n\n\n\n\nUsing this code:\n\n---\ntitle: \"💍 Diamonds dashboard\"\nformat: html\nexecute:\n  echo: false\n---\n\n```{r}\n#| label: setup\n#| include: false\n\nlibrary(tidyverse)\nlibrary(gt)\n```\n\n::: panel-tabset\n## Plots\n\n```{r}\n#| layout: [[30,-5, 30, -5, 30], [100]]\n\nggplot(diamonds, aes(x = carat)) + geom_histogram(binwidth = 0.1)\nggplot(diamonds, aes(x = price)) + geom_histogram(binwidth = 500)\nggplot(diamonds, aes(x = cut, color = cut)) + geom_bar()\n\nggplot(diamonds, aes(x = carat, y = price, color = cut)) + geom_point()\n```\n\n## Summaries\n\n```{r}\ndiamonds |>\n  select(price, carat, cut) |>\n  group_by(cut) |>\n  summarize(\n    across(where(is.numeric), list(mean = mean, median = median, sd = sd, IQR = IQR))\n  ) |>\n  pivot_longer(cols = -cut) |>\n  pivot_wider(names_from = cut, values_from = value) |>\n  separate(name, into = c(\"var\", \"stat\")) |>\n  mutate(\n    var = str_to_title(var),\n    stat = str_to_title(stat),\n    stat = if_else(stat == \"Iqr\", \"IQR\", stat)\n    ) |>\n  group_by(var) |>\n  gt() |>\n  fmt_currency(columns = -stat, rows = 1:4, decimals = 0) |>\n  fmt_number(columns = -stat, rows = 5:8,) |>\n  cols_align(columns = -stat, align = \"center\") |>\n  cols_label(stat = \"\")\n```\n\n## Data\n\n```{r}\ndiamonds |> \n  arrange(desc(carat)) |> \n  slice_head(n = 100) |> \n  select(price, carat, cut) |> \n  DT::datatable()\n```\n:::\n\nTo learn more about Quarto component layouts, visit https://quarto.org/docs/interactive/layout.html."
  },
  {
    "objectID": "quarto-formats.html#interactivity",
    "href": "quarto-formats.html#interactivity",
    "title": "30  Quarto formats",
    "section": "\n30.5 Interactivity",
    "text": "30.5 Interactivity\nJust like any HTML document, HTML documents created with Quarto can contain interactive components as well. Here we introduce two options for including interactivity in your Quarto documents: htmlwidgets and Shiny.\n\n30.5.1 htmlwidgets\nHTML is an interactive format, and you can take advantage of that interactivity with htmlwidgets, R functions that produce interactive HTML visualizations. For example, take the leaflet map below. If you’re viewing this page on the web, you can drag the map around, zoom in and out, etc. You obviously can’t do that in a book, so Quarto automatically inserts a static screenshot for you.\n\nlibrary(leaflet)\nleaflet() |>\n  setView(174.764, -36.877, zoom = 16) |> \n  addTiles() |>\n  addMarkers(174.764, -36.877, popup = \"Maungawhau\") \n\n\n\n\n\nThe great thing about htmlwidgets is that you don’t need to know anything about HTML or JavaScript to use them. All the details are wrapped inside the package, so you don’t need to worry about it.\nThere are many packages that provide htmlwidgets, including:\n\ndygraphs for interactive time series visualizations.\nDT for interactive tables.\nthreejs for interactive 3d plots.\nDiagrammeR for diagrams (like flow charts and simple node-link diagrams).\n\nTo learn more about htmlwidgets and see a complete list of packages that provide them visit https://www.htmlwidgets.org.\n\n30.5.2 Shiny\nhtmlwidgets provide client-side interactivity — all the interactivity happens in the browser, independently of R. On the one hand, that’s great because you can distribute the HTML file without any connection to R. However, that fundamentally limits what you can do to things that have been implemented in HTML and JavaScript. An alternative approach is to use shiny, a package that allows you to create interactivity using R code, not JavaScript.\nTo call Shiny code from a Quarto document, add server: shiny to the YAML header:\ntitle: \"Shiny Web App\"\nformat: html\nserver: shiny\nThen you can use the “input” functions to add interactive components to the document:\n\nlibrary(shiny)\n\ntextInput(\"name\", \"What is your name?\")\nnumericInput(\"age\", \"How old are you?\", NA, min = 0, max = 150)\n\nAnd you also need a code chunk with chunk option context: server which contains the code that needs to run in a Shiny server.\n\n\n\n\n\nYou can then refer to the values with input$name and input$age, and the code that uses them will be automatically re-run whenever they change.\nWe can’t show you a live shiny app here because shiny interactions occur on the server-side. This means that you can write interactive apps without knowing JavaScript, but you need a server to run them on. This introduces a logistical issue: Shiny apps need a Shiny server to be run online. When you run Shiny apps on your own computer, Shiny automatically sets up a Shiny server for you, but you need a public-facing Shiny server if you want to publish this sort of interactivity online. That’s the fundamental trade-off of shiny: you can do anything in a shiny document that you can do in R, but it requires someone to be running R.\nFor learning more about Shiny, we recommend reading Mastering Shiny by Hadley Wickham, https://mastering-shiny.org."
  },
  {
    "objectID": "quarto-formats.html#websites-and-books",
    "href": "quarto-formats.html#websites-and-books",
    "title": "30  Quarto formats",
    "section": "\n30.6 Websites and books",
    "text": "30.6 Websites and books\nWith a bit of additional infrastructure, you can use Quarto to generate a complete website or book:\n\nPut your .qmd files in a single directory. index.qmd will become the home page.\n\nAdd a YAML file named _quarto.yml that provides the navigation for the site. In this file, set the project type to either book or website, e.g.:\nproject:\n  type: book\n\n\nFor example, the following _quarto.yml file creates a website from three source files: index.qmd (the home page), viridis-colors.qmd, and terrain-colors.qmd.\n\nproject:\n  type: website\n\nwebsite:\n  title: \"A website on color scales\"\n  navbar:\n    left:\n      - href: index.qmd\n        text: Home\n      - href: viridis-colors.qmd\n        text: Viridis colors\n      - href: terrain-colors.qmd\n        text: Terrain colors\n\nThe _quarto.yml file you need for a book is very similarly structured. The following example shows how you can create a book with four chapters that renders to three different outputs (html, pdf, and epub). Once again, the source files are .qmd files.\n\nproject:\n  type: book\n\nbook:\n  title: \"A book on color scales\"\n  author: \"Jane Coloriste\"\n  chapters:\n    - index.qmd\n    - intro.qmd\n    - viridis-colors.qmd\n    - terrain-colors.qmd\n\nformat:\n  html:\n    theme: cosmo\n  pdf: default\n  epub: default\n\nWe recommend that you use an RStudio project for your websites and books. Based on the _quarto.yml file, RStudio will recognize the type of project you’re working on, and add a Built tab to the IDE that you can use to render and preview your websites and books. Both websites and books can also be rendered using quarto::render().\nRead more at https://quarto.org/docs/websites about Quarto websites and https://quarto.org/docs/books about books."
  },
  {
    "objectID": "quarto-formats.html#other-formats",
    "href": "quarto-formats.html#other-formats",
    "title": "30  Quarto formats",
    "section": "\n30.7 Other formats",
    "text": "30.7 Other formats\nQuarto offers even more output formats:\n\nYou can write journal articles using Quarto Journal Templates: https://quarto.org/docs/journals/templates.html.\nYou can output Quarto documents to Jupyter Notebooks with format: ipynb: https://quarto.org/docs/reference/formats/ipynb.html.\n\nSee https://quarto.org/docs/output-formats/all-formats.html for a list of even more formats."
  },
  {
    "objectID": "quarto-formats.html#learning-more",
    "href": "quarto-formats.html#learning-more",
    "title": "31  Quarto formats",
    "section": "\n31.9 Learning more",
    "text": "31.9 Learning more\nTo learn more about effective communication in these different formats, we recommend the following resources:\n\nTo improve your presentation skills, try Presentation Patterns by Neal Ford, Matthew McCollough, and Nathaniel Schutta. It provides a set of effective patterns (both low- and high-level) that you can apply to improve your presentations.\nIf you give academic talks, you might like the Leek group guide to giving talks.\nWe haven’t taken it ourselves, but we’ve heard good things about Matt McGarrity’s online course on public speaking: https://www.coursera.org/learn/public-speaking.\nIf you are creating many dashboards, make sure to read Stephen Few’s Information Dashboard Design: The Effective Visual Communication of Data. It will help you create dashboards that are truly useful, not just pretty to look at.\nEffectively communicating your ideas often benefits from some knowledge of graphic design. Robin Williams’ The Non-Designer’s Design Book is a great place to start."
  },
  {
    "objectID": "numbers.html#introducción",
    "href": "numbers.html#introducción",
    "title": "14  Números",
    "section": "",
    "text": "14.1.1 Requisitos previos\nEste capítulo utiliza principalmente funciones de base R, que están disponibles sin cargar ningún paquete. Pero aún necesitamos el tidyverse porque usaremos estas funciones básicas de R dentro de las funciones de tidyverse como mutate() y filter(). Como en el último capítulo, usaremos ejemplos reales de nycflights13, así como ejemplos de juguetes hechos con c() y tribble().\n\nlibrary(tidyverse)\nlibrary(nycflights13)",
    "crumbs": [
      "Transformar",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Números</span>"
    ]
  },
  {
    "objectID": "numbers.html#haciendo-úmeros",
    "href": "numbers.html#haciendo-úmeros",
    "title": "14  Números",
    "section": "\n14.2 Haciendo úmeros",
    "text": "14.2 Haciendo úmeros\nEn la mayoría de los casos, obtendrá números ya registrados en uno de los tipos numéricos de R: entero o doble. En algunos casos, sin embargo, los encontrará como cadenas, posiblemente porque los creó al girar desde los encabezados de columna o porque algo salió mal en su proceso de importación de datos.\nreadr proporciona dos funciones útiles para analizar cadenas en números: parse_double() y parse_number(). Usa parse_double() cuando tengas números escritos como cadenas:\n\nx &lt;- c(\"1.2\", \"5.6\", \"1e3\")\nparse_double(x)\n#&gt; [1]    1.2    5.6 1000.0\n\nUsa parse_number() cuando la cadena contenga texto no numérico que quieras ignorar. Esto es particularmente útil para datos de moneda y porcentajes:\n\nx &lt;- c(\"$1,234\", \"USD 3,513\", \"59%\")\nparse_number(x)\n#&gt; [1] 1234 3513   59",
    "crumbs": [
      "Transformar",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Números</span>"
    ]
  },
  {
    "objectID": "numbers.html#contar",
    "href": "numbers.html#contar",
    "title": "14  Números",
    "section": "\n14.3 Contar",
    "text": "14.3 Contar\nEs sorprendente la cantidad de ciencia de datos que puede hacer con solo conteos y un poco de aritmética básica, por lo que dplyr se esfuerza por hacer que contar sea lo más fácil posible con count(). Esta función es excelente para realizar exploraciones y comprobaciones rápidas durante el análisis:\n\nflights |&gt; count(dest)\n#&gt; # A tibble: 105 × 2\n#&gt;   dest      n\n#&gt;   &lt;chr&gt; &lt;int&gt;\n#&gt; 1 ABQ     254\n#&gt; 2 ACK     265\n#&gt; 3 ALB     439\n#&gt; 4 ANC       8\n#&gt; 5 ATL   17215\n#&gt; 6 AUS    2439\n#&gt; # ℹ 99 more rows\n\n(A pesar de los consejos en Capítulo 5, generalmente colocamos count() en una sola línea porque generalmente se usa en la consola para verificar rápidamente que un cálculo funciona como se esperaba.)\nSi desea ver los valores más comunes, agregue sort = TRUE:\n\nflights |&gt; count(dest, sort = TRUE)\n#&gt; # A tibble: 105 × 2\n#&gt;   dest      n\n#&gt;   &lt;chr&gt; &lt;int&gt;\n#&gt; 1 ORD   17283\n#&gt; 2 ATL   17215\n#&gt; 3 LAX   16174\n#&gt; 4 BOS   15508\n#&gt; 5 MCO   14082\n#&gt; 6 CLT   14064\n#&gt; # ℹ 99 more rows\n\nY recuerda que si quieres ver todos los valores, puedes usar |&gt; View() o |&gt; print(n = Inf).\nPuede realizar el mismo cálculo “a mano” con group_by(), summarize() y n(). Esto es útil porque le permite calcular otros resúmenes al mismo tiempo:\n\nflights |&gt; \n  group_by(dest) |&gt; \n  summarize(\n    n = n(),\n    delay = mean(arr_delay, na.rm = TRUE)\n  )\n#&gt; # A tibble: 105 × 3\n#&gt;   dest      n delay\n#&gt;   &lt;chr&gt; &lt;int&gt; &lt;dbl&gt;\n#&gt; 1 ABQ     254  4.38\n#&gt; 2 ACK     265  4.85\n#&gt; 3 ALB     439 14.4 \n#&gt; 4 ANC       8 -2.5 \n#&gt; 5 ATL   17215 11.3 \n#&gt; 6 AUS    2439  6.02\n#&gt; # ℹ 99 more rows\n\nn() es una función de resumen especial que no toma ningún argumento y en su lugar accede a información sobre el grupo “actual”. Esto significa que solo funciona dentro de los verbos dplyr:\n\nn()\n#&gt; Error in `n()`:\n#&gt; ! Must only be used inside data-masking verbs like `mutate()`,\n#&gt;   `filter()`, and `group_by()`.\n\nHay un par de variantes de n() y count() que pueden resultarle útiles:\n\n\nn_distinct(x) cuenta el número de valores distintos (únicos) de una o más variables. Por ejemplo, podríamos averiguar qué destinos son atendidos por la mayoría de los transportistas:\n\nflights |&gt; \n  group_by(dest) |&gt; \n  summarize(carriers = n_distinct(carrier)) |&gt; \n  arrange(desc(carriers))\n#&gt; # A tibble: 105 × 2\n#&gt;   dest  carriers\n#&gt;   &lt;chr&gt;    &lt;int&gt;\n#&gt; 1 ATL          7\n#&gt; 2 BOS          7\n#&gt; 3 CLT          7\n#&gt; 4 ORD          7\n#&gt; 5 TPA          7\n#&gt; 6 AUS          6\n#&gt; # ℹ 99 more rows\n\n\n\nUna cuenta ponderada es una suma. Por ejemplo, podría “contar” el número de millas que voló cada avión:\n\nflights |&gt; \n  group_by(tailnum) |&gt; \n  summarize(miles = sum(distance))\n#&gt; # A tibble: 4,044 × 2\n#&gt;   tailnum  miles\n#&gt;   &lt;chr&gt;    &lt;dbl&gt;\n#&gt; 1 D942DN    3418\n#&gt; 2 N0EGMQ  250866\n#&gt; 3 N10156  115966\n#&gt; 4 N102UW   25722\n#&gt; 5 N103US   24619\n#&gt; 6 N104UW   25157\n#&gt; # ℹ 4,038 more rows\n\nLos recuentos ponderados son un problema común, por lo que count() tiene un argumento wt que hace lo mismo:\n\nflights |&gt; count(tailnum, wt = distance)\n\n\n\nPuede contar los valores perdidos combinando sum() y is.na(). En el conjunto de datos de flights, esto representa los vuelos que se cancelan:\n\nflights |&gt; \n  group_by(dest) |&gt; \n  summarize(n_cancelled = sum(is.na(dep_time))) \n#&gt; # A tibble: 105 × 2\n#&gt;   dest  n_cancelled\n#&gt;   &lt;chr&gt;       &lt;int&gt;\n#&gt; 1 ABQ             0\n#&gt; 2 ACK             0\n#&gt; 3 ALB            20\n#&gt; 4 ANC             0\n#&gt; 5 ATL           317\n#&gt; 6 AUS            21\n#&gt; # ℹ 99 more rows\n\n\n\n\n14.3.1 Ejercicios\n\n¿Cómo puedes usar count() para contar las filas de números con un valor faltante para una variable dada?\nExpanda las siguientes llamadas a count() para usar en su lugar group_by(), summarize() y arrange():\n\nflights |&gt; count(dest, sort = TRUE)\nflights |&gt; count(tailnum, wt = distance)",
    "crumbs": [
      "Transformar",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Números</span>"
    ]
  },
  {
    "objectID": "numbers.html#transformaciones-numéricas",
    "href": "numbers.html#transformaciones-numéricas",
    "title": "14  Números",
    "section": "\n14.4 Transformaciones numéricas",
    "text": "14.4 Transformaciones numéricas\nLas funciones de transformación funcionan bien con mutate() porque su salida tiene la misma longitud que la entrada. La gran mayoría de las funciones de transformación ya están integradas en la base R. No es práctico enumerarlos todos, por lo que esta sección mostrará los más útiles. Como ejemplo, aunque R proporciona todas las funciones trigonométricas con las que podría soñar, no las enumeramos aquí porque rara vez se necesitan para la ciencia de datos.\n\n14.4.1 Reglas aritméticas y de reciclaje.\nIntrodujimos los conceptos básicos de aritmética (+, -, *, /, ^) en Capítulo 3 y los hemos usado mucho desde entonces. Estas funciones no necesitan una gran cantidad de explicación porque hacen lo que aprendiste en la escuela primaria. Pero necesitamos hablar brevemente sobre las reglas de reciclaje que determinan lo que sucede cuando los lados izquierdo y derecho tienen diferentes longitudes. Esto es importante para operaciones como flights |&gt; mutate(air_time = air_time / 60) porque hay 336.776 números a la izquierda de / pero solo uno a la derecha.\nR maneja las longitudes que no coinciden reciclando o repitiendo el vector corto. Podemos ver esto en funcionamiento más fácilmente si creamos algunos vectores fuera de un data frame:\n\nx &lt;- c(1, 2, 10, 20)\nx / 5\n#&gt; [1] 0.2 0.4 2.0 4.0\n# is shorthand for\nx / c(5, 5, 5, 5)\n#&gt; [1] 0.2 0.4 2.0 4.0\n\nEn general, solo desea reciclar números individuales (es decir, vectores de longitud 1), pero R reciclará cualquier vector de longitud más corta. Por lo general (pero no siempre) le da una advertencia si el vector más largo no es un múltiplo del más corto:\n\nx * c(1, 2)\n#&gt; [1]  1  4 10 40\nx * c(1, 2, 3)\n#&gt; Warning in x * c(1, 2, 3): longitud de objeto mayor no es múltiplo de la\n#&gt; longitud de uno menor\n#&gt; [1]  1  4 30 20\n\nEstas reglas de reciclaje también se aplican a las comparaciones lógicas (==, &lt;, &lt;=, &gt;, &gt;=, !=) y pueden conducir a un resultado sorprendente si accidentalmente usa == en lugar de %in% y el data frame tiene un número desafortunado de filas. Por ejemplo, tome este código que intenta encontrar todos los vuelos en enero y febrero:\n\nflights |&gt; \n  filter(month == c(1, 2))\n#&gt; # A tibble: 25,977 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      542            540         2      923            850\n#&gt; 3  2013     1     1      554            600        -6      812            837\n#&gt; 4  2013     1     1      555            600        -5      913            854\n#&gt; 5  2013     1     1      557            600        -3      838            846\n#&gt; 6  2013     1     1      558            600        -2      849            851\n#&gt; # ℹ 25,971 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\nEl código se ejecuta sin errores, pero no devuelve lo que desea. Debido a las reglas de reciclaje, encuentra vuelos en filas impares que partieron en enero y vuelos en filas pares que partieron en febrero. Y, lamentablemente, no hay ninguna advertencia porque flights tiene un número par de filas.\nPara protegerlo de este tipo de fallas silenciosas, la mayoría de las funciones de tidyverse utilizan una forma más estricta de reciclaje que solo recicla valores únicos. Desafortunadamente, eso no ayuda aquí, ni en muchos otros casos, porque el cálculo clave lo realiza la función base R ==, no filter().\n\n14.4.2 Mínimo y máximo\nLas funciones aritméticas trabajan con pares de variables. Dos funciones estrechamente relacionadas son pmin() y pmax(), que cuando se les dan dos o más variables devolverán el valor más pequeño o más grande en cada fila:\n\ndf &lt;- tribble(\n  ~x, ~y,\n  1,  3,\n  5,  2,\n  7, NA,\n)\n\ndf |&gt; \n  mutate(\n    min = pmin(x, y, na.rm = TRUE),\n    max = pmax(x, y, na.rm = TRUE)\n  )\n#&gt; # A tibble: 3 × 4\n#&gt;       x     y   min   max\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1     3     1     3\n#&gt; 2     5     2     2     5\n#&gt; 3     7    NA     7     7\n\nTenga en cuenta que estas son diferentes a las funciones de resumen min() y max() que toman múltiples observaciones y devuelven un solo valor. Puedes darte cuenta de que has usado la forma incorrecta cuando todos los mínimos y todos los máximos tienen el mismo valor:\n\ndf |&gt; \n  mutate(\n    min = min(x, y, na.rm = TRUE),\n    max = max(x, y, na.rm = TRUE)\n  )\n#&gt; # A tibble: 3 × 4\n#&gt;       x     y   min   max\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1     3     1     7\n#&gt; 2     5     2     1     7\n#&gt; 3     7    NA     1     7\n\n\n14.4.3 Aritmética modular\nLa aritmética modular es el nombre técnico del tipo de matemática que hacías antes de aprender sobre los lugares decimales, es decir, la división que produce un número entero y un resto. En R, %/% realiza la división de enteros y %% calcula el resto:\n\n1:10 %/% 3\n#&gt;  [1] 0 0 1 1 1 2 2 2 3 3\n1:10 %% 3\n#&gt;  [1] 1 2 0 1 2 0 1 2 0 1\n\nLa aritmética modular es útil para el conjunto de datos flights, porque podemos usarla para desempaquetar la variable sched_dep_time en hour y minute:\n\nflights |&gt; \n  mutate(\n    hour = sched_dep_time %/% 100,\n    minute = sched_dep_time %% 100,\n    .keep = \"used\"\n  )\n#&gt; # A tibble: 336,776 × 3\n#&gt;   sched_dep_time  hour minute\n#&gt;            &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1            515     5     15\n#&gt; 2            529     5     29\n#&gt; 3            540     5     40\n#&gt; 4            545     5     45\n#&gt; 5            600     6      0\n#&gt; 6            558     5     58\n#&gt; # ℹ 336,770 more rows\n\nPodemos combinar eso con el truco mean(is.na(x)) de Sección 13.4 para ver cómo varía la proporción de vuelos cancelados a lo largo del día. Los resultados se muestran en Figura 14.1.\n\nflights |&gt; \n  group_by(hour = sched_dep_time %/% 100) |&gt; \n  summarize(prop_cancelled = mean(is.na(dep_time)), n = n()) |&gt; \n  filter(hour &gt; 1) |&gt; \n  ggplot(aes(x = hour, y = prop_cancelled)) +\n  geom_line(color = \"grey50\") + \n  geom_point(aes(size = n))\n\n\n\n\n\n\nFigura 14.1: Un gráfico de líneas con la hora de salida programada en el eje x y la proporción de vuelos cancelados en el eje y. Las cancelaciones parecen acumularse en el transcurso del día hasta las 8:00 p. m., los vuelos muy tardíos son mucho menos probables de ser cancelado.\n\n\n\n\n\n14.4.4 Logaritmos\nLos logaritmos son una transformación increíblemente útil para manejar datos que varían en varios órdenes de magnitud y convertir el crecimiento exponencial en crecimiento lineal. En R, puede elegir entre tres logaritmos: log() (el logaritmo natural, base e), log2() (base 2) y log10() (base 10). Recomendamos usar log2() o log10(). log2() es fácil de interpretar porque una diferencia de 1 en la escala logarítmica corresponde a duplicar la escala original y una diferencia de -1 corresponde a reducir a la mitad; mientras que log10() es fácil de transformar porque (por ejemplo) 3 es 10^3 = 1000. El inverso de log() es exp(); para calcular el inverso de log2() o log10() necesitará usar 2^ o 10^.\n\n14.4.5 Redondeo\nUsa round(x) para redondear un número al entero más cercano:\n\nround(123.456)\n#&gt; [1] 123\n\nPuede controlar la precisión del redondeo con el segundo argumento dígitos, digits. round(x, digits) se redondea al 10^-n más cercano, por lo que digits = 2 se redondea al 0,01 más cercano. Esta definición es útil porque implica que round(x, -3) se redondeará al millar más cercano, lo que de hecho sucede:\n\nround(123.456, 2)  # dos dígitos\n#&gt; [1] 123.46\nround(123.456, 1)  # un dígito\n#&gt; [1] 123.5\nround(123.456, -1) # redondear a la decena más cercana\n#&gt; [1] 120\nround(123.456, -2) # redondear a la centena más cercana\n#&gt; [1] 100\n\nHay una rareza con round() que parece sorprendente a primera vista:\n\nround(c(1.5, 2.5))\n#&gt; [1] 2 2\n\nround() utiliza lo que se conoce como “redondear la mitad a par” o redondeo bancario: si un número está a medio camino entre dos enteros, se redondeará al entero par. Esta es una buena estrategia porque mantiene el redondeo imparcial: la mitad de todos los 0,5 se redondean hacia arriba y la otra mitad hacia abajo.\nround() se empareja con floor() que siempre redondea hacia abajo y ceiling() que siempre redondea hacia arriba:\n\nx &lt;- 123.456\n\nfloor(x)\n#&gt; [1] 123\nceiling(x)\n#&gt; [1] 124\n\nEstas funciones no tienen un argumento dígitos, digits, por lo que puede reducir, redondear y luego volver a aumentar:\n\n# Redondear hacia abajo a los dos dígitos más cercanos\nfloor(x / 0.01) * 0.01\n#&gt; [1] 123.45\n# Redondea hacia arriba a los dos dígitos más cercanos\nceiling(x / 0.01) * 0.01\n#&gt; [1] 123.46\n\nPuedes usar la misma técnica si quieres round() a un múltiplo de algún otro número:\n\n# Redondea al múltiplo más cercano de 4\nround(x / 4) * 4\n#&gt; [1] 124\n\n# Redondear al 0,25 más cercano\nround(x / 0.25) * 0.25\n#&gt; [1] 123.5\n\n\n14.4.6 Cortar números en rangos\nUse cut()1 para dividir (también conocido como bin) un vector numérico en cubos discretos:\n\nx &lt;- c(1, 2, 5, 10, 15, 20)\ncut(x, breaks = c(0, 5, 10, 15, 20))\n#&gt; [1] (0,5]   (0,5]   (0,5]   (5,10]  (10,15] (15,20]\n#&gt; Levels: (0,5] (5,10] (10,15] (15,20]\n\nLos cortes no necesitan estar espaciados uniformemente:\n\ncut(x, breaks = c(0, 5, 10, 100))\n#&gt; [1] (0,5]    (0,5]    (0,5]    (5,10]   (10,100] (10,100]\n#&gt; Levels: (0,5] (5,10] (10,100]\n\nOpcionalmente, puede proporcionar sus propias etiquetas, labels. Tenga en cuenta que debe haber una etiqueta, labels, menos que rupturas, breaks.\n\ncut(x, \n  breaks = c(0, 5, 10, 15, 20), \n  labels = c(\"sm\", \"md\", \"lg\", \"xl\")\n)\n#&gt; [1] sm sm sm md lg xl\n#&gt; Levels: sm md lg xl\n\nCualquier valor fuera del rango de las rupturas se convertirá en NA:\n\ny &lt;- c(NA, -10, 5, 10, 30)\ncut(y, breaks = c(0, 5, 10, 15, 20))\n#&gt; [1] &lt;NA&gt;   &lt;NA&gt;   (0,5]  (5,10] &lt;NA&gt;  \n#&gt; Levels: (0,5] (5,10] (10,15] (15,20]\n\nConsulte la documentación para ver otros argumentos útiles como right e include.lowest, que controlan si los intervalos son [a, b) o (a, b] y si el intervalo más bajo debe ser [a, b].\n\n14.4.7 Agregados acumulativos y rodantes\nBase R proporciona cumsum(), cumprod(), cummin(), cummax() para ejecutar, o acumular, sumas, productos, mínimos y máximos. dplyr proporciona cummean() para medios acumulativos. Las sumas acumulativas tienden a ser las más importantes en la práctica:\n\nx &lt;- 1:10\ncumsum(x)\n#&gt;  [1]  1  3  6 10 15 21 28 36 45 55\n\nSi necesita agregados rodantes o deslizantes más complejos, pruebe el paquete slider.\n\n14.4.8 Ejercicios\n\nExplique con palabras qué hace cada línea del código utilizado para generar Figura 14.1.\n¿Qué funciones trigonométricas proporciona R? Adivina algunos nombres y busca la documentación. ¿Usan grados o radianes?\n\nActualmente, dep_time y sched_dep_time son convenientes de ver, pero difíciles de calcular porque en realidad no son números continuos. Puede ver el problema básico ejecutando el siguiente código: hay un intervalo entre cada hora.\n\nflights |&gt; \n  filter(month == 1, day == 1) |&gt; \n  ggplot(aes(x = sched_dep_time, y = dep_delay)) +\n  geom_point()\n\nConviértalos a una representación más veraz del tiempo (ya sean horas fraccionarias o minutos desde la medianoche).\n\nRedondea dep_time y arr_time a los cinco minutos más cercanos.",
    "crumbs": [
      "Transformar",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Números</span>"
    ]
  },
  {
    "objectID": "numbers.html#transformaciones-generales",
    "href": "numbers.html#transformaciones-generales",
    "title": "14  Números",
    "section": "\n14.5 Transformaciones generales",
    "text": "14.5 Transformaciones generales\nLas siguientes secciones describen algunas transformaciones generales que se usan a menudo con vectores numéricos, pero que se pueden aplicar a todos los demás tipos de columnas.\n\n14.5.1 Rangos\ndplyr proporciona una serie de funciones de clasificación inspiradas en SQL, pero siempre debe comenzar con dplyr::min_rank(). Utiliza el método típico para tratar los empates, p.ej., 1°, 2°, 2°, 4°.\n\nx &lt;- c(1, 2, 2, 3, 4, NA)\nmin_rank(x)\n#&gt; [1]  1  2  2  4  5 NA\n\nTenga en cuenta que los valores más pequeños obtienen los rangos más bajos; usa desc(x) para dar a los valores más grandes los rangos más pequeños:\n\nmin_rank(desc(x))\n#&gt; [1]  5  3  3  2  1 NA\n\nSi min_rank() no hace lo que necesita, observe las variantes dplyr::row_number(), dplyr::dense_rank(), dplyr::percent_rank() y dplyr:: cume_dist(). Consulte la documentación para obtener más información.\n\ndf &lt;- tibble(x = x)\ndf |&gt; \n  mutate(\n    row_number = row_number(x),\n    dense_rank = dense_rank(x),\n    percent_rank = percent_rank(x),\n    cume_dist = cume_dist(x)\n  )\n#&gt; # A tibble: 6 × 5\n#&gt;       x row_number dense_rank percent_rank cume_dist\n#&gt;   &lt;dbl&gt;      &lt;int&gt;      &lt;int&gt;        &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1     1          1          1         0          0.2\n#&gt; 2     2          2          2         0.25       0.6\n#&gt; 3     2          3          2         0.25       0.6\n#&gt; 4     3          4          3         0.75       0.8\n#&gt; 5     4          5          4         1          1  \n#&gt; 6    NA         NA         NA        NA         NA\n\nPuede lograr muchos de los mismos resultados eligiendo el argumento ties.method adecuado para basar el rank() de R; probablemente también querrá configurar na.last = \"keep\" para mantener NAs como NA.\nrow_number() también se puede usar sin ningún argumento dentro de un verbo dplyr. En este caso, dará el número de la fila “current”. Cuando se combina con %% o %/%, esta puede ser una herramienta útil para dividir datos en grupos de tamaño similar:\n\ndf &lt;- tibble(id = 1:10)\n\ndf |&gt; \n  mutate(\n    row0 = row_number() - 1,\n    three_groups = row0 %% 3,\n    three_in_each_group = row0 %/% 3\n  )\n#&gt; # A tibble: 10 × 4\n#&gt;      id  row0 three_groups three_in_each_group\n#&gt;   &lt;int&gt; &lt;dbl&gt;        &lt;dbl&gt;               &lt;dbl&gt;\n#&gt; 1     1     0            0                   0\n#&gt; 2     2     1            1                   0\n#&gt; 3     3     2            2                   0\n#&gt; 4     4     3            0                   1\n#&gt; 5     5     4            1                   1\n#&gt; 6     6     5            2                   1\n#&gt; # ℹ 4 more rows\n\n\n14.5.2 Compensaciones\ndplyr::lead() y dplyr::lag() le permiten referirse a los valores justo antes o justo después del valor “actual”. Devuelven un vector de la misma longitud que la entrada, rellenado con NA al principio o al final:\n\nx &lt;- c(2, 5, 11, 11, 19, 35)\nlag(x)\n#&gt; [1] NA  2  5 11 11 19\nlead(x)\n#&gt; [1]  5 11 11 19 35 NA\n\n\n\nx - lag(x) te da la diferencia entre el valor actual y el anterior.\n\nx - lag(x)\n#&gt; [1] NA  3  6  0  8 16\n\n\n\nx == lag(x) le indica cuándo cambia el valor actual.\n\nx == lag(x)\n#&gt; [1]    NA FALSE FALSE  TRUE FALSE FALSE\n\n\n\nPuede adelantarse o retrasarse en más de una posición utilizando el segundo argumento, n.\n\n14.5.3 Identificadores consecutivos\nA veces desea iniciar un nuevo grupo cada vez que ocurre algún evento. Por ejemplo, cuando está mirando los datos del sitio web, es común querer dividir los eventos en sesiones, donde comienza una nueva sesión después de un intervalo de más de x minutos desde la última actividad. Por ejemplo, imagina que tienes las veces que alguien visitó un sitio web:\n\nevents &lt;- tibble(\n  time = c(0, 1, 2, 3, 5, 10, 12, 15, 17, 19, 20, 27, 28, 30)\n)\n\nY calculó el tiempo entre cada evento y descubrió si hay una brecha lo suficientemente grande como para calificar:\n\nevents &lt;- events |&gt; \n  mutate(\n    diff = time - lag(time, default = first(time)),\n    has_gap = diff &gt;= 5\n  )\nevents\n#&gt; # A tibble: 14 × 3\n#&gt;    time  diff has_gap\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt;  \n#&gt; 1     0     0 FALSE  \n#&gt; 2     1     1 FALSE  \n#&gt; 3     2     1 FALSE  \n#&gt; 4     3     1 FALSE  \n#&gt; 5     5     2 FALSE  \n#&gt; 6    10     5 TRUE   \n#&gt; # ℹ 8 more rows\n\nPero, ¿cómo pasamos de ese vector lógico a algo que podamos group_by()? cumsum(), de Sección 14.4.7, viene al rescate como brecha, es decir, has_gap es TRUE, incrementará group en uno (?sec-numeric-summaries-of -lógicos):\n\nevents |&gt; mutate(\n  group = cumsum(has_gap)\n)\n#&gt; # A tibble: 14 × 4\n#&gt;    time  diff has_gap group\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt;   &lt;int&gt;\n#&gt; 1     0     0 FALSE       0\n#&gt; 2     1     1 FALSE       0\n#&gt; 3     2     1 FALSE       0\n#&gt; 4     3     1 FALSE       0\n#&gt; 5     5     2 FALSE       0\n#&gt; 6    10     5 TRUE        1\n#&gt; # ℹ 8 more rows\n\nOtro enfoque para crear variables de agrupación es consecutive_id(), que inicia un nuevo grupo cada vez que cambia uno de sus argumentos. Por ejemplo, inspirado por esta pregunta de stackoverflow, imagine que tiene un data frame con un montón de valores repetidos:\n\ndf &lt;- tibble(\n  x = c(\"a\", \"a\", \"a\", \"b\", \"c\", \"c\", \"d\", \"e\", \"a\", \"a\", \"b\", \"b\"),\n  y = c(1, 2, 3, 2, 4, 1, 3, 9, 4, 8, 10, 199)\n)\n\nSi desea conservar la primera fila de cada x repetida, puede usar group_by(), consecutive_id() y slice_head():\n\ndf |&gt; \n  group_by(id = consecutive_id(x)) |&gt; \n  slice_head(n = 1)\n#&gt; # A tibble: 7 × 3\n#&gt; # Groups:   id [7]\n#&gt;   x         y    id\n#&gt;   &lt;chr&gt; &lt;dbl&gt; &lt;int&gt;\n#&gt; 1 a         1     1\n#&gt; 2 b         2     2\n#&gt; 3 c         4     3\n#&gt; 4 d         3     4\n#&gt; 5 e         9     5\n#&gt; 6 a         4     6\n#&gt; # ℹ 1 more row\n\n\n14.5.4 Ejercicios\n\nEncuentre los 10 vuelos más retrasados usando una función de clasificación. ¿Cómo quieres manejar los empates? Lea atentamente la documentación de min_rank().\n¿Qué avión (tailnum) tiene el peor récord de puntualidad?\n¿A qué hora del día debes volar si quieres evitar los retrasos tanto como sea posible?\n¿Qué hace flights |&gt; group_by(dest) |&gt; filter(row_number() &lt; 4)? ¿Qué hace flights |&gt; group_by(dest) |&gt; filter(row_number(dep_delay) &lt; 4)?\nPara cada destino, calcule el total de minutos de retraso. Para cada vuelo, calcule la proporción de la demora total para su destino.\n\nLos retrasos suelen tener una correlación temporal: incluso una vez que se ha resuelto el problema que causó el retraso inicial, los vuelos posteriores se retrasan para permitir que salgan los vuelos anteriores. Utilizando lag(), explore cómo se relaciona el retraso promedio de un vuelo durante una hora con el retraso promedio de la hora anterior.\n\nflights |&gt; \n  mutate(hour = dep_time %/% 100) |&gt; \n  group_by(year, month, day, hour) |&gt; \n  summarize(\n    dep_delay = mean(dep_delay, na.rm = TRUE),\n    n = n(),\n    .groups = \"drop\"\n  ) |&gt; \n  filter(n &gt; 5)\n\n\nMira cada destino. ¿Puedes encontrar vuelos que sean sospechosamente rápidos (es decir, vuelos que representen un posible error de ingreso de datos)? Calcule el tiempo de aire de un vuelo en relación con el vuelo más corto a ese destino. ¿Qué vuelos se retrasaron más en el aire?\nEncuentre todos los destinos en los que vuelan al menos dos transportistas. Utilice esos destinos para obtener una clasificación relativa de los transportistas en función de su desempeño para el mismo destino.",
    "crumbs": [
      "Transformar",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Números</span>"
    ]
  },
  {
    "objectID": "numbers.html#numeric-summaries",
    "href": "numbers.html#numeric-summaries",
    "title": "15  Números",
    "section": "\n15.6 Numeric summaries",
    "text": "15.6 Numeric summaries\nJust using the counts, means, and sums that we’ve introduced already can get you a long way, but R provides many other useful summary functions. Here is a selection that you might find useful.\n\n15.6.1 Center\nSo far, we’ve mostly used mean() to summarize the center of a vector of values. Because the mean is the sum divided by the count, it is sensitive to even just a few unusually high or low values. An alternative is to use the median(), which finds a value that lies in the “middle” of the vector, i.e. 50% of the values is above it and 50% are below it. Depending on the shape of the distribution of the variable you’re interested in, mean or median might be a better measure of center. For example, for symmetric distributions we generally report the mean while for skewed distributions we usually report the median.\nFigure 15.2 compares the mean vs. the median when looking at the hourly vs. median departure delay for each destination. The median delay is always smaller than the mean delay because flights sometimes leave multiple hours late, but never leave multiple hours early.\n\nflights |>\n  group_by(year, month, day) |>\n  summarize(\n    mean = mean(dep_delay, na.rm = TRUE),\n    median = median(dep_delay, na.rm = TRUE),\n    n = n(),\n    .groups = \"drop\"\n  ) |> \n  ggplot(aes(x = mean, y = median)) + \n  geom_abline(slope = 1, intercept = 0, color = \"white\", linewidth = 2) +\n  geom_point()\n\n\n\nFigure 15.2: A scatterplot showing the differences of summarizing hourly depature delay with median instead of mean.\n\n\n\n\nYou might also wonder about the mode, or the most common value. This is a summary that only works well for very simple cases (which is why you might have learned about it in high school), but it doesn’t work well for many real datasets. If the data is discrete, there may be multiple most common values, and if the data is continuous, there might be no most common value because every value is ever so slightly different. For these reasons, the mode tends not to be used by statisticians and there’s no mode function included in base R2.\n\n15.6.2 Minimum, maximum, and quantiles\nWhat if you’re interested in locations other than the center? min() and max() will give you the largest and smallest values. Another powerful tool is quantile() which is a generalization of the median: quantile(x, 0.25) will find the value of x that is greater than 25% of the values, quantile(x, 0.5) is equivalent to the median, and quantile(x, 0.95) will find the value that’s greater than 95% of the values.\nFor the flights data, you might want to look at the 95% quantile of delays rather than the maximum, because it will ignore the 5% of most delayed flights which can be quite extreme.\n\nflights |>\n  group_by(year, month, day) |>\n  summarize(\n    max = max(dep_delay, na.rm = TRUE),\n    q95 = quantile(dep_delay, 0.95, na.rm = TRUE),\n    .groups = \"drop\"\n  )\n#> # A tibble: 365 × 5\n#>    year month   day   max   q95\n#>   <int> <int> <int> <dbl> <dbl>\n#> 1  2013     1     1   853  70.1\n#> 2  2013     1     2   379  85  \n#> 3  2013     1     3   291  68  \n#> 4  2013     1     4   288  60  \n#> 5  2013     1     5   327  41  \n#> 6  2013     1     6   202  51  \n#> # … with 359 more rows\n\n\n15.6.3 Spread\nSometimes you’re not so interested in where the bulk of the data lies, but in how it is spread out. Two commonly used summaries are the standard deviation, sd(x), and the inter-quartile range, IQR(). We won’t explain sd() here since you’re probably already familiar with it, but IQR() might be new — it’s quantile(x, 0.75) - quantile(x, 0.25) and gives you the range that contains the middle 50% of the data.\nWe can use this to reveal a small oddity in the flights data. You might expect the spread of the distance between origin and destination to be zero, since airports are always in the same place. But the code below makes it looks like one airport, EGE, might have moved.\n\nflights |> \n  group_by(origin, dest) |> \n  summarize(\n    distance_sd = IQR(distance), \n    n = n(),\n    .groups = \"drop\"\n  ) |> \n  filter(distance_sd > 0)\n#> # A tibble: 2 × 4\n#>   origin dest  distance_sd     n\n#>   <chr>  <chr>       <dbl> <int>\n#> 1 EWR    EGE             1   110\n#> 2 JFK    EGE             1   103\n\n\n15.6.4 Distributions\nIt’s worth remembering that all of the summary statistics described above are a way of reducing the distribution down to a single number. This means that they’re fundamentally reductive, and if you pick the wrong summary, you can easily miss important differences between groups. That’s why it’s always a good idea to visualize the distribution before committing to your summary statistics.\nFigure 15.3 shows the overall distribution of departure delays. The distribution is so skewed that we have to zoom in to see the bulk of the data. This suggests that the mean is unlikely to be a good summary and we might prefer the median instead.\n\n\n\n\nFigure 15.3: (Left) The histogram of the full data is extremely skewed making it hard to get any details. (Right) Zooming into delays of less than two hours makes it possible to see what’s happening with the bulk of the observations.\n\n\n\n\nIt’s also a good idea to check that distributions for subgroups resemble the whole. Figure 15.4 overlays a frequency polygon for each day. The distributions seem to follow a common pattern, suggesting it’s fine to use the same summary for each day.\n\nflights |>\n  filter(dep_delay < 120) |> \n  ggplot(aes(x = dep_delay, group = interaction(day, month))) + \n  geom_freqpoly(binwidth = 5, alpha = 1/5)\n\n\n\nFigure 15.4: 365 frequency polygons of dep_delay, one for each day. The frequency polygons appear to have the same shape, suggesting that it’s reasonable to compare days by looking at just a few summary statistics.\n\n\n\n\nDon’t be afraid to explore your own custom summaries specifically tailored for the data that you’re working with. In this case, that might mean separately summarizing the flights that left early vs. the flights that left late, or given that the values are so heavily skewed, you might try a log-transformation. Finally, don’t forget what you learned in Section 4.5: whenever creating numerical summaries, it’s a good idea to include the number of observations in each group.\n\n15.6.5 Positions\nThere’s one final type of summary that’s useful for numeric vectors, but also works with every other type of value: extracting a value at a specific position: first(x), last(x), and nth(x, n).\nFor example, we can find the first and last departure for each day:\n\nflights |> \n  group_by(year, month, day) |> \n  summarize(\n    first_dep = first(dep_time, na_rm = TRUE), \n    fifth_dep = nth(dep_time, 5, na_rm = TRUE),\n    last_dep = last(dep_time, na_rm = TRUE)\n  )\n#> `summarise()` has grouped output by 'year', 'month'. You can override using\n#> the `.groups` argument.\n#> # A tibble: 365 × 6\n#> # Groups:   year, month [12]\n#>    year month   day first_dep fifth_dep last_dep\n#>   <int> <int> <int>     <int>     <int>    <int>\n#> 1  2013     1     1       517       554     2356\n#> 2  2013     1     2        42       535     2354\n#> 3  2013     1     3        32       520     2349\n#> 4  2013     1     4        25       531     2358\n#> 5  2013     1     5        14       534     2357\n#> 6  2013     1     6        16       555     2355\n#> # … with 359 more rows\n\n(NB: Because dplyr functions use _ to separate components of function and arguments names, these functions use na_rm instead of na.rm.)\nIf you’re familiar with [, which we’ll come back to in Section 29.2, you might wonder if you ever need these functions. There are three reasons: the default argument allows you to provide a default if the specified position doesn’t exist, the order_by argument allows you to locally override the order of the rows, and the na_rm argument allows you to drop missing values.\nExtracting values at positions is complementary to filtering on ranks. Filtering gives you all variables, with each observation in a separate row:\n\nflights |> \n  group_by(year, month, day) |> \n  mutate(r = min_rank(desc(sched_dep_time))) |> \n  filter(r %in% c(1, max(r)))\n#> # A tibble: 1,195 × 20\n#> # Groups:   year, month, day [365]\n#>    year month   day dep_time sched_…¹ dep_d…² arr_t…³ sched…⁴ arr_d…⁵ carrier\n#>   <int> <int> <int>    <int>    <int>   <dbl>   <int>   <int>   <dbl> <chr>  \n#> 1  2013     1     1      517      515       2     830     819      11 UA     \n#> 2  2013     1     1     2353     2359      -6     425     445     -20 B6     \n#> 3  2013     1     1     2353     2359      -6     418     442     -24 B6     \n#> 4  2013     1     1     2356     2359      -3     425     437     -12 B6     \n#> 5  2013     1     2       42     2359      43     518     442      36 B6     \n#> 6  2013     1     2      458      500      -2     703     650      13 US     \n#> # … with 1,189 more rows, 10 more variables: flight <int>, tailnum <chr>,\n#> #   origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>,\n#> #   minute <dbl>, time_hour <dttm>, r <int>, and abbreviated variable names\n#> #   ¹​sched_dep_time, ²​dep_delay, ³​arr_time, ⁴​sched_arr_time, ⁵​arr_delay\n\n\n15.6.6 With mutate()\n\nAs the names suggest, the summary functions are typically paired with summarize(). However, because of the recycling rules we discussed in Section 15.4.1 they can also be usefully paired with mutate(), particularly when you want do some sort of group standardization. For example:\n\n\nx / sum(x) calculates the proportion of a total.\n\n(x - mean(x)) / sd(x) computes a Z-score (standardized to mean 0 and sd 1).\n\n(x - min(x)) / (max(x) - min(x)) standardizes to range [0, 1].\n\nx / first(x) computes an index based on the first observation.\n\n15.6.7 Exercises\n\nBrainstorm at least 5 different ways to assess the typical delay characteristics of a group of flights. When is mean() useful? When is median() useful? When might you want to use something else? Should you use arrival delay or departure delay? Why might you want to use data from planes?\nWhich destinations show the greatest variation in air speed?\nCreate a plot to further explore the adventures of EGE. Can you find any evidence that the airport moved locations?"
  },
  {
    "objectID": "numbers.html#summary",
    "href": "numbers.html#summary",
    "title": "15  Números",
    "section": "\n15.7 Summary",
    "text": "15.7 Summary\nYou’re already familiar with many tools for working with numbers, and after reading this chapter you now know how to use them in R. You’ve also learned a handful of useful general transformations that are commonly, but not exclusively, applied to numeric vectors like ranks and offsets. Finally, you worked through a number of numeric summaries, and discussed a few of the statistical challenges that you should consider.\nOver the next two chapters, we’ll dive into working with strings with the stringr package. Strings are a big topic so they get two chapters, one on the fundamentals of strings and one on regular expressions."
  },
  {
    "objectID": "preface-2e.html",
    "href": "preface-2e.html",
    "title": "Prefacio a la segunda edición",
    "section": "",
    "text": "¡Bienvenidos a la segunda edición de “R para la Ciencia de Datos”! Esta es una reelaboración importante de la primera edición, eliminando material que ya no creemos que sea útil, agregando material que desearíamos haber incluido en la primera edición y, en general, actualizando el texto y el código para reflejar los cambios en las mejores prácticas. También estamos muy emocionados de dar la bienvenida a un nuevo coautor: Mine Çetinkaya-Rundel, una destacada educadora en ciencia de datos y una de nuestras colegas en Posit (la compañía anteriormente conocida como RStudio).\nA continuación se incluye un breve resumen de los cambios más importantes:\n\nLa primera parte del libro ha sido renombrada como “El juego completo”. El objetivo de esta sección es brindarle los detalles aproximados del “juego completo” de la ciencia de datos antes de sumergirnos en los detalles.\nLa segunda parte del libro es “Visualizar”. Esta parte brinda a las herramientas de visualización de datos y a las mejores prácticas una cobertura más completa en comparación con la primera edición.\nLa tercera parte del libro ahora se llama “Transformar” y gana nuevos capítulos sobre números, vectores lógicos y valores faltantes. Anteriormente, estas eran partes del capítulo de transformación de datos, pero necesitaban mucho más espacio.\nLa cuarta parte del libro se llama “Importar”. Es un nuevo conjunto de capítulos que va más allá de la lectura de archivos de texto sin formato para abarcar ahora el trabajo con hojas de cálculo, la extracción de datos de bases de datos, el trabajo con macrodatos, el rectángulo de datos jerárquicos y la extracción de datos de sitios web.\nLa parte “Programar” continúa, pero se ha reescrito de arriba a abajo para centrarse en las partes más importantes de la escritura e iteración de funciones. La escritura de funciones ahora incluye secciones sobre cómo envolver funciones tidyverse (que se ocupan de los desafíos de la evaluación ordenada), ya que esto se ha vuelto mucho más fácil en los últimos años. Hemos agregado un nuevo capítulo sobre funciones importantes de R Base que es probable que vea al leer el código R que se encuentra en la naturaleza.\nLa parte de modelado ha sido eliminada. Nunca tuvimos suficiente espacio para hacer justicia a las distintas técnicas de modelación por completo, y ahora hay muchos y mejores recursos disponibles. Por lo general, recomendamos utilizar el paquete tidymodels y leer Tidy Modeling with R de Max Kuhn y Julia Silge.\nLa parte de “Comunicación” también continúa, pero presenta Quarto en lugar de R Markdown. Esta edición del libro ha sido escrita en Quarto y es claramente la herramienta del futuro.\n\nOtros cambios incluyen cambiar de la canalización o pipe de Magrittr (%&gt;%) a la canalización base (|&gt;) y cambiar el código fuente del libro de RMarkdown a Quarto."
  },
  {
    "objectID": "data-visualize.html#introducción",
    "href": "data-visualize.html#introducción",
    "title": "2  Visualización de datos",
    "section": "\n2.1 Introducción",
    "text": "2.1 Introducción\n\n“El gráfico simple ha traído más información a la mente del analista de datos que cualquier otro dispositivo.” — John Tukey\n\nR tiene varios sistemas para hacer gráficos, pero ggplot2 es uno de los más elegantes y versátiles. ggplot2 implementa la gramática de gráficos, un sistema coherente para describir y construir gráficos. Con ggplot2, puede hacer más y más rápido aprendiendo un sistema y aplicándolo en muchos lugares.\nEste capítulo le enseñará cómo visualizar sus datos usando ggplot2. Comenzaremos creando un diagrama de dispersión simple y lo usaremos para presentar asignaciones aesthetics y objetos geométricos, los componentes básicos de ggplot2. Luego lo guiaremos a través de la visualización de distribuciones de variables individuales, así como la visualización de relaciones entre dos o más variables. Terminaremos guardando sus gráficas y consejos para la solución de problemas.\n\n2.1.1 Requisitos previos\nEste capítulo se centra en ggplot2, uno de los paquetes principales de tidyverse. Para acceder a los conjuntos de datos, las páginas de ayuda y las funciones utilizadas en este capítulo, cargue tidyverse ejecutando:\n\nlibrary(tidyverse)\n#> Warning: package 'tibble' was built under R version 4.2.3\n#> Warning: package 'readr' was built under R version 4.2.3\n#> Warning: package 'dplyr' was built under R version 4.2.3\n#> ── Attaching core tidyverse packages ───────────────────── tidyverse 2.0.0 ──\n#> ✔ dplyr     1.1.1     ✔ readr     2.1.4\n#> ✔ forcats   1.0.0     ✔ stringr   1.5.0\n#> ✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n#> ✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n#> ✔ purrr     1.0.1     \n#> ── Conflicts ─────────────────────────────────────── tidyverse_conflicts() ──\n#> ✖ dplyr::filter() masks stats::filter()\n#> ✖ dplyr::lag()    masks stats::lag()\n#> ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\nEsa línea de código carga el núcleo tidyverse; los paquetes que utilizará en casi todos los análisis de datos. También le dice qué funciones del tidyverse entran en conflicto con funciones en la base de R (o de otros paquetes que haya cargado) 1.\nSi ejecuta este código y obtiene el mensaje de error there is no package called 'tidyverse', primero deberá instalarlo, luego ejecutar library() una vez más.\n\ninstall.packages(\"tidyverse\")\nlibrary(tidyverse)\n\nSolo necesita instalar un paquete una vez, pero debe cargarlo cada vez que inicie una nueva sesión.\nAdemás de tidyverse, también usaremos el paquete palmerpenguins, que incluye el conjunto de datos penguins que contiene las medidas corporales de los pingüinos en tres islas del archipiélago Palmer, y el paquete ggthemes, que ofrece una paleta de colores segura para daltónicos.\n\nlibrary(palmerpenguins)\nlibrary(ggthemes)"
  },
  {
    "objectID": "data-visualize.html#primeros-pasos",
    "href": "data-visualize.html#primeros-pasos",
    "title": "2  Visualización de datos",
    "section": "\n2.2 Primeros pasos",
    "text": "2.2 Primeros pasos\n¿Los pingüinos con aletas más largas pesan más o menos que los pingüinos con aletas más cortas? Probablemente ya tenga una respuesta, pero intente que su respuesta sea precisa. ¿Cómo es la relación entre la longitud de las aletas y la masa corporal? ¿Es positivo? ¿Negativo? ¿Lineal? ¿No lineal? ¿Varía la relación según la especie del pingüino? Y que tal por la isla donde vive el pinguino. Vamos a crear visualizaciones que podamos usar para responder estas preguntas.\n\n2.2.1 El data frame penguins\n\nPuedes probar tu respuesta con el data frame penguins que se encuentra en palmerpenguins (a.k.a. palmerpenguins::penguins). Un data frame es una colección rectangular de variables (en las columnas) y observaciones (en las filas). penguins contiene observaciones 344 recopiladas y puestas a disposición por la Dra. Kristen Gorman y la Estación Palmer, Antártida LTER2.\nPara facilitar la discusión, definamos algunos términos:\n\nUna variable es una cantidad, calidad o propiedad que puedes medir.\nUn valor es el estado de una variable cuando la mides. El valor de una variable puede cambiar de una medida a otra.\nUna observación es un conjunto de mediciones realizadas en condiciones similares (usualmente realiza todas las mediciones en una observación al mismo tiempo y en el mismo objeto). Una observación contendrá varios valores, cada uno asociado con una variable diferente. A veces nos referiremos a una observación como un punto de datos.\nDatos tabulares es un conjunto de valores, cada uno asociado con una variable y una observación. Los datos tabulares están ordenados si cada valor se coloca en su propia “celda”, cada variable en su propia columna y cada observación en su propia fila.\n\nEn este contexto, una variable se refiere a un atributo de todos los pingüinos y una observación se refiere a todos los atributos de un solo pingüino.\nEscriba el nombre del data frame en la consola y R imprimirá una vista previa de su contenido. Tenga en cuenta que dice “tibble” en la parte superior de esta vista previa. En tidyverse, usamos data frames especiales llamados tibbles sobre los que aprenderá más pronto.\n\npenguins\n#> # A tibble: 344 × 8\n#>   species island   bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n#>   <fct>   <fct>             <dbl>         <dbl>             <int>       <int>\n#> 1 Adelie  Torgers…           39.1          18.7               181        3750\n#> 2 Adelie  Torgers…           39.5          17.4               186        3800\n#> 3 Adelie  Torgers…           40.3          18                 195        3250\n#> 4 Adelie  Torgers…           NA            NA                  NA          NA\n#> 5 Adelie  Torgers…           36.7          19.3               193        3450\n#> 6 Adelie  Torgers…           39.3          20.6               190        3650\n#> # ℹ 338 more rows\n#> # ℹ 2 more variables: sex <fct>, year <int>\n\nEste data frame contiene columnas 8. Para una vista alternativa, donde puede ver todas las variables y las primeras observaciones de cada variable, use glimpse(). O, si está en RStudio, haga clic en el nombre del data frame en el panel Entorno o ejecute View(penguins) para abrir un visor de datos interactivo.\n\nglimpse(penguins)\n#> Rows: 344\n#> Columns: 8\n#> $ species           <fct> Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, A…\n#> $ island            <fct> Torgersen, Torgersen, Torgersen, Torgersen, Torge…\n#> $ bill_length_mm    <dbl> 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.…\n#> $ bill_depth_mm     <dbl> 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.…\n#> $ flipper_length_mm <int> 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, …\n#> $ body_mass_g       <int> 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 347…\n#> $ sex               <fct> male, female, female, NA, female, male, female, m…\n#> $ year              <int> 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2…\n\nEntre las variables en penguins están:\n\nspecies: una especie de pingüino (Adelie, Chinstrap o Gentoo).\nflipper_length_mm: longitud de la aleta de un pingüino, en milímetros.\nbody_mass_g: masa corporal de un pingüino, en gramos.\n\nPara aprender más sobre penguins, abra su página de ayuda ejecutando ?penguins.\n\n2.2.2 Objetivo final\nNuestro objetivo final en este capítulo es recrear la siguiente visualización que muestra la relación entre la longitud de las aletas y la masa corporal de estos pingüinos, teniendo en cuenta la especie del pingüino.\n\n\n\n\n\n\n2.2.3 Creando un ggplot\nRecreemos esta gráfica paso a paso.\nCon ggplot2, comienza una gráfica con la función ggplot(), definiendo un objeto de gráfica al que luego agrega capas. El primer argumento de ggplot() es el conjunto de datos que se usará en el gráfico, por lo que ggplot(data = penguins) crea un gráfico vacío que está preparado para mostrar los datos de penguins, pero como no lo hemos dicho cómo visualizarlo todavía, por ahora está vacío.\n\nggplot(data = penguins)\n\n\n\n\nA continuación, debemos decirle a ggplot() cómo se representará visualmente la información de nuestros datos. El argumento mapping de la función ggplot() define cómo las variables en su conjunto de datos se asignan a las propiedades visuales (aesthetics) de su gráfico. El argumento mapping siempre se define en la función aes(), y los argumentos x e y de aes() especifican qué variables asignar a los ejes x e y. Por ahora, solo asignaremos la longitud de las aletas a la aesthetic x y la masa corporal a la aesthetic y. ggplot2 busca las variables mapeadas en el argumento data, en este caso, penguins.\nLas siguientes gráficas muestran el resultado de agregar estas asignaciones.\n\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g)\n)\n\n\n\n\nNuestro lienzo vacío ahora tiene más estructura: está claro dónde se mostrarán las longitudes de las aletas (en el eje x) y dónde se mostrarán las masas corporales (en el eje y). Pero los propios pingüinos aún no están en la gráfica. Esto se debe a que aún no hemos articulado, en nuestro código, cómo representar las observaciones de nuestro data frame en nuestra gráfica.\nPara hacerlo, necesitamos definir una geom: el objeto geométrico que usa una gráfica para representar datos. Estos objetos geométricos están disponibles en ggplot2 con funciones que comienzan con geom_. La gente a menudo describe las gráfica por el tipo de geom que utiliza la gráfica. Por ejemplo, los gráficos de barras usan geoms de barras (geom_bar()), los gráficos de líneas usan geoms de líneas (geom_line()), los diagramas de caja usan geoms de diagramas de caja (geom_boxplot()), los diagramas de dispersión usan geoms de puntos (geom_point()), y así sucesivamente.\nLa función geom_point() agrega una capa de puntos a su diagrama, lo que crea un diagrama de dispersión. ggplot2 viene con muchas funciones geom, cada una de las cuales agrega un tipo diferente de capa a una gráfica. Aprenderás un montón de geoms a lo largo del libro, particularmente en Chapter 11.\n\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g)\n) +\n  geom_point()\n#> Warning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\nAhora tenemos algo que se parece a lo que podríamos considerar como un “diagrama de dispersión”. Todavía no coincide con nuestra gráfica de “objetivo final”, pero usando esta gráfica podemos comenzar a responder la pregunta que motivó nuestra exploración: “¿Cómo es la relación entre la longitud de las aletas y la masa corporal?” La relación parece ser positiva (a medida que aumenta la longitud de la aleta, también lo hace la masa corporal), bastante lineal (los puntos se agrupan alrededor de una línea en lugar de una curva) y moderadamente fuerte (no hay demasiada dispersión alrededor de esa línea). Los pingüinos con aletas más largas son generalmente más grandes en términos de masa corporal.\nAntes de agregar más capas a este gráfico, hagamos una pausa por un momento y revisemos el mensaje de advertencia que recibimos:\n\nRemoved 2 rows containing missing values (geom_point()).\n\nEstamos viendo este mensaje porque hay dos pingüinos en nuestro conjunto de datos a los que les faltan valores de masa corporal y/o longitud de aleta y ggplot2 no tiene forma de representarlos en el gráfico sin estos dos valores. Al igual que R, ggplot2 se suscribe a la filosofía de que los valores faltantes nunca deben desaparecer en silencio. Este tipo de advertencia es probablemente uno de los tipos de advertencia más comunes que verá cuando trabaje con datos reales: los valores faltantes son un problema muy común y aprenderá más sobre ellos a lo largo del libro, particularmente en ?sec-missing- valores. Para las gráficas restantes en este capítulo, suprimiremos esta advertencia para que no se imprima junto con cada gráfica que hagamos\n\n2.2.4 Agregar estética y capas\nLos diagramas de dispersión son útiles para mostrar la relación entre dos variables numéricas, pero siempre es una buena idea ser escéptico ante cualquier relación aparente entre dos variables y preguntar si puede haber otras variables que expliquen o cambien la naturaleza de esta relación aparente. Por ejemplo, ¿la relación entre la longitud de las aletas y la masa corporal difiere según la especie? Incorporemos las especies a nuestra gráfica y veamos si esto revela alguna información adicional sobre la aparente relación entre estas variables. Haremos esto representando especies con puntos de diferentes colores.\nPara conseguirlo, ¿tendremos que modificar la estética o la geom? Si adivinaste “en el mapeo estético, dentro de aes()”, ¡ya estás aprendiendo a crear visualizaciones de datos con ggplot2! Y si no, no te preocupes. A lo largo del libro, hará muchos más ggplots y tendrá muchas más oportunidades para verificar su intuición a medida que los hace.\n\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g, color = species)\n) +\n  geom_point()\n\n\n\n\nCuando una variable categórica se asigna a una estética, ggplot2 asignará automáticamente un valor único de la estética (aquí, un color único) a cada nivel único de la variable (cada una de las tres especies), un proceso conocido como escalado . ggplot2 también agregará una leyenda que explica qué valores corresponden a qué niveles.\nAhora agreguemos una capa más: una curva suave que muestre la relación entre la masa corporal y la longitud de la aleta. Antes de continuar, consulte el código anterior y piense en cómo podemos agregar esto a nuestra gráfica existente.\nDado que este es un nuevo objeto geométrico que representa nuestros datos, agregaremos un nuevo geom como una capa encima de nuestro punto geom: geom_smooth(). Y especificaremos que queremos dibujar la línea de mejor ajuste en base a un modelo lineal con method = \"lm\".\n\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g, color = species)\n) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n\n\n\nAgregamos líneas con éxito, pero este gráfico no se parece al gráfico de Section 2.2.2, que solo tiene una línea para todo el conjunto de datos en lugar de líneas separadas para cada una de las especies de pingüinos.\nCuando las asignaciones estéticas se definen en ggplot(), en el nivel global, se transmiten a cada una de las capas de geom subsiguientes de la trama. Sin embargo, cada función geom en ggplot2 también puede tomar un argumento mapping, que permite mapeos estéticos en el nivel local que se agregan a los heredados del nivel global. Dado que queremos que los puntos se coloreen en función de las especies, pero no queremos que las líneas se separen para ellos, debemos especificar color = species solo para geom_point().\n\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g)\n) +\n  geom_point(mapping = aes(color = species)) +\n  geom_smooth(method = \"lm\")\n\n\n\n\n¡Voila! Tenemos algo que se parece mucho a nuestro objetivo final, aunque todavía no es perfecto. Todavía necesitamos usar diferentes formas para cada especie de pingüinos y mejorar las etiquetas.\nPor lo general, no es una buena idea representar información usando solo colores en un gráfico, ya que las personas perciben los colores de manera diferente debido a la ceguera al color u otras diferencias en la visión del color. Por lo tanto, además del color, también podemos asignar species a la aesthetic de shape(forma).\n\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g)\n) +\n  geom_point(mapping = aes(color = species, shape = species)) +\n  geom_smooth(method = \"lm\")\n\n\n\n\nTenga en cuenta que la leyenda se actualiza automáticamente para reflejar también las diferentes formas de los puntos.\nY finalmente, podemos mejorar las etiquetas de nuestro gráfico usando la función labs() en una nueva capa. Algunos de los argumentos de labs() pueden explicarse por sí mismos: title agrega un título y subtitle agrega un subtítulo a la gráfica. Otros argumentos coinciden con las asignaciones aesthetics, x es la etiqueta del eje x, y es la etiqueta del eje y, y color y shape definen la etiqueta de la leyenda. Además, podemos mejorar la paleta de colores para que sea segura para los daltónicos con la función scale_color_colorblind() del paquete ggthemes.\n\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g)\n) +\n  geom_point(aes(color = species, shape = species)) +\n  geom_smooth(method = \"lm\") +\n  labs(\n    title = \"Masa corporal y longitud de las aletas\",\n    subtitle = \"Dimensiones para pingüinos Adelia, barbijo y papúa\",\n    x = \"Longitud de la aleta (mm)\", y = \"Masa corporal (g)\",\n    color = \"Especies\", shape = \"Especies\"\n  ) +\n  scale_color_colorblind()\n\n\n\n\n¡Finalmente tenemos una gráfica que encaja perfectamente con nuestro “objetivo final”!\n\n2.2.5 Ejercicios\n\n¿Cuántas filas hay en penguins? ¿Cuántas columnas?\n¿Qué describe la variable bill_ depth_mm en el data frame penguins? Lea la ayuda con ?penguins para averiguarlo.\nHaz un diagrama de dispersión de bill_depth_mm frente a bill_length_mm. Describe la relación entre estas dos variables.\n¿Qué pasa si haces un diagrama de dispersión de species frente a bill_depth_mm? Es decir, haz un diagrama de dispersión con bill_depth_mm en el eje y y bill_length_mm en el eje x. ¿Cuál podría ser una mejor elección de geom?\n\n¿Por qué lo siguiente da un error y cómo lo solucionaría?\n\nggplot(data = penguins) + \n  geom_point()\n\n\n¿Qué hace el argumento na.rm en geom_point()? ¿Cuál es el valor predeterminado del argumento? Cree un diagrama de dispersión en el que utilice con éxito este argumento con valor TRUE.\nAgregue el siguiente título al gráfico que hizo en el ejercicio anterior: “Los datos provienen del paquete palmerpenguins”. Sugerencia: Eche un vistazo a la documentación de labs().\n\nVuelva a crear la siguiente visualización. ¿A qué aesthetic se debe asignar bill_depth_mm? ¿Y debería mapearse a nivel global o a nivel de geom?\n\n\n\n\n\n\n\nEjecute este código en su cabeza y prediga cómo se verá la salida. Luego, ejecuta el código en R y verifica tus predicciones.\n\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g, color = island)\n) +\n  geom_point() +\n  geom_smooth(se = FALSE)\n\n\n\n¿Se verán diferentes estos dos gráficos? ¿Por qué/ por qué no?\n\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g)\n) +\n  geom_point() +\n  geom_smooth()\n\nggplot() +\n  geom_point(\n    data = penguins,\n    mapping = aes(x = flipper_length_mm, y = body_mass_g)\n  ) +\n  geom_smooth(\n    data = penguins,\n    mapping = aes(x = flipper_length_mm, y = body_mass_g)\n  )"
  },
  {
    "objectID": "data-visualize.html#sec-ggplot2-calls",
    "href": "data-visualize.html#sec-ggplot2-calls",
    "title": "2  Visualización de datos",
    "section": "\n2.3 Llamadas ggplot2",
    "text": "2.3 Llamadas ggplot2\nA medida que avancemos desde estas secciones introductorias, pasaremos a una expresión más concisa del código ggplot2. Hasta ahora hemos sido muy explícitos, lo cual es útil cuando estás aprendiendo:\n\nggplot(\n  data = penguins,\n  mapping = aes(x = flipper_length_mm, y = body_mass_g)\n) +\n  geom_point()\n\nPor lo general, los primeros uno o dos argumentos de una función son tan importantes que debe saberlos de memoria. Los dos primeros argumentos de ggplot() son data y mapping; en el resto del libro, no proporcionaremos esos nombres. Eso ahorra escribir y, al reducir la cantidad de texto adicional, hace que sea más fácil ver las diferencias entre los gráficos. Esa es una preocupación de programación realmente importante a la que volveremos en Chapter 27.\nReescribiendo la gráfica anterior de forma más concisa se obtiene:\n\nggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g)) + \n  geom_point()\n\nEn el futuro, también aprenderá sobre pipe, |>, que le permitirá crear esa gráfica con:\n\npenguins |> \n  ggplot(aes(x = flipper_length_mm, y = body_mass_g)) + \n  geom_point()"
  },
  {
    "objectID": "data-visualize.html#visualización-de-distribuciones",
    "href": "data-visualize.html#visualización-de-distribuciones",
    "title": "2  Visualización de datos",
    "section": "\n2.4 Visualización de distribuciones",
    "text": "2.4 Visualización de distribuciones\nCómo visualiza la distribución de una variable depende del tipo de variable: categórica o numérica.\n\n2.4.1 Una variable categórica\nUna variable es categórica si solo puede tomar uno de un pequeño conjunto de valores. Para examinar la distribución de una variable categórica, puede utilizar un gráfico de barras. La altura de las barras muestra cuántas observaciones ocurrieron con cada valor x.\n\nggplot(penguins, aes(x = species)) +\n  geom_bar()\n\n\n\n\nEn gráficos de barras de variables categóricas con niveles no ordenados, como la “especies” de pingüinos anterior, a menudo es preferible reordenar las barras en función de sus frecuencias. Hacerlo requiere transformar la variable en un factor (cómo R maneja los datos categóricos) y luego reordenar los niveles de ese factor.\n\nggplot(penguins, aes(x = fct_infreq(species))) +\n  geom_bar()\n\n\n\n\nAprenderá más sobre factores y funciones para manejar factores (como fct_infreq() que se muestra arriba) en Chapter 18.\n\n2.4.2 Una variable numérica\nUna variable es numérica (o cuantitativa) si puede tomar una amplia gama de valores numéricos, y es sensato sumar, restar o tomar promedios con esos valores. Las variables numéricas pueden ser continuas o discretas.\nUna visualización de uso común para distribuciones de variables continuas es un histograma.\n\nggplot(penguins, aes(x = body_mass_g)) +\n  geom_histogram(binwidth = 200)\n\n\n\n\nUn histograma divide el eje x en contenedores igualmente espaciados y luego usa la altura de una barra para mostrar el número de observaciones que caen en cada contenedor. En el gráfico anterior, la barra más alta muestra que 39 observaciones tienen un valor de body_mass_g entre 3500 y 3700 gramos, que son los bordes izquierdo y derecho de la barra.\nPuede establecer el ancho de los intervalos en un histograma con el argumento binwidth (ancho de barra), que se mide en las unidades de la variable x. Siempre debe explorar una variedad de anchos de bin cuando trabaje con histogramas, ya que diferentes anchos de bin pueden revelar patrones diferentes. En las gráficas a continuación, un ancho de bin de 20 es demasiado estrecho, lo que da como resultado demasiadas barras, lo que dificulta determinar la forma de la distribución. Del mismo modo, un ancho de intervalo de 2000 es demasiado alto, lo que da como resultado que todos los datos se agrupan en solo tres barras y también dificulta determinar la forma de la distribución. Un binwidth de 200 proporciona un equilibrio razonable.\n\nggplot(penguins, aes(x = body_mass_g)) +\n  geom_histogram(binwidth = 20)\nggplot(penguins, aes(x = body_mass_g)) +\n  geom_histogram(binwidth = 2000)\n\n\n\n\n\n\n\n\n\n\n\nUna visualización alternativa para distribuciones de variables numéricas es una gráfica de densidad. Un gráfico de densidad es una versión suavizada de un histograma y una alternativa práctica, particularmente para datos continuos que provienen de una distribución suave subyacente. No entraremos en cómo geom_density() estima la densidad (puede leer más sobre eso en la documentación de la función), pero expliquemos cómo se dibuja la curva de densidad con una analogía. Imagina un histograma hecho de bloques de madera. Luego, imagina que le tiras encima un hilo de espagueti cocido. La forma que tomarán los espaguetis sobre los bloques se puede considerar como la forma de la curva de densidad. Muestra menos detalles que un histograma, pero puede facilitar la obtención rápida de la forma de la distribución, en particular con respecto a las modas y la asimetría.\n\nggplot(penguins, aes(x = body_mass_g)) +\n  geom_density()\n#> Warning: Removed 2 rows containing non-finite values (`stat_density()`).\n\n\n\n\n\n2.4.3 Ejercicios\n\nHaz un gráfico de barras de species de penguins, donde asignas species a la aesthetic y. ¿En qué se diferencia esta gráfica?\n\n¿En qué se diferencian las siguientes dos gráficas? ¿Qué aesthetic, color o fill, es más útil para cambiar el color de las barras?\n\nggplot(penguins, aes(x = species)) +\n  geom_bar(color = \"red\")\n\nggplot(penguins, aes(x = species)) +\n  geom_bar(fill = \"red\")\n\n\n¿Qué hace el argumento bins en geom_histogram()?\nHaz un histograma de la variable carat en el conjunto de datos diamonds que está disponible cuando carga el paquete tidyverse. Experimente con diferentes binwidths. ¿Qué binwidth revela los patrones más interesantes?"
  },
  {
    "objectID": "data-visualize.html#visualizando-relaciones",
    "href": "data-visualize.html#visualizando-relaciones",
    "title": "2  Visualización de datos",
    "section": "\n2.5 Visualizando relaciones",
    "text": "2.5 Visualizando relaciones\nPara visualizar una relación, necesitamos tener al menos dos variables asignadas a la aesthetic de una gráfica. En las siguientes secciones, aprenderá acerca de las gráficas comúnmente utilizadas para visualizar las relaciones entre dos o más variables y las geoms utilizados para crearlas.\n\n2.5.1 Una variable numérica y categórica\nPara visualizar la relación entre una variable numérica y categórica, podemos usar diagramas de caja uno al lado del otro. Un diagrama de caja es un tipo de abreviatura visual para las medidas de posición (percentiles) que describen una distribución. También es útil para identificar posibles valores atípicos. Como se muestra en Figure 2.1, cada diagrama de caja consta de:\n\nUn caja que indica el rango de la mitad central de los datos, una distancia conocida como rango intercuartil (RIC), que se extiende desde el percentil 25 de la distribución hasta el percentil 75. En el medio del cuadro hay una línea que muestra la mediana, es decir, el percentil 50, de la distribución. Estas tres líneas le dan una idea de la dispersión de la distribución y si la distribución es o no simétrica con respecto a la mediana o sesgada hacia un lado.\nPuntos visuales que muestran observaciones que caen más de 1,5 veces el IQR desde cualquier borde del cuadro. Estos puntos periféricos son inusuales, por lo que se grafican individualmente.\nUna línea (o bigote) que se extiende desde cada extremo de la caja y va hasta el punto no atípico más alejado de la distribución.\n\n\n\n\n\nFigure 2.1: Diagrama que muestra cómo se crea un diagrama de caja.\n\n\n\n\nEchemos un vistazo a la distribución de la masa corporal por especie usando geom_boxplot():\n\nggplot(penguins, aes(x = species, y = body_mass_g)) +\n  geom_boxplot()\n\n\n\n\nAlternativamente, podemos hacer gráficas de densidad con geom_density().\n\nggplot(penguins, aes(x = body_mass_g, color = species)) +\n  geom_density(linewidth = 0.75)\n\n\n\n\nTambién hemos personalizado el grosor de las líneas usando el argumento linewidth para que se destaquen un poco más contra el fondo.\nAdicionalmente, podemos asignar species a la estética de color y fill y usar la estética alpha para agregar transparencia a las curvas de densidad rellenas. Esta aesthetic toma valores entre 0 (totalmente transparente) y 1 (totalmente opaco). En la siguiente gráfica está establecido en 0.5.\n\nggplot(penguins, aes(x = body_mass_g, color = species, fill = species)) +\n  geom_density(alpha = 0.5)\n\n\n\n\nTenga en cuenta la terminología que hemos utilizado aquí:\n\n\nAsignamos variables a la aesthetic si queremos que el atributo visual representado por esa aesthetic varíe según los valores de esa variable.\nDe lo contrario, establecemos el valor de una aesthetic.\n\n2.5.2 Dos variables categóricas\nPodemos usar diagramas de barras apiladas para visualizar la relación entre dos variables categóricas. Por ejemplo, los siguientes dos diagramas de barras apiladas muestran la relación entre “isla” y “especies”, o específicamente, visualizan la distribución de “especies” dentro de cada isla.\nEl primer gráfico muestra las frecuencias de cada especie de pingüinos en cada isla y el gráfico de la derecha muestra las frecuencias relativas (proporciones) de cada especie dentro de cada isla (a pesar del eje y etiquetado incorrectamente que dice “count”). El gráfico de frecuencias muestra que hay un número igual de Adelia en cada isla. Pero no tenemos una buena idea del equilibrio porcentual dentro de cada isla. En el gráfico de proporciones, hemos perdido nuestra noción de pingüinos totales, pero hemos ganado la ventaja del “desglose por isla”.\n\nggplot(penguins, aes(x = island, fill = species)) +\n  geom_bar()\n\n\n\n\nEl segundo gráfico es un gráfico de frecuencia relativa, creado al configurar position = \"fill\" en la geom, es más útil para comparar las distribuciones de especies en las islas, ya que no se ve afectado por el número desigual de pingüinos en las islas. Usando este gráfico, podemos ver que todos los pingüinos Gentoo viven en la isla Biscoe y constituyen aproximadamente el 75% de los pingüinos en esa isla, Chinstrap todos viven en la isla Dream y constituyen aproximadamente el 50% de los pingüinos en esa isla, y Adelie vive en las tres islas y componen todos los pingüinos en Torgersen.\n\nggplot(penguins, aes(x = island, fill = species)) +\n  geom_bar(position = \"fill\")\n\n\n\n\nAl crear estos gráficos de barras, asignamos la variable que se separará en barras a la estética x y la variable que cambiará los colores dentro de las barras a la estética fill.\n\n2.5.3 Dos variables numéricas\nHasta ahora has aprendido acerca de diagramas de dispersión (creados con geom_point()) y curvas suaves (creadas con geom_smooth()) para visualizar la relación entre dos variables numéricas. Una gráfica de dispersión es probablemente la gráfica más utilizada para visualizar la relación entre dos variables numéricas.\n\nggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g)) +\n  geom_point()\n\n\n\n\n\n2.5.4 Tres o más variables\nComo vimos en Section 2.2.4, podemos incorporar más variables en una trama asignándolas a una estética adicional. Por ejemplo, en el siguiente diagrama de dispersión, los colores de los puntos representan especies y las formas de los puntos representan islas.\n\nggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g)) +\n  geom_point(aes(color = species, shape = island))\n\n\n\n\nSin embargo, agregar demasiadas asignaciones aesthetics a una gráfica hace que sea desordenada y difícil de entender. Otra forma, que es particularmente útil para las variables categóricas, es dividir su gráfico en facetas, subgráficos que muestran un subconjunto de los datos.\nPara facetar su gráfica por una sola variable, use facet_wrap(). El primer argumento de facet_wrap() es una fórmula3, que se crea con ~ seguido de un nombre de variable. La variable que pasa a facet_wrap() debe ser categórica.\n\nggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g)) +\n  geom_point(aes(color = species, shape = species)) +\n  facet_wrap(~island)\n\n\n\n\nAprenderá sobre muchas otros geoms para visualizar distribuciones de variables y relaciones entre ellas en Chapter 11.\n\n2.5.5 Ejercicios\n\nEl marco de datos mpg que se incluye con el paquete ggplot2 contiene observaciones 234 recopiladas por la Agencia de Protección Ambiental de los EE. ¿Qué variables en mpg son categóricas? ¿Qué variables son númericas? (Sugerencia: escriba ?mpg para leer la documentación del conjunto de datos). ¿Cómo puedes ver esta información cuando ejecutas mpg?\nHaz un diagrama de dispersión de hwy vs. displ usando el data frame mpg. A continuación, asigne una tercera variable numérica a color, luego a size, luego a color y size, luego a shape. ¿Cómo se comportan estas aesthetics de manera diferente para las variables categóricas frente a las numéricas?\nEn el diagrama de dispersión de hwy vs. displ, ¿qué sucede si mapeas una tercera variable a linewidth?\n¿Qué sucede si mapeas la misma variable a múltiples aesthetics?\nHaz un diagrama de dispersión de bill_depth_mm vs. bill_length_mm y colorea los puntos por species. ¿Qué revela la adición de colores por especie sobre la relación entre estas dos variables? ¿Qué pasa con el facetado por especies?\n\n¿Por qué lo siguiente produce dos leyendas separadas? ¿Cómo lo arreglarías para combinar las dos leyendas?\n\nggplot(\n  data = penguins,\n  mapping = aes(\n    x = bill_length_mm, y = bill_depth_mm, \n    color = species, shape = species\n  )\n) +\n  geom_point() +\n  labs(color = \"Especies\")\n\n\n\nCree los dos siguientes diagramas de barras apiladas. ¿Qué pregunta puedes responder con la primera? ¿Qué pregunta puedes responder con la segunda?\n\nggplot(penguins, aes(x = island, fill = species)) +\n  geom_bar(position = \"fill\")\nggplot(penguins, aes(x = species, fill = island)) +\n  geom_bar(position = \"fill\")"
  },
  {
    "objectID": "data-visualize.html#sec-ggsave",
    "href": "data-visualize.html#sec-ggsave",
    "title": "2  Visualización de datos",
    "section": "\n2.6 Guardando tus gráficas",
    "text": "2.6 Guardando tus gráficas\nUna vez que haya creado un gráfico, es posible que desee sacarlo de R guardándolo como una imagen que puede usar en otro lugar. Ese es el trabajo de ggsave(), que guardará el gráfico creado más reciente en el disco:\n\nggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g)) +\n  geom_point()\nggsave(filename = \"penguin-plot.png\")\n\nEsto guardará su gráfica en su directorio de trabajo, un concepto sobre el que aprenderá más en Chapter 9.\nSi no especifica el ancho (argumento width) y la altura (argumento height) se tomarán de las dimensiones del dispositivo del gráfico actual. Para código reproducible, querrá especificarlos. Puede aprender más sobre ggsave() en la documentación.\nEn general, sin embargo, recomendamos que armes tus informes finales utilizando Quarto, un sistema de creación reproducible que te permite intercalar tu código y tu prosa e incluir automáticamente tus gráficas en tus redacciones. Aprenderá más sobre Quarto en Chapter 30.\n\n2.6.1 Ejercicios\n\n\nEjecute las siguientes líneas de código. ¿Cuál de los dos gráficos se guarda como mpg-grafica.png? ¿Por qué?\n\nggplot(mpg, aes(x = class)) +\n  geom_bar()\nggplot(mpg, aes(x = cty, y = hwy)) +\n  geom_point()\nggsave(\"mpg-grafica.png\")\n\n\n¿Qué necesita cambiar en el código anterior para guardar el gráfico como PDF en lugar de PNG? ¿Cómo podría averiguar qué tipos de archivos de imagen funcionarían en ggsave()?"
  },
  {
    "objectID": "data-visualize.html#problemas-comunes",
    "href": "data-visualize.html#problemas-comunes",
    "title": "2  Visualización de datos",
    "section": "\n2.7 Problemas comunes",
    "text": "2.7 Problemas comunes\nA medida que comience a ejecutar el código de R, es probable que tenga problemas. No te preocupes — le pasa a todo el mundo. Todos hemos estado escribiendo código R durante años, ¡pero todos los días seguimos escribiendo código que no funciona en el primer intento!\nComience comparando cuidadosamente el código que está ejecutando con el código del libro. R es extremadamente quisquilloso, y un carácter fuera de lugar puede marcar la diferencia. Asegúrate de que cada ( coincida con un ) y cada \" esté emparejado con otro \". A veces, ejecutará el código y no sucederá nada. Verifique la parte izquierda de su consola: si es un +, significa que R no cree que haya escrito una expresión completa y está esperando que la termine. En este caso, por lo general es fácil volver a empezar desde cero presionando ESCAPE para cancelar el procesamiento del comando actual.\nUn problema común al crear gráficos ggplot2 es colocar el + en el lugar equivocado: tiene que estar al final de la línea, no al principio. En otras palabras, asegúrese de no haber escrito accidentalmente un código como este:\n\nggplot(data = mpg) \n+ geom_point(mapping = aes(x = displ, y = hwy))\n\nSi todavía estás atascado, prueba la ayuda. Puede obtener ayuda sobre cualquier función de R ejecutando ?function_name en la consola, o resaltando el nombre de la función y presionando F1 en RStudio. No se preocupe si la ayuda no parece tan útil; en su lugar, salte a los ejemplos y busque el código que coincida con lo que está tratando de hacer.\nSi eso no ayuda, lea atentamente el mensaje de error. ¡A veces la respuesta estará enterrada allí! Pero cuando eres nuevo en R, incluso si la respuesta está en el mensaje de error, es posible que aún no sepas cómo entenderlo. Otra gran herramienta es Google: intente buscar en Google el mensaje de error, ya que es probable que alguien más haya tenido el mismo problema y haya obtenido ayuda en línea."
  },
  {
    "objectID": "data-visualize.html#resumen",
    "href": "data-visualize.html#resumen",
    "title": "2  Visualización de datos",
    "section": "\n2.8 Resumen",
    "text": "2.8 Resumen\nEn este capítulo, ha aprendido los conceptos básicos de la visualización de datos con ggplot2. Comenzamos con la idea básica que sustenta ggplot2: una visualización es un mapeo de variables en sus datos a propiedades estéticas como posición, color, tamaño y forma. Luego aprendió a aumentar la complejidad y mejorar la presentación de sus gráficos capa por capa. También aprendió sobre las gráficas de uso común para visualizar la distribución de una sola variable, así como para visualizar las relaciones entre dos o más variables, aprovechando mapeos estéticos adicionales y/o dividiendo su gráfica en pequeños múltiplos usando facetas.\nUsaremos visualizaciones una y otra vez a lo largo de este libro, presentaremos nuevas técnicas a medida que las necesitemos y profundizaremos en la creación de visualizaciones con ggplot2 en Chapter 11 a través de Chapter 12.\nCon los conceptos básicos de visualización en su haber, en el próximo capítulo vamos a cambiar un poco de tema y le daremos algunos consejos prácticos sobre el flujo de trabajo. Intercalamos consejos de flujo de trabajo con herramientas de ciencia de datos a lo largo de esta parte del libro porque lo ayudará a mantenerse organizado a medida que escribe cantidades crecientes de código de R."
  },
  {
    "objectID": "layers.html#introducción",
    "href": "layers.html#introducción",
    "title": "10  Capas",
    "section": "\n10.1 Introducción",
    "text": "10.1 Introducción\nEn Chapter 2, aprendió mucho más que solo cómo hacer diagramas de dispersión, gráficos de barras y diagramas de caja. Aprendiste una base que puedes usar para hacer cualquier tipo de gráfico con ggplot2.\nEn este capítulo, ampliará esa base a medida que aprenda sobre la gramática en capas de los gráficos. Comenzaremos con una inmersión más profunda en mapeos estéticos, objetos geométricos y facetas. Luego, aprenderá sobre las transformaciones estadísticas que ggplot2 hace bajo el capó al crear un gráfico. Estas transformaciones se utilizan para calcular nuevos valores para graficar, como las alturas de las barras en un diagrama de barras o las medianas en un diagrama de caja. También aprenderá sobre los ajustes de posición, que modifican cómo se muestran los geoms en sus gráficos. Finalmente, presentaremos brevemente los sistemas de coordenadas.\nNo cubriremos todas las funciones y opciones para cada una de estas capas, pero lo guiaremos a través de la funcionalidad más importante y de uso común proporcionada por ggplot2 y le presentaremos los paquetes que amplían ggplot2.\n\n10.1.1 Requisitos previos\nEste capítulo se centra en ggplot2. Para acceder a los conjuntos de datos, las páginas de ayuda y las funciones utilizadas en este capítulo, cargue tidyverse ejecutando este código:\n\nlibrary(tidyverse)\n#> Warning: package 'tibble' was built under R version 4.2.3\n#> Warning: package 'readr' was built under R version 4.2.3\n#> Warning: package 'dplyr' was built under R version 4.2.3"
  },
  {
    "objectID": "layers.html#asignaciones-de-aesthetic",
    "href": "layers.html#asignaciones-de-aesthetic",
    "title": "10  Capas",
    "section": "\n10.2 Asignaciones de aesthetic",
    "text": "10.2 Asignaciones de aesthetic\n\n“El mayor valor de una imagen es cuando nos obliga a notar lo que nunca esperábamos ver.” — John Tukey\n\nRecuerde que el marco de datos mpg incluido con el paquete ggplot2 contiene observaciones 234 en modelos de automóviles 38.\n\nmpg\n#> # A tibble: 234 × 11\n#>   manufacturer model displ  year   cyl trans    drv     cty   hwy fl    class\n#>   <chr>        <chr> <dbl> <int> <int> <chr>    <chr> <int> <int> <chr> <chr>\n#> 1 audi         a4      1.8  1999     4 auto(l5) f        18    29 p     comp…\n#> 2 audi         a4      1.8  1999     4 manual(… f        21    29 p     comp…\n#> 3 audi         a4      2    2008     4 manual(… f        20    31 p     comp…\n#> 4 audi         a4      2    2008     4 auto(av) f        21    30 p     comp…\n#> 5 audi         a4      2.8  1999     6 auto(l5) f        16    26 p     comp…\n#> 6 audi         a4      2.8  1999     6 manual(… f        18    26 p     comp…\n#> # ℹ 228 more rows\n\nEntre las variables en mpg están:\n\ndispl: Tamaño del motor de un automóvil, en litros. Una variable numérica.\nhwy: La eficiencia de combustible de un automóvil en la carretera, en millas por galón (mpg). Un automóvil con una eficiencia de combustible baja consume más combustible que un automóvil con una eficiencia de combustible alta cuando recorren la misma distancia. Una variable numérica.\nclass: Tipo de coche. Una variable categórica.\n\nComencemos visualizando la relación entre displ y hwy para varias clases de autos. Podemos hacer esto con un diagrama de dispersión donde las variables numéricas se asignan a la estética x e y y la variable categórica se asigna a una estética como color o shape.\n\n# Left\nggplot(mpg, aes(x = displ, y = hwy, color = class)) +\n  geom_point()\n\n# Right\nggplot(mpg, aes(x = displ, y = hwy, shape = class)) +\n  geom_point()\n#> Warning: The shape palette can deal with a maximum of 6 discrete values\n#> because more than 6 becomes difficult to discriminate; you have 7.\n#> Consider specifying shapes manually if you must have them.\n#> Warning: Removed 62 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\nCuando class se asigna a shape, recibimos dos advertencias:\n\n1: The shape palette can deal with a maximum of 6 discrete values because more than 6 becomes difficult to discriminate; you have 7. Consider specifying shapes manually if you must have them.\n2: Removed 62 rows containing missing values (geom_point()).\n\nDado que ggplot2 solo usará seis formas a la vez, de manera predeterminada, los grupos adicionales no se trazarán cuando use la aesthetic shape. La segunda advertencia está relacionada: hay 62 SUV (todoterrenos) en el conjunto de datos y no están representados.\nDe manera similar, también podemos mapear la estética class a size o alpha, que controlan la forma y la transparencia de los puntos, respectivamente.\n\n# Left\nggplot(mpg, aes(x = displ, y = hwy, size = class)) +\n  geom_point()\n#> Warning: Using size for a discrete variable is not advised.\n\n# Right\nggplot(mpg, aes(x = displ, y = hwy, alpha = class)) +\n  geom_point()\n#> Warning: Using alpha for a discrete variable is not advised.\n\n\n\n\n\n\n\n\n\n\n\nAmbos producen advertencias también:\n\nUsing alpha for a discrete variable is not advised.\n\nAsignar una variable discreta (categórica) no ordenada (class) a una aesthetic ordenada (size o alpha) generalmente no es una buena idea porque implica una clasificación que de hecho no existe.\nUna vez que mapeas una aesthetic, ggplot2 se encarga del resto. Selecciona una escala razonable para usar con la aesthetic y construye una leyenda que explica el mapeo entre niveles y valores. Para las aesthetics x e y, ggplot2 no crea una leyenda, pero crea una línea de eje con marcas y una etiqueta. La línea del eje proporciona la misma información que una leyenda; explica el mapeo entre ubicaciones y valores.\nTambién puede establecer las propiedades visuales de su geom manualmente como un argumento de su función geom (fuera de aes()) en lugar de depender de un mapeo de variables para determinar la apariencia. Por ejemplo, podemos hacer que todos los puntos de nuestro gráfico sean azules:\n\nggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_point(color = \"blue\")\n\n\n\n\nAquí, el color no transmite información sobre una variable, sino que solo cambia la apariencia de la gráfica. Deberá elegir un valor que tenga sentido para esa estética:\n\nEl nombre de un color como una cadena de caracteres, por ejemplo, color = \"blue\".\nEl tamaño de un punto en mm, por ejemplo, size = 1.\nLa forma de un punto como un número, por ejemplo, shape = 1, como se muestra en Figure 10.1.\n\n\n\n\n\nFigure 10.1: R tiene 25 formas integradas que se identifican con números. Hay algunos duplicados aparentes: por ejemplo, 0, 15 y 22 son todos cuadrados. La diferencia proviene de la interacción de las asthetics color y fill. Las formas huecas (0–14) tienen un borde determinado por color; las formas sólidas (15–20) se rellenan con color; las formas rellenas (21–24) tienen un borde de color y se rellenan con fill. Las formas se organizan para mantener formas similares una al lado de la otra..\n\n\n\n\nHasta ahora hemos discutido la estética que podemos mapear o establecer en un diagrama de dispersión, cuando usamos un geom_point. Puede obtener más información sobre todas las asignaciones estéticas posibles en la viñeta de especificaciones estéticas en https://ggplot2.tidyverse.org/articles/ggplot2-specs.html.\nLa estética específica que puede usar para una gráfica depende de la geom que use para representar los datos. En la siguiente sección profundizaremos en las geomas.\n\n10.2.1 Ejercicios\n\nCree un diagrama de dispersión de hwy vs. displ donde los puntos son triángulos rellenos de rosa.\n\n¿Por qué el siguiente código no dio como resultado un gráfico con puntos azules?\n\nggplot(mpg) + \n  geom_point(aes(x = displ, y = hwy, color = \"blue\"))\n\n\n¿Qué hace la estética stroke? ¿Con qué formas trabaja? (Pista: usa ?geom_point)\n¿Qué sucede si asigna una estética a algo que no sea un nombre de variable, como aes (color = displ < 5)? Tenga en cuenta que también deberá especificar x e y."
  },
  {
    "objectID": "layers.html#sec-geometric-objects",
    "href": "layers.html#sec-geometric-objects",
    "title": "10  Capas",
    "section": "\n10.3 Objetos geométricos",
    "text": "10.3 Objetos geométricos\n¿En qué se parecen estas dos gráficas?\n\n\n\n\n\n\n\n\n\n\nAmbas gráficas contienen la misma variable x, la misma variable y, y ambas describen los mismos datos. Pero las gráficas no son idénticas. Cada gráfico utiliza un objeto geométrico diferente, geom, para representar los datos. La gráfica de la izquierda usa geom_point, y la gráfica de la derecha usa geom_smooth, una línea suave ajustada a los datos.\nPara cambiar la geom en su gráfico, cambie la función geom que agrega a ggplot(). Por ejemplo, para hacer los diagramas de arriba, puedes usar el siguiente código:\n\n# Left\nggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_point()\n\n# Right\nggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_smooth()\n#> `geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\nCada función geom en ggplot2 toma un argumento mapping, definido localmente en la capa geom o globalmente en la capa ggplot(). Sin embargo, no todas las estéticas funcionan con todas las geom. Puede establecer la forma de un punto, pero no puede establecer la “forma” de una línea. Si lo intenta, ggplot2 ignorará silenciosamente ese mapeo estético. Por otro lado, podría establecer el tipo de línea de una línea. geom_smooth() dibujará una línea diferente, con un tipo de línea diferente, para cada valor único de la variable que asignas al tipo de línea.\n\n# Izquierda\nggplot(mpg, aes(x = displ, y = hwy, shape = drv)) + \n  geom_smooth()\n\n# Derecha\nggplot(mpg, aes(x = displ, y = hwy, linetype = drv)) + \n  geom_smooth()\n\n\n\n\n\n\n\n\n\n\n\nAquí, geom_smooth() separa los autos en tres líneas según su valor drv, que describe el tren de transmisión de un auto. Una línea describe todos los puntos que tienen un valor 4, una línea describe todos los puntos que tienen un valor f y una línea describe todos los puntos que tienen un valor r. Aquí, 4 significa tracción en las cuatro ruedas, f para tracción delantera y r para tracción trasera.\nSi esto suena extraño, podemos hacerlo más claro superponiendo las líneas sobre los datos sin procesar y luego coloreando todo de acuerdo con drv.\n\nggplot(mpg, aes(x = displ, y = hwy, color = drv)) + \n  geom_point() +\n  geom_smooth(aes(linetype = drv))\n\n\n\n\nObserve que este gráfico contiene dos geomas en el mismo gráfico.\nMuchos geoms, como geom_smooth(), utilizan un único objeto geométrico para mostrar varias filas de datos. Para estos geoms, puede establecer la estética group en una variable categórica para dibujar múltiples objetos. ggplot2 dibujará un objeto separado para cada valor único de la variable de agrupación. En la práctica, ggplot2 agrupará automáticamente los datos de estos geoms siempre que asigne una estética a una variable discreta (como en el ejemplo de linetype). Es conveniente confiar en esta característica porque la estética group por sí misma no agrega una leyenda o características distintivas a las geomas.\n\n# Izquierda\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_smooth()\n\n# Centro              \nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_smooth(aes(group = drv))\n\n# Derecha    \nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_smooth(aes(color = drv), show.legend = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSi coloca asignaciones en una función geom, ggplot2 las tratará como asignaciones locales para la capa. Utilizará estas asignaciones para extender o sobrescribir las asignaciones globales solo para esa capa. Esto hace posible mostrar diferentes estéticas en diferentes capas.\n\nggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_point(aes(color = class)) + \n  geom_smooth()\n\n\n\n\nPuede usar la misma idea para especificar datos diferentes para cada capa. Aquí, usamos puntos rojos y círculos abiertos para resaltar los autos de dos plazas. El argumento de datos locales en geom_point() anula el argumento de datos globales en ggplot() solo para esa capa.\n\nggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_point() + \n  geom_point(\n    data = mpg |> filter(class == \"2seater\"), \n    color = \"red\"\n  ) +\n  geom_point(\n    data = mpg |> filter(class == \"2seater\"), \n    shape = \"circle open\", size = 3, color = \"red\"\n  )\n\n\n\n\nLas geomas son los bloques de construcción fundamentales de ggplot2. Puede transformar por completo el aspecto de su gráfico cambiando su geom, y diferentes geoms pueden revelar diferentes características de sus datos. Por ejemplo, el histograma y el diagrama de densidad a continuación revelan que la distribución del kilometraje en carretera es bimodal y sesgada hacia la derecha, mientras que el diagrama de caja revela dos posibles valores atípicos.\n\n# Izquierda\nggplot(mpg, aes(x = hwy)) +\n  geom_histogram(binwidth = 2)\n\n# Centro\nggplot(mpg, aes(x = hwy)) +\n  geom_density()\n\n# Derecha\nggplot(mpg, aes(x = hwy)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot2 proporciona más de 40 geoms, pero estos no cubren todos los gráficos posibles que uno podría hacer. Si necesita un geom diferente, le recomendamos que busque primero en los paquetes de extensión para ver si alguien más ya lo ha implementado (vea https://exts.ggplot2.tidyverse.org/gallery/ para ver una muestra). Por ejemplo, el paquete ggridges (https://wilkelab.org/ggridges) es útil para hacer gráficos de líneas de crestas, que pueden ser útiles para visualizar la densidad de una variable numérica para diferentes niveles de una variable categórica. En la siguiente gráfica, no solo usamos un nuevo geom (geom_density_ridges()), sino que también asignamos la misma variable a múltiples estéticas (drv a y, fill y color) así como establecer una estética (alpha = 0.5) para hacer que las curvas de densidad sean transparentes.\n\nlibrary(ggridges)\n\nggplot(mpg, aes(x = hwy, y = drv, fill = drv, color = drv)) +\n  geom_density_ridges(alpha = 0.5, show.legend = FALSE)\n#> Picking joint bandwidth of 1.28\n\n\n\n\nEl mejor lugar para obtener una descripción completa de todos los geoms que ofrece ggplot2, así como de todas las funciones del paquete, es la página de referencia: https://ggplot2.tidyverse.org/reference. Para obtener más información sobre cualquier geom individual, use la ayuda (por ejemplo, ? geom_smooth).\n\n10.3.1 Ejercicios\n\n¿Qué geom usarías para dibujar un gráfico de líneas? ¿Un diagrama de caja? ¿Un histograma? ¿Un gráfico de áreas?\n\nAnteriormente en este capítulo usamos show.legend sin explicarlo:\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_smooth(aes(color = drv), show.legend = FALSE)\n\n¿Qué hace show.legend = FALSE aquí? ¿Qué pasa si lo quitas? ¿Por qué crees que lo usamos antes?\n\n¿Qué hace el argumento se para geom_smooth()?\n\nVuelva a crear el código R necesario para generar los siguientes gráficos. Tenga en cuenta que siempre que se use una variable categórica en el gráfico, es drv."
  },
  {
    "objectID": "layers.html#facetas",
    "href": "layers.html#facetas",
    "title": "10  Capas",
    "section": "\n10.4 Facetas",
    "text": "10.4 Facetas\nEn Chapter 2, aprendió sobre facetas con facet_wrap(), que divide una gráfica en sub-gráficas, cada una de las cuales muestra un subconjunto de los datos en función de una variable categórica.\n\nggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_point() + \n  facet_wrap(~cyl)\n\n\n\n\nPara facetar su gráfico con la combinación de dos variables, cambie de facet_wrap() a facet_grid(). El primer argumento de facet_grid() también es una fórmula, pero ahora es una fórmula de doble cara: rows ~ cols.\n\nggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_point() + \n  facet_grid(drv ~ cyl)\n\n\n\n\nPor defecto, cada una de las facetas comparte la misma escala y rango para los ejes x e y. Esto es útil cuando desea comparar datos entre facetas, pero puede ser limitante cuando desea visualizar mejor la relación dentro de cada faceta. Establecer el argumento scales en una función de facetado en \"free\" permitirá diferentes escalas de eje tanto en filas como en columnas, \"free_x\" permitirá diferentes escalas en filas y \"free_y\" permitirá diferentes escalas en las columnas.\n\nggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_point() + \n  facet_grid(drv ~ cyl, scales = \"free_y\")\n\n\n\n\n\n10.4.1 Ejercicios\n\n¿Qué sucede si facetas en una variable continua?\n\n¿Qué significan las celdas vacías en el gráfico con facet_grid(drv ~ cyl)? Ejecute el siguiente código. ¿Cómo se relacionan con la gráfica resultante?\n\nggplot(mpg) + \n  geom_point(aes(x = drv, y = cyl))\n\n\n\n¿Qué gráficas hace el siguiente código? ¿Qué hace .?\n\nggplot(mpg) + \n  geom_point(aes(x = displ, y = hwy)) +\n  facet_grid(drv ~ .)\n\nggplot(mpg) + \n  geom_point(aes(x = displ, y = hwy)) +\n  facet_grid(. ~ cyl)\n\n\n\nTome la primera gráfica facetada en esta sección:\n\nggplot(mpg) + \n  geom_point(aes(x = displ, y = hwy)) + \n  facet_wrap(~ class, nrow = 2)\n\n\n\n¿Cuáles son las ventajas de usar facetas en lugar de la estética del color? ¿Cuales son las desventajas? ¿Cómo podría cambiar el equilibrio si tuviera un conjunto de datos más grande?\n\nLee ?facet_wrap. ¿Qué hace nrow? ¿Qué hace ncol? ¿Qué otras opciones controlan el diseño de los paneles individuales? ¿Por qué facet_grid() no tiene argumentos nrow y ncol?\n\n¿Cuál de las siguientes gráficas facilita la comparación del tamaño del motor (displ) entre automóviles con diferentes trenes motrices? ¿Qué dice esto acerca de cuándo colocar una variable de facetado en filas o columnas?\n\nggplot(mpg, aes(x = displ)) + \n  geom_histogram() + \n  facet_grid(drv ~ .)\n\nggplot(mpg, aes(x = displ)) + \n  geom_histogram() +\n  facet_grid(. ~ drv)\n\n\n\nVuelva a crear la siguiente gráfica usando facet_wrap() en lugar de facet_grid(). ¿Cómo cambian las posiciones de las etiquetas de las facetas?\n\nggplot(mpg) + \n  geom_point(aes(x = displ, y = hwy)) +\n  facet_grid(drv ~ .)"
  },
  {
    "objectID": "layers.html#transformaciones-estadísticas",
    "href": "layers.html#transformaciones-estadísticas",
    "title": "10  Capas",
    "section": "\n10.5 Transformaciones estadísticas",
    "text": "10.5 Transformaciones estadísticas\nConsidere un gráfico de barras básico, dibujado con geom_bar() o geom_col(). El siguiente gráfico muestra el número total de diamantes en el conjunto de datos de diamonds, agrupados por corte curt. El conjunto de datos de diamond está en el paquete ggplot2 y contiene información sobre ~54 000 diamantes, incluido el precio price, el quilate carat, el color, la claridad clarity y el corte cut de cada diamante. El gráfico muestra que hay más diamantes disponibles con cortes de alta calidad que con cortes de baja calidad.\n\nggplot(diamonds, aes(x = cut)) + \n  geom_bar()\n\n\n\n\nEn el eje x, el gráfico muestra cut, una variable de diamond. En el eje y, muestra el conteo, ¡pero el conteo no es una variable en diamond! ¿De dónde viene el conteo? Muchos gráficos, como diagramas de dispersión, trazan los valores sin procesar de su conjunto de datos. Otros gráficos, como gráficos de barras, calculan nuevos valores para trazar:\n\nLos gráficos de barras, los histogramas y los polígonos de frecuencia agrupan sus datos y luego trazan los recuentos de contenedores, la cantidad de puntos que caen en cada contenedor.\nLos suavizadores ajustan un modelo a sus datos y luego trazan predicciones del modelo.\nLos diagramas de caja calculan el resumen de cinco números de la distribución y luego muestran ese resumen como un cuadro con formato especial.\n\nEl algoritmo utilizado para calcular nuevos valores para un gráfico se llama stat, abreviatura de transformación estadística. Figure 10.2 muestra cómo funciona este proceso con geom_bar().\n\n\n\n\nFigure 10.2: Cuando creamos un gráfico de barras, primero comenzamos con los datos sin procesar, luego agregarlo para contar el número de observaciones en cada barra, y finalmente mapear esas variables calculadas para trazar las aesthetics.\n\n\n\n\nPuede saber qué estadística usa un geom inspeccionando el valor predeterminado para el argumento stat. Por ejemplo, ?geom_bar muestra que el valor predeterminado para stat es “count”, lo que significa que geom_bar() usa stat_count(). stat_count() está documentado en la misma página que geom_bar(). Si se desplaza hacia abajo, la sección llamada “Variables calculadas” explica que calcula dos nuevas variables: count y prop.\nCada geom tiene una estadística predeterminada; y cada estadística tiene un geom predeterminado. Esto significa que normalmente puede usar geoms sin preocuparse por la transformación estadística subyacente. Sin embargo, hay tres razones por las que podría necesitar usar una estadística explícitamente:\n\n\nEs posible que desee anular la estadística predeterminada. En el siguiente código, cambiamos la estadística de geom_bar() de contar (el valor predeterminado) a identidad. Esto nos permite asignar la altura de las barras a los valores brutos de una variable y.\n\ndiamonds |>\n  count(cut) |>\n  ggplot(aes(x = cut, y = n)) +\n  geom_bar(stat = \"identity\")\n\n\n\n\n\n\nEs posible que desee anular la asignación predeterminada de variables transformadas a estética. Por ejemplo, es posible que desee mostrar un gráfico de barras de proporciones, en lugar de recuentos:\n\nggplot(diamonds, aes(x = cut, y = after_stat(prop), group = 1)) + \n  geom_bar()\n\n\n\n\nPara encontrar las posibles variables que puede calcular la estadística, busque la sección titulada “variables calculadas” en la ayuda de geom_bar().\n\n\nEs posible que desee llamar más la atención sobre la transformación estadística en su código. Por ejemplo, puede usar stat_summary(), que resume los valores de y para cada valor único de x, para llamar la atención sobre el resumen que está calculando:\n\nggplot(diamonds) + \n  stat_summary(\n    aes(x = cut, y = depth),\n    fun.min = min,\n    fun.max = max,\n    fun = median\n  )\n\n\n\n\n\n\nggplot2 proporciona más de 20 estadísticas para su uso. Cada estadística es una función, por lo que puede obtener ayuda de la forma habitual, p. ?stat_bin.\n\n10.5.1 Ejercicios\n\n¿Cuál es el geom predeterminado asociado con stat_summary()? ¿Cómo podría reescribir el diagrama anterior para usar esa función geom en lugar de la función stat?\n¿Qué hace geom_col()? ¿En qué se diferencia de geom_bar()?\nLa mayoría de los geoms y estadísticas vienen en pares que casi siempre se usan en conjunto. Haz una lista de todas las parejas. ¿Qué tienen en común? (Sugerencia: lea la documentación).\n¿Qué variables calcula stat_smooth()? ¿Qué argumentos controlan su comportamiento?\n\nEn nuestro gráfico de barras de proporciones, debemos establecer group = 1. ¿Por qué? En otras palabras, ¿cuál es el problema con estos dos gráficos?\n\nggplot(diamonds, aes(x = cut, y = after_stat(prop))) + \n  geom_bar()\nggplot(diamonds, aes(x = cut, fill = color, y = after_stat(prop))) + \n  geom_bar()"
  },
  {
    "objectID": "layers.html#ajustes-de-posición",
    "href": "layers.html#ajustes-de-posición",
    "title": "10  Capas",
    "section": "\n10.6 Ajustes de posición",
    "text": "10.6 Ajustes de posición\nHay una pieza más de magia asociada con los gráficos de barras. Puede colorear un gráfico de barras utilizando la estética color o, más útil, la estética fill:\n\n# Izquierda\nggplot(mpg, aes(x = drv, color = drv)) + \n  geom_bar()\n\n# Derecha\nggplot(mpg, aes(x = drv, fill = drv)) + \n  geom_bar()\n\n\n\n\n\n\n\n\n\n\n\nTenga en cuenta lo que sucede si asigna la estética de relleno a otra variable, como class: las barras se apilan automáticamente. Cada rectángulo de color representa una combinación de drv y class.\n\nggplot(mpg, aes(x = drv, fill = class)) + \n  geom_bar()\n\n\n\n\nEl apilamiento se realiza automáticamente usando el ajuste de posición especificado por el argumento position. Si no desea un gráfico de barras apiladas, puede usar una de las otras tres opciones: \"identity\", \"dodge\" o \"fill\".\n\n\nposition = \"identity\" colocará cada objeto exactamente donde cae en el contexto del gráfico. Esto no es muy útil para las barras, porque las superpone. Para ver esa superposición, necesitamos hacer que las barras sean ligeramente transparentes configurando alpha en un valor pequeño, o completamente transparentes configurando fill = NA.\n\n# Izquierda\nggplot(mpg, aes(x = drv, fill = class)) +\n  geom_bar(alpha = 1/5, position = \"identity\")\n\n# Derecha\nggplot(mpg, aes(x = drv, color = class)) +  \n  geom_bar(fill = NA, position = \"identity\")\n\n\n\n\n\n\n\n\n\n\n\nEl ajuste de posición de identidad es más útil para geomas 2d, como puntos, donde es el valor predeterminado.\n\nposition = \"fill\" funciona como apilar, pero hace que cada conjunto de barras apiladas tenga la misma altura. Esto facilita la comparación de proporciones entre grupos.\n\nposition = \"dodge\" coloca objetos superpuestos directamente al lado uno del otro. Esto facilita la comparación de valores individuales.\n\n# Izquierda\nggplot(mpg, aes(x = drv, fill = class)) + \n  geom_bar(position = \"fill\")\n\n# Derecha\nggplot(mpg, aes(x = drv, fill = class)) +  \n  geom_bar(position = \"dodge\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nHay otro tipo de ajuste que no es útil para gráficos de barras, pero puede ser muy útil para diagramas de dispersión. Recuerde nuestro primer diagrama de dispersión. ¿Notó que la gráfica muestra solo 126 puntos, aunque hay 234 observaciones en el conjunto de datos?\n\n\n\n\n\nLos valores subyacentes de hwy y displ se redondean para que los puntos aparezcan en una cuadrícula y muchos puntos se superpongan entre sí. Este problema se conoce como overplotting. Este arreglo hace que sea difícil ver la distribución de los datos. ¿Los puntos de datos están repartidos por igual a lo largo del gráfico, o hay una combinación especial de ‘hwy’ y ‘displ’ que contiene 109 valores?\nPuede evitar esta cuadrícula configurando el ajuste de posición en “jitter”. position = \"jitter\" agrega una pequeña cantidad de ruido aleatorio a cada punto. Esto dispersa los puntos porque es probable que dos puntos no reciban la misma cantidad de ruido aleatorio.\n\nggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_point(position = \"jitter\")\n\n\n\n\nAgregar aleatoriedad parece una forma extraña de mejorar su gráfico, pero mientras hace que su gráfico sea menos preciso a escalas pequeñas, hace que su gráfico sea más revelador a escalas grandes. Debido a que esta es una operación tan útil, ggplot2 viene con una forma abreviada de geom_point(position = \"jitter\"): geom_jitter().\nPara obtener más información sobre un ajuste de posición, consulte la página de ayuda asociada con cada ajuste: ?position_dodge, ?position_fill, ?position_identity, ?position_jitter y ?position_stack.\n\n10.6.1 Ejercicios\n\n\n¿Cuál es el problema con la gráfica siguiente? ¿Cómo podrías mejorarlo?\n\nggplot(mpg, aes(x = cty, y = hwy)) + \n  geom_point()\n\n\n\n¿Cuál es, en todo caso, la diferencia entre las dos gráficas? ¿Por qué?\n\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point()\nggplot(mpg, aes(x = displ, y = hwy)) +\n  geom_point(position = \"identity\")\n\n\n¿Qué parámetros de geom_jitter() controlan la cantidad de fluctuación?\nCompare y contraste geom_jitter() con geom_count().\n¿Cuál es el ajuste de posición predeterminado para geom_boxplot()? Cree una visualización del conjunto de datos mpg que lo demuestre."
  },
  {
    "objectID": "layers.html#sistemas-de-coordenadas",
    "href": "layers.html#sistemas-de-coordenadas",
    "title": "10  Capas",
    "section": "\n10.7 Sistemas de coordenadas",
    "text": "10.7 Sistemas de coordenadas\nLos sistemas de coordenadas son probablemente la parte más complicada de ggplot2. El sistema de coordenadas predeterminado es el sistema de coordenadas cartesianas en el que las posiciones x e y actúan de forma independiente para determinar la ubicación de cada punto. Hay otros dos sistemas de coordenadas que ocasionalmente son útiles.\n\n\ncoord_quickmap() establece la relación de aspecto correctamente para los mapas gegráficos. Esto es muy importante si está trazando datos espaciales con ggplot2. No tenemos el espacio para discutir mapas en este libro, pero puede obtener más información en el [capítulo de mapas] (https://ggplot2-book.org/maps.html) de ggplot2: Gráficos elegantes para el análisis de datos .\n\nnz <- map_data(\"nz\")\n\nggplot(nz, aes(x = long, y = lat, group = group)) +\n  geom_polygon(fill = \"white\", color = \"black\")\n\nggplot(nz, aes(x = long, y = lat, group = group)) +\n  geom_polygon(fill = \"white\", color = \"black\") +\n  coord_quickmap()\n\n\n\n\n\n\n\n\n\n\n\n\n\ncoord_polar() utiliza coordenadas polares. Las coordenadas polares revelan una conexión interesante entre un gráfico de barras y un gráfico de Coxcomb.\n\nbar <- ggplot(data = diamonds) + \n  geom_bar(\n    mapping = aes(x = clarity, fill = clarity), \n    show.legend = FALSE,\n    width = 1\n  ) + \n  theme(aspect.ratio = 1)\n\nbar + coord_flip()\nbar + coord_polar()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n10.7.1 Ejercicios\n\nConvierte un gráfico de barras apiladas en un gráfico circular usando coord_polar().\n¿Cuál es la diferencia entre coord_quickmap() y coord_map()?\n\n¿Qué te dice la siguiente gráfica sobre la relación entre mpg en ciudad y en carretera? ¿Por qué es importante coord_fixed()? ¿Qué hace geom_abline()?\n\nggplot(data = mpg, mapping = aes(x = cty, y = hwy)) +\n  geom_point() + \n  geom_abline() +\n  coord_fixed()"
  },
  {
    "objectID": "layers.html#la-gramática-en-capas-de-los-gráficos",
    "href": "layers.html#la-gramática-en-capas-de-los-gráficos",
    "title": "10  Capas",
    "section": "\n10.8 La gramática en capas de los gráficos",
    "text": "10.8 La gramática en capas de los gráficos\nPodemos ampliar la plantilla de gráficos que aprendió en Section 2.3 agregando ajustes de posición, estadísticas, sistemas de coordenadas y facetas:\nggplot(data = <DATA>) + \n  <GEOM_FUNCTION>(\n     mapping = aes(<MAPPINGS>),\n     stat = <STAT>, \n     position = <POSITION>\n  ) +\n  <COORDINATE_FUNCTION> +\n  <FACET_FUNCTION>\nNuestra nueva plantilla toma siete parámetros, las palabras entre paréntesis que aparecen en la plantilla. En la práctica, rara vez necesita proporcionar los siete parámetros para hacer un gráfico porque ggplot2 proporcionará valores predeterminados útiles para todo excepto los datos, las asignaciones y la función geom.\nLos siete parámetros de la plantilla componen la gramática de los gráficos, un sistema formal para la construcción de gráficas. La gramática de los gráficos se basa en la idea de que puede describir de manera única cualquier gráfico como una combinación de un conjunto de datos, una geom, un conjunto de asignaciones, una estadística, un ajuste de posición, un sistema de coordenadas y un esquema de facetas y un tema.\nPara ver cómo funciona esto, considere cómo podría construir un gráfico básico desde cero: podría comenzar con un conjunto de datos y luego transformarlo en la información que desea mostrar (con una estadística). A continuación, podría elegir un objeto geométrico para representar cada observación en los datos transformados. Luego podría usar las propiedades estéticas de los geoms para representar variables en los datos. Asignaría los valores de cada variable a los niveles de una estética. Estos pasos se ilustran en Figure 10.3. Luego, seleccionaría un sistema de coordenadas para colocar los geomas, utilizando la ubicación de los objetos (que en sí misma es una propiedad estética) para mostrar los valores de las variables x e y.\n\n\n\n\nFigure 10.3: Pasos para pasar de datos sin procesar a una tabla de frecuencias a un gráfico de barras donde las alturas de la barra representan las frecuencias.\n\n\n\n\nEn este punto, tendría un gráfico completo, pero podría ajustar aún más las posiciones de las geomas dentro del sistema de coordenadas (un ajuste de posición) o dividir el gráfico en subgráficos (facetas). También puede ampliar el gráfico agregando una o más capas adicionales, donde cada capa adicional utiliza un conjunto de datos, una geom, un conjunto de asignaciones, una estadística y un ajuste de posición.\nPodrías usar este método para construir cualquier gráfico que imagines. En otras palabras, puede usar la plantilla de código que aprendió en este capítulo para crear cientos de miles de gráficos únicos.\nSi desea obtener más información sobre los fundamentos teóricos de ggplot2, puede disfrutar leyendo “La gramática en capas de los gráficos”, el artículo científico que describe la teoría de ggplot2 en detalle."
  },
  {
    "objectID": "layers.html#resumen",
    "href": "layers.html#resumen",
    "title": "10  Capas",
    "section": "\n10.9 Resumen",
    "text": "10.9 Resumen\nEn este capítulo, aprendió sobre la gramática en capas de los gráficos, comenzando con la estética y las geometrías para construir un gráfico simple, facetas para dividir el gráfico en subconjuntos, estadísticas para comprender cómo se calculan los geoms, ajustes de posición para controlar los detalles finos de la posición cuando los geoms podrían de lo contrario superponerse y los sistemas de coordenadas le permiten cambiar fundamentalmente lo que significan x e y. Una capa que aún no hemos abordado es el tema, que presentaremos en Section 13.5.\nDos recursos muy útiles para obtener una descripción general de la funcionalidad completa de ggplot2 son la hoja de trucos de ggplot2 (que puede encontrar en https://posit.co/resources/cheatsheets) y el sitio web del paquete ggplot2 (https://ggplot2. tidyverse.org).\nUna lección importante que debe aprender de este capítulo es que cuando sienta la necesidad de un geom que ggplot2 no proporciona, siempre es una buena idea investigar si alguien más ya resolvió su problema creando un paquete de extensión ggplot2 que ofrece esa geom."
  },
  {
    "objectID": "factors.html#introducción",
    "href": "factors.html#introducción",
    "title": "17  Factores",
    "section": "",
    "text": "17.1.1 Requisitos previos\nBase R proporciona algunas herramientas básicas para crear y manipular factores. Los complementaremos con el paquete forcats, que es parte del tidyverse principal. Proporciona herramientas para tratar con variables categóricas (¡y es un anagrama de factores!) usando una amplia gama de ayudantes para trabajar con factores.\n\nlibrary(tidyverse)",
    "crumbs": [
      "Transformar",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Factores</span>"
    ]
  },
  {
    "objectID": "factors.html#fundamentos-de-los-factores",
    "href": "factors.html#fundamentos-de-los-factores",
    "title": "17  Factores",
    "section": "\n17.2 Fundamentos de los factores",
    "text": "17.2 Fundamentos de los factores\nImagina que tienes una variable que registra el mes:\n\nx1 &lt;- c(\"Dic\", \"Abr\", \"Ene\", \"Mar\")\n\nUsar una cadena para registrar esta variable tiene dos problemas:\n\n\nSolo hay doce meses posibles, y no hay nada que lo salve de los errores tipográficos:\n\nx2 &lt;- c(\"Dic\", \"Abr\", \"Eme\", \"Mar\")\n\n\n\nNo ordena de una manera útil:\n\nsort(x1)\n#&gt; [1] \"Abr\" \"Dic\" \"Ene\" \"Mar\"\n\n\n\nPuede solucionar ambos problemas con un factor. Para crear un factor, debe comenzar creando una lista de los niveles (levels) válidos:\n\nmeses_levels &lt;- c(\n  \"Ene\", \"Feb\", \"Mar\", \"Abr\", \"May\", \"Jun\", \n  \"Jul\", \"Ago\", \"Sep\", \"Oct\", \"Nov\", \"Dic\"\n)\n\nAhora puedes crear un factor:\n\ny1 &lt;- factor(x1, levels = meses_levels)\ny1\n#&gt; [1] Dic Abr Ene Mar\n#&gt; Levels: Ene Feb Mar Abr May Jun Jul Ago Sep Oct Nov Dic\n\nsort(y1)\n#&gt; [1] Ene Mar Abr Dic\n#&gt; Levels: Ene Feb Mar Abr May Jun Jul Ago Sep Oct Nov Dic\n\nY cualquier valor que no esté en el nivel se convertirá silenciosamente a NA:\n\ny2 &lt;- factor(x2, levels = meses_levels)\ny2\n#&gt; [1] Dic  Abr  &lt;NA&gt; Mar \n#&gt; Levels: Ene Feb Mar Abr May Jun Jul Ago Sep Oct Nov Dic\n\nEsto parece arriesgado, por lo que es posible que desee utilizar forcats::fct() en su lugar:\n\ny2 &lt;- fct(x2, levels = meses_levels)\n#&gt; Error in `fct()`:\n#&gt; ! All values of `x` must appear in `levels` or `na`\n#&gt; ℹ Missing level: \"Eme\"\n\nSi omite los niveles, se tomarán de los datos en orden alfabético:\n\nfactor(x1)\n#&gt; [1] Dic Abr Ene Mar\n#&gt; Levels: Abr Dic Ene Mar\n\nOrdenar alfabéticamente es un poco arriesgado porque no todas las computadoras ordenarán las cadenas de la misma manera. Entonces forcats::fct() ordena por primera aparición:\n\nfct(x1)\n#&gt; [1] Dic Abr Ene Mar\n#&gt; Levels: Dic Abr Ene Mar\n\nSi alguna vez necesita acceder directamente al conjunto de niveles válidos, puede hacerlo con levels():\n\nlevels(y2)\n#&gt;  [1] \"Ene\" \"Feb\" \"Mar\" \"Abr\" \"May\" \"Jun\" \"Jul\" \"Ago\" \"Sep\" \"Oct\" \"Nov\" \"Dic\"\n\nTambién puedes crear un factor al leer tus datos con readr con col_factor():\n\ncsv &lt;- \"\nmonth,value\nJan,12\nFeb,56\nMar,12\"\n\ndf &lt;- read_csv(csv, col_types = cols(month = col_factor(meses_levels)))\n#&gt; Warning: One or more parsing issues, call `problems()` on your data frame for\n#&gt; details, e.g.:\n#&gt;   dat &lt;- vroom(...)\n#&gt;   problems(dat)\ndf$month\n#&gt; [1] &lt;NA&gt; Feb  Mar \n#&gt; Levels: Ene Feb Mar Abr May Jun Jul Ago Sep Oct Nov Dic",
    "crumbs": [
      "Transformar",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Factores</span>"
    ]
  },
  {
    "objectID": "factors.html#encuesta-social-general",
    "href": "factors.html#encuesta-social-general",
    "title": "17  Factores",
    "section": "\n17.3 Encuesta Social General",
    "text": "17.3 Encuesta Social General\nPara el resto de este capítulo, usaremos forcats::gss_cat. Es una muestra de datos de la Encuesta Social General, una encuesta estadounidense de larga duración realizada por la organización de investigación independiente NORC en la Universidad de Chicago. La encuesta tiene miles de preguntas, por lo que en gss_cat Hadley seleccionó algunas que ilustrarán algunos desafíos comunes que encontrará al trabajar con factores.\n\ngss_cat\n#&gt; # A tibble: 21,483 × 9\n#&gt;    year marital         age race  rincome        partyid           \n#&gt;   &lt;int&gt; &lt;fct&gt;         &lt;int&gt; &lt;fct&gt; &lt;fct&gt;          &lt;fct&gt;             \n#&gt; 1  2000 Never married    26 White $8000 to 9999  Ind,near rep      \n#&gt; 2  2000 Divorced         48 White $8000 to 9999  Not str republican\n#&gt; 3  2000 Widowed          67 White Not applicable Independent       \n#&gt; 4  2000 Never married    39 White Not applicable Ind,near rep      \n#&gt; 5  2000 Divorced         25 White Not applicable Not str democrat  \n#&gt; 6  2000 Married          25 White $20000 - 24999 Strong democrat   \n#&gt; # ℹ 21,477 more rows\n#&gt; # ℹ 3 more variables: relig &lt;fct&gt;, denom &lt;fct&gt;, tvhours &lt;int&gt;\n\n(Recuerde, dado que este conjunto de datos lo proporciona un paquete, puede obtener más información sobre las variables con ?gss_cat.)\nCuando los factores se almacenan en un tibble, no puede ver sus niveles tan fácilmente. Una forma de verlos es con count():\n\ngss_cat |&gt;\n  count(race)\n#&gt; # A tibble: 3 × 2\n#&gt;   race      n\n#&gt;   &lt;fct&gt; &lt;int&gt;\n#&gt; 1 Other  1959\n#&gt; 2 Black  3129\n#&gt; 3 White 16395\n\nCuando se trabaja con factores, las dos operaciones más comunes son cambiar el orden de los niveles y cambiar los valores de los niveles. Esas operaciones se describen en las secciones siguientes.\n\n17.3.1 Ejercicios\n\nExplore la distribución de rincome (ingresos declarados). ¿Qué hace que el gráfico de barras predeterminado sea difícil de entender? ¿Cómo podrías mejorar la gráfica?\n¿Cuál es la relig más común en esta encuesta? ¿Cuál es el partyid más común?\n¿A qué relig se aplica denom (denominación)? ¿Cómo puedes averiguarlo con una tabla? ¿Cómo puedes averiguarlo con una visualización?",
    "crumbs": [
      "Transformar",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Factores</span>"
    ]
  },
  {
    "objectID": "factors.html#sec-modifying-factor-order",
    "href": "factors.html#sec-modifying-factor-order",
    "title": "17  Factores",
    "section": "\n17.4 Modificación del orden de los factores",
    "text": "17.4 Modificación del orden de los factores\nSuele ser útil cambiar el orden de los niveles de los factores en una visualización. Por ejemplo, imagine que desea explorar la cantidad promedio de horas que pasan viendo televisión por día en todas las religiones:\n\nrelig_summary &lt;- gss_cat |&gt;\n  group_by(relig) |&gt;\n  summarize(\n    tvhours = mean(tvhours, na.rm = TRUE),\n    n = n()\n  )\n\nggplot(relig_summary, aes(x = tvhours, y = relig)) + \n  geom_point()\n\n\n\n\n\n\n\nEs difícil leer esta trama porque no hay un patrón general. Podemos mejorarlo reordenando los niveles de relig usando fct_reorder(). fct_reorder() toma tres argumentos:\n\n\n.f, el factor cuyos niveles desea modificar.\n\n.x, un vector numérico que desea utilizar para reordenar los niveles.\nOpcionalmente, .fun, una función que se usa si hay varios valores de .x para cada valor de .f. El valor predeterminado es median.\n\n\nggplot(relig_summary, aes(x = tvhours, y = fct_reorder(relig, tvhours))) +\n  geom_point()\n\n\n\n\n\n\n\nReordenar la religión hace que sea mucho más fácil ver que las personas en la categoría “No sé” ven mucha más televisión, y el hinduismo y otras religiones orientales ven mucho menos.\nA medida que comience a realizar transformaciones más complicadas, le recomendamos que las saque de aes() y las lleve a un paso separado de mutate(). Por ejemplo, podría reescribir el gráfico anterior como:\n\nrelig_summary |&gt;\n  mutate(\n    relig = fct_reorder(relig, tvhours)\n  ) |&gt;\n  ggplot(aes(x = tvhours, y = relig)) +\n  geom_point()\n\n¿Qué sucede si creamos una gráfica similar que observa cómo varía la edad promedio según el nivel de ingresos informado?\n\nrincome_summary &lt;- gss_cat |&gt;\n  group_by(rincome) |&gt;\n  summarize(\n    age = mean(age, na.rm = TRUE),\n    n = n()\n  )\n\nggplot(rincome_summary, aes(x = age, y = fct_reorder(rincome, age))) + \n  geom_point()\n\n\n\n\n\n\n\n¡Aquí, reordenar arbitrariamente los niveles no es una buena idea! Esto se debe a que rincome ya tiene un orden de principios con el que no debemos meternos. Reserve fct_reorder() para factores cuyos niveles estén ordenados arbitrariamente.\nSin embargo, tiene sentido poner “No aplicable” al frente con los otros niveles especiales. Puedes usar fct_relevel(). Se necesita un factor, .f, y luego cualquier cantidad de niveles que desee mover al frente de la fila.\n\nggplot(rincome_summary, aes(x = age, y = fct_relevel(rincome, \"No aplicable\"))) +\n  geom_point()\n#&gt; Warning: 1 unknown level in `f`: No aplicable\n\n\n\n\n\n\n\n¿Por qué cree que la edad promedio para “No aplicable” es tan alta?\nOtro tipo de reordenación es útil cuando colorea las líneas de un gráfico. fct_reorder2(.f, .x, .y) reordena el factor .f por los valores .y asociados con los valores .x más grandes. Esto hace que el gráfico sea más fácil de leer porque los colores de la línea en el extremo derecho del gráfico se alinearán con la leyenda.\nby_age &lt;- gss_cat |&gt;\n  filter(!is.na(age)) |&gt; \n  count(age, marital) |&gt;\n  group_by(age) |&gt;\n  mutate(\n    prop = n / sum(n)\n  )\n\nggplot(by_age, aes(x = age, y = prop, color = marital)) +\n  geom_line(linewidth = 1) + \n  scale_color_brewer(palette = \"Set1\")\n\nggplot(by_age, aes(x = age, y = prop, color = fct_reorder2(marital, age, prop))) +\n  geom_line(linewidth = 1) +\n  scale_color_brewer(palette = \"Set1\") + \n  labs(color = \"marital\") \n\n\n\n\n\n\n\n\n\n\nFinalmente, para gráficos de barras, puede usar fct_infreq() para ordenar niveles en frecuencia decreciente: este es el tipo más simple de reordenamiento porque no necesita variables adicionales. Combínelo con fct_rev() si los quiere en frecuencia creciente para que en el gráfico de barras los valores más grandes estén a la derecha, no a la izquierda.\n\ngss_cat |&gt;\n  mutate(marital = marital |&gt; fct_infreq() |&gt; fct_rev()) |&gt;\n  ggplot(aes(x = marital)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n17.4.1 Ejercicios\n\nHay algunos números sospechosamente altos en tvhours. ¿Es la media un buen resumen?\nPara cada factor en gss_cat, identifique si el orden de los niveles es arbitrario o basado en principios.\n¿Por qué mover “No aplicable” al frente de los niveles lo movió al final de la gráfica?",
    "crumbs": [
      "Transformar",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Factores</span>"
    ]
  },
  {
    "objectID": "factors.html#modificar-los-niveles-de-los-factores",
    "href": "factors.html#modificar-los-niveles-de-los-factores",
    "title": "17  Factores",
    "section": "\n17.5 Modificar los niveles de los factores",
    "text": "17.5 Modificar los niveles de los factores\nMás poderoso que cambiar el orden de los niveles es cambiar sus valores. Esto le permite aclarar etiquetas para publicación y contraer niveles para visualizaciones de alto nivel. La herramienta más general y poderosa es fct_recode(). Le permite recodificar, o cambiar, el valor de cada nivel. Por ejemplo, tome la variable partyid del marco de datos gss_cat:\n\ngss_cat |&gt; count(partyid)\n#&gt; # A tibble: 10 × 2\n#&gt;   partyid                n\n#&gt;   &lt;fct&gt;              &lt;int&gt;\n#&gt; 1 No answer            154\n#&gt; 2 Don't know             1\n#&gt; 3 Other party          393\n#&gt; 4 Strong republican   2314\n#&gt; 5 Not str republican  3032\n#&gt; 6 Ind,near rep        1791\n#&gt; # ℹ 4 more rows\n\nLos niveles son breves e inconsistentes. Modifiquémoslos para que sean más largos y usemos una construcción paralela. Como la mayoría de las funciones de renombrar y recodificar en tidyverse, los valores nuevos van a la izquierda y los valores antiguos van a la derecha:\n\ngss_cat |&gt;\n  mutate(\n    partyid = fct_recode(partyid,\n      \"Republican, strong\"    = \"Strong republican\",\n      \"Republican, weak\"      = \"Not str republican\",\n      \"Independent, near rep\" = \"Ind,near rep\",\n      \"Independent, near dem\" = \"Ind,near dem\",\n      \"Democrat, weak\"        = \"Not str democrat\",\n      \"Democrat, strong\"      = \"Strong democrat\"\n    )\n  ) |&gt;\n  count(partyid)\n#&gt; # A tibble: 10 × 2\n#&gt;   partyid                   n\n#&gt;   &lt;fct&gt;                 &lt;int&gt;\n#&gt; 1 No answer               154\n#&gt; 2 Don't know                1\n#&gt; 3 Other party             393\n#&gt; 4 Republican, strong     2314\n#&gt; 5 Republican, weak       3032\n#&gt; 6 Independent, near rep  1791\n#&gt; # ℹ 4 more rows\n\nfct_recode() dejará los niveles que no se mencionan explícitamente como están y le avisará si accidentalmente hace referencia a un nivel que no existe.\nPara combinar grupos, puede asignar varios niveles antiguos al mismo nivel nuevo:\n\ngss_cat |&gt;\n  mutate(\n    partyid = fct_recode(partyid,\n      \"Republican, strong\"    = \"Strong republican\",\n      \"Republican, weak\"      = \"Not str republican\",\n      \"Independent, near rep\" = \"Ind,near rep\",\n      \"Independent, near dem\" = \"Ind,near dem\",\n      \"Democrat, weak\"        = \"Not str democrat\",\n      \"Democrat, strong\"      = \"Strong democrat\",\n      \"Other\"                 = \"No answer\",\n      \"Other\"                 = \"Don't know\",\n      \"Other\"                 = \"Other party\"\n    )\n  )\n\nUsa esta técnica con cuidado: si agrupas categorías que son realmente diferentes, terminarás con resultados engañosos.\nSi desea colapsar muchos niveles, fct_collapse() es una variante útil de fct_recode(). Para cada variable nueva, puede proporcionar un vector de niveles antiguos:\n\ngss_cat |&gt;\n  mutate(\n    partyid = fct_collapse(partyid,\n      \"other\" = c(\"No answer\", \"Don't know\", \"Other party\"),\n      \"rep\" = c(\"Strong republican\", \"Not str republican\"),\n      \"ind\" = c(\"Ind,near rep\", \"Independent\", \"Ind,near dem\"),\n      \"dem\" = c(\"Not str democrat\", \"Strong democrat\")\n    )\n  ) |&gt;\n  count(partyid)\n#&gt; # A tibble: 4 × 2\n#&gt;   partyid     n\n#&gt;   &lt;fct&gt;   &lt;int&gt;\n#&gt; 1 other     548\n#&gt; 2 rep      5346\n#&gt; 3 ind      8409\n#&gt; 4 dem      7180\n\nA veces, solo desea agrupar los grupos pequeños para simplificar un diagrama o una tabla. Ese es el trabajo de la familia de funciones fct_lump_*(). fct_lump_lowfreq() es un punto de partida simple que agrupa progresivamente las categorías de grupos más pequeños en “Otros”, manteniendo siempre “Otros” como la categoría más pequeña.\n\ngss_cat |&gt;\n  mutate(relig = fct_lump_lowfreq(relig)) |&gt;\n  count(relig)\n#&gt; # A tibble: 2 × 2\n#&gt;   relig          n\n#&gt;   &lt;fct&gt;      &lt;int&gt;\n#&gt; 1 Protestant 10846\n#&gt; 2 Other      10637\n\nEn este caso, no es muy útil: es cierto que la mayoría de los estadounidenses en esta encuesta son protestantes, ¡pero probablemente nos gustaría ver más detalles! En cambio, podemos usar fct_lump_n() para especificar que queremos exactamente 10 grupos:\n\ngss_cat |&gt;\n  mutate(relig = fct_lump_n(relig, n = 10)) |&gt;\n  count(relig, sort = TRUE)\n#&gt; # A tibble: 10 × 2\n#&gt;   relig          n\n#&gt;   &lt;fct&gt;      &lt;int&gt;\n#&gt; 1 Protestant 10846\n#&gt; 2 Catholic    5124\n#&gt; 3 None        3523\n#&gt; 4 Christian    689\n#&gt; 5 Other        458\n#&gt; 6 Jewish       388\n#&gt; # ℹ 4 more rows\n\nLea la documentación para conocer fct_lump_min() y fct_lump_prop(), que son útiles en otros casos.\n\n17.5.1 Ejercicios\n\n¿Cómo han cambiado con el tiempo las proporciones de personas que se identifican como demócratas, republicanas e independientes?\n¿Cómo podría colapsar ‘rincome’ en un pequeño conjunto de categorías?\nObserve que hay 9 grupos (excluyendo otros) en el ejemplo fct_lump anterior. ¿Por qué no 10? (Sugerencia: escriba ?fct_lump y encuentre que el valor predeterminado para el argumento other_level es “Other”.)",
    "crumbs": [
      "Transformar",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Factores</span>"
    ]
  },
  {
    "objectID": "factors.html#sec-ordered-factors",
    "href": "factors.html#sec-ordered-factors",
    "title": "17  Factores",
    "section": "\n17.6 Factores ordenados",
    "text": "17.6 Factores ordenados\nAntes de continuar, hay un tipo especial de factor que debe mencionarse brevemente: los factores ordenados. Los factores ordenados, creados con ordered(), implican un ordenamiento estricto y la misma distancia entre los niveles: el primer nivel es “menor que” el segundo nivel en la misma cantidad que el segundo nivel es “menor que” el tercer nivel, y pronto.. Puede reconocerlos al imprimir porque usan &lt; entre los niveles de los factores:\n\nordered(c(\"a\", \"b\", \"c\"))\n#&gt; [1] a b c\n#&gt; Levels: a &lt; b &lt; c\n\nEn la práctica, los factores ordered() se comportan de manera muy similar a los factores regulares. Solo hay dos lugares donde puede notar un comportamiento diferente:\n\nSi asigna un factor ordenado a color o rellena ggplot2, se establecerá de forma predeterminada en scale_color_viridis()/scale_fill_viridis(), una escala de color que implica una clasificación.\nSi usa una función ordenada en un modelo lineal, usará “contrastes poligonales”. Estos son medianamente útiles, pero es poco probable que haya oído hablar de ellos a menos que tenga un doctorado en Estadística, e incluso entonces probablemente no los interprete de forma rutinaria. Si desea obtener más información, le recomendamos vignette(\"contrasts\", package = \"faux\") de Lisa DeBruine.\n\nDada la utilidad discutible de estas diferencias, generalmente no recomendamos usar factores ordenados.",
    "crumbs": [
      "Transformar",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Factores</span>"
    ]
  },
  {
    "objectID": "factors.html#resumen",
    "href": "factors.html#resumen",
    "title": "17  Factores",
    "section": "\n17.7 Resumen",
    "text": "17.7 Resumen\nEste capítulo le presentó el práctico paquete forcats para trabajar con factores, y le presentó las funciones más utilizadas. forcats contiene una amplia gama de otros ayudantes que no tuvimos espacio para discutir aquí, por lo que siempre que se enfrente a un desafío de análisis factorial que no haya enfrentado antes, le recomiendo hojear el índice de referencia para ver si hay una función enlatada que pueda ayudar a resolver su problema.\nSi desea obtener más información sobre los factores después de leer este capítulo, le recomendamos que lea el artículo de Amelia McNamara y Nicholas Horton, Wrangling categorical data in R. Este artículo expone parte de la historia discutida en stringsAsFactors: An noauthorized biography y stringsAsFactors = &lt;sigh&gt;, y compara los enfoques ordenados de los datos categóricos descritos en este libro con los métodos base R. Una primera versión del documento ayudó a motivar y definir el alcance del paquete forcats; ¡Gracias Amelia y Nick!\nEn el próximo capítulo, cambiaremos de marcha para comenzar a aprender sobre fechas y horas en R. Las fechas y las horas parecen engañosamente simples, pero como verá pronto, cuanto más aprende sobre ellas, ¡más complejas parecen volverse!",
    "crumbs": [
      "Transformar",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Factores</span>"
    ]
  },
  {
    "objectID": "datetimes.html#introducción",
    "href": "datetimes.html#introducción",
    "title": "18  Fechas y horas",
    "section": "\n18.1 Introducción",
    "text": "18.1 Introducción\nEste capítulo le mostrará cómo trabajar con fechas y horas en R. A primera vista, las fechas y horas parecen simples. Los usa todo el tiempo en su vida normal y no parecen causar mucha confusión. Sin embargo, cuanto más aprendes sobre las fechas y las horas, ¡más complicadas parecen volverse!\nPara entrar en calor, piensa en cuántos días hay en un año y cuántas horas hay en un día. Probablemente recordó que la mayoría de los años tienen 365 días, pero los años bisiestos tienen 366. ¿Conoces la regla completa para determinar si un año es bisiesto1? La cantidad de horas en un día es un poco menos obvia: la mayoría de los días tienen 24 horas, pero en lugares que usan el horario de verano (DST), un día cada año tiene 23 horas y otro tiene 25.\nLas fechas y las horas son difíciles porque tienen que conciliar dos fenómenos físicos (la rotación de la Tierra y su órbita alrededor del sol) con toda una serie de fenómenos geopolíticos, incluidos los meses, las zonas horarias y el horario de verano. Este capítulo no le enseñará hasta el último detalle sobre fechas y horas, pero le brindará una base sólida de habilidades prácticas que lo ayudarán con los desafíos comunes de análisis de datos.\nComenzaremos mostrándole cómo crear fechas y horas a partir de varias entradas y luego, una vez que tenga una fecha y hora, cómo puede extraer componentes como año, mes y día. Luego nos sumergiremos en el tema complicado de trabajar con intervalos de tiempo, que vienen en una variedad de sabores dependiendo de lo que esté tratando de hacer. Concluiremos con una breve discusión de los desafíos adicionales que plantean las zonas horarias.\n\n18.1.1 Requisitos previos\nEste capítulo se centrará en el paquete lubridate, que facilita el trabajo con fechas y horas en R. A partir de la última versión de tidyverse, lubridate es parte del núcleo de tidyverse. También necesitaremos nycflights13 para datos de práctica.\n\nlibrary(tidyverse)\nlibrary(nycflights13)"
  },
  {
    "objectID": "datetimes.html#sec-creating-datetimes",
    "href": "datetimes.html#sec-creating-datetimes",
    "title": "18  Fechas y horas",
    "section": "\n18.2 Creando fecha/horas",
    "text": "18.2 Creando fecha/horas\nHay tres tipos de datos de fecha/hora que se refieren a un instante en el tiempo:\n\nUna fecha. Tibbles imprime esto como &lt;date&gt;.\nUna hora en un d’ia. Tibbles impreme esto como &lt;time&gt;.\nUna fecha-hora es una fecha más una hora: identifica de manera única un instante en el tiempo (generalmente al segundo más cercano). Tibbles imprime esto como &lt;dttm&gt;. Base R los llama POSIXct, pero no se sale de la lengua exactamente.\n\nEn este capítulo nos vamos a centrar en fechas y fechas y horas, ya que R no tiene una clase nativa para almacenar horas. Si necesita uno, puede usar el paquete hms.\nSiempre debe usar el tipo de datos más simple posible que funcione para sus necesidades. Eso significa que si puede usar una fecha en lugar de una fecha y hora, debería hacerlo. Las fechas y horas son sustancialmente más complicadas debido a la necesidad de manejar las zonas horarias, a lo que volveremos al final del capítulo.\nPara obtener la fecha actual o la fecha y hora, puede usar today() o now():\n\ntoday()\n#&gt; [1] \"2023-11-12\"\nnow()\n#&gt; [1] \"2023-11-12 19:23:04 CET\"\n\nDe lo contrario, las siguientes secciones describen las cuatro formas en las que es probable que cree una fecha/hora:\n\nAl leer un archivo con readr.\nDe una cadena de caracteres.\nA partir de componentes individuales de fecha y hora.\nDe un objeto de fecha/hora existente.\n\n\n18.2.1 Durante la importación\nSi su CSV contiene una fecha ISO8601 o una fecha y hora, no necesita hacer nada; readr lo reconocerá automáticamente:\n\ncsv &lt;- \"\n  date,datetime\n  2022-01-02,2022-01-02 05:12\n\"\nread_csv(csv)\n#&gt; # A tibble: 1 × 2\n#&gt;   date       datetime           \n#&gt;   &lt;date&gt;     &lt;dttm&gt;             \n#&gt; 1 2022-01-02 2022-01-02 05:12:00\n\nSi no ha oído hablar de ISO8601 antes, es un estándar internacional2 para escribir fechas donde los componentes de una fecha se organizan de mayor a menor separados por -. Por ejemplo, en ISO8601 el 3 de mayo de 2022 es 2022-05-03. Las fechas ISO8601 también pueden incluir horas, donde la hora, el minuto y el segundo están separados por :, y los componentes de fecha y hora están separados por una T o un espacio. Por ejemplo, podría escribir 4:26 p. m. el 3 de mayo de 2022 como 2022-05-03 16:26 o 2022-05-03T16:26.\nPara otros formatos de fecha y hora, necesitará usar col_types más col_date() o col_datetime() junto con un formato de fecha y hora. El formato de fecha y hora utilizado por readr es un estándar utilizado en muchos lenguajes de programación, que describe un componente de fecha con un % seguido de un solo carácter. Por ejemplo, %Y-%m-%d especifica una fecha que es un año, -, mes (como número) -, día. La tabla Tabla 18.1 enumera todas las opciones.\n\n\nTabla 18.1: Todos los formatos de fecha entendidos por readr\n\n\n\n\n\n\n\nType\nCode\nMeaning\nExample\n\n\n\nAño\n%Y\naño de 4 digitos\n2021\n\n\n\n%y\naño de 2 digitos\n21\n\n\nMes\n%m\nNúmero\n2\n\n\n\n%b\nNombre abreviado\nFeb\n\n\n\n%B\nNombre completo\nFebruary\n\n\nDía\n%d\nUno o dos digitos\n2\n\n\n\n%e\nDos digitos\n02\n\n\nHora\n%H\nHoras en 24-horas\n13\n\n\n\n%I\nHoras en 12-horas\n1\n\n\n\n%p\nAM/PM\npm\n\n\n\n%M\nMinutos\n35\n\n\n\n%S\nSegundos\n45\n\n\n\n%OS\nSegundos con componente decimal\n45.35\n\n\n\n%Z\nNombre de la zona horaria\nAmerica/Chicago\n\n\n\n%z\nDesplazamiento de UTC\n+0800\n\n\nOtros\n%.\nEvitar un no digito\n:\n\n\n\n%*\nEvitar cualquier número de no digitos\n\n\n\n\n\nY este código muestra algunas opciones aplicadas a una fecha muy ambigua:\n\ncsv &lt;- \"\n  date\n  01/02/15\n\"\n\nread_csv(csv, col_types = cols(date = col_date(\"%m/%d/%y\")))\n#&gt; # A tibble: 1 × 1\n#&gt;   date      \n#&gt;   &lt;date&gt;    \n#&gt; 1 2015-01-02\n\nread_csv(csv, col_types = cols(date = col_date(\"%d/%m/%y\")))\n#&gt; # A tibble: 1 × 1\n#&gt;   date      \n#&gt;   &lt;date&gt;    \n#&gt; 1 2015-02-01\n\nread_csv(csv, col_types = cols(date = col_date(\"%y/%m/%d\")))\n#&gt; # A tibble: 1 × 1\n#&gt;   date      \n#&gt;   &lt;date&gt;    \n#&gt; 1 2001-02-15\n\nTenga en cuenta que no importa cómo especifique el formato de fecha, siempre se muestra de la misma manera una vez que lo ingresa en R.\nSi está utilizando %b o %B y trabaja con fechas que no están en inglés, también deberá proporcionar un locale(). Vea la lista de idiomas integrados en date_names_langs(), o cree el suyo propio con date_names().\n\n18.2.2 De una cadena de caracteres\nEl lenguaje de especificación de fecha y hora es poderoso, pero requiere un análisis cuidadoso del formato de fecha. Un enfoque alternativo es usar los ayudantes de lubridate que intentan determinar automáticamente el formato una vez que especifica el orden del componente. Para usarlos, identifique el orden en que aparecen el año, el mes y el día en sus fechas, luego organice “y”, “m” y “d” en el mismo orden. Eso le da el nombre de la función lubridate que analizará su fecha. Por ejemplo:\n\nymd(\"2017-01-31\")\n#&gt; [1] \"2017-01-31\"\nmdy(\"January 31st, 2017\")\n#&gt; [1] \"2017-01-31\"\ndmy(\"31-Jan-2017\")\n#&gt; [1] \"2017-01-31\"\n\nymd() y amigos crean fechas. Para crear una fecha y hora, agregue un guión bajo y uno o más de “h”, “m” y “s” al nombre de la función de análisis:\n\nymd_hms(\"2017-01-31 20:11:59\")\n#&gt; [1] \"2017-01-31 20:11:59 UTC\"\nmdy_hm(\"01/31/2017 08:01\")\n#&gt; [1] \"2017-01-31 08:01:00 UTC\"\n\nTambién puede forzar la creación de una fecha y hora a partir de una fecha proporcionando una zona horaria:\n\nymd(\"2017-01-31\", tz = \"UTC\")\n#&gt; [1] \"2017-01-31 UTC\"\n\nAquí utilizo la zona horaria UTC3 que también puede conocer como GMT, o Greenwich Mean Time, la hora en 0° de longitud4 . No utiliza el horario de verano, por lo que es un poco más fácil de calcular .\n\n18.2.3 De componentes individuales\nEn lugar de una sola cadena, a veces tendrá los componentes individuales de la fecha y hora distribuidos en varias columnas. Esto es lo que tenemos en los datos de flights:\n\nflights |&gt; \n  select(year, month, day, hour, minute)\n#&gt; # A tibble: 336,776 × 5\n#&gt;    year month   day  hour minute\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1  2013     1     1     5     15\n#&gt; 2  2013     1     1     5     29\n#&gt; 3  2013     1     1     5     40\n#&gt; 4  2013     1     1     5     45\n#&gt; 5  2013     1     1     6      0\n#&gt; 6  2013     1     1     5     58\n#&gt; # ℹ 336,770 more rows\n\nPara crear una fecha/hora a partir de este tipo de entrada, usa make_date() para fechas, o make_datetime() para fechas y horas:\n\nflights |&gt; \n  select(year, month, day, hour, minute) |&gt; \n  mutate(departure = make_datetime(year, month, day, hour, minute))\n#&gt; # A tibble: 336,776 × 6\n#&gt;    year month   day  hour minute departure          \n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dttm&gt;             \n#&gt; 1  2013     1     1     5     15 2013-01-01 05:15:00\n#&gt; 2  2013     1     1     5     29 2013-01-01 05:29:00\n#&gt; 3  2013     1     1     5     40 2013-01-01 05:40:00\n#&gt; 4  2013     1     1     5     45 2013-01-01 05:45:00\n#&gt; 5  2013     1     1     6      0 2013-01-01 06:00:00\n#&gt; 6  2013     1     1     5     58 2013-01-01 05:58:00\n#&gt; # ℹ 336,770 more rows\n\nHagamos lo mismo para cada una de las cuatro columnas de tiempo en flights. Los tiempos se representan en un formato ligeramente extraño, por lo que usamos aritmética de módulo para extraer los componentes de hora y minuto. Una vez que hayamos creado las variables de fecha y hora, nos centraremos en las variables que exploraremos en el resto del capítulo.\n\nmake_datetime_100 &lt;- function(year, month, day, time) {\n  make_datetime(year, month, day, time %/% 100, time %% 100)\n}\n\nflights_dt &lt;- flights |&gt; \n  filter(!is.na(dep_time), !is.na(arr_time)) |&gt; \n  mutate(\n    dep_time = make_datetime_100(year, month, day, dep_time),\n    arr_time = make_datetime_100(year, month, day, arr_time),\n    sched_dep_time = make_datetime_100(year, month, day, sched_dep_time),\n    sched_arr_time = make_datetime_100(year, month, day, sched_arr_time)\n  ) |&gt; \n  select(origin, dest, ends_with(\"delay\"), ends_with(\"time\"))\n\nflights_dt\n#&gt; # A tibble: 328,063 × 9\n#&gt;   origin dest  dep_delay arr_delay dep_time            sched_dep_time     \n#&gt;   &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dttm&gt;              &lt;dttm&gt;             \n#&gt; 1 EWR    IAH           2        11 2013-01-01 05:17:00 2013-01-01 05:15:00\n#&gt; 2 LGA    IAH           4        20 2013-01-01 05:33:00 2013-01-01 05:29:00\n#&gt; 3 JFK    MIA           2        33 2013-01-01 05:42:00 2013-01-01 05:40:00\n#&gt; 4 JFK    BQN          -1       -18 2013-01-01 05:44:00 2013-01-01 05:45:00\n#&gt; 5 LGA    ATL          -6       -25 2013-01-01 05:54:00 2013-01-01 06:00:00\n#&gt; 6 EWR    ORD          -4        12 2013-01-01 05:54:00 2013-01-01 05:58:00\n#&gt; # ℹ 328,057 more rows\n#&gt; # ℹ 3 more variables: arr_time &lt;dttm&gt;, sched_arr_time &lt;dttm&gt;, …\n\nCon estos datos, podemos visualizar la distribución de los horarios de salida a lo largo del año:\n\nflights_dt |&gt; \n  ggplot(aes(x = dep_time)) + \n  geom_freqpoly(binwidth = 86400) # 86400 seconds = 1 day\n\n\n\n\nO dentro de un solo día:\n\nflights_dt |&gt; \n  filter(dep_time &lt; ymd(20130102)) |&gt; \n  ggplot(aes(x = dep_time)) + \n  geom_freqpoly(binwidth = 600) # 600 s = 10 minutes\n\n\n\n\nTenga en cuenta que cuando usa fecha y hora en un contexto numérico (como en un histograma), 1 significa 1 segundo, por lo que un ancho de bin de 86400 significa un día. Para fechas, 1 significa 1 día.\n\n18.2.4 De otros tipos\nEs posible que desee cambiar entre una fecha y hora y una fecha. Ese es el trabajo de as_datetime() y as_date():\n\nas_datetime(today())\n#&gt; [1] \"2023-11-12 UTC\"\nas_date(now())\n#&gt; [1] \"2023-11-12\"\n\nA veces obtendrá la fecha/hora como compensaciones numéricas de la “época de Unix”, 1970-01-01. Si el desplazamiento está en segundos, use as_datetime(); si es en días, usa as_date().\n\nas_datetime(60 * 60 * 10)\n#&gt; [1] \"1970-01-01 10:00:00 UTC\"\nas_date(365 * 10 + 2)\n#&gt; [1] \"1980-01-01\"\n\n\n18.2.5 Ejercicios\n\n\n¿Qué sucede si analiza una cadena que contiene fechas no válidas?\n\nymd(c(\"2010-10-10\", \"bananas\"))\n\n\n¿Qué hace el argumento tzone para today()? ¿Por qué es importante?\n\nPara cada una de las siguientes fechas y horas, muestre cómo las analizaría utilizando una especificación de columna readr y una función lubridate.\n\nd1 &lt;- \"January 1, 2010\"\nd2 &lt;- \"2015-Mar-07\"\nd3 &lt;- \"06-Jun-2017\"\nd4 &lt;- c(\"August 19 (2015)\", \"July 1 (2015)\")\nd5 &lt;- \"12/30/14\" # Dec 30, 2014\nt1 &lt;- \"1705\"\nt2 &lt;- \"11:15:10.12 PM\""
  },
  {
    "objectID": "datetimes.html#componentes-de-fecha-y-hora",
    "href": "datetimes.html#componentes-de-fecha-y-hora",
    "title": "18  Fechas y horas",
    "section": "\n18.3 Componentes de fecha y hora",
    "text": "18.3 Componentes de fecha y hora\nAhora que sabe cómo obtener datos de fecha y hora en las estructuras de datos de fecha y hora de R, exploremos qué puede hacer con ellos. Esta sección se centrará en las funciones de acceso que le permiten obtener y configurar componentes individuales. La siguiente sección verá cómo funciona la aritmética con fechas y horas.\n\n18.3.1 Obtener componentes\nPuede extraer partes individuales de la fecha con las funciones de acceso year(), month(), mday() (día del mes), yday() (día del año), wday() (día de la semana), hour(), minute() y second(). Estos son efectivamente los opuestos de make_datetime().\n\ndatetime &lt;- ymd_hms(\"2026-07-08 12:34:56\")\n\nyear(datetime)\n#&gt; [1] 2026\nmonth(datetime)\n#&gt; [1] 7\nmday(datetime)\n#&gt; [1] 8\n\nyday(datetime)\n#&gt; [1] 189\nwday(datetime)\n#&gt; [1] 4\n\nPara month() y wday() puede configurar label = TRUE para devolver el nombre abreviado del mes o día de la semana. Establezca abbr = FALSE para devolver el nombre completo.\n\nmonth(datetime, label = TRUE)\n#&gt; [1] jul\n#&gt; 12 Levels: ene &lt; feb &lt; mar &lt; abr &lt; may &lt; jun &lt; jul &lt; ago &lt; sep &lt; ... &lt; dic\nwday(datetime, label = TRUE, abbr = FALSE)\n#&gt; [1] miércoles\n#&gt; 7 Levels: domingo &lt; lunes &lt; martes &lt; miércoles &lt; jueves &lt; ... &lt; sábado\n\nPodemos usar wday() para ver que salen más vuelos durante la semana que el fin de semana:\n\nflights_dt |&gt; \n  mutate(wday = wday(dep_time, label = TRUE)) |&gt; \n  ggplot(aes(x = wday)) +\n  geom_bar()\n\n\n\n\nTambién podemos ver el retraso de salida promedio por minuto dentro de la hora. Hay un patrón interesante: ¡los vuelos que salen en los minutos 20-30 y 50-60 tienen retrasos mucho menores que el resto de la hora!\n\nflights_dt |&gt; \n  mutate(minute = minute(dep_time)) |&gt; \n  group_by(minute) |&gt; \n  summarize(\n    avg_delay = mean(dep_delay, na.rm = TRUE),\n    n = n()\n  ) |&gt; \n  ggplot(aes(x = minute, y = avg_delay)) +\n  geom_line()\n\n\n\n\nCuriosamente, si observamos la hora de salida programada, no vemos un patrón tan fuerte:\n\nsched_dep &lt;- flights_dt |&gt; \n  mutate(minute = minute(sched_dep_time)) |&gt; \n  group_by(minute) |&gt; \n  summarize(\n    avg_delay = mean(arr_delay, na.rm = TRUE),\n    n = n()\n  )\n\nggplot(sched_dep, aes(x = minute, y = avg_delay)) +\n  geom_line()\n\n\n\n\nEntonces, ¿por qué vemos ese patrón con los horarios de salida reales? Bueno, como gran parte de los datos recopilados por humanos, hay un fuerte sesgo hacia los vuelos que salen en “buenos” horarios de salida, como muestra Figura 18.1. ¡Esté siempre alerta a este tipo de patrón cada vez que trabaje con datos que involucran el juicio humano!\n\n\n\n\nFigura 18.1: Un polígono de frecuencia que muestra el número de vuelos programados para salir cada hora. Puede ver una fuerte preferencia por los números redondos como el 0 y el 30 y, en general, por los números que son múltiplos de cinco.\n\n\n\n\n18.3.2 Redondeo\nUn enfoque alternativo para trazar componentes individuales es redondear la fecha a una unidad de tiempo cercana, con floor_date(), round_date() y ceiling_date(). Cada función toma un vector de fechas para ajustar y luego el nombre de la unidad redondea hacia abajo (floor), redondea hacia arriba (ceiling) o redondea a. Esto, por ejemplo, nos permite graficar el número de vuelos por semana:\n\nflights_dt |&gt; \n  count(week = floor_date(dep_time, \"week\")) |&gt; \n  ggplot(aes(x = week, y = n)) +\n  geom_line() + \n  geom_point()\n\n\n\n\nPuede usar el redondeo para mostrar la distribución de vuelos a lo largo de un día calculando la diferencia entre dep_time y el primer instante de ese día:\n\nflights_dt |&gt; \n  mutate(dep_hour = dep_time - floor_date(dep_time, \"day\")) |&gt; \n  ggplot(aes(x = dep_hour)) +\n  geom_freqpoly(binwidth = 60 * 30)\n#&gt; Don't know how to automatically pick scale for object of type &lt;difftime&gt;.\n#&gt; Defaulting to continuous.\n\n\n\n\nCalcular la diferencia entre un par de fechas y horas produce un tiempo de diferencia (más sobre eso en Sección 18.4.3). Podemos convertir eso en un objeto hms para obtener un eje x más útil:\n\nflights_dt |&gt; \n  mutate(dep_hour = hms::as_hms(dep_time - floor_date(dep_time, \"day\"))) |&gt; \n  ggplot(aes(x = dep_hour)) +\n  geom_freqpoly(binwidth = 60 * 30)\n\n\n\n\n\n18.3.3 Modificación de componentes\nTambién puede utilizar cada función de acceso para modificar los componentes de una fecha/hora. Esto no aparece mucho en el análisis de datos, pero puede ser útil cuando se limpian datos que tienen fechas claramente incorrectas.\n\n(datetime &lt;- ymd_hms(\"2026-07-08 12:34:56\"))\n#&gt; [1] \"2026-07-08 12:34:56 UTC\"\n\nyear(datetime) &lt;- 2030\ndatetime\n#&gt; [1] \"2030-07-08 12:34:56 UTC\"\nmonth(datetime) &lt;- 01\ndatetime\n#&gt; [1] \"2030-01-08 12:34:56 UTC\"\nhour(datetime) &lt;- hour(datetime) + 1\ndatetime\n#&gt; [1] \"2030-01-08 13:34:56 UTC\"\n\nAlternativamente, en lugar de modificar una variable existente, puede crear una nueva fecha y hora con update(). Esto también le permite establecer múltiples valores en un solo paso:\n\nupdate(datetime, year = 2030, month = 2, mday = 2, hour = 2)\n#&gt; [1] \"2030-02-02 02:34:56 UTC\"\n\nSi los valores son demasiado grandes, se transferirán:\n\nupdate(ymd(\"2023-02-01\"), mday = 30)\n#&gt; [1] \"2023-03-02\"\nupdate(ymd(\"2023-02-01\"), hour = 400)\n#&gt; [1] \"2023-02-17 16:00:00 UTC\"\n\n\n18.3.4 Ejercicios\n\n¿Cómo cambia la distribución de los tiempos de vuelo dentro de un día a lo largo del año?\nCompara dep_time, sched_dep_time y dep_delay. ¿Son consistentes? Explique sus hallazgos.\nCompara air_time con la duración entre la salida y la llegada. Explique sus hallazgos. (Sugerencia: considere la ubicación del aeropuerto).\n¿Cómo cambia el tiempo de demora promedio en el transcurso de un día? ¿Deberías usar dep_time o sched_dep_time? ¿Por qué?\n¿Qué día de la semana debe salir si quiere minimizar la posibilidad de un retraso?\n¿Qué hace que la distribución de diamonds$carat y flights$sched_dep_time sea similar?\nConfirme nuestra hipótesis de que las salidas anticipadas de vuelos en los minutos 20-30 y 50-60 son causadas por vuelos programados que salen temprano. Sugerencia: cree una variable binaria que le indique si un vuelo se retrasó o no."
  },
  {
    "objectID": "datetimes.html#intervalos-de-tiempo",
    "href": "datetimes.html#intervalos-de-tiempo",
    "title": "18  Fechas y horas",
    "section": "\n18.4 Intervalos de tiempo",
    "text": "18.4 Intervalos de tiempo\nA continuación, aprenderá cómo funciona la aritmética con fechas, incluidas la resta, la suma y la división. En el camino, aprenderá acerca de tres clases importantes que representan períodos de tiempo:\n\n\nDuración, que representa un número exacto de segundos.\n\nPeríodos, que representan unidades humanas como semanas y meses.\n\nIntervalos, que representan un punto inicial y final.\n\n¿Cómo eliges entre duración, períodos e intervalos? Como siempre, elija la estructura de datos más simple que resuelva su problema. Si solo te importa el tiempo físico, usa una duración; si necesita agregar tiempos humanos, use un período; si necesita averiguar cuánto mide un lapso en unidades humanas, use un intervalo.\n\n18.4.1 Duraciones\nEn R, cuando restas dos fechas, obtienes un objeto difftime:\n\n# How old is Hadley?\nh_age &lt;- today() - ymd(\"1979-10-14\")\nh_age\n#&gt; Time difference of 16100 days\n\nUn objeto de clase difftime registra un lapso de tiempo de segundos, minutos, horas, días o semanas. Esta ambigüedad puede hacer que trabajar con difftimes sea un poco doloroso, por lo que lubridate ofrece una alternativa que siempre usa segundos: la duración.\n\nas.duration(h_age)\n#&gt; [1] \"1391040000s (~44.08 years)\"\n\nLas duraciones vienen con un montón de constructoras convenientes:\n\ndseconds(15)\n#&gt; [1] \"15s\"\ndminutes(10)\n#&gt; [1] \"600s (~10 minutes)\"\ndhours(c(12, 24))\n#&gt; [1] \"43200s (~12 hours)\" \"86400s (~1 days)\"\nddays(0:5)\n#&gt; [1] \"0s\"                \"86400s (~1 days)\"  \"172800s (~2 days)\"\n#&gt; [4] \"259200s (~3 days)\" \"345600s (~4 days)\" \"432000s (~5 days)\"\ndweeks(3)\n#&gt; [1] \"1814400s (~3 weeks)\"\ndyears(1)\n#&gt; [1] \"31557600s (~1 years)\"\n\nLas duraciones siempre registran el lapso de tiempo en segundos. Las unidades más grandes se crean al convertir minutos, horas, días, semanas y años en segundos: 60 segundos en un minuto, 60 minutos en una hora, 24 horas en un día y 7 días en una semana. Las unidades de tiempo más grandes son más problemáticas. Un año utiliza el número “promedio” de días en un año, es decir, 365,25. No hay forma de convertir un mes en una duración, porque hay demasiada variación.\nPuedes sumar y multiplicar duraciones:\n\n2 * dyears(1)\n#&gt; [1] \"63115200s (~2 years)\"\ndyears(1) + dweeks(12) + dhours(15)\n#&gt; [1] \"38869200s (~1.23 years)\"\n\nPuede sumar y restar duraciones desde y hacia días:\n\ntomorrow &lt;- today() + ddays(1)\nlast_year &lt;- today() - dyears(1)\n\nSin embargo, debido a que las duraciones representan una cantidad exacta de segundos, a veces puede obtener un resultado inesperado:\n\none_am &lt;- ymd_hms(\"2026-03-08 01:00:00\", tz = \"America/New_York\")\n\none_am\n#&gt; [1] \"2026-03-08 01:00:00 EST\"\none_am + ddays(1)\n#&gt; [1] \"2026-03-09 02:00:00 EDT\"\n\n¿Por qué un día después de la 1 a. m. es el 8 de marzo y a las 2 a. m. el 9 de marzo? Si observa detenidamente la fecha, también puede notar que las zonas horarias han cambiado. El 8 de marzo solo tiene 23 horas porque es cuando comienza el horario de verano, por lo que si agregamos un día completo en segundos, terminamos con una hora diferente.\n\n18.4.2 Períodos\nPara resolver este problema, lubridate proporciona períodos. Los períodos son lapsos de tiempo, pero no tienen una duración fija en segundos, sino que funcionan con tiempos “humanos”, como días y meses. Eso les permite trabajar de una manera más intuitiva:\n\none_am\n#&gt; [1] \"2026-03-08 01:00:00 EST\"\none_am + days(1)\n#&gt; [1] \"2026-03-09 01:00:00 EDT\"\n\nAl igual que las duraciones, los períodos se pueden crear con una serie de funciones constructoras amigables.\n\nhours(c(12, 24))\n#&gt; [1] \"12H 0M 0S\" \"24H 0M 0S\"\ndays(7)\n#&gt; [1] \"7d 0H 0M 0S\"\nmonths(1:6)\n#&gt; [1] \"1m 0d 0H 0M 0S\" \"2m 0d 0H 0M 0S\" \"3m 0d 0H 0M 0S\" \"4m 0d 0H 0M 0S\"\n#&gt; [5] \"5m 0d 0H 0M 0S\" \"6m 0d 0H 0M 0S\"\n\nPuede sumar y multiplicar períodos:\n\n10 * (months(6) + days(1))\n#&gt; [1] \"60m 10d 0H 0M 0S\"\ndays(50) + hours(25) + minutes(2)\n#&gt; [1] \"50d 25H 2M 0S\"\n\nY por supuesto, añádelos a las fechas. En comparación con las duraciones, es más probable que los períodos hagan lo que esperas:\n\n# Un año bisiesto\nymd(\"2024-01-01\") + dyears(1)\n#&gt; [1] \"2024-12-31 06:00:00 UTC\"\nymd(\"2024-01-01\") + years(1)\n#&gt; [1] \"2025-01-01\"\n\n# El horario de verano\none_am + ddays(1)\n#&gt; [1] \"2026-03-09 02:00:00 EDT\"\none_am + days(1)\n#&gt; [1] \"2026-03-09 01:00:00 EDT\"\n\nUsemos períodos para arreglar una rareza relacionada con nuestras fechas de vuelo. Algunos aviones parecen haber llegado a su destino antes de partir de la ciudad de Nueva York.\n\nflights_dt |&gt; \n  filter(arr_time &lt; dep_time) \n#&gt; # A tibble: 10,633 × 9\n#&gt;   origin dest  dep_delay arr_delay dep_time            sched_dep_time     \n#&gt;   &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dttm&gt;              &lt;dttm&gt;             \n#&gt; 1 EWR    BQN           9        -4 2013-01-01 19:29:00 2013-01-01 19:20:00\n#&gt; 2 JFK    DFW          59        NA 2013-01-01 19:39:00 2013-01-01 18:40:00\n#&gt; 3 EWR    TPA          -2         9 2013-01-01 20:58:00 2013-01-01 21:00:00\n#&gt; 4 EWR    SJU          -6       -12 2013-01-01 21:02:00 2013-01-01 21:08:00\n#&gt; 5 EWR    SFO          11       -14 2013-01-01 21:08:00 2013-01-01 20:57:00\n#&gt; 6 LGA    FLL         -10        -2 2013-01-01 21:20:00 2013-01-01 21:30:00\n#&gt; # ℹ 10,627 more rows\n#&gt; # ℹ 3 more variables: arr_time &lt;dttm&gt;, sched_arr_time &lt;dttm&gt;, …\n\nEstos son vuelos nocturnos. Utilizamos la misma información de fecha tanto para la hora de salida como para la de llegada, pero estos vuelos llegaron al día siguiente. Podemos arreglar esto agregando días (1) a la hora de llegada de cada vuelo nocturno.\n\nflights_dt &lt;- flights_dt |&gt; \n  mutate(\n    overnight = arr_time &lt; dep_time,\n    arr_time = arr_time + days(overnight),\n    sched_arr_time = sched_arr_time + days(overnight)\n  )\n\nAhora todos nuestros vuelos obedecen las leyes de la física.\n\nflights_dt |&gt; \n  filter(overnight, arr_time &lt; dep_time) \n#&gt; # A tibble: 0 × 10\n#&gt; # ℹ 10 variables: origin &lt;chr&gt;, dest &lt;chr&gt;, dep_delay &lt;dbl&gt;,\n#&gt; #   arr_delay &lt;dbl&gt;, dep_time &lt;dttm&gt;, sched_dep_time &lt;dttm&gt;, …\n\n\n18.4.3 Intervalos\n¿Qué devuelve dyears(1) / ddays(365)? No es exactamente uno, porque dyear() se define como el número de segundos por año promedio, que son 365,25 días.\n¿Qué devuelve years(1) / days(1)? Bueno, si el año fue 2015, debería devolver 365, pero si fue 2016, ¡debería devolver 366! No hay suficiente información sobre lubridate para dar una sola respuesta clara. Lo que hace en cambio es dar una estimación:\n\nyears(1) / days(1)\n#&gt; [1] 365.25\n\nSi desea una medición más precisa, deberá usar un intervalo. Un intervalo es un par de fechas de inicio y finalización, o puede considerarlo como una duración con un punto de inicio.\nPuede crear un intervalo escribiendo start %--% end:\n\ny2023 &lt;- ymd(\"2023-01-01\") %--% ymd(\"2024-01-01\")\ny2024 &lt;- ymd(\"2024-01-01\") %--% ymd(\"2025-01-01\")\n\ny2023\n#&gt; [1] 2023-01-01 UTC--2024-01-01 UTC\ny2024\n#&gt; [1] 2024-01-01 UTC--2025-01-01 UTC\n\nLuego podrías dividirlo por days() para averiguar cuántos días caben en el año:\n\ny2023 / days(1)\n#&gt; [1] 365\ny2024 / days(1)\n#&gt; [1] 366\n\n\n18.4.4 Ejercicios\n\nExplique days(!overnight) y days(overnight) a alguien que acaba de empezar a aprender R. ¿Cuál es el hecho clave que necesita saber?\nCree un vector de fechas que proporcione el primer día de cada mes en 2015. Cree un vector de fechas que proporcione el primer día de cada mes en el año actual.\nEscribe una función que, dado tu cumpleaños (como una fecha), devuelva la edad que tienes en años.\n¿Por qué (today() %--% (today() + years(1))) / months(1) no puede funcionar?"
  },
  {
    "objectID": "datetimes.html#zonas-horarias",
    "href": "datetimes.html#zonas-horarias",
    "title": "18  Fechas y horas",
    "section": "\n18.5 Zonas horarias",
    "text": "18.5 Zonas horarias\nLas zonas horarias son un tema enormemente complicado debido a su interacción con las entidades geopolíticas. Afortunadamente, no necesitamos profundizar en todos los detalles, ya que no todos son importantes para el análisis de datos, pero hay algunos desafíos que debemos abordar de frente.\n\nEl primer desafío es que los nombres cotidianos de las zonas horarias tienden a ser ambiguos. Por ejemplo, si es estadounidense, probablemente esté familiarizado con EST u Hora estándar del este. Sin embargo, ¡tanto Australia como Canadá también tienen EST! Para evitar confusiones, R utiliza las zonas horarias estándar internacionales de la IANA. Estos usan un esquema de nomenclatura consistente {área}/{ubicación}, normalmente en la forma {continente}/{ciudad} o {océano}/{ciudad}. Los ejemplos incluyen “America/Nueva_York”, “Europe/Paris” y “Pacific/Auckland”.\nQuizás se pregunte por qué la zona horaria usa una ciudad, cuando normalmente piensa en las zonas horarias como asociadas con un país o una región dentro de un país. Esto se debe a que la base de datos de la IANA tiene que registrar décadas de reglas de zonas horarias. A lo largo de las décadas, los países cambian de nombre (o se separan) con bastante frecuencia, pero los nombres de las ciudades tienden a permanecer igual. Otro problema es que el nombre debe reflejar no solo el comportamiento actual, sino también el historial completo. Por ejemplo, hay zonas horarias tanto para “America/Nueva_York” como para “America/Detroit”. Ambas ciudades utilizan actualmente la hora estándar del este, pero en 1969-1972 Michigan (el estado en el que se encuentra Detroit) no siguió el horario de verano, por lo que necesita un nombre diferente. ¡Vale la pena leer la base de datos de zonas horarias sin procesar (disponible en https://www.iana.org/time-zones) solo para leer algunas de estas historias!\nPuedes averiguar cuál cree R que es tu zona horaria actual con Sys.timezone():\n\nSys.timezone()\n#&gt; [1] \"Europe/Madrid\"\n\n(Si R no lo sabe, obtendrá una NA.)\nY vea la lista completa de todos los nombres de zonas horarias con OlsonNames():\n\nlength(OlsonNames())\n#&gt; [1] 596\nhead(OlsonNames())\n#&gt; [1] \"Africa/Abidjan\"     \"Africa/Accra\"       \"Africa/Addis_Ababa\"\n#&gt; [4] \"Africa/Algiers\"     \"Africa/Asmara\"      \"Africa/Asmera\"\n\nEn R, la zona horaria es un atributo de la fecha-hora que solo controla la impresión. Por ejemplo, estos tres objetos representan el mismo instante en el tiempo:\n\nx1 &lt;- ymd_hms(\"2024-06-01 12:00:00\", tz = \"America/New_York\")\nx1\n#&gt; [1] \"2024-06-01 12:00:00 EDT\"\n\nx2 &lt;- ymd_hms(\"2024-06-01 18:00:00\", tz = \"Europe/Copenhagen\")\nx2\n#&gt; [1] \"2024-06-01 18:00:00 CEST\"\n\nx3 &lt;- ymd_hms(\"2024-06-02 04:00:00\", tz = \"Pacific/Auckland\")\nx3\n#&gt; [1] \"2024-06-02 04:00:00 NZST\"\n\nPuedes verificar que son la misma hora usando la resta:\n\nx1 - x2\n#&gt; Time difference of 0 secs\nx1 - x3\n#&gt; Time difference of 0 secs\n\nA menos que se especifique lo contrario, lubridate siempre usa UTC. UTC (Tiempo Universal Coordinado) es la zona horaria estándar utilizada por la comunidad científica y es aproximadamente equivalente a GMT (Greenwich Mean Time). No tiene DST, lo que hace una representación conveniente para el cálculo. Las operaciones que combinan fechas y horas, como c(), a menudo eliminarán la zona horaria. En ese caso, las fechas y horas se mostrarán en la zona horaria del primer elemento:\n\nx4 &lt;- c(x1, x2, x3)\nx4\n#&gt; [1] \"2024-06-01 12:00:00 EDT\" \"2024-06-01 12:00:00 EDT\"\n#&gt; [3] \"2024-06-01 12:00:00 EDT\"\n\nPuede cambiar la zona horaria de dos maneras:\n\n\nMantenga el instante en el tiempo igual y cambie la forma en que se muestra. Use esto cuando el instante sea correcto, pero desee una visualización más natural.\n\nx4a &lt;- with_tz(x4, tzone = \"Australia/Lord_Howe\")\nx4a\n#&gt; [1] \"2024-06-02 02:30:00 +1030\" \"2024-06-02 02:30:00 +1030\"\n#&gt; [3] \"2024-06-02 02:30:00 +1030\"\nx4a - x4\n#&gt; Time differences in secs\n#&gt; [1] 0 0 0\n\n(Esto también ilustra otro desafío de las zonas horarias: ¡no todas son compensaciones de horas enteras!)\n\n\nCambia el instante subyacente en el tiempo. Usa esto cuando tengas un instante que ha sido etiquetado con la zona horaria incorrecta y necesites corregirlo.\n\nx4b &lt;- force_tz(x4, tzone = \"Australia/Lord_Howe\")\nx4b\n#&gt; [1] \"2024-06-01 12:00:00 +1030\" \"2024-06-01 12:00:00 +1030\"\n#&gt; [3] \"2024-06-01 12:00:00 +1030\"\nx4b - x4\n#&gt; Time differences in hours\n#&gt; [1] -14.5 -14.5 -14.5"
  },
  {
    "objectID": "datetimes.html#resumen",
    "href": "datetimes.html#resumen",
    "title": "18  Fechas y horas",
    "section": "\n18.6 Resumen",
    "text": "18.6 Resumen\nEste capítulo le ha presentado las herramientas que proporciona lubridate para ayudarle a trabajar con datos de fecha y hora. Trabajar con fechas y horas puede parecer más difícil de lo necesario, pero espero que este capítulo le haya ayudado a ver por qué: las fechas y horas son más complejas de lo que parecen a primera vista, y el manejo de todas las situaciones posibles agrega complejidad. Incluso si sus datos nunca cruzan un límite de ahorro de luz diurna o involucran un año bisiesto, las funciones deben poder manejarlo.\nEl siguiente capítulo ofrece un resumen de los valores perdidos. Los ha visto en algunos lugares y sin duda los ha encontrado en su propio análisis, y ahora es el momento de proporcionar una bolsa de sorpresas con técnicas útiles para tratar con ellos."
  },
  {
    "objectID": "missing-values.html#introducción",
    "href": "missing-values.html#introducción",
    "title": "19  Valores faltanres",
    "section": "\n19.1 Introducción",
    "text": "19.1 Introducción\nYa aprendiste los conceptos básicos de los valores faltantes anteriormente en el libro. Los vio por primera vez en Chapter 2, donde resultaron en una advertencia al hacer un gráfico, así como en Section 4.5.2, donde interfirieron con el cálculo de estadísticas de resumen, y aprendió sobre su naturaleza infecciosa y cómo verificar su presencia en ?sec-na-comparation. Ahora volveremos a ellos con más profundidad, para que pueda conocer más detalles.\nComenzaremos discutiendo algunas herramientas generales para trabajar con valores faltantes registrados como NAs. Luego, exploraremos la idea de valores que faltan implícitamente, los valores que simplemente están ausentes de sus datos, y mostraremos algunas herramientas que puede usar para hacerlos explícitos. Terminaremos con una discusión relacionada con los grupos vacíos, causados por niveles de factores que no aparecen en los datos.\n\n19.1.1 Requisitos previos\nLas funciones para trabajar con datos faltantes provienen principalmente de dplyr y tidyr, que son miembros centrales de tidyverse.\n\nlibrary(tidyverse)\n#> Warning: package 'tibble' was built under R version 4.2.3\n#> Warning: package 'readr' was built under R version 4.2.3\n#> Warning: package 'dplyr' was built under R version 4.2.3"
  },
  {
    "objectID": "missing-values.html#valores-perdidos-explícitos",
    "href": "missing-values.html#valores-perdidos-explícitos",
    "title": "19  Valores faltanres",
    "section": "\n19.2 Valores perdidos explícitos",
    "text": "19.2 Valores perdidos explícitos\nPara comenzar, exploremos algunas herramientas útiles para crear o eliminar valores explícitos que faltan, es decir, celdas en las que ve un NA.\n\n19.2.1 Última observación llevada adelante\nUn uso común para los valores faltantes es como una comodidad para la entrada de datos. Cuando los datos se ingresan a mano, los valores que faltan a veces indican que el valor en la fila anterior se ha repetido (o trasladado):\n\ntreatment <- tribble(\n  ~person,           ~treatment, ~response,\n  \"Derrick Whitmore\", 1,         7,\n  NA,                 2,         10,\n  NA,                 3,         NA,\n  \"Katherine Burke\",  1,         4\n)\n\nPuede completar estos valores faltantes con tidyr::fill(). Funciona como select(), tomando un conjunto de columnas:\n\ntreatment |>\n  fill(everything())\n#> # A tibble: 4 × 3\n#>   person           treatment response\n#>   <chr>                <dbl>    <dbl>\n#> 1 Derrick Whitmore         1        7\n#> 2 Derrick Whitmore         2       10\n#> 3 Derrick Whitmore         3       10\n#> 4 Katherine Burke          1        4\n\nEste tratamiento a veces se denomina “última observación realizada”, o locf (del inglés “last observation carried forward”) para abreviar. Puede usar el argumento .direction para completar los valores faltantes que se han generado de formas más exóticas.\n\n19.2.2 Valores fijos\nAlgunas veces, los valores faltantes representan algún valor fijo y conocido, más comúnmente 0. Puedes usar dplyr::coalesce() para reemplazarlos:\n\nx <- c(1, 4, 5, 7, NA)\ncoalesce(x, 0)\n#> [1] 1 4 5 7 0\n\nA veces te encontrarás con el problema opuesto en el que algún valor concreto en realidad representa un valor faltante. Por lo general, esto surge en los datos generados por un software antiguo que no tiene una forma adecuada de representar los valores faltantes, por lo que debe usar algún valor especial como 99 o -999.\nSi es posible, maneje esto cuando lea los datos, por ejemplo, usando el argumento na para readr::read_csv(), p. read_csv(ruta, na = \"99\"). Si descubre el problema más tarde, o su fuente de datos no proporciona una forma de manejarlo, puede usar dplyr::na_if():\n\nx <- c(1, 4, 5, 7, -99)\nna_if(x, -99)\n#> [1]  1  4  5  7 NA\n\n\n19.2.3 NaN\nAntes de continuar, hay un tipo especial de valor faltante que encontrará de vez en cuando: un NaN (pronunciado “nan”), del inglés not a nnumber. No es tan importante saberlo porque generalmente se comporta como NA:\n\nx <- c(NA, NaN)\nx * 10\n#> [1]  NA NaN\nx == 1\n#> [1] NA NA\nis.na(x)\n#> [1] TRUE TRUE\n\nEn el raro caso de que necesites distinguir un NA de un NaN, puedes usar is.nan(x).\nPor lo general, encontrará un NaN cuando realice una operación matemática que tenga un resultado indeterminado:\n\n0 / 0 \n#> [1] NaN\n0 * Inf\n#> [1] NaN\nInf - Inf\n#> [1] NaN\nsqrt(-1)\n#> Warning in sqrt(-1): Se han producido NaNs\n#> [1] NaN"
  },
  {
    "objectID": "missing-values.html#sec-missing-implicit",
    "href": "missing-values.html#sec-missing-implicit",
    "title": "19  Valores faltanres",
    "section": "\n19.3 Valores perdidos implícitos",
    "text": "19.3 Valores perdidos implícitos\nHasta ahora hemos hablado de los valores que faltan explícitamente, es decir, puede ver un NA en sus datos. Pero los valores faltantes también pueden faltar implícitamente, si una fila completa de datos simplemente está ausente de los datos. Ilustremos la diferencia con un conjunto de datos simple que registra el precio de algunas acciones cada trimestre:\n\nstocks <- tibble(\n  year  = c(2020, 2020, 2020, 2020, 2021, 2021, 2021),\n  qtr   = c(   1,    2,    3,    4,    2,    3,    4),\n  price = c(1.88, 0.59, 0.35,   NA, 0.92, 0.17, 2.66)\n)\n\nEste conjunto de datos tiene dos observaciones faltantes:\n\nFalta explícitamente el precio en el cuarto trimestre de 2020, porque su valor es NA.\nEl ‘precio’ para el primer trimestre de 2021 falta implícitamente, porque simplemente no aparece en el conjunto de datos.\n\nUna forma de pensar en la diferencia es con este koan de estilo zen:\n\nUn valor perdido explícito es la presencia de una ausencia.\nUn valor perdido implícito es la ausencia de una presencia.\n\nA veces, desea hacer explícitos los faltantes implícitos para tener algo físico con lo que trabajar. En otros casos, la estructura de los datos le impone faltas explícitas y desea deshacerse de ellas. Las siguientes secciones discuten algunas herramientas para moverse entre faltantes implícitos y explícitos.\n\n19.3.1 Pivotar\nYa ha visto una herramienta que puede hacer explícitas las faltas implícitas y viceversa: pivotar. Ampliar los datos puede hacer que los valores faltantes implícitos sean explícitos porque cada combinación de filas y columnas nuevas debe tener algún valor. Por ejemplo, si hacemos pivotar stocks para colocar el qtr en las columnas, ambos valores faltantes se vuelven explícitos:\n\nstocks |>\n  pivot_wider(\n    names_from = qtr, \n    values_from = price\n  )\n#> # A tibble: 2 × 5\n#>    year   `1`   `2`   `3`   `4`\n#>   <dbl> <dbl> <dbl> <dbl> <dbl>\n#> 1  2020  1.88  0.59  0.35 NA   \n#> 2  2021 NA     0.92  0.17  2.66\n\nDe forma predeterminada, hacer que los datos duren más tiempo conserva los valores faltantes explícitos, pero si son valores faltantes estructuralmente que solo existen porque los datos no están ordenados, puede descartarlos (hacerlos implícitos) configurando values_drop_na = TRUE. Consulte los ejemplos en Section 6.2 para obtener más detalles.\n\n19.3.2 Completo\ntidyr::complete() te permite generar valores perdidos explícitos proporcionando un conjunto de variables que definen la combinación de filas que deberían existir. Por ejemplo, sabemos que todas las combinaciones de year y qtr deben existir en los datos de stocks:\n\nstocks |>\n  complete(year, qtr)\n#> # A tibble: 8 × 3\n#>    year   qtr price\n#>   <dbl> <dbl> <dbl>\n#> 1  2020     1  1.88\n#> 2  2020     2  0.59\n#> 3  2020     3  0.35\n#> 4  2020     4 NA   \n#> 5  2021     1 NA   \n#> 6  2021     2  0.92\n#> # ℹ 2 more rows\n\nPor lo general, llamará a complete() con los nombres de las variables existentes, completando las combinaciones que faltan. Sin embargo, a veces las variables individuales están incompletas, por lo que puede proporcionar sus propios datos. Por ejemplo, es posible que sepa que se supone que el conjunto de datos de stocks se ejecutará desde 2019 hasta 2021, por lo que podría proporcionar explícitamente esos valores para year:\n\nstocks |>\n  complete(year = 2019:2021, qtr)\n#> # A tibble: 12 × 3\n#>    year   qtr price\n#>   <dbl> <dbl> <dbl>\n#> 1  2019     1 NA   \n#> 2  2019     2 NA   \n#> 3  2019     3 NA   \n#> 4  2019     4 NA   \n#> 5  2020     1  1.88\n#> 6  2020     2  0.59\n#> # ℹ 6 more rows\n\nSi el rango de una variable es correcto, pero no todos los valores están presentes, puede usar full_seq(x, 1) para generar todos los valores desde min(x) hasta max(x) separados por 1.\nEn algunos casos, el conjunto completo de observaciones no puede generarse mediante una simple combinación de variables. En ese caso, puede hacer manualmente lo que complete() hace por usted: crear un marco de datos que contenga todas las filas que deberían existir (usando cualquier combinación de técnicas que necesite), luego combínelo con su conjunto de datos original con dplyr ::full_join().\n\n19.3.3 Uniones\nEsto nos lleva a otra forma importante de revelar observaciones que faltan implícitamente: las uniones. Aprenderá más sobre las uniones en Chapter 20, pero queríamos mencionarlas rápidamente aquí, ya que a menudo solo puede saber que faltan valores en un conjunto de datos cuando lo compara con otro.\ndplyr::anti_join(x, y) es una herramienta particularmente útil aquí porque selecciona solo las filas en x que no tienen una coincidencia en y. Por ejemplo, podemos usar dos anti_join()s para revelar que nos falta información para cuatro aeropuertos y 722 aviones mencionados en flights:\n\nlibrary(nycflights13)\n\nflights |> \n  distinct(faa = dest) |> \n  anti_join(airports)\n#> Joining with `by = join_by(faa)`\n#> # A tibble: 4 × 1\n#>   faa  \n#>   <chr>\n#> 1 BQN  \n#> 2 SJU  \n#> 3 STT  \n#> 4 PSE\n\nflights |> \n  distinct(tailnum) |> \n  anti_join(planes)\n#> Joining with `by = join_by(tailnum)`\n#> # A tibble: 722 × 1\n#>   tailnum\n#>   <chr>  \n#> 1 N3ALAA \n#> 2 N3DUAA \n#> 3 N542MQ \n#> 4 N730MQ \n#> 5 N9EAMQ \n#> 6 N532UA \n#> # ℹ 716 more rows\n\n\n19.3.4 Ejercicios\n\n¿Puedes encontrar alguna relación entre el portaaviones y las filas que parecen faltar en planes?"
  },
  {
    "objectID": "missing-values.html#factores-y-grupos-vacíos",
    "href": "missing-values.html#factores-y-grupos-vacíos",
    "title": "19  Valores faltanres",
    "section": "\n19.4 Factores y grupos vacíos",
    "text": "19.4 Factores y grupos vacíos\nUn último tipo de ausencia es el grupo vacío, un grupo que no contiene ninguna observación, que puede surgir cuando se trabaja con factores. Por ejemplo, imagina que tenemos un conjunto de datos que contiene información sobre la salud de las personas:\n\nhealth <- tibble(\n  name   = c(\"Ikaia\", \"Oletta\", \"Leriah\", \"Dashay\", \"Tresaun\"),\n  smoker = factor(c(\"no\", \"no\", \"no\", \"no\", \"no\"), levels = c(\"yes\", \"no\")),\n  age    = c(34, 88, 75, 47, 56),\n)\n\nY queremos contar el número de fumadores con dplyr::count():\n\nhealth |> count(smoker)\n#> # A tibble: 1 × 2\n#>   smoker     n\n#>   <fct>  <int>\n#> 1 no         5\n\nEste conjunto de datos solo contiene no fumadores, pero sabemos que existen fumadores; el grupo de no fumadores está vacío. Podemos solicitar a count() que mantenga todos los grupos, incluso aquellos que no se ven en los datos usando .drop = FALSE:\n\nhealth |> count(smoker, .drop = FALSE)\n#> # A tibble: 2 × 2\n#>   smoker     n\n#>   <fct>  <int>\n#> 1 yes        0\n#> 2 no         5\n\nEl mismo principio se aplica a los ejes discretos de ggplot2, que también eliminarán los niveles que no tengan ningún valor. Puede obligarlos a que se muestren proporcionando drop = FALSE en el eje discreto apropiado:\n\nggplot(health, aes(x = smoker)) +\n  geom_bar() +\n  scale_x_discrete()\n\nggplot(health, aes(x = smoker)) +\n  geom_bar() +\n  scale_x_discrete(drop = FALSE)\n\n\n\n\n\n\n\n\n\n\n\nEl mismo problema surge de manera más general con dplyr::group_by(). Y de nuevo puedes usar .drop = FALSE para conservar todos los niveles de los factores:\n\nhealth |> \n  group_by(smoker, .drop = FALSE) |> \n  summarize(\n    n = n(),\n    mean_age = mean(age),\n    min_age = min(age),\n    max_age = max(age),\n    sd_age = sd(age)\n  )\n#> # A tibble: 2 × 6\n#>   smoker     n mean_age min_age max_age sd_age\n#>   <fct>  <int>    <dbl>   <dbl>   <dbl>  <dbl>\n#> 1 yes        0      NaN     Inf    -Inf   NA  \n#> 2 no         5       60      34      88   21.6\n\nAquí obtenemos algunos resultados interesantes porque al resumir un grupo vacío, las funciones de resumen se aplican a vectores de longitud cero. Hay una distinción importante entre los vectores vacíos, que tienen una longitud de 0, y los valores faltantes, cada uno de los cuales tiene una longitud de 1.\n\n# Un vector que contiene dos valores faltantes\nx1 <- c(NA, NA)\nlength(x1)\n#> [1] 2\n\n# Un vector que no contiene nada\nx2 <- numeric()\nlength(x2)\n#> [1] 0\n\nTodas las funciones de resumen funcionan con vectores de longitud cero, pero pueden devolver resultados sorprendentes a primera vista. Aquí vemos que mean(age) devuelve NaN porque mean(age) = sum(age)/length(age) que aquí es 0/0. max() y min() devuelven -Inf e Inf para vectores vacíos, por lo que si combina los resultados con un vector no vacío de nuevos datos y vuelve a calcular, obtendrá el mínimo o el máximo de los nuevos datos[^ valores perdidos-1].\nA veces, un enfoque más simple es realizar el resumen y luego hacer explícitas las faltas implícitas con complete().\n\nhealth |> \n  group_by(smoker) |> \n  summarize(\n    n = n(),\n    mean_age = mean(age),\n    min_age = min(age),\n    max_age = max(age),\n    sd_age = sd(age)\n  ) |> \n  complete(smoker)\n#> # A tibble: 2 × 6\n#>   smoker     n mean_age min_age max_age sd_age\n#>   <fct>  <int>    <dbl>   <dbl>   <dbl>  <dbl>\n#> 1 yes       NA       NA      NA      NA   NA  \n#> 2 no         5       60      34      88   21.6\n\nEl principal inconveniente de este enfoque es que obtienes un NA para el conteo, aunque sabes que debería ser cero."
  },
  {
    "objectID": "missing-values.html#resumen",
    "href": "missing-values.html#resumen",
    "title": "19  Valores faltanres",
    "section": "\n19.5 Resumen",
    "text": "19.5 Resumen\n¡Los valores perdidos son raros! A veces se registran como un ‘NA’ explícito, pero otras veces solo se notan por su ausencia. Este capítulo le ha brindado algunas herramientas para trabajar con valores perdidos explícitos, herramientas para descubrir valores perdidos implícitos y discutido algunas de las formas en que lo implícito puede volverse explícito y viceversa.\nEn el siguiente capítulo, abordamos el último capítulo de esta parte del libro: las uniones. Este es un pequeño cambio con respecto a los capítulos hasta ahora porque vamos a discutir las herramientas que funcionan con marcos de datos como un todo, no algo que se coloca dentro de un marco de datos."
  },
  {
    "objectID": "joins.html#introducción",
    "href": "joins.html#introducción",
    "title": "20  Uniones",
    "section": "\n20.1 Introducción",
    "text": "20.1 Introducción\nEs raro que un análisis de datos involucre solo un único marco de datos. Por lo general, tiene muchos marcos de datos y debe unirlos para responder las preguntas que le interesan. Este capítulo le presentará dos tipos importantes de uniones:\n\nCombinaciones mutantes, que agregan nuevas variables a un marco de datos a partir de observaciones coincidentes en otro.\nCombinaciones de filtrado, que filtran las observaciones de un marco de datos en función de si coinciden o no con una observación en otro.\n\nComenzaremos analizando las llaves, las variables que se utilizan para conectar un par de marcos de datos en una combinación. Cimentamos la teoría con un examen de las llaves en los conjuntos de datos del paquete nycflights13, luego usamos ese conocimiento para comenzar a unir marcos de datos. A continuación, analizaremos cómo funcionan las uniones, centrándonos en su acción en las filas. Terminaremos con una discusión sobre las uniones no equitativas, una familia de uniones que proporcionan una forma más flexible de hacer coincidir llaves que la relación de igualdad predeterminada.\n\n20.1.1 Requisitos previos\nEn este capítulo, exploraremos los cinco conjuntos de datos relacionados de nycflights13 utilizando las funciones de combinación de dplyr.\n\nlibrary(tidyverse)\nlibrary(nycflights13)"
  },
  {
    "objectID": "joins.html#llaves",
    "href": "joins.html#llaves",
    "title": "20  Uniones",
    "section": "\n20.2 Llaves",
    "text": "20.2 Llaves\nPara comprender las uniones, primero debe comprender cómo se pueden conectar dos tablas a través de un par de llaves, dentro de cada tabla. En esta sección, aprenderá sobre los dos tipos de llave y verá ejemplos de ambos en los conjuntos de datos del paquete nycflights13. También aprenderá cómo verificar que sus llaves sean válidas y qué hacer si su tabla no tiene una llave.\n\n20.2.1 Llaves primarias y foráneas\nCada unión implica un par de llaves: una llave principal y una llave externa. Una Llave principal es una variable o un conjunto de variables que identifica de forma única cada observación. Cuando se necesita más de una variable, la llave se denomina Llave compuesta. Por ejemplo, en nycflights13:\n\n\nairlines registra dos datos sobre cada aerolínea: su código de aerolínea y su nombre completo. Puede identificar una línea aérea con su código de dos letras, haciendo que carrier sea la llave principal.\n\nairlines\n#&gt; # A tibble: 16 × 2\n#&gt;   carrier name                    \n#&gt;   &lt;chr&gt;   &lt;chr&gt;                   \n#&gt; 1 9E      Endeavor Air Inc.       \n#&gt; 2 AA      American Airlines Inc.  \n#&gt; 3 AS      Alaska Airlines Inc.    \n#&gt; 4 B6      JetBlue Airways         \n#&gt; 5 DL      Delta Air Lines Inc.    \n#&gt; 6 EV      ExpressJet Airlines Inc.\n#&gt; # ℹ 10 more rows\n\n\n\nairports registra datos sobre cada aeropuerto. Puede identificar cada aeropuerto por su código de aeropuerto de tres letras, haciendo que faa sea la llave principal.\n\nairports\n#&gt; # A tibble: 1,458 × 8\n#&gt;   faa   name                            lat   lon   alt    tz dst  \n#&gt;   &lt;chr&gt; &lt;chr&gt;                         &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;\n#&gt; 1 04G   Lansdowne Airport              41.1 -80.6  1044    -5 A    \n#&gt; 2 06A   Moton Field Municipal Airport  32.5 -85.7   264    -6 A    \n#&gt; 3 06C   Schaumburg Regional            42.0 -88.1   801    -6 A    \n#&gt; 4 06N   Randall Airport                41.4 -74.4   523    -5 A    \n#&gt; 5 09J   Jekyll Island Airport          31.1 -81.4    11    -5 A    \n#&gt; 6 0A9   Elizabethton Municipal Airpo…  36.4 -82.2  1593    -5 A    \n#&gt; # ℹ 1,452 more rows\n#&gt; # ℹ 1 more variable: tzone &lt;chr&gt;\n\n\n\nplanes registra datos sobre cada plano. Puede identificar un avión por su número de cola, haciendo que tailnum sea la llave principal.\n\nplanes\n#&gt; # A tibble: 3,322 × 9\n#&gt;   tailnum  year type              manufacturer    model     engines\n#&gt;   &lt;chr&gt;   &lt;int&gt; &lt;chr&gt;             &lt;chr&gt;           &lt;chr&gt;       &lt;int&gt;\n#&gt; 1 N10156   2004 Fixed wing multi… EMBRAER         EMB-145XR       2\n#&gt; 2 N102UW   1998 Fixed wing multi… AIRBUS INDUSTR… A320-214        2\n#&gt; 3 N103US   1999 Fixed wing multi… AIRBUS INDUSTR… A320-214        2\n#&gt; 4 N104UW   1999 Fixed wing multi… AIRBUS INDUSTR… A320-214        2\n#&gt; 5 N10575   2002 Fixed wing multi… EMBRAER         EMB-145LR       2\n#&gt; 6 N105UW   1999 Fixed wing multi… AIRBUS INDUSTR… A320-214        2\n#&gt; # ℹ 3,316 more rows\n#&gt; # ℹ 3 more variables: seats &lt;int&gt;, speed &lt;int&gt;, engine &lt;chr&gt;\n\n\n\nweather registra datos sobre el clima en los aeropuertos de origen. Puede identificar cada observación por la combinación de ubicación y hora, haciendo que origin y time_hour sean la llave principal compuesta.\n\nweather\n#&gt; # A tibble: 26,115 × 15\n#&gt;   origin  year month   day  hour  temp  dewp humid wind_dir\n#&gt;   &lt;chr&gt;  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 EWR     2013     1     1     1  39.0  26.1  59.4      270\n#&gt; 2 EWR     2013     1     1     2  39.0  27.0  61.6      250\n#&gt; 3 EWR     2013     1     1     3  39.0  28.0  64.4      240\n#&gt; 4 EWR     2013     1     1     4  39.9  28.0  62.2      250\n#&gt; 5 EWR     2013     1     1     5  39.0  28.0  64.4      260\n#&gt; 6 EWR     2013     1     1     6  37.9  28.0  67.2      240\n#&gt; # ℹ 26,109 more rows\n#&gt; # ℹ 6 more variables: wind_speed &lt;dbl&gt;, wind_gust &lt;dbl&gt;, …\n\n\n\nUna llave externa es una variable (o conjunto de variables) que corresponde a una llave principal en otra tabla. Por ejemplo:\n\n\nflights$tailnum es una llave foránea que corresponde a la llave primaria planes$tailnum.\n\nflights$carrier es una llave foránea que corresponde a la llave primaria airlines$carrier.\n\nflights$origin es una llave foránea que corresponde a la llave primaria airports$faa.\n\nflights$dest es una llave foránea que corresponde a la llave primaria airports$faa.\n\nflights$origin-flights$time_hour es una llave foránea compuesta que corresponde a la llave primaria compuesta weather$origin-weather$time_hour.\n\nEstas relaciones se resumen visualmente en Figura 20.1.\n\n\n\n\nFigura 20.1: Conexiones entre los cinco marcos de datos en el paquete nycflights13. Las variables que componen una llave primaria son de color gris y están conectadas a sus correspondientes llaves foráneas con flechas.\n\n\n\nNotará una buena característica en el diseño de estas claves: las claves principal y externa casi siempre tienen los mismos nombres, lo que, como verá en breve, hará que su vida de unión sea mucho más fácil. También vale la pena señalar la relación opuesta: casi todos los nombres de variables utilizados en varias tablas tienen el mismo significado en cada lugar. Sólo hay una excepción: year significa año de salida en flights y año de fabricación en planes. Esto se volverá importante cuando empecemos a unir tablas.\n\n20.2.2 Comprobación de llaves primarias\nAhora que hemos identificado las claves principales en cada tabla, es una buena práctica verificar que realmente identifiquen de manera única cada observación. Una forma de hacerlo es contar, count(), las llaves primarias y buscar entradas donde n sea mayor que uno. Esto revela que planes y weather se ven bien:\n\nplanes |&gt; \n  count(tailnum) |&gt; \n  filter(n &gt; 1)\n#&gt; # A tibble: 0 × 2\n#&gt; # ℹ 2 variables: tailnum &lt;chr&gt;, n &lt;int&gt;\n\nweather |&gt; \n  count(time_hour, origin) |&gt; \n  filter(n &gt; 1)\n#&gt; # A tibble: 0 × 3\n#&gt; # ℹ 3 variables: time_hour &lt;dttm&gt;, origin &lt;chr&gt;, n &lt;int&gt;\n\nTambién debe verificar si faltan valores en sus llaves principales — si falta un valor, ¡entonces no puede identificar una observación!\n\nplanes |&gt; \n  filter(is.na(tailnum))\n#&gt; # A tibble: 0 × 9\n#&gt; # ℹ 9 variables: tailnum &lt;chr&gt;, year &lt;int&gt;, type &lt;chr&gt;, manufacturer &lt;chr&gt;,\n#&gt; #   model &lt;chr&gt;, engines &lt;int&gt;, seats &lt;int&gt;, speed &lt;int&gt;, engine &lt;chr&gt;\n\nweather |&gt; \n  filter(is.na(time_hour) | is.na(origin))\n#&gt; # A tibble: 0 × 15\n#&gt; # ℹ 15 variables: origin &lt;chr&gt;, year &lt;int&gt;, month &lt;int&gt;, day &lt;int&gt;,\n#&gt; #   hour &lt;int&gt;, temp &lt;dbl&gt;, dewp &lt;dbl&gt;, humid &lt;dbl&gt;, wind_dir &lt;dbl&gt;, …\n\n\n20.2.3 Llaves sustitutas\nHasta ahora no hemos hablado de la llave principal para flights. No es muy importante aquí, porque no hay marcos de datos que lo usen como clave externa, pero aún así es útil considerarlo porque es más fácil trabajar con observaciones si tenemos alguna forma de describirlas a otros.\nDespués de pensar un poco y experimentar, determinamos que hay tres variables que juntas identifican de manera única cada vuelo:\n\nflights |&gt; \n  count(time_hour, carrier, flight) |&gt; \n  filter(n &gt; 1)\n#&gt; # A tibble: 0 × 4\n#&gt; # ℹ 4 variables: time_hour &lt;dttm&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, n &lt;int&gt;\n\n¿La ausencia de duplicados convierte automáticamente a time_hour-carrier-flight en una llave principal? Sin duda es un buen comienzo, pero no lo garantiza. Por ejemplo, ¿son la altitud y la latitud una buena clave principal para airports?\n\nairports |&gt;\n  count(alt, lat) |&gt; \n  filter(n &gt; 1)\n#&gt; # A tibble: 1 × 3\n#&gt;     alt   lat     n\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n#&gt; 1    13  40.6     2\n\nIdentificar un aeropuerto por su altitud y latitud es claramente una mala idea y, en general, no es posible saber solo a partir de los datos si una combinación de variables constituye o no una buena clave primaria. Pero para los vuelos, la combinación de time_hour, carrier y flight parece razonable porque sería realmente confuso para una aerolínea y sus clientes si hubiera varios vuelos con el mismo número de vuelo en el aire al mismo tiempo.\nDicho esto, sería mejor que introdujéramos una clave sustituta numérica simple usando el número de fila:\n\nflights2 &lt;- flights |&gt; \n  mutate(id = row_number(), .before = 1)\nflights2\n#&gt; # A tibble: 336,776 × 20\n#&gt;      id  year month   day dep_time sched_dep_time dep_delay arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;\n#&gt; 1     1  2013     1     1      517            515         2      830\n#&gt; 2     2  2013     1     1      533            529         4      850\n#&gt; 3     3  2013     1     1      542            540         2      923\n#&gt; 4     4  2013     1     1      544            545        -1     1004\n#&gt; 5     5  2013     1     1      554            600        -6      812\n#&gt; 6     6  2013     1     1      554            558        -4      740\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 12 more variables: sched_arr_time &lt;int&gt;, arr_delay &lt;dbl&gt;, …\n\nLas claves sustitutas pueden ser particularmente útiles cuando se comunican con otros humanos: es mucho más fácil decirle a alguien que mire el vuelo 2001 que decir que mire el UA430 que partió 9am 2013-01-03.\n\n20.2.4 Ejercicios\n\nNos olvidamos de dibujar la relación entre weather y airports en Figura 20.1. ¿Cuál es la relación y cómo debería aparecer en el diagrama?\nweather solo contiene información de los tres aeropuertos de origen en NYC. Si contuviera registros meteorológicos de todos los aeropuertos de EE.UU. ¿qué conexión adicional haría con flights?\nLas variables year, month, day, hour y origin casi forman una clave compuesta para weather, pero hay una hora que tiene observaciones duplicadas. ¿Puedes averiguar qué tiene de especial esa hora?\nSabemos que algunos días del año son especiales y en ellos vuelan menos personas de lo habitual (por ejemplo, la víspera de Navidad y el día de Navidad). ¿Cómo podría representar esos datos como un marco de datos? ¿Cuál sería la llave principal? ¿Cómo se conectaría a los marcos de datos existentes?\nDibuje un diagrama que ilustre las conexiones entre los marcos de datos Batting, People y Salaries en el paquete Lahman. Dibuja otro diagrama que muestre la relación entre People, Managers, AwardsManagers. ¿Cómo caracterizaría la relación entre los data frames Batting, Pitching, y Fielding?"
  },
  {
    "objectID": "joins.html#sec-mutating-joins",
    "href": "joins.html#sec-mutating-joins",
    "title": "20  Uniones",
    "section": "\n20.3 Uniones básicas",
    "text": "20.3 Uniones básicas\nAhora que comprende cómo se conectan los marcos de datos a través de claves, podemos comenzar a usar uniones para comprender mejor el conjunto de datos de flights. dplyr proporciona seis funciones de unión: left_join(), inner_join(), right_join(), full_join(), semi_join() y anti_join(). Todas tienen la misma interfaz: toman un par de marcos de datos (x e y) y devuelven un marco de datos. El orden de las filas y columnas en la salida está determinado principalmente por x.\nEn esta sección, aprenderá a usar una unión mutante, left_join(), y dos uniones de filtrado, semi_join() y anti_join(). En la siguiente sección, aprenderá exactamente cómo funcionan estas funciones y sobre las inner_join(), right_join() y full_join() restantes.\n\n20.3.1 Uniones mutantes\nUna unión mutante le permite combinar variables de dos marcos de datos: primero hace coincidir las observaciones por sus claves, luego copia las variables de un marco de datos al otro. Al igual que mutate(), las funciones de combinación agregan variables a la derecha, por lo que si su conjunto de datos tiene muchas variables, no verá las nuevas. Para estos ejemplos, facilitaremos ver lo que sucede creando un conjunto de datos más estrecho con solo seis variables1:\n\nflights2 &lt;- flights |&gt; \n  select(year, time_hour, origin, dest, tailnum, carrier)\nflights2\n#&gt; # A tibble: 336,776 × 6\n#&gt;    year time_hour           origin dest  tailnum carrier\n#&gt;   &lt;int&gt; &lt;dttm&gt;              &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;  \n#&gt; 1  2013 2013-01-01 05:00:00 EWR    IAH   N14228  UA     \n#&gt; 2  2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA     \n#&gt; 3  2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA     \n#&gt; 4  2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6     \n#&gt; 5  2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL     \n#&gt; 6  2013 2013-01-01 05:00:00 EWR    ORD   N39463  UA     \n#&gt; # ℹ 336,770 more rows\n\nHay cuatro tipos de unión mutante, pero hay una que usará casi todo el tiempo: left_join(). Es especial porque la salida siempre tendrá las mismas filas que x, el dataframe al que estas uniendo2. El uso principal de left_join() es agregar metadatos adicionales. Por ejemplo, podemos usar left_join() para agregar el nombre completo de la aerolínea a los datos de flights2:\n\nflights2 |&gt;\n  left_join(airlines)\n#&gt; Joining with `by = join_by(carrier)`\n#&gt; # A tibble: 336,776 × 7\n#&gt;    year time_hour           origin dest  tailnum carrier name                \n#&gt;   &lt;int&gt; &lt;dttm&gt;              &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;               \n#&gt; 1  2013 2013-01-01 05:00:00 EWR    IAH   N14228  UA      United Air Lines In…\n#&gt; 2  2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA      United Air Lines In…\n#&gt; 3  2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA      American Airlines I…\n#&gt; 4  2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6      JetBlue Airways     \n#&gt; 5  2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL      Delta Air Lines Inc.\n#&gt; 6  2013 2013-01-01 05:00:00 EWR    ORD   N39463  UA      United Air Lines In…\n#&gt; # ℹ 336,770 more rows\n\nO podríamos averiguar la temperatura y la velocidad del viento cuando partió cada avión:\n\nflights2 |&gt; \n  left_join(weather |&gt; select(origin, time_hour, temp, wind_speed))\n#&gt; Joining with `by = join_by(time_hour, origin)`\n#&gt; # A tibble: 336,776 × 8\n#&gt;    year time_hour           origin dest  tailnum carrier  temp wind_speed\n#&gt;   &lt;int&gt; &lt;dttm&gt;              &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;      &lt;dbl&gt;\n#&gt; 1  2013 2013-01-01 05:00:00 EWR    IAH   N14228  UA       39.0       12.7\n#&gt; 2  2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA       39.9       15.0\n#&gt; 3  2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA       39.0       15.0\n#&gt; 4  2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6       39.0       15.0\n#&gt; 5  2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL       39.9       16.1\n#&gt; 6  2013 2013-01-01 05:00:00 EWR    ORD   N39463  UA       39.0       12.7\n#&gt; # ℹ 336,770 more rows\n\nO qué tamaño de avión estaba volando:\n\nflights2 |&gt; \n  left_join(planes |&gt; select(tailnum, type, engines, seats))\n#&gt; Joining with `by = join_by(tailnum)`\n#&gt; # A tibble: 336,776 × 9\n#&gt;    year time_hour           origin dest  tailnum carrier type                \n#&gt;   &lt;int&gt; &lt;dttm&gt;              &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;               \n#&gt; 1  2013 2013-01-01 05:00:00 EWR    IAH   N14228  UA      Fixed wing multi en…\n#&gt; 2  2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA      Fixed wing multi en…\n#&gt; 3  2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA      Fixed wing multi en…\n#&gt; 4  2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6      Fixed wing multi en…\n#&gt; 5  2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL      Fixed wing multi en…\n#&gt; 6  2013 2013-01-01 05:00:00 EWR    ORD   N39463  UA      Fixed wing multi en…\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 2 more variables: engines &lt;int&gt;, seats &lt;int&gt;\n\nCuando left_join() no encuentra una coincidencia para una fila en x, completa las nuevas variables con los valores que faltan. Por ejemplo, no hay información sobre el avión con el número de cola N3ALAA, por lo que faltarán el type, los engines y los seats:\n\nflights2 |&gt; \n  filter(tailnum == \"N3ALAA\") |&gt; \n  left_join(planes |&gt; select(tailnum, type, engines, seats))\n#&gt; Joining with `by = join_by(tailnum)`\n#&gt; # A tibble: 63 × 9\n#&gt;    year time_hour           origin dest  tailnum carrier type  engines seats\n#&gt;   &lt;int&gt; &lt;dttm&gt;              &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;int&gt; &lt;int&gt;\n#&gt; 1  2013 2013-01-01 06:00:00 LGA    ORD   N3ALAA  AA      &lt;NA&gt;       NA    NA\n#&gt; 2  2013 2013-01-02 18:00:00 LGA    ORD   N3ALAA  AA      &lt;NA&gt;       NA    NA\n#&gt; 3  2013 2013-01-03 06:00:00 LGA    ORD   N3ALAA  AA      &lt;NA&gt;       NA    NA\n#&gt; 4  2013 2013-01-07 19:00:00 LGA    ORD   N3ALAA  AA      &lt;NA&gt;       NA    NA\n#&gt; 5  2013 2013-01-08 17:00:00 JFK    ORD   N3ALAA  AA      &lt;NA&gt;       NA    NA\n#&gt; 6  2013 2013-01-16 06:00:00 LGA    ORD   N3ALAA  AA      &lt;NA&gt;       NA    NA\n#&gt; # ℹ 57 more rows\n\nVolveremos a este problema unas cuantas veces en el resto del capítulo.\n\n20.3.2 Especificación de llaves de combinación\nPor defecto, left_join() usará todas las variables que aparecen en ambos marcos de datos como llave de unión, la llamada unión natural. Esta es una heurística útil, pero no siempre funciona. Por ejemplo, ¿qué sucede si tratamos de unir flights2 con el conjunto de datos completo planes?\n\nflights2 |&gt; \n  left_join(planes)\n#&gt; Joining with `by = join_by(year, tailnum)`\n#&gt; # A tibble: 336,776 × 13\n#&gt;    year time_hour           origin dest  tailnum carrier type  manufacturer\n#&gt;   &lt;int&gt; &lt;dttm&gt;              &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;       \n#&gt; 1  2013 2013-01-01 05:00:00 EWR    IAH   N14228  UA      &lt;NA&gt;  &lt;NA&gt;        \n#&gt; 2  2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA      &lt;NA&gt;  &lt;NA&gt;        \n#&gt; 3  2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA      &lt;NA&gt;  &lt;NA&gt;        \n#&gt; 4  2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6      &lt;NA&gt;  &lt;NA&gt;        \n#&gt; 5  2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL      &lt;NA&gt;  &lt;NA&gt;        \n#&gt; 6  2013 2013-01-01 05:00:00 EWR    ORD   N39463  UA      &lt;NA&gt;  &lt;NA&gt;        \n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 5 more variables: model &lt;chr&gt;, engines &lt;int&gt;, seats &lt;int&gt;, …\n\nNos faltan muchas coincidencias porque nuestra combinación intenta usar tailnum y year como clave compuesta. Tanto flights como planes tienen una columna de year pero significan cosas diferentes: flights$year es el año en que ocurrió el vuelo y planes$year es el año en que se construyó el avión. Solo queremos unirnos en tailnum, por lo que debemos proporcionar una especificación explícita con join_by ():\n\nflights2 |&gt; \n  left_join(planes, join_by(tailnum))\n#&gt; # A tibble: 336,776 × 14\n#&gt;   year.x time_hour           origin dest  tailnum carrier year.y\n#&gt;    &lt;int&gt; &lt;dttm&gt;              &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;    &lt;int&gt;\n#&gt; 1   2013 2013-01-01 05:00:00 EWR    IAH   N14228  UA        1999\n#&gt; 2   2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA        1998\n#&gt; 3   2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA        1990\n#&gt; 4   2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6        2012\n#&gt; 5   2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL        1991\n#&gt; 6   2013 2013-01-01 05:00:00 EWR    ORD   N39463  UA        2012\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 7 more variables: type &lt;chr&gt;, manufacturer &lt;chr&gt;, model &lt;chr&gt;, …\n\nTenga en cuenta que las variables year se eliminan de la ambigüedad en la salida con un sufijo (year.x y year.y), que le indica si la variable proviene del argumento x o y. Puede anular los sufijos predeterminados con el argumento suffix.\njoin_by(tailnum) es corto para join_by(tailnum == tailnum). Es importante saber acerca de esta forma más completa por dos razones. En primer lugar, describe la relación entre las dos tablas: las claves deben ser iguales. Es por eso que este tipo de unión a menudo se denomina equi-unión. Aprenderá acerca de las uniones no equitativas en Sección 20.5.\nEn segundo lugar, es cómo especifica diferentes claves de combinación en cada tabla. Por ejemplo, hay dos formas de unirs las tablas flight2 y airports: ya sea por dest o origin:\n\nflights2 |&gt; \n  left_join(airports, join_by(dest == faa))\n#&gt; # A tibble: 336,776 × 13\n#&gt;    year time_hour           origin dest  tailnum carrier name                \n#&gt;   &lt;int&gt; &lt;dttm&gt;              &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;               \n#&gt; 1  2013 2013-01-01 05:00:00 EWR    IAH   N14228  UA      George Bush Interco…\n#&gt; 2  2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA      George Bush Interco…\n#&gt; 3  2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA      Miami Intl          \n#&gt; 4  2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6      &lt;NA&gt;                \n#&gt; 5  2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL      Hartsfield Jackson …\n#&gt; 6  2013 2013-01-01 05:00:00 EWR    ORD   N39463  UA      Chicago Ohare Intl  \n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 6 more variables: lat &lt;dbl&gt;, lon &lt;dbl&gt;, alt &lt;dbl&gt;, tz &lt;dbl&gt;, …\n\nflights2 |&gt; \n  left_join(airports, join_by(origin == faa))\n#&gt; # A tibble: 336,776 × 13\n#&gt;    year time_hour           origin dest  tailnum carrier name               \n#&gt;   &lt;int&gt; &lt;dttm&gt;              &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;              \n#&gt; 1  2013 2013-01-01 05:00:00 EWR    IAH   N14228  UA      Newark Liberty Intl\n#&gt; 2  2013 2013-01-01 05:00:00 LGA    IAH   N24211  UA      La Guardia         \n#&gt; 3  2013 2013-01-01 05:00:00 JFK    MIA   N619AA  AA      John F Kennedy Intl\n#&gt; 4  2013 2013-01-01 05:00:00 JFK    BQN   N804JB  B6      John F Kennedy Intl\n#&gt; 5  2013 2013-01-01 06:00:00 LGA    ATL   N668DN  DL      La Guardia         \n#&gt; 6  2013 2013-01-01 05:00:00 EWR    ORD   N39463  UA      Newark Liberty Intl\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 6 more variables: lat &lt;dbl&gt;, lon &lt;dbl&gt;, alt &lt;dbl&gt;, tz &lt;dbl&gt;, …\n\nEn el código anterior, es posible que vea una forma diferente de especificar las claves de combinación, utilizando un vector de caracteres:\n\n\nby = \"x\" corresponde a join_by(x).\n\nby = c(\"a\" = \"x\") corresponde a join_by(a == x).\n\nAhora que existe, preferimos join_by() ya que proporciona una especificación más clara y flexible.\ninner_join(), right_join(), full_join() tienen la misma que left_join(). La diferencia es qué filas conservan: la combinación izquierda mantiene todas las filas en x, la combinación derecha mantiene todas las filas en y, la combinación completa mantiene todas las filas en x o y, y la combinación interna solo mantiene las filas que aparecen tanto en x como en y. Volveremos a esto con más detalle más adelante.\n\n20.3.3 Filtrado de uniones\nComo puede suponer, la acción principal de una unión de filtrado es filtrar las filas. Hay dos tipos: semi-uniones y anti-uniones. Semi-uniones mantienen todas las filas en x que tienen una coincidencia en y. Por ejemplo, podríamos usar una semi-unión para filtrar el conjunto de datos airports para mostrar solo los aeropuertos de origen:\n\nairports |&gt; \n  semi_join(flights2, join_by(faa == origin))\n#&gt; # A tibble: 3 × 8\n#&gt;   faa   name                  lat   lon   alt    tz dst   tzone           \n#&gt;   &lt;chr&gt; &lt;chr&gt;               &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;           \n#&gt; 1 EWR   Newark Liberty Intl  40.7 -74.2    18    -5 A     America/New_York\n#&gt; 2 JFK   John F Kennedy Intl  40.6 -73.8    13    -5 A     America/New_York\n#&gt; 3 LGA   La Guardia           40.8 -73.9    22    -5 A     America/New_York\n\nO solo los destinos:\n\nairports |&gt; \n  semi_join(flights2, join_by(faa == dest))\n#&gt; # A tibble: 101 × 8\n#&gt;   faa   name                     lat    lon   alt    tz dst   tzone          \n#&gt;   &lt;chr&gt; &lt;chr&gt;                  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;          \n#&gt; 1 ABQ   Albuquerque Internati…  35.0 -107.   5355    -7 A     America/Denver \n#&gt; 2 ACK   Nantucket Mem           41.3  -70.1    48    -5 A     America/New_Yo…\n#&gt; 3 ALB   Albany Intl             42.7  -73.8   285    -5 A     America/New_Yo…\n#&gt; 4 ANC   Ted Stevens Anchorage…  61.2 -150.    152    -9 A     America/Anchor…\n#&gt; 5 ATL   Hartsfield Jackson At…  33.6  -84.4  1026    -5 A     America/New_Yo…\n#&gt; 6 AUS   Austin Bergstrom Intl   30.2  -97.7   542    -6 A     America/Chicago\n#&gt; # ℹ 95 more rows\n\nAnti-joins son lo contrario: devuelven todas las filas en x que no tienen una coincidencia en y. Son útiles para encontrar valores perdidos que están implícitos en los datos, el tema de Sección 19.3. Los valores faltantes implícitos no se muestran como NA, sino que solo existen como una ausencia. Por ejemplo, podemos encontrar filas que faltan en airports buscando vuelos que no tengan un aeropuerto de destino coincidente:\n\nflights2 |&gt; \n  anti_join(airports, join_by(dest == faa)) |&gt; \n  distinct(dest)\n#&gt; # A tibble: 4 × 1\n#&gt;   dest \n#&gt;   &lt;chr&gt;\n#&gt; 1 BQN  \n#&gt; 2 SJU  \n#&gt; 3 STT  \n#&gt; 4 PSE\n\nO podemos encontrar qué tailnums faltan en planes:\n\nflights2 |&gt;\n  anti_join(planes, join_by(tailnum)) |&gt; \n  distinct(tailnum)\n#&gt; # A tibble: 722 × 1\n#&gt;   tailnum\n#&gt;   &lt;chr&gt;  \n#&gt; 1 N3ALAA \n#&gt; 2 N3DUAA \n#&gt; 3 N542MQ \n#&gt; 4 N730MQ \n#&gt; 5 N9EAMQ \n#&gt; 6 N532UA \n#&gt; # ℹ 716 more rows\n\n\n20.3.4 Ejercicios\n\nEncuentra las 48 horas (en el transcurso de todo el año) que tienen los peores retrasos. Haga una referencia cruzada con los datos del weather. ¿Puedes ver algún patrón?\n\nImagina que has encontrado los 10 destinos más populares usando este código:\n\ntop_dest &lt;- flights2 |&gt;\n  count(dest, sort = TRUE) |&gt;\n  head(10)\n\n¿Cómo puede encontrar todos los vuelos a esos destinos?\n\n¿Todos los vuelos que salen tienen los datos meteorológicos correspondientes a esa hora?\n¿Qué tienen en común los números de cola que no tienen un registro coincidente en planes? (Pista: una variable explica ~90% de los problemas.)\nAgregue una columna a planes que enumere cada carrier que ha volado ese avión. Es de esperar que haya una relación implícita entre el avión y la línea aérea, porque cada avión lo pilota una sola línea aérea. Confirme o rechace esta hipótesis utilizando las herramientas que ha aprendido en los capítulos anteriores.\nAñade la latitud y la longitud del aeropuerto de origen y de destino a flights. ¿Es más fácil cambiar el nombre de las columnas antes o después de la unión?\n\nCalcule el retraso promedio por destino, luego únase al marco de datos airports para que pueda mostrar la distribución espacial de los retrasos. Aquí hay una manera fácil de dibujar un mapa de los Estados Unidos.:\n\nairports |&gt;\n  semi_join(flights, join_by(faa == dest)) |&gt;\n  ggplot(aes(x = lon, y = lat)) +\n    borders(\"state\") +\n    geom_point() +\n    coord_quickmap()\n\nEs posible que desee utilizar el size o el color de los puntos para mostrar el retraso promedio de cada aeropuerto.\n\n¿Qué pasó el 13 de junio de 2013? Dibuje un mapa de los retrasos y luego use Google para hacer una referencia cruzada con el clima."
  },
  {
    "objectID": "joins.html#cómo-funcionan-las-uniones",
    "href": "joins.html#cómo-funcionan-las-uniones",
    "title": "20  Uniones",
    "section": "\n20.4 ¿Cómo funcionan las uniones?",
    "text": "20.4 ¿Cómo funcionan las uniones?\nAhora que ha usado combinaciones varias veces, es hora de aprender más sobre cómo funcionan, enfocándose en cómo cada fila en x coincide con las filas en y. Comenzaremos presentando una representación visual de las uniones, usando los simples tibbles definidos a continuación y que se muestran en Figura 20.2. En estos ejemplos, usaremos una sola llave llamada key y una sola columna de valor (val_x y val_y), pero todas las ideas se generalizan a múltiples llaves y múltiples valores.\n\nx &lt;- tribble(\n  ~key, ~val_x,\n     1, \"x1\",\n     2, \"x2\",\n     3, \"x3\"\n)\ny &lt;- tribble(\n  ~key, ~val_y,\n     1, \"y1\",\n     2, \"y2\",\n     4, \"y3\"\n)\n\n\n\n\n\nFigura 20.2: Representación gráfica de dos tablas simples. Las columnas key coloreadas asignan el color de fondo al valor clave. Las columnas grises representan las columnas de “value” que se llevan durante el viaje.\n\n\n\nFigura 20.3 introduce la base para nuestra representación visual. Muestra todas las posibles coincidencias entre x e y como la intersección entre las líneas dibujadas desde cada fila de x y cada fila de y. Las filas y columnas en la salida están determinadas principalmente por x, por lo que la tabla x es horizontal y se alinea con la salida.\n\n\n\n\nFigura 20.3: Para comprender cómo funcionan las uniones, es útil pensar en todas las coincidencias posibles. Aquí lo mostramos con una cuadrícula de líneas de conexión.\n\n\n\nPara describir un tipo específico de combinación, indicamos coincidencias con puntos. Las coincidencias determinan las filas en la salida, un nuevo marco de datos que contiene la clave, los valores x y los valores y. Por ejemplo, Figura 20.4 muestra una combinación interna, donde las filas se retienen si y solo si las claves son iguales.\n\n\n\n\nFigura 20.4: Una unión interna hace coincidir cada fila en x con la fila en y que tiene el mismo valor de key. Cada coincidencia se convierte en una fila en la salida.\n\n\n\nPodemos aplicar los mismos principios para explicar las uniones externas, que mantienen las observaciones que aparecen en al menos uno de los marcos de datos. Estas uniones funcionan agregando una observación “virtual” adicional a cada marco de datos. Esta observación tiene una clave que coincide si ninguna otra clave coincide, y los valores se completan con NA. Hay tres tipos de uniones externas:\n\n\nUna unión izquierda mantiene todas las observaciones en x, Figura 20.5. Cada fila de x se conserva en la salida porque puede volver a coincidir con una fila de NAs en y.\n\n\n\n\nFigura 20.5: Una representación visual de la combinación izquierda donde cada fila en x aparece en la salida.\n\n\n\n\n\nUna unión derecha mantiene todas las observaciones en y, Figura 20.6. Cada fila de y se conserva en la salida porque puede volver a hacer coincidir una fila de NAs en x. La salida aún coincide con x tanto como sea posible; cualquier fila adicional de y se agrega al final.\n\n\n\n\nFigura 20.6: Una representación visual de la combinación correcta donde cada fila de y aparece en la salida.\n\n\n\n\n\nUna combinación completa mantiene todas las observaciones que aparecen en x o y, Figura 20.7. Cada fila de x e y se incluye en la salida porque tanto x como y tienen una fila de reserva de NA. Una vez más, la salida comienza con todas las filas desde x, seguidas de las filas restantes y no coincidentes.\n\n\n\n\nFigura 20.7: Una representación visual de la combinación completa donde cada fila en x e y aparece en la salida.\n\n\n\n\n\nOtra forma de mostrar cómo difieren los tipos de unión externa es con un diagrama de Venn, como en Figura 20.8. Sin embargo, esta no es una gran representación porque, si bien puede refrescar su memoria sobre qué filas se conservan, no ilustra lo que sucede con las columnas.\n\n\n\n\nFigura 20.8: Diagramas de Venn que muestran la diferencia entre uniones internas, izquierdas, derechas y completas.\n\n\n\nLas uniones que se muestran aquí son las denominadas equi uniones, donde las filas coinciden si las claves son iguales. Las uniones equitativas son el tipo de unión más común, por lo que normalmente omitiremos el prefijo equi y solo diremos “unión interna” en lugar de “unión interna equi”. Volveremos a las uniones no equitativas en Sección 20.5.\n\n20.4.1 Coincidencia de filas\nHasta ahora hemos explorado lo que sucede si una fila en x coincide con cero o una fila en y. ¿Qué sucede si coincide con más de una fila? Para comprender lo que sucede, primero limitemos nuestro enfoque a inner_join() y luego dibujemos una imagen, Figura 20.9.\n\n\n\n\nFigura 20.9: Las tres formas en que una fila en x puede coincidir. x1 coincide con una fila en y, x2 coincide con dos filas en y, x3 coincide con cero filas en y. Tenga en cuenta que si bien hay tres filas en x y tres filas en la salida, no hay una correspondencia directa entre las filas.\n\n\n\nHay tres resultados posibles para una fila en x:\n\nSi no coincide con nada, se descarta.\nSi coincide con 1 fila en y, se conserva.\nSi coincide con más de 1 fila en y, se duplica una vez para cada coincidencia.\n\nEn principio, esto significa que no hay una correspondencia garantizada entre las filas de la salida y las filas de x, pero en la práctica, esto rara vez causa problemas. Hay, sin embargo, un caso particularmente peligroso que puede provocar una explosión combinatoria de filas. Imagina unir las siguientes dos tablas:\n\ndf1 &lt;- tibble(key = c(1, 2, 2), val_x = c(\"x1\", \"x2\", \"x3\"))\ndf2 &lt;- tibble(key = c(1, 2, 2), val_y = c(\"y1\", \"y2\", \"y3\"))\n\nMientras que la primera fila en df1 solo coincide con una fila en df2, la segunda y la tercera fila coinciden con dos filas. Esto a veces se denomina unión de muchos a muchos y hará que dplyr emita una advertencia:\n\ndf1 |&gt; \n  inner_join(df2, join_by(key))\n#&gt; Warning in inner_join(df1, df2, join_by(key)): Detected an unexpected many-to-many relationship between `x` and `y`.\n#&gt; ℹ Row 2 of `x` matches multiple rows in `y`.\n#&gt; ℹ Row 2 of `y` matches multiple rows in `x`.\n#&gt; ℹ If a many-to-many relationship is expected, set `relationship =\n#&gt;   \"many-to-many\"` to silence this warning.\n#&gt; # A tibble: 5 × 3\n#&gt;     key val_x val_y\n#&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;\n#&gt; 1     1 x1    y1   \n#&gt; 2     2 x2    y2   \n#&gt; 3     2 x2    y3   \n#&gt; 4     2 x3    y2   \n#&gt; 5     2 x3    y3\n\nSi está haciendo esto deliberadamente, puede configurar relationship = \"many-to-many\", como sugiere la advertencia.\n\n20.4.2 Filtrado de uniones\nEl número de coincidencias también determina el comportamiento de las uniones de filtrado. El semi-join mantiene filas en x que tienen una o más coincidencias en y, como en Figura 20.10. El anti-join mantiene filas en x que coinciden con cero filas en y, como en Figura 20.11. En ambos casos, solo es importante la existencia de una coincidencia; no importa cuantas veces coincida. Esto significa que las uniones de filtrado nunca duplican filas como lo hacen las uniones mutantes.\n\n\n\n\nFigura 20.10: En un semi-join solo importa que haya coincidencia; de lo contrario, los valores en y no afectan la salida.\n\n\n\n\n\n\n\nFigura 20.11: Un anti-join es lo contrario de un semi-join, eliminando filas de x que tienen una coincidencia en y."
  },
  {
    "objectID": "joins.html#non-equi-joins",
    "href": "joins.html#non-equi-joins",
    "title": "20  Uniones",
    "section": "\n20.5 Non-equi joins",
    "text": "20.5 Non-equi joins\nHasta ahora solo has visto uniones de igualdad, uniones donde las filas coinciden si la tecla x es igual a la tecla y. Ahora relajaremos esa restricción y analizaremos otras formas de determinar si un par de filas coinciden.\nPero antes de que podamos hacer eso, debemos revisar una simplificación que hicimos anteriormente. En equi-joins, las teclas x e y son siempre iguales, por lo que solo necesitamos mostrar una en la salida. Podemos solicitar que dplyr mantenga ambas claves con keep = TRUE, lo que lleva al siguiente código y inner_join() redibujado en Figure 20.12.\n\nx |> left_join(y, by = \"key\", keep = TRUE)\n#> # A tibble: 3 × 4\n#>   key.x val_x key.y val_y\n#>   <dbl> <chr> <dbl> <chr>\n#> 1     1 x1        1 y1   \n#> 2     2 x2        2 y2   \n#> 3     3 x3       NA <NA>\n\n\n\n\n\nFigure 20.12: Una combinación izquierda que muestra las teclas x e y en la salida.\n\n\n\n\nCuando nos alejamos de las combinaciones de igualdad, siempre mostraremos las claves, porque los valores de las claves a menudo serán diferentes. Por ejemplo, en lugar de hacer coincidir solo cuando la x$key y la y$key son iguales, podríamos hacer coincidir siempre que la x$key sea mayor o igual que la y$key, lo que lleva a Figure 20.13. Las funciones de combinación de dplyr entienden esta distinción entre combinaciones equi y no equi, por lo que siempre mostrará ambas teclas cuando realice una combinación no equi.\n\n\n\n\nFigure 20.13: Una combinación no equitativa en la que la tecla x debe ser mayor o igual que la tecla y. Muchas filas generan múltiples coincidencias.\n\n\n\n\nUnión no equitativa no es un término particularmente útil porque solo le dice qué no es la unión, no qué es. dplyr ayuda identificando cuatro tipos particularmente útiles de unión no equitativa:\n\n\nUniones cruzadas coinciden con cada par de filas.\n\nUniones de desigualdad use <, <=, > y >= en lugar de ==.\n\nLas uniones continuas son similares a las uniones de desigualdad, pero solo encuentran la coincidencia más cercana.\n\nLas uniones superpuestas son un tipo especial de unión de desigualdades diseñadas para trabajar con rangos.\n\nCada uno de estos se describe con más detalle en las siguientes secciones.\n\n20.5.1 Uniones cruzadas\nUna unión cruzada coincide con todo, como en Figure 20.14, generando el producto cartesiano de filas. Esto significa que la salida tendrá filas nrow(x) * nrow(y).\n\n\n\n\nFigure 20.14: Una combinación cruzada hace coincidir cada fila en x con cada fila en y.\n\n\n\n\nLas uniones cruzadas son útiles cuando se generan permutaciones. Por ejemplo, el siguiente código genera todos los pares de nombres posibles. Dado que estamos uniendo df a sí mismo, esto a veces se denomina autounión. Las uniones cruzadas usan una función de unión diferente porque no hay distinción entre inner/left/right/full cuando estás haciendo coincidir cada fila.\n\ndf <- tibble(name = c(\"John\", \"Simon\", \"Tracy\", \"Max\"))\ndf |> cross_join(df)\n#> # A tibble: 16 × 2\n#>   name.x name.y\n#>   <chr>  <chr> \n#> 1 John   John  \n#> 2 John   Simon \n#> 3 John   Tracy \n#> 4 John   Max   \n#> 5 Simon  John  \n#> 6 Simon  Simon \n#> # ℹ 10 more rows\n\n\n20.5.2 Uniones de desigualdad\nLas uniones de desigualdad usan <, <=, >= o > para restringir el conjunto de posibles coincidencias, como en Figure 20.13 y Figure 20.15.\n\n\n\n\nFigure 20.15: Una unión de desigualdad donde ‘x’ se une a ‘y’ en filas donde la clave de ‘x’ es menor que la clave de ‘y’. Esto crea una forma triangular en la esquina superior izquierda.\n\n\n\n\nLas uniones de desigualdad son extremadamente generales, tan generales que es difícil encontrar casos de uso específicos significativos. Una pequeña técnica útil es usarlos para restringir la unión cruzada de modo que, en lugar de generar todas las permutaciones, generemos todas las combinaciones:\n\ndf <- tibble(id = 1:4, name = c(\"John\", \"Simon\", \"Tracy\", \"Max\"))\n\ndf |> left_join(df, join_by(id < id))\n#> # A tibble: 7 × 4\n#>    id.x name.x  id.y name.y\n#>   <int> <chr>  <int> <chr> \n#> 1     1 John       2 Simon \n#> 2     1 John       3 Tracy \n#> 3     1 John       4 Max   \n#> 4     2 Simon      3 Tracy \n#> 5     2 Simon      4 Max   \n#> 6     3 Tracy      4 Max   \n#> # ℹ 1 more row\n\n\n20.5.3 Uniones rodantes\nLas combinaciones rotativas son un tipo especial de combinación de desigualdad donde en lugar de obtener todas las filas que satisfacen la desigualdad, obtienes solo la fila más cercana, como en Figure 20.16. Puede convertir cualquier combinación de desigualdad en una combinación continua agregando closest(). Por ejemplo, join_by(closest(x <= y)) coincide con la y más pequeña que es mayor o igual que x, y join_by(closest(x > y)) coincide con la y más grande que es menor que x.\n\n\n\n\nFigure 20.16: Una siguiente combinación es similar a una combinación de desigualdad mayor o igual, pero solo coincide con el primer valor.\n\n\n\n\nLas uniones rotativas son particularmente útiles cuando tiene dos tablas de fechas que no se alinean perfectamente y desea encontrar (por ejemplo) la fecha más cercana en la tabla 1 que viene antes (o después) de alguna fecha en la tabla 2.\nPor ejemplo, imagina que estás a cargo de la comisión de planificación de fiestas de tu oficina. Su empresa es bastante barata, por lo que en lugar de tener fiestas individuales, solo tiene una fiesta una vez cada trimestre. Las reglas para determinar cuándo se realizará una fiesta son un poco complejas: las fiestas siempre son los lunes, te saltas la primera semana de enero porque mucha gente está de vacaciones y el primer lunes del tercer trimestre de 2022 es el 4 de julio, por lo que eso tiene que ser retrasado una semana. Eso lleva a los siguientes días de fiesta:\n\nparties <- tibble(\n  q = 1:4,\n  party = ymd(c(\"2022-01-10\", \"2022-04-04\", \"2022-07-11\", \"2022-10-03\"))\n)\n\nAhora imagina que tienes una tabla de cumpleaños de los empleados:\n\nemployees <- tibble(\n  name = sample(babynames::babynames$name, 100),\n  birthday = ymd(\"2022-01-01\") + (sample(365, 100, replace = TRUE) - 1)\n)\nemployees\n#> # A tibble: 100 × 2\n#>   name    birthday  \n#>   <chr>   <date>    \n#> 1 Case    2022-09-13\n#> 2 Shonnie 2022-03-30\n#> 3 Burnard 2022-01-10\n#> 4 Omer    2022-11-25\n#> 5 Hillel  2022-07-30\n#> 6 Curlie  2022-12-11\n#> # ℹ 94 more rows\n\nY para cada empleado queremos encontrar la fecha de la primera fiesta que viene después (o en) su cumpleaños. Podemos expresar eso con una unión rodante:\n\nemployees |> \n  left_join(parties, join_by(closest(birthday >= party)))\n#> # A tibble: 100 × 4\n#>   name    birthday       q party     \n#>   <chr>   <date>     <int> <date>    \n#> 1 Case    2022-09-13     3 2022-07-11\n#> 2 Shonnie 2022-03-30     1 2022-01-10\n#> 3 Burnard 2022-01-10     1 2022-01-10\n#> 4 Omer    2022-11-25     4 2022-10-03\n#> 5 Hillel  2022-07-30     3 2022-07-11\n#> 6 Curlie  2022-12-11     4 2022-10-03\n#> # ℹ 94 more rows\n\nSin embargo, hay un problema con este enfoque: las personas que cumplen años antes del 10 de enero no organizan una fiesta:\n\nemployees |> \n  anti_join(parties, join_by(closest(birthday >= party)))\n#> # A tibble: 0 × 2\n#> # ℹ 2 variables: name <chr>, birthday <date>\n\nPara resolver ese problema, necesitaremos abordar el problema de una manera diferente, con uniones superpuestas.\n\n20.5.4 Uniones superpuestas\nLas uniones superpuestas proporcionan tres ayudantes que usan uniones de desigualdad para facilitar el trabajo con intervalos:\n\n\nbetween(x, y_lower, y_upper) es abreviatura para x >= y_lower, x <= y_upper.\n\nwithin(x_lower, x_upper, y_lower, y_upper) es abreviatura para x_lower >= y_lower, x_upper <= y_upper.\n\noverlaps(x_lower, x_upper, y_lower, y_upper) es abreviatura para x_lower <= y_upper, x_upper >= y_lower.\n\nSigamos con el ejemplo del cumpleaños para ver cómo podría usarlos. Hay un problema con la estrategia que usamos anteriormente: no hay fiesta antes de los cumpleaños del 1 al 9 de enero. Por lo tanto, sería mejor ser explícito sobre los rangos de fechas que abarca cada fiesta y hacer un caso especial para esos cumpleaños anticipados:\n\nparties <- tibble(\n  q = 1:4,\n  party = ymd(c(\"2022-01-10\", \"2022-04-04\", \"2022-07-11\", \"2022-10-03\")),\n  start = ymd(c(\"2022-01-01\", \"2022-04-04\", \"2022-07-11\", \"2022-10-03\")),\n  end = ymd(c(\"2022-04-03\", \"2022-07-11\", \"2022-10-02\", \"2022-12-31\"))\n)\nparties\n#> # A tibble: 4 × 4\n#>       q party      start      end       \n#>   <int> <date>     <date>     <date>    \n#> 1     1 2022-01-10 2022-01-01 2022-04-03\n#> 2     2 2022-04-04 2022-04-04 2022-07-11\n#> 3     3 2022-07-11 2022-07-11 2022-10-02\n#> 4     4 2022-10-03 2022-10-03 2022-12-31\n\nHadley es terriblemente malo ingresando datos, por lo que también quería verificar que los períodos de las fiestas no se superpusieran. Una forma de hacer esto es usar una autounión para verificar si algún intervalo de inicio-fin se superpone con otro:\n\nparties |> \n  inner_join(parties, join_by(overlaps(start, end, start, end), q < q)) |> \n  select(start.x, end.x, start.y, end.y)\n#> # A tibble: 1 × 4\n#>   start.x    end.x      start.y    end.y     \n#>   <date>     <date>     <date>     <date>    \n#> 1 2022-04-04 2022-07-11 2022-07-11 2022-10-02\n\nVaya, hay una superposición, así que solucionemos ese problema y continuemos:\n\nparties <- tibble(\n  q = 1:4,\n  party = ymd(c(\"2022-01-10\", \"2022-04-04\", \"2022-07-11\", \"2022-10-03\")),\n  start = ymd(c(\"2022-01-01\", \"2022-04-04\", \"2022-07-11\", \"2022-10-03\")),\n  end = ymd(c(\"2022-04-03\", \"2022-07-10\", \"2022-10-02\", \"2022-12-31\"))\n)\n\nAhora podemos emparejar a cada empleado con su partido. Este es un buen lugar para usar unmatched = \"error\" porque queremos averiguar rápidamente si a algún empleado no se le asignó una fiesta.\n\nemployees |> \n  inner_join(parties, join_by(between(birthday, start, end)), unmatched = \"error\")\n#> # A tibble: 100 × 6\n#>   name    birthday       q party      start      end       \n#>   <chr>   <date>     <int> <date>     <date>     <date>    \n#> 1 Case    2022-09-13     3 2022-07-11 2022-07-11 2022-10-02\n#> 2 Shonnie 2022-03-30     1 2022-01-10 2022-01-01 2022-04-03\n#> 3 Burnard 2022-01-10     1 2022-01-10 2022-01-01 2022-04-03\n#> 4 Omer    2022-11-25     4 2022-10-03 2022-10-03 2022-12-31\n#> 5 Hillel  2022-07-30     3 2022-07-11 2022-07-11 2022-10-02\n#> 6 Curlie  2022-12-11     4 2022-10-03 2022-10-03 2022-12-31\n#> # ℹ 94 more rows\n\n\n20.5.5 Ejercicios\n\n\n¿Puedes explicar qué está pasando con las claves en esta unión equitativa? ¿Por qué son diferentes?\n\nx |> full_join(y, by = \"key\")\n#> # A tibble: 4 × 3\n#>     key val_x val_y\n#>   <dbl> <chr> <chr>\n#> 1     1 x1    y1   \n#> 2     2 x2    y2   \n#> 3     3 x3    <NA> \n#> 4     4 <NA>  y3\n\nx |> full_join(y, by = \"key\", keep = TRUE)\n#> # A tibble: 4 × 4\n#>   key.x val_x key.y val_y\n#>   <dbl> <chr> <dbl> <chr>\n#> 1     1 x1        1 y1   \n#> 2     2 x2        2 y2   \n#> 3     3 x3       NA <NA> \n#> 4    NA <NA>      4 y3\n\n\nAl encontrar si algún período de fiesta se superponía con otro período de fiesta, usamos q < q en join_by () ¿Por qué? ¿Qué pasa si eliminas esta desigualdad?"
  },
  {
    "objectID": "joins.html#resumen",
    "href": "joins.html#resumen",
    "title": "20  Uniones",
    "section": "\n20.6 Resumen",
    "text": "20.6 Resumen\nEn este capítulo, aprendió a usar combinaciones de mutación y filtrado para combinar datos de un par de marcos de datos. En el camino, aprendió cómo identificar claves y la diferencia entre claves primarias y externas. También comprende cómo funcionan las uniones y cómo averiguar cuántas filas tendrá la salida. Finalmente, ha logrado vislumbrar el poder de las uniones no equitativas y ha visto algunos casos de uso interesantes.\nEste capítulo concluye la parte “Transformar” del libro, donde la atención se centró en las herramientas que podría usar con columnas y tibbles individuales. Aprendió sobre las funciones dplyr y base para trabajar con vectores lógicos, números y tablas completas, funciones stringr para trabajar con cadenas, funciones lubridate para trabajar con fechas y horas y funciones forcats para trabajar con factores.\nEn la siguiente parte del libro, aprenderá más sobre cómo obtener varios tipos de datos en R de forma ordenada."
  },
  {
    "objectID": "import.html",
    "href": "import.html",
    "title": "Importar",
    "section": "",
    "text": "En esta parte del libro, aprenderá a importar una gama más amplia de datos en R, así como a convertirlos en una forma útil para el análisis. A veces, esto es solo una cuestión de llamar a una función desde el paquete de importación de datos apropiado. Pero en casos más complejos, puede ser necesario ordenar y transformar para llegar al rectángulo ordenado con el que preferiría trabajar.\n\n\n\n\nFigure 1: La importación de datos es el comienzo del proceso de ciencia de datos; ¡Sin datos no se puede hacer ciencia de datos!\n\n\n\n\nEn esta parte del libro, aprenderá cómo acceder a los datos almacenados de las siguientes maneras:\n\nEn Chapter 21, aprenderá a importar datos de hojas de cálculo de Excel y Google Sheets.\nEn Chapter 22, aprenderá a sacar datos de una base de datos y llevarlos a R (y también aprenderá un poco acerca de cómo sacar datos de R a una base de datos).\nEn Chapter 23, aprenderá sobre Arrow, una poderosa herramienta para trabajar con datos sin memoria, especialmente cuando se almacenan en formato parquet.\nEn Chapter 24, aprenderá a trabajar con datos jerárquicos, incluidas las listas profundamente anidadas producidas por datos almacenados en formato JSON.\nEn Chapter 25, aprenderá “scraping” web, el arte y la ciencia de extraer datos de páginas web.\n\nHay dos paquetes importantes de tidyverse que no discutiremos aquí: haven y xml2. Si trabaja con datos de archivos SPSS, Stata y SAS, consulte el paquete haven, https://haven.tidyverse.org. Si está trabajando con datos XML, consulte el paquete xml2, https://xml2.r-lib.org. De lo contrario, deberá investigar un poco para determinar qué paquete necesitará usar; Google es tu amigo aquí 😃."
  },
  {
    "objectID": "spreadsheets.html#introducción",
    "href": "spreadsheets.html#introducción",
    "title": "21  Hojas de calculo",
    "section": "\n21.1 Introducción",
    "text": "21.1 Introducción\nEn Capítulo 8, aprendió a importar datos de archivos de texto sin formato como .csv y .tsv. Ahora es el momento de aprender cómo obtener datos de una hoja de cálculo, ya sea una hoja de cálculo de Excel o una hoja de cálculo de Google. Esto se basará en gran parte de lo que ha aprendido en Capítulo 8, pero también analizaremos consideraciones y complejidades adicionales al trabajar con datos de hojas de cálculo.\nSi usted o sus colaboradores utilizan hojas de cálculo para organizar datos, le recomendamos leer el documento “Organización de datos en hojas de cálculo” de Karl Broman y Kara Woo: https://doi.org/10.1080/00031305.2017.1375989. Las mejores prácticas presentadas en este documento le ahorrarán muchos dolores de cabeza cuando importe datos de una hoja de cálculo a R para analizarlos y visualizarlos."
  },
  {
    "objectID": "spreadsheets.html#excel",
    "href": "spreadsheets.html#excel",
    "title": "21  Hojas de calculo",
    "section": "\n21.2 Excel",
    "text": "21.2 Excel\nMicrosoft Excel es un programa de software de hojas de cálculo ampliamente utilizado donde los datos se organizan en hojas de trabajo dentro de archivos de hojas de cálculo.\n\n21.2.1 Requisitos previos\nEn esta sección, aprenderá a cargar datos de hojas de cálculo de Excel en R con el paquete readxl. Este paquete es tidyverse no central, por lo que debe cargarlo explícitamente, pero se instala automáticamente cuando instala el paquete tidyverse. Más tarde, también usaremos el paquete writexl, que nos permite crear hojas de cálculo de Excel.\n\nlibrary(readxl)\nlibrary(tidyverse)\nlibrary(writexl)\n\n\n21.2.2 Empezando\nLa mayoría de las funciones de readxl le permiten cargar hojas de cálculo de Excel en R:\n\n\nread_xls() lee archivos de Excel con formato xls.\n\nread_xlsx() leer archivos de Excel con formato xlsx.\n\nread_excel() puede leer archivos con formato xls y xlsx. Adivina el tipo de archivo en función de la entrada.\n\nTodas estas funciones tienen una sintaxis similar al igual que otras funciones que hemos introducido anteriormente para leer otros tipos de archivos, p.ej., read_csv(), read_table(), etc. Para el resto del capítulo nos enfocaremos en usar read_excel().\n\n21.2.3 Lectura de hojas de cálculo de Excel\nFigura 21.1 muestra cómo se ve la hoja de cálculo que vamos a leer en R en Excel. Esta hoja de cálculo se puede descargar en un archivo Excel desde https://docs.google.com/spreadsheets/d/1V1nPp1tzOuutXFLb3G9Eyxi3qxeEhnOXUzL5_BcCQ0w/.\n\n\n\n\nFigura 21.1: Hoja de cálculo llamada students.xlsx en Excel.\n\n\n\nEl primer argumento de read_excel() es la ruta al archivo a leer.\n\nstudents &lt;- read_excel(\"data/students.xlsx\")\n\nread_excel() leerá el archivo como un tibble.\n\nstudents\n#&gt; # A tibble: 6 × 5\n#&gt;   `Student ID` `Full Name`      favourite.food     mealPlan            AGE  \n#&gt;          &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;chr&gt;\n#&gt; 1            1 Sunil Huffmann   Strawberry yoghurt Lunch only          4    \n#&gt; 2            2 Barclay Lynn     French fries       Lunch only          5    \n#&gt; 3            3 Jayendra Lyne    N/A                Breakfast and lunch 7    \n#&gt; 4            4 Leon Rossini     Anchovies          Lunch only          &lt;NA&gt; \n#&gt; 5            5 Chidiegwu Dunkel Pizza              Breakfast and lunch five \n#&gt; 6            6 Güvenç Attila    Ice cream          Lunch only          6\n\nTenemos seis estudiantes en los datos y cinco variables en cada estudiante. Sin embargo, hay algunas cosas que podríamos querer abordar en este conjunto de datos:\n\n\nLos nombres de las columnas están por todas partes. Puede proporcionar nombres de columna que sigan un formato coherente; recomendamos snake_case usando el argumento col_names.\n\nread_excel(\n  \"data/students.xlsx\",\n  col_names = c(\"student_id\", \"full_name\", \"favourite_food\", \"meal_plan\", \"age\")\n)\n#&gt; # A tibble: 7 × 5\n#&gt;   student_id full_name        favourite_food     meal_plan           age  \n#&gt;   &lt;chr&gt;      &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;chr&gt;\n#&gt; 1 Student ID Full Name        favourite.food     mealPlan            AGE  \n#&gt; 2 1          Sunil Huffmann   Strawberry yoghurt Lunch only          4    \n#&gt; 3 2          Barclay Lynn     French fries       Lunch only          5    \n#&gt; 4 3          Jayendra Lyne    N/A                Breakfast and lunch 7    \n#&gt; 5 4          Leon Rossini     Anchovies          Lunch only          &lt;NA&gt; \n#&gt; 6 5          Chidiegwu Dunkel Pizza              Breakfast and lunch five \n#&gt; 7 6          Güvenç Attila    Ice cream          Lunch only          6\n\nDesafortunadamente, esto no funcionó del todo. Ahora tenemos los nombres de las variables que queremos, pero lo que antes era la fila del encabezado ahora aparece como la primera observación en los datos. Puede omitir explícitamente esa fila usando el argumento skip.\n\nread_excel(\n  \"data/students.xlsx\",\n  col_names = c(\"student_id\", \"full_name\", \"favourite_food\", \"meal_plan\", \"age\"),\n  skip = 1\n)\n#&gt; # A tibble: 6 × 5\n#&gt;   student_id full_name        favourite_food     meal_plan           age  \n#&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;chr&gt;\n#&gt; 1          1 Sunil Huffmann   Strawberry yoghurt Lunch only          4    \n#&gt; 2          2 Barclay Lynn     French fries       Lunch only          5    \n#&gt; 3          3 Jayendra Lyne    N/A                Breakfast and lunch 7    \n#&gt; 4          4 Leon Rossini     Anchovies          Lunch only          &lt;NA&gt; \n#&gt; 5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch five \n#&gt; 6          6 Güvenç Attila    Ice cream          Lunch only          6\n\n\n\nEn la columna favourite_food, una de las observaciones es N/A, que significa “no disponible”, pero actualmente no se reconoce como NA (tenga en cuenta el contraste entre este N/A y la edad de el cuarto estudiante de la lista). Puede especificar qué cadenas de caracteres deben reconocerse como NAs con el argumento na. De forma predeterminada, solo \"\" (cadena vacía o, en el caso de leer desde una hoja de cálculo, una celda vacía o una celda con la fórmula =NA()) se reconoce como NA.\n\nread_excel(\n  \"data/students.xlsx\",\n  col_names = c(\"student_id\", \"full_name\", \"favourite_food\", \"meal_plan\", \"age\"),\n  skip = 1,\n  na = c(\"\", \"N/A\")\n)\n#&gt; # A tibble: 6 × 5\n#&gt;   student_id full_name        favourite_food     meal_plan           age  \n#&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;chr&gt;\n#&gt; 1          1 Sunil Huffmann   Strawberry yoghurt Lunch only          4    \n#&gt; 2          2 Barclay Lynn     French fries       Lunch only          5    \n#&gt; 3          3 Jayendra Lyne    &lt;NA&gt;               Breakfast and lunch 7    \n#&gt; 4          4 Leon Rossini     Anchovies          Lunch only          &lt;NA&gt; \n#&gt; 5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch five \n#&gt; 6          6 Güvenç Attila    Ice cream          Lunch only          6\n\n\n\nOtro problema pendiente es que age se lee como una variable de carácter, pero en realidad debería ser numérico. Al igual que con read_csv() y amigos para leer datos de archivos planos, puede proporcionar un argumento col_types a read_excel() y especificar los tipos de columna para las variables que lee. Sin embargo, la sintaxis es un poco diferente. Sus opciones son \"skip\", \"guess\", \"logical\", \"numeric\", \"date\", \"text\" o \"list\".\n\nread_excel(\n  \"data/students.xlsx\",\n  col_names = c(\"student_id\", \"full_name\", \"favourite_food\", \"meal_plan\", \"age\"),\n  skip = 1,\n  na = c(\"\", \"N/A\"),\n  col_types = c(\"numeric\", \"text\", \"text\", \"text\", \"numeric\")\n)\n#&gt; Warning: Expecting numeric in E6 / R6C5: got 'five'\n#&gt; # A tibble: 6 × 5\n#&gt;   student_id full_name        favourite_food     meal_plan             age\n#&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;dbl&gt;\n#&gt; 1          1 Sunil Huffmann   Strawberry yoghurt Lunch only              4\n#&gt; 2          2 Barclay Lynn     French fries       Lunch only              5\n#&gt; 3          3 Jayendra Lyne    &lt;NA&gt;               Breakfast and lunch     7\n#&gt; 4          4 Leon Rossini     Anchovies          Lunch only             NA\n#&gt; 5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch    NA\n#&gt; 6          6 Güvenç Attila    Ice cream          Lunch only              6\n\nSin embargo, esto tampoco produjo el resultado deseado. Al especificar que la edad, age, debe ser numérica, hemos convertido la única celda con la entrada no numérica (que tenía el valor five) en NA. En este caso, deberíamos leer la edad como \"texto\" y luego hacer el cambio una vez que los datos estén cargados en R.\n\nstudents &lt;- read_excel(\n  \"data/students.xlsx\",\n  col_names = c(\"student_id\", \"full_name\", \"favourite_food\", \"meal_plan\", \"age\"),\n  skip = 1,\n  na = c(\"\", \"N/A\"),\n  col_types = c(\"numeric\", \"text\", \"text\", \"text\", \"text\")\n)\n\nstudents &lt;- students |&gt;\n  mutate(\n    age = if_else(age == \"five\", \"5\", age),\n    age = parse_number(age)\n  )\n\nstudents\n#&gt; # A tibble: 6 × 5\n#&gt;   student_id full_name        favourite_food     meal_plan             age\n#&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;dbl&gt;\n#&gt; 1          1 Sunil Huffmann   Strawberry yoghurt Lunch only              4\n#&gt; 2          2 Barclay Lynn     French fries       Lunch only              5\n#&gt; 3          3 Jayendra Lyne    &lt;NA&gt;               Breakfast and lunch     7\n#&gt; 4          4 Leon Rossini     Anchovies          Lunch only             NA\n#&gt; 5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch     5\n#&gt; 6          6 Güvenç Attila    Ice cream          Lunch only              6\n\n\n\nNos tomó varios pasos y prueba y error para cargar los datos exactamente en el formato que queríamos, y esto no es inesperado. La ciencia de datos es un proceso iterativo, y el proceso de iteración puede ser aún más tedioso cuando se leen datos de hojas de cálculo en comparación con otros archivos de datos rectangulares de texto sin formato porque los humanos tienden a ingresar datos en hojas de cálculo y los usan no solo para el almacenamiento de datos sino también para compartir y comunicar.\nNo hay forma de saber exactamente cómo se verán los datos hasta que los cargue y los mire. Bueno, hay una manera, en realidad. Puede abrir el archivo en Excel y echar un vistazo. Si va a hacerlo, le recomendamos que haga una copia del archivo de Excel para abrirlo y navegar de forma interactiva mientras deja intacto el archivo de datos original y lee en R desde el archivo intacto. Esto asegurará que no sobrescriba accidentalmente nada en la hoja de cálculo mientras la inspecciona. Tampoco debe tener miedo de hacer lo que hicimos aquí: cargue los datos, eche un vistazo, realice ajustes en su código, cárguelo nuevamente y repita hasta que esté satisfecho con el resultado.\n\n21.2.4 Hojas de trabajo de lectura\nUna característica importante que distingue a las hojas de cálculo de los archivos planos es la noción de hojas múltiples, llamadas hojas de trabajo. Figura 21.2 muestra una hoja de cálculo de Excel con varias hojas de trabajo. Los datos provienen del paquete palmerpenguins. Cada hoja de trabajo contiene información sobre pingüinos de una isla diferente donde se recopilaron datos.\n\n\n\n\nFigura 21.2: Hoja de cálculo llamada penguins.xlsx en Excel que contiene tres hojas de cálculo.\n\n\n\nPuede leer una sola hoja de trabajo desde una hoja de cálculo con el argumento sheet en read_excel(). El valor predeterminado, en el que nos hemos basado hasta ahora, es la primera hoja.\n\nread_excel(\"data/penguins.xlsx\", sheet = \"Torgersen Island\")\n#&gt; # A tibble: 52 × 8\n#&gt;   species island    bill_length_mm     bill_depth_mm      flipper_length_mm\n#&gt;   &lt;chr&gt;   &lt;chr&gt;     &lt;chr&gt;              &lt;chr&gt;              &lt;chr&gt;            \n#&gt; 1 Adelie  Torgersen 39.1               18.7               181              \n#&gt; 2 Adelie  Torgersen 39.5               17.399999999999999 186              \n#&gt; 3 Adelie  Torgersen 40.299999999999997 18                 195              \n#&gt; 4 Adelie  Torgersen NA                 NA                 NA               \n#&gt; 5 Adelie  Torgersen 36.700000000000003 19.3               193              \n#&gt; 6 Adelie  Torgersen 39.299999999999997 20.6               190              \n#&gt; # ℹ 46 more rows\n#&gt; # ℹ 3 more variables: body_mass_g &lt;chr&gt;, sex &lt;chr&gt;, year &lt;dbl&gt;\n\nAlgunas variables que parecen contener datos numéricos se leen como caracteres debido a que la cadena de caracteres \"NA\" no se reconoce como verdadera NA.\n\npenguins_torgersen &lt;- read_excel(\"data/penguins.xlsx\", sheet = \"Torgersen Island\", na = \"NA\")\n\npenguins_torgersen\n#&gt; # A tibble: 52 × 8\n#&gt;   species island    bill_length_mm bill_depth_mm flipper_length_mm\n#&gt;   &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;\n#&gt; 1 Adelie  Torgersen           39.1          18.7               181\n#&gt; 2 Adelie  Torgersen           39.5          17.4               186\n#&gt; 3 Adelie  Torgersen           40.3          18                 195\n#&gt; 4 Adelie  Torgersen           NA            NA                  NA\n#&gt; 5 Adelie  Torgersen           36.7          19.3               193\n#&gt; 6 Adelie  Torgersen           39.3          20.6               190\n#&gt; # ℹ 46 more rows\n#&gt; # ℹ 3 more variables: body_mass_g &lt;dbl&gt;, sex &lt;chr&gt;, year &lt;dbl&gt;\n\nAlternativamente, puede usar excel_sheets() para obtener información sobre todas las hojas de trabajo en una hoja de cálculo de Excel y luego leer las que le interesan.\n\nexcel_sheets(\"data/penguins.xlsx\")\n#&gt; [1] \"Torgersen Island\" \"Biscoe Island\"    \"Dream Island\"\n\nUna vez que sepa los nombres de las hojas de trabajo, puede leerlas individualmente con read_excel().\n\npenguins_biscoe &lt;- read_excel(\"data/penguins.xlsx\", sheet = \"Biscoe Island\", na = \"NA\")\npenguins_dream  &lt;- read_excel(\"data/penguins.xlsx\", sheet = \"Dream Island\", na = \"NA\")\n\nEn este caso, el conjunto de datos completo de pingüinos se distribuye en tres hojas de trabajo en la hoja de cálculo. Cada hoja de cálculo tiene el mismo número de columnas pero diferente número de filas.\n\ndim(penguins_torgersen)\n#&gt; [1] 52  8\ndim(penguins_biscoe)\n#&gt; [1] 168   8\ndim(penguins_dream)\n#&gt; [1] 124   8\n\nPodemos juntarlos con bind_rows().\n\npenguins &lt;- bind_rows(penguins_torgersen, penguins_biscoe, penguins_dream)\npenguins\n#&gt; # A tibble: 344 × 8\n#&gt;   species island    bill_length_mm bill_depth_mm flipper_length_mm\n#&gt;   &lt;chr&gt;   &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;\n#&gt; 1 Adelie  Torgersen           39.1          18.7               181\n#&gt; 2 Adelie  Torgersen           39.5          17.4               186\n#&gt; 3 Adelie  Torgersen           40.3          18                 195\n#&gt; 4 Adelie  Torgersen           NA            NA                  NA\n#&gt; 5 Adelie  Torgersen           36.7          19.3               193\n#&gt; 6 Adelie  Torgersen           39.3          20.6               190\n#&gt; # ℹ 338 more rows\n#&gt; # ℹ 3 more variables: body_mass_g &lt;dbl&gt;, sex &lt;chr&gt;, year &lt;dbl&gt;\n\nEn Capítulo 27 hablaremos sobre formas de realizar este tipo de tareas sin código repetitivo.\n\n21.2.5 Leer parte de una hoja\nDado que muchos usan hojas de cálculo de Excel para la presentación, así como para el almacenamiento de datos, es bastante común encontrar entradas de celdas en una hoja de cálculo que no forman parte de los datos que desea leer en R. Figura 21.3 muestra una hoja de cálculo de este tipo: en el medio de la hoja hay lo que parece un marco de datos, pero hay texto superfluo en las celdas por encima y por debajo de los datos.\n\n\n\n\nFigura 21.3: Hoja de cálculo llamada death.xlsx en Excel.\n\n\n\nEsta hoja de cálculo es una de las hojas de cálculo de ejemplo proporcionadas en el paquete readxl. Puede usar la función readxl_example() para ubicar la hoja de cálculo en su sistema en el directorio donde está instalado el paquete. Esta función devuelve la ruta a la hoja de cálculo, que puede usar en read_excel() como de costumbre.\n\ndeaths_path &lt;- readxl_example(\"deaths.xlsx\")\ndeaths &lt;- read_excel(deaths_path)\n#&gt; New names:\n#&gt; • `` -&gt; `...2`\n#&gt; • `` -&gt; `...3`\n#&gt; • `` -&gt; `...4`\n#&gt; • `` -&gt; `...5`\n#&gt; • `` -&gt; `...6`\ndeaths\n#&gt; # A tibble: 18 × 6\n#&gt;   `Lots of people`    ...2       ...3  ...4     ...5          ...6           \n#&gt;   &lt;chr&gt;               &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;         &lt;chr&gt;          \n#&gt; 1 simply cannot resi… &lt;NA&gt;       &lt;NA&gt;  &lt;NA&gt;     &lt;NA&gt;          some notes     \n#&gt; 2 at                  the        top   &lt;NA&gt;     of            their spreadsh…\n#&gt; 3 or                  merging    &lt;NA&gt;  &lt;NA&gt;     &lt;NA&gt;          cells          \n#&gt; 4 Name                Profession Age   Has kids Date of birth Date of death  \n#&gt; 5 David Bowie         musician   69    TRUE     17175         42379          \n#&gt; 6 Carrie Fisher       actor      60    TRUE     20749         42731          \n#&gt; # ℹ 12 more rows\n\nLas tres filas superiores y las cuatro filas inferiores no forman parte del marco de datos. Es posible eliminar estas filas superfluas usando los argumentos skip y n_max, pero recomendamos usar rangos de celdas. En Excel, la celda superior izquierda es A1. A medida que se mueve por las columnas hacia la derecha, la etiqueta de la celda se mueve hacia abajo en el alfabeto, es decir, B1, C1, etc. Y a medida que se mueve hacia abajo en una columna, el número en la etiqueta de la celda aumenta, es decir, A2, A3, etc.\nAquí, los datos que queremos leer comienzan en la celda A5 y terminan en la celda F15. En notación de hoja de cálculo, esto es A5:F15, que proporcionamos al argumento range:\n\nread_excel(deaths_path, range = \"A5:F15\")\n#&gt; # A tibble: 10 × 6\n#&gt;   Name          Profession   Age `Has kids` `Date of birth`    \n#&gt;   &lt;chr&gt;         &lt;chr&gt;      &lt;dbl&gt; &lt;lgl&gt;      &lt;dttm&gt;             \n#&gt; 1 David Bowie   musician      69 TRUE       1947-01-08 00:00:00\n#&gt; 2 Carrie Fisher actor         60 TRUE       1956-10-21 00:00:00\n#&gt; 3 Chuck Berry   musician      90 TRUE       1926-10-18 00:00:00\n#&gt; 4 Bill Paxton   actor         61 TRUE       1955-05-17 00:00:00\n#&gt; 5 Prince        musician      57 TRUE       1958-06-07 00:00:00\n#&gt; 6 Alan Rickman  actor         69 FALSE      1946-02-21 00:00:00\n#&gt; # ℹ 4 more rows\n#&gt; # ℹ 1 more variable: `Date of death` &lt;dttm&gt;\n\n\n21.2.6 Tipos de datos\nEn los archivos CSV, todos los valores son cadenas. Esto no es particularmente cierto para los datos, pero es simple: todo es una cadena.\nLos datos subyacentes en las hojas de cálculo de Excel son más complejos. Una célula puede ser una de cuatro cosas:\n\nUn valor booleano, como TRUE, FALSE o NA.\nUn número, como “10” o “10.5”.\nUna fecha y hora, que también puede incluir una hora como “1/11/21” o “1/11/21 3:00 PM”.\nUna cadena de texto, como “diez”.\n\nAl trabajar con datos de hojas de cálculo, es importante tener en cuenta que los datos subyacentes pueden ser muy diferentes de lo que ve en la celda. Por ejemplo, Excel no tiene noción de un número entero. Todos los números se almacenan como puntos flotantes, pero puede optar por mostrar los datos con un número personalizable de puntos decimales. De manera similar, las fechas en realidad se almacenan como números, específicamente la cantidad de segundos desde el 1 de enero de 1970. Puede personalizar cómo muestra la fecha aplicando formato en Excel. De manera confusa, también es posible tener algo que parezca un número pero que en realidad sea una cadena (por ejemplo, escriba '10 en una celda de Excel).\nEstas diferencias entre cómo se almacenan los datos subyacentes y cómo se muestran pueden causar sorpresas cuando los datos se cargan en R. Por defecto, readxl adivinará el tipo de datos en una columna determinada. Un flujo de trabajo recomendado es dejar que readxl adivine los tipos de columna, confirme que está satisfecho con los tipos de columna adivinados y, si no, regrese y vuelva a importar especificando col_types como se muestra en Sección 21.2.3.\nOtro desafío es cuando tiene una columna en su hoja de cálculo de Excel que tiene una combinación de estos tipos, p.ej., algunas celdas son numéricas, otras de texto, otras de fechas. Al importar los datos a R, readxl tiene que tomar algunas decisiones. En estos casos, puede establecer el tipo de esta columna en \"list\", lo que cargará la columna como una lista de vectores de longitud 1, donde se adivina el tipo de cada elemento del vector.\n\n\n\n\n\n\nA veces, los datos se almacenan de formas más exóticas, como el color del fondo de la celda o si el texto está en negrita o no. En tales casos, puede encontrar útil el paquete tidyxl. Consulte https://nacnudus.github.io/spreadsheet-munging-strategies/ para obtener más información sobre estrategias para trabajar con datos no tabulares de Excel.\n\n\n\n\n21.2.7 Escribir en Excel\nVamos a crear un pequeño marco de datos que luego podamos escribir. Tenga en cuenta que item es un factor y quantity es un número entero.\n\nbake_sale &lt;- tibble(\n  item     = factor(c(\"brownie\", \"cupcake\", \"cookie\")),\n  quantity = c(10, 5, 8)\n)\n\nbake_sale\n#&gt; # A tibble: 3 × 2\n#&gt;   item    quantity\n#&gt;   &lt;fct&gt;      &lt;dbl&gt;\n#&gt; 1 brownie       10\n#&gt; 2 cupcake        5\n#&gt; 3 cookie         8\n\nPuede volver a escribir datos en el disco como un archivo de Excel usando write_xlsx() del paquete writexl:\n\nwrite_xlsx(bake_sale, path = \"data/bake-sale.xlsx\")\n\nFigura 21.4 muestra cómo se ven los datos en Excel. Tenga en cuenta que los nombres de las columnas están incluidos y en negrita. Estos se pueden desactivar configurando los argumentos col_names y format_headers en FALSE.\n\n\n\n\nFigura 21.4: Hoja de cálculo llamada bake_sale.xlsx en Excel.\n\n\n\nAl igual que la lectura de un CSV, la información sobre el tipo de datos se pierde cuando volvemos a leer los datos. Esto hace que los archivos de Excel no sean confiables para almacenar en caché los resultados intermedios. Para ver alternativas, consulte Sección 8.5.\n\nread_excel(\"data/bake-sale.xlsx\")\n#&gt; # A tibble: 3 × 2\n#&gt;   item    quantity\n#&gt;   &lt;chr&gt;      &lt;dbl&gt;\n#&gt; 1 brownie       10\n#&gt; 2 cupcake        5\n#&gt; 3 cookie         8\n\n\n21.2.8 Salida formateada\nEl paquete writexl es una solución liviana para escribir una hoja de cálculo de Excel simple, pero si está interesado en funciones adicionales como escribir en hojas dentro de una hoja de cálculo y diseñar, querrá usar el paquete openxlsx. No entraremos en los detalles del uso de este paquete aquí, pero recomendamos leer https://ycphs.github.io/openxlsx/articles/Formatting.html para una discusión extensa sobre la funcionalidad de formato adicional para los datos escritos desde R a Excel con openxlsx.\nTenga en cuenta que este paquete no forma parte de tidyverse, por lo que las funciones y los flujos de trabajo pueden parecerle desconocidos. Por ejemplo, los nombres de las funciones son camelCase, varias funciones no se pueden componer en canalizaciones y los argumentos están en un orden diferente al que suelen tener en el tidyverse. Sin embargo, esto está bien. A medida que su aprendizaje y uso de R se expanda fuera de este libro, encontrará muchos estilos diferentes utilizados en varios paquetes de R que puede usar para lograr objetivos específicos en R. Una buena manera de familiarizarse con el estilo de codificación utilizado en un nuevo paquete es ejecutar los ejemplos proporcionados en la documentación de la función para tener una idea de la sintaxis y los formatos de salida, así como leer cualquier viñeta que pueda venir con el paquete.\n\n21.2.9 Ejercicios\n\n\nEn un archivo de Excel, cree el siguiente conjunto de datos y guárdelo como survey.xlsx. Como alternativa, puede descargarlo como un archivo de Excel desde aquí.\n\n\n\n\n\nLuego, léalo en R, con survey_id como variable de carácter y n_pets como variable numérica.\n\n#&gt; # A tibble: 6 × 2\n#&gt;   survey_id n_pets\n#&gt;   &lt;chr&gt;      &lt;dbl&gt;\n#&gt; 1 1              0\n#&gt; 2 2              1\n#&gt; 3 3             NA\n#&gt; 4 4              2\n#&gt; 5 5              2\n#&gt; 6 6             NA\n\n\n\nEn otro archivo de Excel, cree el siguiente conjunto de datos y guárdelo como roster.xlsx. Como alternativa, puede descargarlo como un archivo de Excel desde aquí.\n\n\n\n\n\nLuego, léalo en R. El marco de datos resultante debe llamarse roster y debe tener el siguiente aspecto.\n\n#&gt; # A tibble: 12 × 3\n#&gt;    group subgroup    id\n#&gt;    &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;\n#&gt;  1     1 A            1\n#&gt;  2     1 A            2\n#&gt;  3     1 A            3\n#&gt;  4     1 B            4\n#&gt;  5     1 B            5\n#&gt;  6     1 B            6\n#&gt;  7     1 B            7\n#&gt;  8     2 A            8\n#&gt;  9     2 A            9\n#&gt; 10     2 B           10\n#&gt; 11     2 B           11\n#&gt; 12     2 B           12\n\n\n\nEn un nuevo archivo de Excel, cree el siguiente conjunto de datos y guárdelo como sales.xlsx. Como alternativa, puede descargarlo como un archivo de Excel desde aquí.\n\n\n\n\n\na. Lea sales.xlsx y guárdelo como sales. El marco de datos debería verse como el siguiente, con id y n como nombres de columna y con 9 filas.\n\n#&gt; # A tibble: 9 × 2\n#&gt;   id      n    \n#&gt;   &lt;chr&gt;   &lt;chr&gt;\n#&gt; 1 Brand 1 n    \n#&gt; 2 1234    8    \n#&gt; 3 8721    2    \n#&gt; 4 1822    3    \n#&gt; 5 Brand 2 n    \n#&gt; 6 3333    1    \n#&gt; 7 2156    3    \n#&gt; 8 3987    6    \n#&gt; 9 3216    5\n\nb. Modifique sales aún más para obtener el siguiente formato ordenado con tres columnas (brand, id y n) y 7 filas de datos. Tenga en cuenta que id y n son numéricos, brand es una variable de carácter.\n\n#&gt; # A tibble: 7 × 3\n#&gt;   brand      id     n\n#&gt;   &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 Brand 1  1234     8\n#&gt; 2 Brand 1  8721     2\n#&gt; 3 Brand 1  1822     3\n#&gt; 4 Brand 2  3333     1\n#&gt; 5 Brand 2  2156     3\n#&gt; 6 Brand 2  3987     6\n#&gt; 7 Brand 2  3216     5\n\n\nVuelva a crear el marco de datos bake_sale, escríbalo en un archivo de Excel usando la función write.xlsx() del paquete openxlsx.\nEn Capítulo 8, aprendió sobre la función janitor::clean_names() para convertir los nombres de las columnas en mayúsculas y minúsculas. Lea el archivo students.xlsx que presentamos anteriormente en esta sección y use esta función para “limpiar” los nombres de las columnas.\n¿Qué sucede si intentas leer un archivo con la extensión .xlsx con read_xls()?"
  },
  {
    "objectID": "spreadsheets.html#hojas-de-cálculo-de-google",
    "href": "spreadsheets.html#hojas-de-cálculo-de-google",
    "title": "21  Hojas de calculo",
    "section": "\n21.3 Hojas de cálculo de Google",
    "text": "21.3 Hojas de cálculo de Google\nGoogle Sheets es otro programa de hoja de cálculo ampliamente utilizado. Es gratis y está basado en la web. Al igual que con Excel, en Hojas de cálculo de Google, los datos se organizan en hojas de trabajo (también llamadas hojas) dentro de archivos de hojas de cálculo.\n\n21.3.1 Requisitos previos\nEsta sección también se centrará en las hojas de cálculo, pero esta vez cargará datos de una hoja de cálculo de Google con el paquete googlesheets4. Este paquete también es tidyverse no central, debe cargarlo explícitamente.\n\nlibrary(googlesheets4)\nlibrary(tidyverse)\n\nUna nota rápida sobre el nombre del paquete: googlesheets4 usa v4 de Sheets API v4 para proporcionar una interfaz R a Google Sheets, de ahí el nombre.\n\n21.3.2 Empezando\nLa función principal del paquete googlesheets4 es read_sheet(), que lee una hoja de cálculo de Google desde una URL o una identificación de archivo. Esta función también se conoce con el nombre range_read().\nTambién puede crear una hoja nueva con gs4_create() o escribir en una hoja existente con sheet_write() y amigos.\nEn esta sección, trabajaremos con los mismos conjuntos de datos que los de la sección de Excel para resaltar las similitudes y diferencias entre los flujos de trabajo para leer datos de Excel y Hojas de cálculo de Google. Los paquetes readxl y googlesheets4 están diseñados para imitar la funcionalidad del paquete readr, que proporciona la función read_csv() que ha visto en Capítulo 8. Por lo tanto, muchas de las tareas se pueden realizar simplemente cambiando read_excel() por read_sheet(). Sin embargo, también verá que Excel y Google Sheets no se comportan exactamente de la misma manera, por lo tanto, otras tareas pueden requerir más actualizaciones en las llamadas a funciones.\n\n21.3.3 Leer Hojas de cálculo de Google\nFigura 21.5 muestra cómo se ve la hoja de cálculo que vamos a leer en R en Hojas de cálculo de Google. Este es el mismo conjunto de datos que en Figura 21.1, excepto que está almacenado en una hoja de Google en lugar de Excel.\n\n\n\n\nFigura 21.5: Google Sheet llamó a los estudiantes en una ventana del navegador.\n\n\n\nEl primer argumento de read_sheet() es la URL del archivo a leer, y devuelve un tibble:&lt;https://docs.google.com/spreadsheets/d/1V1nPp1tzOuutXFLb3G9Eyxi3qxeEhnOXUzL5_BcCQ0w&gt;. No es agradable trabajar con estas URL, por lo que a menudo querrá identificar una hoja por su ID.\n\ngs4_deauth()\n\n\nstudents_sheet_id &lt;- \"1V1nPp1tzOuutXFLb3G9Eyxi3qxeEhnOXUzL5_BcCQ0w\"\nstudents &lt;- read_sheet(students_sheet_id)\n#&gt; ✔ Reading from students.\n#&gt; ✔ Range Sheet1.\nstudents\n#&gt; # A tibble: 6 × 5\n#&gt;   `Student ID` `Full Name`      favourite.food     mealPlan            AGE   \n#&gt;          &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;list&gt;\n#&gt; 1            1 Sunil Huffmann   Strawberry yoghurt Lunch only          &lt;dbl&gt; \n#&gt; 2            2 Barclay Lynn     French fries       Lunch only          &lt;dbl&gt; \n#&gt; 3            3 Jayendra Lyne    N/A                Breakfast and lunch &lt;dbl&gt; \n#&gt; 4            4 Leon Rossini     Anchovies          Lunch only          &lt;NULL&gt;\n#&gt; 5            5 Chidiegwu Dunkel Pizza              Breakfast and lunch &lt;chr&gt; \n#&gt; 6            6 Güvenç Attila    Ice cream          Lunch only          &lt;dbl&gt;\n\nAl igual que hicimos con read_excel(), podemos proporcionar nombres de columnas, cadenas NA y tipos de columnas a read_sheet().\n\nstudents &lt;- read_sheet(\n  students_sheet_id,\n  col_names = c(\"student_id\", \"full_name\", \"favourite_food\", \"meal_plan\", \"age\"),\n  skip = 1,\n  na = c(\"\", \"N/A\"),\n  col_types = \"dcccc\"\n)\n#&gt; ✔ Reading from students.\n#&gt; ✔ Range 2:10000000.\n\nstudents\n#&gt; # A tibble: 6 × 5\n#&gt;   student_id full_name        favourite_food     meal_plan           age  \n#&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;chr&gt;\n#&gt; 1          1 Sunil Huffmann   Strawberry yoghurt Lunch only          4    \n#&gt; 2          2 Barclay Lynn     French fries       Lunch only          5    \n#&gt; 3          3 Jayendra Lyne    &lt;NA&gt;               Breakfast and lunch 7    \n#&gt; 4          4 Leon Rossini     Anchovies          Lunch only          &lt;NA&gt; \n#&gt; 5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch five \n#&gt; 6          6 Güvenç Attila    Ice cream          Lunch only          6\n\nTenga en cuenta que aquí definimos los tipos de columna de manera un poco diferente, usando códigos cortos. Por ejemplo, “dcccc” significa “doble, carácter, carácter, carácter, carácter”.\nTambién es posible leer hojas individuales de Google Sheets. Leamos la hoja “Isla Torgersen” de la Hoja de Google de pingüinos:\n\npenguins_sheet_id &lt;- \"1aFu8lnD_g0yjF5O-K6SFgSEWiHPpgvFCF0NY9D6LXnY\"\nread_sheet(penguins_sheet_id, sheet = \"Torgersen Island\")\n#&gt; ✔ Reading from penguins.\n#&gt; ✔ Range ''Torgersen Island''.\n#&gt; # A tibble: 52 × 8\n#&gt;   species island    bill_length_mm bill_depth_mm flipper_length_mm\n#&gt;   &lt;chr&gt;   &lt;chr&gt;     &lt;list&gt;         &lt;list&gt;        &lt;list&gt;           \n#&gt; 1 Adelie  Torgersen &lt;dbl [1]&gt;      &lt;dbl [1]&gt;     &lt;dbl [1]&gt;        \n#&gt; 2 Adelie  Torgersen &lt;dbl [1]&gt;      &lt;dbl [1]&gt;     &lt;dbl [1]&gt;        \n#&gt; 3 Adelie  Torgersen &lt;dbl [1]&gt;      &lt;dbl [1]&gt;     &lt;dbl [1]&gt;        \n#&gt; 4 Adelie  Torgersen &lt;chr [1]&gt;      &lt;chr [1]&gt;     &lt;chr [1]&gt;        \n#&gt; 5 Adelie  Torgersen &lt;dbl [1]&gt;      &lt;dbl [1]&gt;     &lt;dbl [1]&gt;        \n#&gt; 6 Adelie  Torgersen &lt;dbl [1]&gt;      &lt;dbl [1]&gt;     &lt;dbl [1]&gt;        \n#&gt; # ℹ 46 more rows\n#&gt; # ℹ 3 more variables: body_mass_g &lt;list&gt;, sex &lt;chr&gt;, year &lt;dbl&gt;\n\nPuede obtener una lista de todas las hojas dentro de una Hoja de Google con sheet_names():\n\nsheet_names(penguins_sheet_id)\n#&gt; [1] \"Torgersen Island\" \"Biscoe Island\"    \"Dream Island\"\n\nFinalmente, al igual que con read_excel(), podemos leer una parte de una hoja de cálculo de Google definiendo un range en read_sheet(). Tenga en cuenta que también estamos usando la función gs4_example() a continuación para ubicar una hoja de cálculo de Google de ejemplo que viene con el paquete googlesheets4.\n\ndeaths_url &lt;- gs4_example(\"deaths\")\ndeaths &lt;- read_sheet(deaths_url, range = \"A5:F15\")\n#&gt; ✔ Reading from deaths.\n#&gt; ✔ Range A5:F15.\ndeaths\n#&gt; # A tibble: 10 × 6\n#&gt;   Name          Profession   Age `Has kids` `Date of birth`    \n#&gt;   &lt;chr&gt;         &lt;chr&gt;      &lt;dbl&gt; &lt;lgl&gt;      &lt;dttm&gt;             \n#&gt; 1 David Bowie   musician      69 TRUE       1947-01-08 00:00:00\n#&gt; 2 Carrie Fisher actor         60 TRUE       1956-10-21 00:00:00\n#&gt; 3 Chuck Berry   musician      90 TRUE       1926-10-18 00:00:00\n#&gt; 4 Bill Paxton   actor         61 TRUE       1955-05-17 00:00:00\n#&gt; 5 Prince        musician      57 TRUE       1958-06-07 00:00:00\n#&gt; 6 Alan Rickman  actor         69 FALSE      1946-02-21 00:00:00\n#&gt; # ℹ 4 more rows\n#&gt; # ℹ 1 more variable: `Date of death` &lt;dttm&gt;\n\n\n21.3.4 Escribir en Hojas de cálculo de Google\nPuede escribir desde R a Hojas de cálculo de Google con write_sheet(). El primer argumento es el marco de datos para escribir, y el segundo argumento es el nombre (u otro identificador) de la Hoja de Google para escribir:\n\nwrite_sheet(bake_sale, ss = \"bake-sale\")\n\nSi desea escribir sus datos en una hoja (de trabajo) específica dentro de una hoja de cálculo de Google, también puede especificarlo con el argumento sheet.\n\nwrite_sheet(bake_sale, ss = \"bake-sale\", sheet = \"Sales\")\n\n\n21.3.5 Autenticación\nSi bien puede leer una hoja de Google pública sin autenticarse con su cuenta de Google y con gs4_deauth(), leer una hoja privada o escribir en una hoja requiere autenticación para que googlesheets4 pueda ver y administrar sus hojas de Google.\nCuando intenta leer una hoja que requiere autenticación, googlesheets4 lo dirigirá a un navegador web con un mensaje para iniciar sesión en su cuenta de Google y otorgar permiso para operar en su nombre con Hojas de cálculo de Google. Sin embargo, si desea especificar una cuenta de Google específica, el alcance de la autenticación, etc., puede hacerlo con gs4_auth(), p.ej., gs4_auth(email = \"mine@example.com\"), que forzará el uso de un token asociado con un correo electrónico específico. Para obtener más detalles de autenticación, recomendamos leer la documentación googlesheets4 auth viñeta: https://googlesheets4.tidyverse.org/articles/auth.html.\n\n21.3.6 Ejercicios\n\nLea el conjunto de datos de students anterior en el capítulo de Excel y también de Hojas de cálculo de Google, sin proporcionar argumentos adicionales a las funciones read_excel() y read_sheet(). ¿Los marcos de datos resultantes en R son exactamente iguales? Si no, ¿en qué se diferencian?\nLea la encuesta titulada Google Sheet de https://pos.it/r4ds-survey, con survey_id como variable de carácter y n_pets como variable numérica.\n\nLea la lista de Google Sheet titulada de https://pos.it/r4ds-roster. El marco de datos resultante debe llamarse roster y debe tener el siguiente aspecto.\n\n#&gt; # A tibble: 12 × 3\n#&gt;    group subgroup    id\n#&gt;    &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;\n#&gt;  1     1 A            1\n#&gt;  2     1 A            2\n#&gt;  3     1 A            3\n#&gt;  4     1 B            4\n#&gt;  5     1 B            5\n#&gt;  6     1 B            6\n#&gt;  7     1 B            7\n#&gt;  8     2 A            8\n#&gt;  9     2 A            9\n#&gt; 10     2 B           10\n#&gt; 11     2 B           11\n#&gt; 12     2 B           12"
  },
  {
    "objectID": "spreadsheets.html#resumen",
    "href": "spreadsheets.html#resumen",
    "title": "21  Hojas de calculo",
    "section": "\n21.4 Resumen",
    "text": "21.4 Resumen\nMicrosoft Excel y Google Sheets son dos de los sistemas de hojas de cálculo más populares. ¡Poder interactuar con datos almacenados en archivos de Excel y Google Sheets directamente desde R es un superpoder! En este capítulo, aprendió a leer datos en R desde hojas de cálculo de Excel con read_excel() del paquete readxl y de Google Sheets con read_sheet() del paquete googlesheets4. Estas funciones funcionan de manera muy similar entre sí y tienen argumentos similares para especificar nombres de columnas, cadenas NA, filas para omitir en la parte superior del archivo que está leyendo, etc. Además, ambas funciones también permiten leer una sola hoja de una hoja de cálculo.\nPor otro lado, escribir en un archivo de Excel requiere un paquete y una función diferentes (writexl::write_xlsx()), mientras que puede escribir en una hoja de cálculo de Google con el paquete googlesheets4, con write_sheet().\nEn el próximo capítulo, aprenderá sobre una fuente de datos diferente y cómo leer datos de esa fuente en R: bases de datos."
  },
  {
    "objectID": "databases.html#introducción",
    "href": "databases.html#introducción",
    "title": "22  Bases de datos",
    "section": "",
    "text": "22.1.1 Requisitos previos\nEn este capítulo, presentaremos DBI y dbplyr. DBI es una interfaz de bajo nivel que se conecta a bases de datos y ejecuta SQL; dbplyr es una interfaz de alto nivel que traduce su código dplyr a consultas SQL y luego las ejecuta con DBI.\n\nlibrary(DBI)\nlibrary(dbplyr)\nlibrary(tidyverse)",
    "crumbs": [
      "Importar",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Bases de datos</span>"
    ]
  },
  {
    "objectID": "databases.html#bases-de-datos-básicos",
    "href": "databases.html#bases-de-datos-básicos",
    "title": "22  Bases de datos",
    "section": "\n22.2 Bases de datos básicos",
    "text": "22.2 Bases de datos básicos\nEn el nivel más simple, puede pensar en una base de datos como una colección de marcos de datos, llamados tablas en la terminología de la base de datos. Al igual que un marco de datos, una tabla de base de datos es una colección de columnas con nombre, donde cada valor en la columna es del mismo tipo. Hay tres diferencias de alto nivel entre los marcos de datos y las tablas de la base de datos:\n\nLas tablas de la base de datos se almacenan en el disco y pueden tener un tamaño arbitrario. Los marcos de datos se almacenan en la memoria y están fundamentalmente limitados (aunque ese límite sigue siendo bastante grande para muchos problemas).\nLas tablas de bases de datos casi siempre tienen índices. Al igual que el índice de un libro, el índice de una base de datos permite encontrar rápidamente filas de interés sin tener que mirar cada una de ellas. Los marcos de datos y los tibbles no tienen índices, pero las tablas de datos sí, que es una de las razones por las que son tan rápidos.\nLa mayoría de las bases de datos clásicas están optimizadas para recopilar datos rápidamente, no para analizar los datos existentes. Estas bases de datos se denominan orientadas a filas porque los datos se almacenan fila por fila, en lugar de columna por columna como R. Más recientemente, ha habido mucho desarrollo de bases de datos orientadas a columnas que hacen que el análisis de los datos existentes sea mucho más rápido.\n\nLas bases de datos se ejecutan mediante sistemas de administración de bases de datos (DBMS para abreviar), que vienen en tres formas básicas:\n\n\nCliente-servidor Los DBMS se ejecutan en un poderoso servidor central, que usted conecta desde su computadora (el cliente). Son excelentes para compartir datos con varias personas en una organización. Los DBMS cliente-servidor populares incluyen PostgreSQL, MariaDB, SQL Server y Oracle.\nLos DBMS de Cloud, como Snowflake, RedShift de Amazon y BigQuery de Google, son similares a los DBMS del servidor del cliente, pero se ejecutan en la nube. Esto significa que pueden manejar fácilmente conjuntos de datos extremadamente grandes y pueden proporcionar automáticamente más recursos informáticos según sea necesario.\nLos DBMS en proceso, como SQLite o duckdb, se ejecutan completamente en su computadora. Son excelentes para trabajar con grandes conjuntos de datos en los que usted es el usuario principal.",
    "crumbs": [
      "Importar",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Bases de datos</span>"
    ]
  },
  {
    "objectID": "databases.html#conexión-a-una-base-de-datos",
    "href": "databases.html#conexión-a-una-base-de-datos",
    "title": "22  Bases de datos",
    "section": "\n22.3 Conexión a una base de datos",
    "text": "22.3 Conexión a una base de datos\nPara conectarse a la base de datos desde R, utilizará un par de paquetes:\n\nSiempre usará DBI (database interface) porque proporciona un conjunto de funciones genéricas que se conectan a la base de datos, cargan datos, ejecutan consultas SQL, etc.\nTambién utilizará un paquete diseñado para el DBMS al que se está conectando. Este paquete traduce los comandos DBI genéricos a los específicos necesarios para un DBMS dado. Por lo general, hay un paquete para cada DBMS, p. RPostgres para PostgresSQL y RMariaDB para MySQL.\n\nSi no puede encontrar un paquete específico para su DBMS, generalmente puede usar el paquete odbc en su lugar. Esto usa el protocolo ODBC soportado por muchos DBMS. odbc requiere un poco más de configuración porque también necesitará instalar un controlador ODBC e indicarle al paquete odbc dónde encontrarlo.\nConcretamente, crea una conexión a la base de datos usando DBI::dbConnect(). El primer argumento selecciona DBMS2, luego el segundo argumento y los subsiguientes describen cómo conectarse a él (es decir, dónde reside y las credenciales que necesita para acceder a él). El siguiente código muestra un par de ejemplos típicos:\n\ncon &lt;- DBI::dbConnect(\n  RMariaDB::MariaDB(), \n  username = \"foo\"\n)\ncon &lt;- DBI::dbConnect(\n  RPostgres::Postgres(), \n  hostname = \"databases.mycompany.com\", \n  port = 1234\n)\n\nLos detalles precisos de la conexión varían mucho de DBMS a DBMS, por lo que lamentablemente no podemos cubrir todos los detalles aquí. Esto significa que tendrás que investigar un poco por tu cuenta. Por lo general, puede preguntar a los otros científicos de datos de su equipo o hablar con su DBA (database aadministrador). La configuración inicial a menudo requerirá un poco de manipulación (y tal vez un poco de google) para hacerlo bien, pero generalmente solo necesitará hacerlo una vez.\n\n22.3.1 En este libro\nConfigurar un DBMS cliente-servidor o en la nube sería una molestia para este libro, por lo que en su lugar usaremos un DBMS en proceso que vive completamente en un paquete R: duckdb. Gracias a la magia de DBI, la única diferencia entre usar duckdb y cualquier otro DBMS es cómo te conectarás a la base de datos. Esto hace que sea excelente para enseñar porque puede ejecutar fácilmente este código y tomar fácilmente lo que aprende y aplicarlo en otro lugar.\nConectarse a duckdb es particularmente simple porque los valores predeterminados crean una base de datos temporal que se elimina cuando sale de R. Eso es excelente para aprender porque garantiza que comenzará desde cero cada vez que reinicie R:\n\ncon &lt;- DBI::dbConnect(duckdb::duckdb())\n\nduckdb es una base de datos de alto rendimiento diseñada en gran medida para las necesidades de un científico de datos. Lo usamos aquí porque es muy fácil de usar, pero también es capaz de manejar gigabytes de datos a gran velocidad. Si desea utilizar duckdb para un proyecto de análisis de datos real, también deberá proporcionar el argumento dbdir para crear una base de datos persistente y decirle a duckdb dónde guardarla. Asumiendo que estás usando un proyecto (Capítulo 7), es razonable guardarlo en el directorio duckdb del proyecto actual:\n\ncon &lt;- DBI::dbConnect(duckdb::duckdb(), dbdir = \"duckdb\")\n\n\n22.3.2 Cargar algunos datos\nDado que esta es una base de datos nueva, debemos comenzar agregando algunos datos. Aquí agregaremos conjuntos de datos mpg y diamonds de ggplot2 usando DBI::dbWriteTable(). El uso más simple de dbWriteTable() necesita tres argumentos: una conexión de base de datos, el nombre de la tabla para crear en la base de datos y un marco de datos de datos.\n\ndbWriteTable(con, \"mpg\", ggplot2::mpg)\ndbWriteTable(con, \"diamonds\", ggplot2::diamonds)\n\nSi está utilizando duckdb en un proyecto real, le recomendamos que aprenda sobre duckdb_read_csv() y duckdb_register_arrow(). Estos le brindan formas potentes y eficaces de cargar rápidamente datos directamente en duckdb, sin tener que cargarlos primero en R. También mostraremos una técnica útil para cargar varios archivos en una base de datos en Sección 27.4.1.\n\n22.3.3 DBI básico\nPuede comprobar que los datos se cargan correctamente utilizando un par de otras funciones de DBI: dbListTables() enumera todas las tablas de la base de datos3 y dbReadTable() recupera el contenido de una tabla.\n\ndbListTables(con)\n#&gt; [1] \"diamonds\" \"mpg\"\n\ncon |&gt; \n  dbReadTable(\"diamonds\") |&gt; \n  as_tibble()\n#&gt; # A tibble: 53,940 × 10\n#&gt;   carat cut       color clarity depth table price     x     y     z\n#&gt;   &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt; &lt;fct&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1  0.23 Ideal     E     SI2      61.5    55   326  3.95  3.98  2.43\n#&gt; 2  0.21 Premium   E     SI1      59.8    61   326  3.89  3.84  2.31\n#&gt; 3  0.23 Good      E     VS1      56.9    65   327  4.05  4.07  2.31\n#&gt; 4  0.29 Premium   I     VS2      62.4    58   334  4.2   4.23  2.63\n#&gt; 5  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75\n#&gt; 6  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48\n#&gt; # ℹ 53,934 more rows\n\ndbReadTable() devuelve un data.frame por lo que usamos as_tibble() para convertirlo en un tibble para que se imprima bien.\nSi ya conoce SQL, puede usar dbGetQuery() para obtener los resultados de ejecutar una consulta en la base de datos:\n\nsql &lt;- \"\n  SELECT carat, cut, clarity, color, price \n  FROM diamonds \n  WHERE price &gt; 15000\n\"\nas_tibble(dbGetQuery(con, sql))\n#&gt; # A tibble: 1,655 × 5\n#&gt;   carat cut       clarity color price\n#&gt;   &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt;   &lt;fct&gt; &lt;int&gt;\n#&gt; 1  1.54 Premium   VS2     E     15002\n#&gt; 2  1.19 Ideal     VVS1    F     15005\n#&gt; 3  2.1  Premium   SI1     I     15007\n#&gt; 4  1.69 Ideal     SI1     D     15011\n#&gt; 5  1.5  Very Good VVS2    G     15013\n#&gt; 6  1.73 Very Good VS1     G     15014\n#&gt; # ℹ 1,649 more rows\n\nSi nunca ha visto SQL antes, ¡no se preocupe! En breve aprenderás más al respecto. Pero si lo lee detenidamente, puede adivinar que selecciona cinco columnas del conjunto de datos de diamantes y todas las filas donde el precio es mayor que 15,000.",
    "crumbs": [
      "Importar",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Bases de datos</span>"
    ]
  },
  {
    "objectID": "databases.html#dbplyr-básico",
    "href": "databases.html#dbplyr-básico",
    "title": "22  Bases de datos",
    "section": "\n22.4 dbplyr básico",
    "text": "22.4 dbplyr básico\nAhora que nos conectamos a una base de datos y cargamos algunos datos, podemos comenzar a aprender sobre dbplyr. dbplyr es un backend de dplyr, lo que significa que sigues escribiendo código dplyr pero el backend lo ejecuta de manera diferente. En esto, dbplyr se traduce a SQL; otros backends incluyen dtplyr que se traduce en data.table, y multidplyr que ejecuta su código en múltiples núcleos.\nPara usar dbplyr, primero debe usar tbl() para crear un objeto que represente una tabla de base de datos:\n\ndiamonds_db &lt;- tbl(con, \"diamonds\")\ndiamonds_db\n#&gt; # Source:   table&lt;diamonds&gt; [?? x 10]\n#&gt; # Database: DuckDB v0.10.0 [DDR@Windows 10 x64:R 4.3.3/:memory:]\n#&gt;   carat cut       color clarity depth table price     x     y     z\n#&gt;   &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt; &lt;fct&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1  0.23 Ideal     E     SI2      61.5    55   326  3.95  3.98  2.43\n#&gt; 2  0.21 Premium   E     SI1      59.8    61   326  3.89  3.84  2.31\n#&gt; 3  0.23 Good      E     VS1      56.9    65   327  4.05  4.07  2.31\n#&gt; 4  0.29 Premium   I     VS2      62.4    58   334  4.2   4.23  2.63\n#&gt; 5  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75\n#&gt; 6  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48\n#&gt; # ℹ more rows\n\n\n\n\n\n\n\nHay otras dos formas comunes de interactuar con una base de datos. Primero, muchas bases de datos corporativas son muy grandes, por lo que necesita cierta jerarquía para mantener todas las tablas organizadas. En ese caso, es posible que deba proporcionar un esquema, o un catálogo y un esquema, para elegir la tabla que le interesa.:\n\ndiamonds_db &lt;- tbl(con, in_schema(\"sales\", \"diamonds\"))\ndiamonds_db &lt;- tbl(con, in_catalog(\"north_america\", \"sales\", \"diamonds\"))\n\nOtras veces, es posible que desee utilizar su propia consulta SQL como punto de partida:\n\ndiamonds_db &lt;- tbl(con, sql(\"SELECT * FROM diamonds\"))\n\n\n\n\nEste objeto es perezoso; cuando usa verbos dplyr en él, dplyr no hace ningún trabajo: solo registra la secuencia de operaciones que desea realizar y solo las realiza cuando es necesario. Por ejemplo, tome la siguiente canalización:\n\nbig_diamonds_db &lt;- diamonds_db |&gt; \n  filter(price &gt; 15000) |&gt; \n  select(carat:clarity, price)\n\nbig_diamonds_db\n#&gt; # Source:   SQL [?? x 5]\n#&gt; # Database: DuckDB v0.10.0 [DDR@Windows 10 x64:R 4.3.3/:memory:]\n#&gt;   carat cut       color clarity price\n#&gt;   &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt; &lt;fct&gt;   &lt;int&gt;\n#&gt; 1  1.54 Premium   E     VS2     15002\n#&gt; 2  1.19 Ideal     F     VVS1    15005\n#&gt; 3  2.1  Premium   I     SI1     15007\n#&gt; 4  1.69 Ideal     D     SI1     15011\n#&gt; 5  1.5  Very Good G     VVS2    15013\n#&gt; 6  1.73 Very Good G     VS1     15014\n#&gt; # ℹ more rows\n\nPuede decir que este objeto representa una consulta de base de datos porque imprime el nombre de DBMS en la parte superior y, aunque le dice el número de columnas, normalmente no sabe el número de filas. Esto se debe a que encontrar el número total de filas generalmente requiere ejecutar la consulta completa, algo que estamos tratando de evitar.\nPuede ver el código SQL generado por la función dbplyr show_query(). Si conoce dplyr, ¡esta es una excelente manera de aprender SQL! Escriba algo de código dplyr, obtenga dbplyr para traducirlo a SQL y luego intente averiguar cómo coinciden los dos idiomas.\n\nbig_diamonds_db |&gt;\n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT carat, cut, color, clarity, price\n#&gt; FROM diamonds\n#&gt; WHERE (price &gt; 15000.0)\n\nPara recuperar todos los datos en R, llama a collect(). Detrás de escena, esto genera el SQL, llama a dbGetQuery() para obtener los datos, luego convierte el resultado en un tibble:\n\nbig_diamonds &lt;- big_diamonds_db |&gt; \n  collect()\nbig_diamonds\n#&gt; # A tibble: 1,655 × 5\n#&gt;   carat cut       color clarity price\n#&gt;   &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt; &lt;fct&gt;   &lt;int&gt;\n#&gt; 1  1.54 Premium   E     VS2     15002\n#&gt; 2  1.19 Ideal     F     VVS1    15005\n#&gt; 3  2.1  Premium   I     SI1     15007\n#&gt; 4  1.69 Ideal     D     SI1     15011\n#&gt; 5  1.5  Very Good G     VVS2    15013\n#&gt; 6  1.73 Very Good G     VS1     15014\n#&gt; # ℹ 1,649 more rows\n\nPor lo general, usará dbplyr para seleccionar los datos que desea de la base de datos, realizando filtrado y agregación básicos utilizando las traducciones que se describen a continuación. Luego, una vez que esté listo para analizar los datos con funciones que son exclusivas de R, collect() los datos para obtener un tibble en memoria y continuar su trabajo con código R puro.",
    "crumbs": [
      "Importar",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Bases de datos</span>"
    ]
  },
  {
    "objectID": "databases.html#sql",
    "href": "databases.html#sql",
    "title": "22  Bases de datos",
    "section": "\n22.5 SQL",
    "text": "22.5 SQL\nEl resto del capítulo le enseñará un poco de SQL a través de la lente de dbplyr. Es una introducción bastante no tradicional a SQL, pero esperamos que lo ponga rápidamente al día con los conceptos básicos. Afortunadamente, si entiende dplyr, está en un buen lugar para aprender SQL rápidamente porque muchos de los conceptos son los mismos.\nExploraremos la relación entre dplyr y SQL usando un par de viejos amigos del paquete nycflights13: flights y planes. Estos conjuntos de datos son fáciles de ingresar a nuestra base de datos de aprendizaje porque dbplyr viene con una función que copia las tablas de nycflights13 a nuestra base de datos:\n\ndbplyr::copy_nycflights13(con)\n#&gt; Creating table: airlines\n#&gt; Creating table: airports\n#&gt; Creating table: flights\n#&gt; Creating table: planes\n#&gt; Creating table: weather\nflights &lt;- tbl(con, \"flights\")\nplanes &lt;- tbl(con, \"planes\")\n\n\n22.5.1 SQL básico\nLos componentes de nivel superior de SQL se denominan declaraciones. Las declaraciones comunes incluyen CREATE para definir nuevas tablas, INSERT para agregar datos y SELECT para recuperar datos. Nos centraremos en las declaraciones SELECT, también llamadas consultas, porque son casi exclusivamente lo que usará como científico de datos.\nUna consulta se compone de cláusulas. Hay cinco cláusulas importantes: SELECT, FROM, WHERE, ORDER BY y GROUP BY. Cada consulta debe tener las cláusulas SELECT4 y FROM5 y la consulta más simple es SELECT * FROM table, que selecciona todas las columnas de la tabla especificada . Esto es lo que genera dbplyr para una tabla sin adulterar :\n\nflights |&gt; show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT *\n#&gt; FROM flights\nplanes |&gt; show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT *\n#&gt; FROM planes\n\nWHERE y ORDER BY controlan qué filas se incluyen y cómo se ordenan:\n\nflights |&gt; \n  filter(dest == \"IAH\") |&gt; \n  arrange(dep_delay) |&gt;\n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT flights.*\n#&gt; FROM flights\n#&gt; WHERE (dest = 'IAH')\n#&gt; ORDER BY dep_delay\n\nGROUP BY convierte la consulta en un resumen, lo que hace que se produzca la agregación:\n\nflights |&gt; \n  group_by(dest) |&gt; \n  summarize(dep_delay = mean(dep_delay, na.rm = TRUE)) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT dest, AVG(dep_delay) AS dep_delay\n#&gt; FROM flights\n#&gt; GROUP BY dest\n\nHay dos diferencias importantes entre los verbos dplyr y las cláusulas SELECT:\n\nEn SQL, el caso no importa: puede escribir select, SELECT o incluso SeLeCt. En este libro nos apegaremos a la convención común de escribir palabras clave de SQL en mayúsculas para distinguirlas de los nombres de tablas o variables.\nEn SQL, el orden importa: siempre debe escribir las cláusulas en el orden SELECT, FROM, WHERE, GROUP BY, ORDER BY. De manera confusa, este orden no coincide con la evaluación real de las cláusulas, que es primero FROM, luego WHERE, GROUP BY, SELECT y ORDER BY.\n\nLas siguientes secciones exploran cada cláusula con más detalle.\n\n\n\n\n\n\nTenga en cuenta que, si bien SQL es un estándar, es extremadamente complejo y ninguna base de datos lo sigue exactamente. Si bien los componentes principales en los que nos centraremos en este libro son muy similares entre los DBMS, existen muchas variaciones menores. Afortunadamente, dbplyr está diseñado para manejar este problema y genera diferentes traducciones para diferentes bases de datos. No es perfecto, pero está mejorando continuamente, y si encuentra un problema, puede presentar un problema en GitHub para ayudarnos a hacerlo mejor.\n\n\n\n\n22.5.2 SELECT\nLa cláusula SELECT es el caballo de batalla de las consultas y realiza el mismo trabajo que select(), mutate(), rename(), relocate() y, como aprenderá en la próxima sección, summarize().\nselect(), rename() y relocate() tienen traducciones muy directas a SELECT ya que solo afectan el lugar donde aparece una columna (si es que aparece) junto con su nombre:\n\nplanes |&gt; \n  select(tailnum, type, manufacturer, model, year) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT tailnum, \"type\", manufacturer, model, \"year\"\n#&gt; FROM planes\n\nplanes |&gt; \n  select(tailnum, type, manufacturer, model, year) |&gt; \n  rename(year_built = year) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT tailnum, \"type\", manufacturer, model, \"year\" AS year_built\n#&gt; FROM planes\n\nplanes |&gt; \n  select(tailnum, type, manufacturer, model, year) |&gt; \n  relocate(manufacturer, model, .before = type) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT tailnum, manufacturer, model, \"type\", \"year\"\n#&gt; FROM planes\n\nEste ejemplo también muestra cómo SQL cambia el nombre. En la terminología SQL, el cambio de nombre se denomina aliasing y se realiza con AS. Tenga en cuenta que, a diferencia de mutate(), el nombre anterior está a la izquierda y el nuevo nombre está a la derecha.\n\n\n\n\n\n\nEn los ejemplos anteriores, tenga en cuenta que \"year\" y \"type\" están entre comillas dobles. Esto se debe a que estas son palabras reservadas en duckdb, por lo que dbplyr las cita para evitar cualquier posible confusión entre los nombres de columnas/tablas y los operadores de SQL.\nCuando trabaje con otras bases de datos, es probable que vea todos los nombres de variables entre comillas porque solo un puñado de paquetes de clientes, como duckdb, saben cuáles son todas las palabras reservadas, por lo que citan todo para estar seguros.\nSELECT \"tailnum\", \"type\", \"manufacturer\", \"model\", \"year\"\nFROM \"planes\"\nAlgunos otros sistemas de bases de datos usan acentos graves en lugar de comillas:\nSELECT `tailnum`, `type`, `manufacturer`, `model`, `year`\nFROM `planes`\n\n\n\nLas traducciones de mutate() son igualmente sencillas: cada variable se convierte en una nueva expresión en SELECT:\n\nflights |&gt; \n  mutate(\n    speed = distance / (air_time / 60)\n  ) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT flights.*, distance / (air_time / 60.0) AS speed\n#&gt; FROM flights\n\nVolveremos a la traducción de componentes individuales (como /) en Sección 22.6.\n\n22.5.3 FROM\nLa cláusula FROM define la fuente de datos. Va a ser poco interesante por un tiempo, porque solo estamos usando tablas individuales. Verá ejemplos más complejos una vez que lleguemos a las funciones de unión.\n\n22.5.4 GROUP BY\ngroup_by() se traduce a la cláusula GROUP BY6 y summarize() se traduce a la cláusula SELECT:\n\ndiamonds_db |&gt; \n  group_by(cut) |&gt; \n  summarize(\n    n = n(),\n    avg_price = mean(price, na.rm = TRUE)\n  ) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT cut, COUNT(*) AS n, AVG(price) AS avg_price\n#&gt; FROM diamonds\n#&gt; GROUP BY cut\n\nVolveremos a lo que sucede con la traducción n() y mean() en Sección 22.6.\n\n22.5.5 WHERE\nfilter() se traduce a la cláusula WHERE:\n\nflights |&gt; \n  filter(dest == \"IAH\" | dest == \"HOU\") |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT flights.*\n#&gt; FROM flights\n#&gt; WHERE (dest = 'IAH' OR dest = 'HOU')\n\nflights |&gt; \n  filter(arr_delay &gt; 0 & arr_delay &lt; 20) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT flights.*\n#&gt; FROM flights\n#&gt; WHERE (arr_delay &gt; 0.0 AND arr_delay &lt; 20.0)\n\nHay algunos detalles importantes a tener en cuenta aquí:\n\n\n| se convierte en OR y & se convierte en AND.\nSQL usa = para comparar, no ==. SQL no tiene asignación, por lo que no hay posibilidad de confusión allí.\nSQL usa solo '' para cadenas, no \"\". En SQL, \"\" se usa para identificar variables, como `` de R.\n\nOtro operador SQL útil es IN, que está muy cerca del %in% de R:\n\nflights |&gt; \n  filter(dest %in% c(\"IAH\", \"HOU\")) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT flights.*\n#&gt; FROM flights\n#&gt; WHERE (dest IN ('IAH', 'HOU'))\n\nSQL usa NULL en lugar de NA. NULLs se comportan de manera similar a NAs. La principal diferencia es que, si bien son “infecciosos” en las comparaciones y la aritmética, se descartan silenciosamente al resumir. dbplyr le recordará este comportamiento la primera vez que lo presione:\n\nflights |&gt; \n  group_by(dest) |&gt; \n  summarize(delay = mean(arr_delay))\n#&gt; Warning: Missing values are always removed in SQL aggregation functions.\n#&gt; Use `na.rm = TRUE` to silence this warning\n#&gt; This warning is displayed once every 8 hours.\n#&gt; # Source:   SQL [?? x 2]\n#&gt; # Database: DuckDB v0.10.0 [DDR@Windows 10 x64:R 4.3.3/:memory:]\n#&gt;   dest   delay\n#&gt;   &lt;chr&gt;  &lt;dbl&gt;\n#&gt; 1 ORD    5.88 \n#&gt; 2 FLL    8.08 \n#&gt; 3 IAD   13.9  \n#&gt; 4 PBI    8.56 \n#&gt; 5 TPA    7.41 \n#&gt; 6 DFW    0.322\n#&gt; # ℹ more rows\n\nSi desea obtener más información sobre cómo funcionan los valores NULL, puede disfrutar de “La lógica de tres valores de SQL” de Markus Winand.\nEn general, puedes trabajar con NULLs usando las funciones que usarías para NAs en R:\n\nflights |&gt; \n  filter(!is.na(dep_delay)) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT flights.*\n#&gt; FROM flights\n#&gt; WHERE (NOT((dep_delay IS NULL)))\n\nEsta consulta SQL ilustra uno de los inconvenientes de dbplyr: si bien el SQL es correcto, no es tan simple como podría escribirse a mano. En este caso, podría quitar los paréntesis y usar un operador especial que sea más fácil de leer:\nWHERE \"dep_delay\" IS NOT NULL\nTenga en cuenta que si filtra, filter(), una variable que creó utilizando un resumen, dbplyr generará una cláusula ‘HAVING’, en lugar de una cláusula ‘WHERE’. Esta es una de las idiosincrasias de SQL: WHERE se evalúa antes que SELECT y GROUP BY, por lo que SQL necesita otra cláusula que se evalúa después.\n\ndiamonds_db |&gt; \n  group_by(cut) |&gt; \n  summarize(n = n()) |&gt; \n  filter(n &gt; 100) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT cut, COUNT(*) AS n\n#&gt; FROM diamonds\n#&gt; GROUP BY cut\n#&gt; HAVING (COUNT(*) &gt; 100.0)\n\n\n22.5.6 ORDER BY\nOrdenar filas implica una traducción directa de arrange() a la cláusula ORDER BY:\n\nflights |&gt; \n  arrange(year, month, day, desc(dep_delay)) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT flights.*\n#&gt; FROM flights\n#&gt; ORDER BY \"year\", \"month\", \"day\", dep_delay DESC\n\nObserve cómo desc() se traduce a DESC: esta es una de las muchas funciones dplyr cuyo nombre se inspiró directamente en SQL.\n\n22.5.7 Subconsultas\nA veces, no es posible traducir una canalización dplyr en una sola declaración SELECT y necesita usar una subconsulta. Una subconsulta es solo una consulta utilizada como fuente de datos en la cláusula FROM, en lugar de la tabla habitual.\ndbplyr normalmente usa subconsultas para sortear las limitaciones de SQL. Por ejemplo, las expresiones en la cláusula SELECT no pueden hacer referencia a columnas que se acaban de crear. Eso significa que la siguiente canalización (tonta) de dplyr debe ocurrir en dos pasos: la primera consulta (interna) calcula year1 y luego la segunda consulta (externa) puede calcular year2.\n\nflights |&gt; \n  mutate(\n    year1 = year + 1,\n    year2 = year1 + 1\n  ) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT q01.*, year1 + 1.0 AS year2\n#&gt; FROM (\n#&gt;   SELECT flights.*, \"year\" + 1.0 AS year1\n#&gt;   FROM flights\n#&gt; ) q01\n\nTambién verá esto si intentó filtrar, filter(), una variable que acaba de crear. Recuerda, aunque WHERE se escribe después de SELECT, se evalúa antes, por lo que necesitamos una subconsulta en este (tonto) ejemplo:\n\nflights |&gt; \n  mutate(year1 = year + 1) |&gt; \n  filter(year1 == 2014) |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT q01.*\n#&gt; FROM (\n#&gt;   SELECT flights.*, \"year\" + 1.0 AS year1\n#&gt;   FROM flights\n#&gt; ) q01\n#&gt; WHERE (year1 = 2014.0)\n\nA veces, dbplyr creará una subconsulta donde no es necesaria porque aún no sabe cómo optimizar esa traducción. A medida que dbplyr mejore con el tiempo, estos casos se volverán más raros pero probablemente nunca desaparezcan.\n\n22.5.8 Uniones\nSi está familiarizado con las uniones de dplyr, las uniones de SQL son muy similares. Aquí hay un ejemplo simple:\n\nflights |&gt; \n  left_join(planes |&gt; rename(year_built = year), by = \"tailnum\") |&gt; \n  show_query()\n#&gt; &lt;SQL&gt;\n#&gt; SELECT\n#&gt;   flights.*,\n#&gt;   planes.\"year\" AS year_built,\n#&gt;   \"type\",\n#&gt;   manufacturer,\n#&gt;   model,\n#&gt;   engines,\n#&gt;   seats,\n#&gt;   speed,\n#&gt;   engine\n#&gt; FROM flights\n#&gt; LEFT JOIN planes\n#&gt;   ON (flights.tailnum = planes.tailnum)\n\nLo principal a notar aquí es la sintaxis: las uniones SQL usan subcláusulas de la cláusula FROM para traer tablas adicionales, usando ON para definir cómo se relacionan las tablas.\nLos nombres de dplyr para estas funciones están tan estrechamente relacionados con SQL que puede adivinar fácilmente el SQL equivalente para inner_join(), right_join() y full_join():\nSELECT flights.*, \"type\", manufacturer, model, engines, seats, speed\nFROM flights\nINNER JOIN planes ON (flights.tailnum = planes.tailnum)\n\nSELECT flights.*, \"type\", manufacturer, model, engines, seats, speed\nFROM flights\nRIGHT JOIN planes ON (flights.tailnum = planes.tailnum)\n\nSELECT flights.*, \"type\", manufacturer, model, engines, seats, speed\nFROM flights\nFULL JOIN planes ON (flights.tailnum = planes.tailnum)\nEs probable que necesite muchas uniones cuando trabaje con datos de una base de datos. Esto se debe a que las tablas de la base de datos a menudo se almacenan en una forma altamente normalizada, donde cada “hecho” se almacena en un solo lugar y para mantener un conjunto de datos completo para el análisis, debe navegar por una red compleja de tablas conectadas por claves primarias y externas. Si te encuentras en este escenario, el paquete dm, de Tobias Schieferdecker, Kirill Müller y Darko Bergant, es un salvavidas. Puede determinar automáticamente las conexiones entre tablas usando las restricciones que los administradores de bases de datos suelen proporcionar, visualizar las conexiones para que pueda ver lo que está pasando y generar las uniones que necesita para conectar una tabla con otra.\n\n22.5.9 Otros verbos\ndbplyr también traduce otros verbos como distinct(), slice_*() e intersect(), y una creciente selección de funciones tidyr como pivot_longer() y pivot_wider(). La forma más fácil de ver el conjunto completo de lo que está disponible actualmente es visitar el sitio web de dbplyr: https://dbplyr.tidyverse.org/reference/.\n\n22.5.10 Ejercicios\n\n¿A qué se traduce distinct()? ¿Qué tal head()?\n\nExplique qué hace cada una de las siguientes consultas SQL e intente recrearlas usando dbplyr.\nSELECT * \nFROM flights\nWHERE dep_delay &lt; arr_delay\n\nSELECT *, distance / (air_time / 60) AS speed\nFROM flights",
    "crumbs": [
      "Importar",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Bases de datos</span>"
    ]
  },
  {
    "objectID": "databases.html#sec-sql-expressions",
    "href": "databases.html#sec-sql-expressions",
    "title": "22  Bases de datos",
    "section": "\n22.6 Traducciones de funciones",
    "text": "22.6 Traducciones de funciones\nHasta ahora nos hemos centrado en el panorama general de cómo se traducen los verbos dplyr a las cláusulas de una consulta. Ahora vamos a acercarnos un poco y hablar sobre la traducción de las funciones R que funcionan con columnas individuales, p.ej., ¿Qué pasa cuando usas mean(x) en summarize()?\nPara ayudar a ver lo que está pasando, usaremos un par de pequeñas funciones auxiliares que ejecutan summarize() o mutate() y muestran el SQL generado. Eso hará que sea un poco más fácil explorar algunas variaciones y ver cómo los resúmenes y las transformaciones pueden diferir.\n\nsummarize_query &lt;- function(df, ...) {\n  df |&gt; \n    summarize(...) |&gt; \n    show_query()\n}\nmutate_query &lt;- function(df, ...) {\n  df |&gt; \n    mutate(..., .keep = \"none\") |&gt; \n    show_query()\n}\n\n¡Vamos a sumergirnos con algunos resúmenes! Si observa el código siguiente, notará que algunas funciones de resumen, como mean(), tienen una traducción relativamente simple, mientras que otras, como median(), son mucho más complejas. La complejidad suele ser mayor para las operaciones que son comunes en las estadísticas pero menos comunes en las bases de datos.\n\nflights |&gt; \n  group_by(year, month, day) |&gt;  \n  summarize_query(\n    mean = mean(arr_delay, na.rm = TRUE),\n    median = median(arr_delay, na.rm = TRUE)\n  )\n#&gt; `summarise()` has grouped output by \"year\" and \"month\". You can override\n#&gt; using the `.groups` argument.\n#&gt; &lt;SQL&gt;\n#&gt; SELECT\n#&gt;   \"year\",\n#&gt;   \"month\",\n#&gt;   \"day\",\n#&gt;   AVG(arr_delay) AS mean,\n#&gt;   PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY arr_delay) AS median\n#&gt; FROM flights\n#&gt; GROUP BY \"year\", \"month\", \"day\"\n\nLa traducción de las funciones de resumen se vuelve más complicada cuando las usa dentro de un mutate() porque tienen que convertirse en las llamadas funciones de ventana. En SQL, convierte una función de agregación ordinaria en una función de ventana agregando OVER después de ella:\n\nflights |&gt; \n  group_by(year, month, day) |&gt;  \n  mutate_query(\n    mean = mean(arr_delay, na.rm = TRUE),\n  )\n#&gt; &lt;SQL&gt;\n#&gt; SELECT\n#&gt;   \"year\",\n#&gt;   \"month\",\n#&gt;   \"day\",\n#&gt;   AVG(arr_delay) OVER (PARTITION BY \"year\", \"month\", \"day\") AS mean\n#&gt; FROM flights\n\nEn SQL, la cláusula GROUP BY se usa exclusivamente para resúmenes, por lo que aquí puede ver que la agrupación se ha movido desde el argumento PARTITION BY a OVER.\nLas funciones de ventana incluyen todas las funciones que miran hacia adelante o hacia atrás, como lead() y lag() que miran el valor “anterior” o “siguiente” respectivamente:\n\nflights |&gt; \n  group_by(dest) |&gt;  \n  arrange(time_hour) |&gt; \n  mutate_query(\n    lead = lead(arr_delay),\n    lag = lag(arr_delay)\n  )\n#&gt; &lt;SQL&gt;\n#&gt; SELECT\n#&gt;   dest,\n#&gt;   LEAD(arr_delay, 1, NULL) OVER (PARTITION BY dest ORDER BY time_hour) AS lead,\n#&gt;   LAG(arr_delay, 1, NULL) OVER (PARTITION BY dest ORDER BY time_hour) AS lag\n#&gt; FROM flights\n#&gt; ORDER BY time_hour\n\nAquí es importante arreglar, arrange(), los datos, porque las tablas SQL no tienen un orden intrínseco. De hecho, si no usa arrange(), ¡podría recuperar las filas en un orden diferente cada vez! Aviso para las funciones de ventana, la información de pedido se repite: la cláusula ORDER BY de la consulta principal no se aplica automáticamente a las funciones de ventana.\nOtra función SQL importante es CASE WHEN. Se usa como la traducción de if_else() y case_when(), la función dplyr que inspiró directamente. Aquí hay un par de ejemplos simples:\n\nflights |&gt; \n  mutate_query(\n    description = if_else(arr_delay &gt; 0, \"delayed\", \"on-time\")\n  )\n#&gt; &lt;SQL&gt;\n#&gt; SELECT CASE WHEN (arr_delay &gt; 0.0) THEN 'delayed' WHEN NOT (arr_delay &gt; 0.0) THEN 'on-time' END AS description\n#&gt; FROM flights\nflights |&gt; \n  mutate_query(\n    description = \n      case_when(\n        arr_delay &lt; -5 ~ \"early\", \n        arr_delay &lt; 5 ~ \"on-time\",\n        arr_delay &gt;= 5 ~ \"late\"\n      )\n  )\n#&gt; &lt;SQL&gt;\n#&gt; SELECT CASE\n#&gt; WHEN (arr_delay &lt; -5.0) THEN 'early'\n#&gt; WHEN (arr_delay &lt; 5.0) THEN 'on-time'\n#&gt; WHEN (arr_delay &gt;= 5.0) THEN 'late'\n#&gt; END AS description\n#&gt; FROM flights\n\nCASE WHEN también se usa para algunas otras funciones que no tienen una traducción directa de R a SQL. Un buen ejemplo de esto es cut():\n\nflights |&gt; \n  mutate_query(\n    description =  cut(\n      arr_delay, \n      breaks = c(-Inf, -5, 5, Inf), \n      labels = c(\"early\", \"on-time\", \"late\")\n    )\n  )\n#&gt; &lt;SQL&gt;\n#&gt; SELECT CASE\n#&gt; WHEN (arr_delay &lt;= -5.0) THEN 'early'\n#&gt; WHEN (arr_delay &lt;= 5.0) THEN 'on-time'\n#&gt; WHEN (arr_delay &gt; 5.0) THEN 'late'\n#&gt; END AS description\n#&gt; FROM flights\n\ndbplyr también traduce funciones comunes de manipulación de cadenas y fecha y hora, sobre las que puede obtener información en vignette(\"funcion-de-traduccion\", package = \"dbplyr\"). Las traducciones de dbplyr ciertamente no son perfectas, y hay muchas funciones de R que aún no están traducidas, pero dbplyr hace un trabajo sorprendentemente bueno al cubrir las funciones que usará la mayor parte del tiempo..",
    "crumbs": [
      "Importar",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Bases de datos</span>"
    ]
  },
  {
    "objectID": "databases.html#resumen",
    "href": "databases.html#resumen",
    "title": "22  Bases de datos",
    "section": "\n22.7 Resumen",
    "text": "22.7 Resumen\nEn este capítulo aprendió cómo acceder a los datos de las bases de datos. Nos enfocamos en dbplyr, un “backend” de dplyr que le permite escribir el código dplyr con el que está familiarizado y hacer que se traduzca automáticamente a SQL. Usamos esa traducción para enseñarle un poco de SQL; es importante aprender algo de SQL porque es el lenguaje más utilizado para trabajar con datos y conocer algunos le facilitará la comunicación con otras personas de datos que no usan R. Si ha terminado este capítulo y desea obtener más información sobre SQL. Tenemos dos recomendaciones:\n\n\nSQL for Data Scientists de Renée M. P. Teate es una introducción a SQL diseñada específicamente para las necesidades de los científicos de datos e incluye ejemplos del tipo de datos altamente interconectados que es probable que encuentre en organizaciones reales.\n\nPractical SQL de Anthony DeBarros está escrito desde la perspectiva de un periodista de datos (un científico de datos especializado en contar historias convincentes) y entra en más detalles sobre cómo obtener sus datos en una base de datos y ejecutar su propio DBMS.\n\nEn el próximo capítulo, aprenderemos sobre otro backend de dplyr para trabajar con datos de gran tamaño: arrow. Arrow está diseñado para trabajar con archivos grandes en disco y es un complemento natural para las bases de datos.",
    "crumbs": [
      "Importar",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Bases de datos</span>"
    ]
  },
  {
    "objectID": "arrow.html#introduction",
    "href": "arrow.html#introduction",
    "title": "23  Arrow",
    "section": "\n23.1 Introduction",
    "text": "23.1 Introduction\nCSV files are designed to be easily read by humans. They’re a good interchange format because they’re very simple and they can be read by every tool under the sun. But CSV files aren’t very efficient: you have to do quite a lot of work to read the data into R. In this chapter, you’ll learn about a powerful alternative: the parquet format, an open standards-based format widely used by big data systems.\nWe’ll pair parquet files with Apache Arrow, a multi-language toolbox designed for efficient analysis and transport of large data sets. We’ll use Apache Arrow via the the arrow package, which provides a dplyr backend allowing you to analyze larger-than-memory datasets using familiar dplyr syntax. As an additional benefit, arrow is extremely fast: you’ll see some examples later in the chapter.\nBoth arrow and dbplyr provide dplyr backends, so you might wonder when to use each. In many cases, the choice is made for you, as in the data is already in a database or in parquet files, and you’ll want to work with it as is. But if you’re starting with your own data (perhaps CSV files), you can either load it into a database or convert it to parquet. In general, it’s hard to know what will work best, so in the early stages of your analysis we’d encourage you to try both and pick the one that works the best for you.\n\n23.1.1 Prerequisites\nIn this chapter, we’ll continue to use the tidyverse, particularly dplyr, but we’ll pair it with the arrow package which is designed specifically for working with large data.\n\nlibrary(tidyverse)\nlibrary(arrow)\n\nLater in the chapter, we’ll also see some connections between arrow and duckdb, so we’ll also need dbplyr and duckdb.\n\nlibrary(dbplyr, warn.conflicts = FALSE)\nlibrary(duckdb)\n#&gt; Loading required package: DBI"
  },
  {
    "objectID": "arrow.html#getting-the-data",
    "href": "arrow.html#getting-the-data",
    "title": "23  Arrow",
    "section": "\n23.2 Getting the data",
    "text": "23.2 Getting the data\nWe begin by getting a dataset worthy of these tools: a data set of item checkouts from Seattle public libraries, available online at data.seattle.gov/Community/Checkouts-by-Title/tmmm-ytt6. This dataset contains 41,389,465 rows that tell you how many times each book was checked out each month from April 2015 to October 2022.\nThe following code will get you a cached copy of the data. The data is a 9GB CSV file, so it will take some time to download: simply getting the data is often the first challenge!\n\ndir.create(\"data\", showWarnings = FALSE)\nurl &lt;- \"https://r4ds.s3.us-west-2.amazonaws.com/seattle-library-checkouts.csv\"\n\n# Default timeout is 60s; bump it up to an hour\noptions(timeout = 60 * 60)\ndownload.file(url, \"data/seattle-library-checkouts.csv\")"
  },
  {
    "objectID": "arrow.html#opening-a-dataset",
    "href": "arrow.html#opening-a-dataset",
    "title": "23  Arrow",
    "section": "\n23.3 Opening a dataset",
    "text": "23.3 Opening a dataset\nLet’s start by taking a look at the data. At 9GB, this file is large enough that we probably don’t want to load the whole thing into memory. A good rule of thumb is that you usually want at least twice as much memory as the size of the data, and many laptops top out at 16 Gb. This means we want to avoid read_csv() and instead use the arrow::open_dataset():\n\n# partial schema for ISBN column only\nopts &lt;- CsvConvertOptions$create(col_types = schema(ISBN = string()))\n\nseattle_csv &lt;- open_dataset(\n  sources = \"data/seattle-library-checkouts.csv\", \n  format = \"csv\",\n  convert_options = opts\n)\n\n(Here we’ve had to use some relatively advanced code to parse the ISBN variable correctly: this is because the first ~83,000 rows don’t contain any data so arrow guesses the wrong types. The arrow team is aware of this problem and there will hopefully be a better approach by the time you read this chapter.)\nWhat happens when this code is run? open_dataset() will scan a few thousand rows to figure out the structure of the data set. Then it records what it’s found and stops; it will only read further rows as you specifically request them. This metadata is what we see if we print seattle_csv:\n\nseattle_csv\n#&gt; FileSystemDataset with 1 csv file\n#&gt; UsageClass: string\n#&gt; CheckoutType: string\n#&gt; MaterialType: string\n#&gt; CheckoutYear: int64\n#&gt; CheckoutMonth: int64\n#&gt; Checkouts: int64\n#&gt; Title: string\n#&gt; ISBN: string\n#&gt; Creator: string\n#&gt; Subjects: string\n#&gt; Publisher: string\n#&gt; PublicationYear: string\n\nThe first line in the output tells you that seattle_csv is stored locally on-disk as a single CSV file; it will only be loaded into memory as needed. The remainder of the output tells you the column type that arrow has imputed for each column.\nWe can see what’s actually in with glimpse(). This reveals that there are ~41 million rows and 12 columns, and shows us a few values.\n\nseattle_csv |&gt; glimpse()\n#&gt; FileSystemDataset with 1 csv file\n#&gt; 41,389,465 rows x 12 columns\n#&gt; $ UsageClass      &lt;string&gt; \"Physical\", \"Physical\", \"Digital\", \"Physical\", \"Ph…\n#&gt; $ CheckoutType    &lt;string&gt; \"Horizon\", \"Horizon\", \"OverDrive\", \"Horizon\", \"Hor…\n#&gt; $ MaterialType    &lt;string&gt; \"BOOK\", \"BOOK\", \"EBOOK\", \"BOOK\", \"SOUNDDISC\", \"BOO…\n#&gt; $ CheckoutYear     &lt;int64&gt; 2016, 2016, 2016, 2016, 2016, 2016, 2016, 2016, 20…\n#&gt; $ CheckoutMonth    &lt;int64&gt; 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,…\n#&gt; $ Checkouts        &lt;int64&gt; 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 2, 3, 2, 1, 3, 2,…\n#&gt; $ Title           &lt;string&gt; \"Super rich : a guide to having it all / Russell S…\n#&gt; $ ISBN            &lt;string&gt; \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n#&gt; $ Creator         &lt;string&gt; \"Simmons, Russell\", \"Barclay, James, 1965-\", \"Tim …\n#&gt; $ Subjects        &lt;string&gt; \"Self realization, Conduct of life, Attitude Psych…\n#&gt; $ Publisher       &lt;string&gt; \"Gotham Books,\", \"Pyr,\", \"Random House, Inc.\", \"Di…\n#&gt; $ PublicationYear &lt;string&gt; \"c2011.\", \"2010.\", \"2015\", \"2005.\", \"c2004.\", \"c20…\n\nWe can start to use this dataset with dplyr verbs, using collect() to force arrow to perform the computation and return some data. For example, this code tells us the total number of checkouts per year:\n\nseattle_csv |&gt; \n  count(CheckoutYear, wt = Checkouts) |&gt; \n  arrange(CheckoutYear) |&gt; \n  collect()\n#&gt; # A tibble: 18 × 2\n#&gt;   CheckoutYear       n\n#&gt;          &lt;int&gt;   &lt;int&gt;\n#&gt; 1         2005 3798685\n#&gt; 2         2006 6599318\n#&gt; 3         2007 7126627\n#&gt; 4         2008 8438486\n#&gt; 5         2009 9135167\n#&gt; 6         2010 8608966\n#&gt; # … with 12 more rows\n\nThanks to arrow, this code will work regardless of how large the underlying dataset is. But it’s currently rather slow: on Hadley’s computer, it took ~10s to run. That’s not terrible given how much data we have, but we can make it much faster by switching to a better format."
  },
  {
    "objectID": "arrow.html#the-parquet-format",
    "href": "arrow.html#the-parquet-format",
    "title": "23  Arrow",
    "section": "\n23.4 The parquet format",
    "text": "23.4 The parquet format\nTo make this data easier to work with, lets switch to the parquet file format and split it up into multiple files. The following sections will first introduce you to parquet and partitioning, and then apply what we learned to the Seattle library data.\n\n23.4.1 Advantages of parquet\nLike CSV, parquet is used for rectangular data, but instead of being a text format that you can read with any file editor, it’s a custom binary format designed specifically for the needs of big data. This means that:\n\nParquet files are usually smaller the equivalent CSV file. Parquet relies on efficient encodings to keep file size down, and supports file compression. This helps make parquet files fast because there’s less data to move from disk to memory.\nParquet files have a rich type system. As we talked about in Sección 8.3, a CSV file does not provide any information about column types. For example, a CSV reader has to guess whether \"08-10-2022\" should be parsed as a string or a date. In contrast, parquet files store data in a way that records the type along with the data.\nParquet files are “column-oriented”. This means that they’re organised column-by-column, much like R’s data frame. This typically leads to better performance for data analysis tasks compared to CSV files, which are organised row-by-row.\nParquet files are “chunked”, which makes it possible to work on different parts of the file at the same time, and, if you’re lucky, to skip some chunks all together.\n\n23.4.2 Partitioning\nAs datasets get larger and larger, storing all the data in a single file gets increasingly painful and it’s often useful to split large datasets across many files. When this structuring is done intelligently, this strategy can lead to significant improvements in performance because many analyses will only require a subset of the files.\nThere are no hard and fast rules about how to partition your data set: the results will depend on your data, access patterns, and the systems that read the data. You’re likely to need to do some experimentation before you find the ideal partitioning for your situation. As a rough guide, arrow suggests that you avoid files smaller than 20MB and larger than 2GB and avoid partitions that produce more than 10,000 files. You should also try to partition by variables that you filter by; as you’ll see shortly, that allows arrow to skip a lot of work by reading only the relevant files.\n\n23.4.3 Rewriting the Seattle library data\nLet’s apply these ideas to the Seattle library data to see how they play out in practice. We’re going to partition by CheckoutYear, since it’s likely some analyses will only want to look at recent data and partitioning by year yields 18 chunks of a reasonable size.\nTo rewrite the data we define the partition using dplyr::group_by() and then save the partitions to a directory with arrow::write_dataset(). write_dataset() has two important arguments: a directory where we’ll create the files and the format we’ll use.\n\npq_path &lt;- \"data/seattle-library-checkouts\"\n\n\nseattle_csv |&gt;\n  group_by(CheckoutYear) |&gt;\n  write_dataset(path = pq_path, format = \"parquet\")\n\nThis takes about a minute to run; as we’ll see shortly this is an initial investment that pays off by making future operations much much faster.\nLet’s take a look at what we just produced:\n\ntibble(\n  files = list.files(pq_path, recursive = TRUE),\n  size_MB = file.size(file.path(pq_path, files)) / 1024^2\n)\n#&gt; # A tibble: 18 × 2\n#&gt;   files                            size_MB\n#&gt;   &lt;chr&gt;                              &lt;dbl&gt;\n#&gt; 1 CheckoutYear=2005/part-0.parquet    109.\n#&gt; 2 CheckoutYear=2006/part-0.parquet    164.\n#&gt; 3 CheckoutYear=2007/part-0.parquet    178.\n#&gt; 4 CheckoutYear=2008/part-0.parquet    195.\n#&gt; 5 CheckoutYear=2009/part-0.parquet    214.\n#&gt; 6 CheckoutYear=2010/part-0.parquet    222.\n#&gt; # … with 12 more rows\n\nOur single 9GB CSV file has been rewritten into 18 parquet files. The file names use a “self-describing” convention used by the Apache Hive project. Hive-style partitions name folders with a “key=value” convention, so as you might guess, the CheckoutYear=2005 directory contains all the data where CheckoutYear is 2005. Each file is between 100 and 300 MB and the total size is now around 4 GB, a little over half the size of the original CSV file. This is as we expect since parquet is a much more efficient format."
  },
  {
    "objectID": "arrow.html#using-dplyr-with-arrow",
    "href": "arrow.html#using-dplyr-with-arrow",
    "title": "23  Arrow",
    "section": "\n23.5 Using dplyr with arrow",
    "text": "23.5 Using dplyr with arrow\nNow we’ve created these parquet files, we’ll need to read them in again. We use open_dataset() again, but this time we give it a directory:\n\nseattle_pq &lt;- open_dataset(pq_path)\n\nNow we can write our dplyr pipeline. For example, we could count the total number of books checked out in each month for the last five years:\n\nquery &lt;- seattle_pq |&gt; \n  filter(CheckoutYear &gt;= 2018, MaterialType == \"BOOK\") |&gt;\n  group_by(CheckoutYear, CheckoutMonth) |&gt;\n  summarise(TotalCheckouts = sum(Checkouts)) |&gt;\n  arrange(CheckoutYear, CheckoutMonth)\n\nWriting dplyr code for arrow data is conceptually similar to dbplyr, Capítulo 22: you write dplyr code, which is automatically transformed into a query that the Apache Arrow C++ library understands, which is then executed when you call collect(). If we print out the query object we can see a little information about what we expect Arrow to return when the execution takes place:\n\nquery\n#&gt; FileSystemDataset (query)\n#&gt; CheckoutYear: int32\n#&gt; CheckoutMonth: int64\n#&gt; TotalCheckouts: int64\n#&gt; \n#&gt; * Grouped by CheckoutYear\n#&gt; * Sorted by CheckoutYear [asc], CheckoutMonth [asc]\n#&gt; See $.data for the source Arrow object\n\nAnd we can get the results by calling collect():\n\nquery |&gt; collect()\n#&gt; # A tibble: 58 × 3\n#&gt; # Groups:   CheckoutYear [5]\n#&gt;   CheckoutYear CheckoutMonth TotalCheckouts\n#&gt;          &lt;int&gt;         &lt;int&gt;          &lt;int&gt;\n#&gt; 1         2018             1         355101\n#&gt; 2         2018             2         309813\n#&gt; 3         2018             3         344487\n#&gt; 4         2018             4         330988\n#&gt; 5         2018             5         318049\n#&gt; 6         2018             6         341825\n#&gt; # … with 52 more rows\n\nLike dbplyr, arrow only understands some R expressions, so you may not be able to write exactly the same code you usually would. However, the list of operations and functions supported is fairly extensive and continues to grow; find a complete list of currently supported functions in ?acero.\n\n23.5.1 Performance\nLet’s take a quick look at the performance impact of switching from CSV to parquet. First, let’s time how long it takes to calculate the number of books checked out in each month of 2021, when the data is stored as a single large csv:\n\nseattle_csv |&gt; \n  filter(CheckoutYear == 2021, MaterialType == \"BOOK\") |&gt;\n  group_by(CheckoutMonth) |&gt;\n  summarise(TotalCheckouts = sum(Checkouts)) |&gt;\n  arrange(desc(CheckoutMonth)) |&gt;\n  collect() |&gt; \n  system.time()\n#&gt;    user  system elapsed \n#&gt;  11.980   0.924  11.350\n\nNow let’s use our new version of the data set in which the Seattle library checkout data has been partitioned into 18 smaller parquet files:\n\nseattle_pq |&gt; \n  filter(CheckoutYear == 2021, MaterialType == \"BOOK\") |&gt;\n  group_by(CheckoutMonth) |&gt;\n  summarise(TotalCheckouts = sum(Checkouts)) |&gt;\n  arrange(desc(CheckoutMonth)) |&gt;\n  collect() |&gt; \n  system.time()\n#&gt;    user  system elapsed \n#&gt;   0.273   0.045   0.055\n\nThe ~100x speedup in performance is attributable to two factors: the multi-file partitioning, and the format of individual files:\n\nPartitioning improves performance because this query uses CheckoutYear == 2021 to filter the data, and arrow is smart enough to recognize that it only needs to read 1 of the 18 parquet files.\nThe parquet format improves performance by storing data in a binary format that can be read more directly into memory. The column-wise format and rich metadata means that arrow only needs to read the four columns actually used in the query (CheckoutYear, MaterialType, CheckoutMonth, and Checkouts).\n\nThis massive difference in performance is why it pays off to convert large CSVs to parquet!\n\n23.5.2 Using dbplyr with arrow\nThere’s one last advantage of parquet and arrow — it’s very easy to turn an arrow dataset into a duckdb datasource by calling arrow::to_duckdb():\n\nseattle_pq |&gt; \n  to_duckdb() |&gt;\n  filter(CheckoutYear &gt;= 2018, MaterialType == \"BOOK\") |&gt;\n  group_by(CheckoutYear) |&gt;\n  summarise(TotalCheckouts = sum(Checkouts)) |&gt;\n  arrange(desc(CheckoutYear)) |&gt;\n  collect()\n#&gt; Warning: Missing values are always removed in SQL aggregation functions.\n#&gt; Use `na.rm = TRUE` to silence this warning\n#&gt; This warning is displayed once every 8 hours.\n#&gt; # A tibble: 5 × 2\n#&gt;   CheckoutYear TotalCheckouts\n#&gt;          &lt;int&gt;          &lt;dbl&gt;\n#&gt; 1         2022        2431502\n#&gt; 2         2021        2266438\n#&gt; 3         2020        1241999\n#&gt; 4         2019        3931688\n#&gt; 5         2018        3987569\n\nThe neat thing about to_duckdb() is that the transfer doesn’t involve any memory copying, and speaks to the goals of the arrow ecosystem: enabling seamless transitions from one computing environment to another."
  },
  {
    "objectID": "arrow.html#summary",
    "href": "arrow.html#summary",
    "title": "23  Arrow",
    "section": "\n23.6 Summary",
    "text": "23.6 Summary\nIn this chapter, you’ve been given a taste of the arrow package, which provides a dplyr backend for working with large on-disk datasets. It can work with CSV files, its much much faster if you convert your data to parquet. Parquet is a binary data format that’s designed specifically for data analysis on modern computers. Far fewer tools can work with parquet files compared to CSV, but it’s partitioned, compressed, and columnar structure makes it much more efficient to analyze.\nNext up you’ll learn about your first non-rectangular data source, which you’ll handle using tools provided by the tidyr package. We’ll focus on data that comes from JSON files, but the general principles apply to tree-like data regardless of its source."
  },
  {
    "objectID": "rectangling.html#introducción",
    "href": "rectangling.html#introducción",
    "title": "24  Datos jerárquicos",
    "section": "\n24.1 Introducción",
    "text": "24.1 Introducción\nEn este capítulo, aprenderá el arte de rectangular datos, tomando datos que son fundamentalmente jerárquicos, o en forma de árbol, y convirtiéndolos en un marco de datos rectangular formado por filas y columnas. Esto es importante porque los datos jerárquicos son sorprendentemente comunes, especialmente cuando se trabaja con datos que provienen de la web.\nPara obtener información sobre el rectángulo, primero deberá aprender sobre las listas, la estructura de datos que hace posible los datos jerárquicos. Luego aprenderá sobre dos funciones cruciales de tidyr: tidyr::unnest_longer() y tidyr::unnest_wider(). Luego le mostraremos algunos casos de estudio, aplicando estas funciones simples una y otra vez para resolver problemas reales. Terminaremos hablando de JSON, la fuente más frecuente de conjuntos de datos jerárquicos y un formato común para el intercambio de datos en la web.\n\n24.1.1 Requisitos previos\nEn este capítulo, usaremos muchas funciones de tidyr, un miembro central de tidyverse. También usaremos repurrrsive para proporcionar algunos conjuntos de datos interesantes para la práctica de rectángulos, y terminaremos usando jsonlite para leer archivos JSON en listas R.\n\nlibrary(tidyverse)\n#> Warning: package 'tibble' was built under R version 4.2.3\n#> Warning: package 'readr' was built under R version 4.2.3\n#> Warning: package 'dplyr' was built under R version 4.2.3\nlibrary(repurrrsive)\nlibrary(jsonlite)"
  },
  {
    "objectID": "rectangling.html#listas",
    "href": "rectangling.html#listas",
    "title": "24  Datos jerárquicos",
    "section": "\n24.2 Listas",
    "text": "24.2 Listas\nHasta ahora, ha trabajado con marcos de datos que contienen vectores simples como enteros, números, caracteres, fechas y horas y factores. Estos vectores son simples porque son homogéneos: cada elemento es del mismo tipo de datos. Si quieres almacenar elementos de diferentes tipos en el mismo vector, necesitarás una lista, que creas con list():\n\nx1 <- list(1:4, \"a\", TRUE)\nx1\n#> [[1]]\n#> [1] 1 2 3 4\n#> \n#> [[2]]\n#> [1] \"a\"\n#> \n#> [[3]]\n#> [1] TRUE\n\nA menudo es conveniente nombrar los componentes, o hijos, de una lista, lo que puede hacer de la misma manera que se nombran las columnas de un tibble:\n\nx2 <- list(a = 1:2, b = 1:3, c = 1:4)\nx2\n#> $a\n#> [1] 1 2\n#> \n#> $b\n#> [1] 1 2 3\n#> \n#> $c\n#> [1] 1 2 3 4\n\nIncluso para estas listas tan simples, la impresión ocupa bastante espacio. Una alternativa útil es str(), que genera una visualización compacta de la estructura, restando énfasis al contenido:\n\nstr(x1)\n#> List of 3\n#>  $ : int [1:4] 1 2 3 4\n#>  $ : chr \"a\"\n#>  $ : logi TRUE\nstr(x2)\n#> List of 3\n#>  $ a: int [1:2] 1 2\n#>  $ b: int [1:3] 1 2 3\n#>  $ c: int [1:4] 1 2 3 4\n\nComo puede ver, str() muestra cada hijo de la lista en su propia línea. Muestra el nombre, si está presente, luego una abreviatura del tipo, luego los primeros valores.\n\n24.2.1 Jerarquía\nLas listas pueden contener cualquier tipo de objeto, incluidas otras listas. Esto los hace adecuados para representar estructuras jerárquicas (en forma de árbol):\n\nx3 <- list(list(1, 2), list(3, 4))\nstr(x3)\n#> List of 2\n#>  $ :List of 2\n#>   ..$ : num 1\n#>   ..$ : num 2\n#>  $ :List of 2\n#>   ..$ : num 3\n#>   ..$ : num 4\n\nEsto es notablemente diferente a c(), que genera un vector plano:\n\nc(c(1, 2), c(3, 4))\n#> [1] 1 2 3 4\n\nx4 <- c(list(1, 2), list(3, 4))\nstr(x4)\n#> List of 4\n#>  $ : num 1\n#>  $ : num 2\n#>  $ : num 3\n#>  $ : num 4\n\nA medida que las listas se vuelven más complejas, str() se vuelve más útil, ya que le permite ver la jerarquía de un vistazo:\n\nx5 <- list(1, list(2, list(3, list(4, list(5)))))\nstr(x5)\n#> List of 2\n#>  $ : num 1\n#>  $ :List of 2\n#>   ..$ : num 2\n#>   ..$ :List of 2\n#>   .. ..$ : num 3\n#>   .. ..$ :List of 2\n#>   .. .. ..$ : num 4\n#>   .. .. ..$ :List of 1\n#>   .. .. .. ..$ : num 5\n\nA medida que las listas se vuelven aún más grandes y complejas, str() eventualmente comienza a fallar, y deberá cambiar a View()1. Figure 24.1 muestra el resultado de llamar a View(x4). El visor comienza mostrando solo el nivel superior de la lista, pero puede expandir interactivamente cualquiera de los componentes para ver más, como en Figure 24.2. RStudio también le mostrará el código que necesita para acceder a ese elemento, como en Figure 24.3. Volveremos sobre cómo funciona este código en Section 28.3.\n\n\n\n\nFigure 24.1: La vista de RStudio le permite explorar de forma interactiva una lista compleja. El visor se abre mostrando solo el nivel superior de la lista.\n\n\n\n\n\n\n\n\nFigure 24.2: Al hacer clic en el triángulo que mira hacia la derecha, se expande ese componente de la lista para que también puedas ver sus hijos.\n\n\n\n\n\n\n\n\nFigure 24.3: Puede repetir esta operación tantas veces como sea necesario para llegar a los datos que le interesan. Tenga en cuenta la esquina inferior izquierda: si hace clic en un elemento de la lista, RStudio le dará el código de subconjunto necesario para acceder a él, en este caso x4[[2]][[2]][[2]].\n\n\n\n\n\n24.2.2 Lista-columnas\nLas listas también pueden vivir dentro de un tibble, donde las llamamos columnas de lista. Las columnas de lista son útiles porque le permiten colocar objetos en un tibble que normalmente no pertenecerían allí. En particular, las columnas de lista se usan mucho en el ecosistema tidymodels, porque le permiten almacenar cosas como resultados de modelos o remuestreos en un marco de datos.\nAquí hay un ejemplo simple de una columna de lista:\n\ndf <- tibble(\n  x = 1:2, \n  y = c(\"a\", \"b\"),\n  z = list(list(1, 2), list(3, 4, 5))\n)\ndf\n#> # A tibble: 2 × 3\n#>       x y     z         \n#>   <int> <chr> <list>    \n#> 1     1 a     <list [2]>\n#> 2     2 b     <list [3]>\n\nNo hay nada especial acerca de las listas en un tibble; se comportan como cualquier otra columna:\n\ndf |> \n  filter(x == 1)\n#> # A tibble: 1 × 3\n#>       x y     z         \n#>   <int> <chr> <list>    \n#> 1     1 a     <list [2]>\n\nComputar con columnas de lista es más difícil, pero eso se debe a que computar con listas es más difícil en general; volveremos a eso en Chapter 27. En este capítulo, nos centraremos en convertir columnas de lista en variables regulares para que pueda usar sus herramientas existentes en ellas.\nEl método de impresión predeterminado solo muestra un resumen aproximado del contenido. La columna de la lista podría ser arbitrariamente compleja, por lo que no hay una buena manera de imprimirla. Si desea verlo, deberá extraer solo una columna de la lista y aplicar una de las técnicas que aprendió anteriormente, como df |> pull(z) |> str() o df |> pull(z) |> Ver().\n\n\n\n\n\n\nR base\n\n\n\nEs posible poner una lista en una columna de un data.frame, pero es mucho más complicado porque data.frame() trata una lista como una lista de columnas:\n\ndata.frame(x = list(1:3, 3:5))\n#>   x.1.3 x.3.5\n#> 1     1     3\n#> 2     2     4\n#> 3     3     5\n\nPuede obligar a data.frame() a tratar una lista como una lista de filas envolviéndola en la lista I(), pero el resultado no se imprime particularmente bien:\n\ndata.frame(\n  x = I(list(1:2, 3:5)), \n  y = c(\"1, 2\", \"3, 4, 5\")\n)\n#>         x       y\n#> 1    1, 2    1, 2\n#> 2 3, 4, 5 3, 4, 5\n\nEs más fácil usar columnas de lista con tibbles porque tibble() trata las listas como vectores y el método de impresión ha sido diseñado teniendo en cuenta las listas."
  },
  {
    "objectID": "rectangling.html#anidando",
    "href": "rectangling.html#anidando",
    "title": "24  Datos jerárquicos",
    "section": "\n24.3 Anidando",
    "text": "24.3 Anidando\nAhora que ha aprendido los conceptos básicos de las listas y las columnas de lista, exploremos cómo puede volver a convertirlas en filas y columnas regulares. Aquí usaremos datos de muestra muy simples para que puedas tener una idea básica; en la siguiente sección cambiaremos a datos reales.\nLas columnas de lista tienden a presentarse en dos formas básicas: con nombre y sin nombre. Cuando los niños tienen nombre, tienden a tener los mismos nombres en todas las filas. Por ejemplo, en df1, cada elemento de la columna de lista y tiene dos elementos llamados a y b. Las columnas de lista con nombre se separan naturalmente en columnas: cada elemento con nombre se convierte en una nueva columna con nombre.\n\ndf1 <- tribble(\n  ~x, ~y,\n  1, list(a = 11, b = 12),\n  2, list(a = 21, b = 22),\n  3, list(a = 31, b = 32),\n)\n\nCuando los elementos secundarios no tienen nombre, la cantidad de elementos tiende a variar de una fila a otra. Por ejemplo, en df2, los elementos de la columna de lista y no tienen nombre y varían en longitud de uno a tres. Las columnas de lista sin nombre se anulan naturalmente en filas: obtendrá una fila para cada niño.\n\n\ndf2 <- tribble(\n  ~x, ~y,\n  1, list(11, 12, 13),\n  2, list(21),\n  3, list(31, 32),\n)\n\ntidyr proporciona dos funciones para estos dos casos: unnest_wider() y unnest_longer(). Las siguientes secciones explican cómo funcionan.\n\n24.3.1 unnest_wider()\n\nCuando cada fila tiene la misma cantidad de elementos con los mismos nombres, como df1, es natural poner cada componente en su propia columna con unnest_wider():\n\ndf1 |> \n  unnest_wider(y)\n#> # A tibble: 3 × 3\n#>       x     a     b\n#>   <dbl> <dbl> <dbl>\n#> 1     1    11    12\n#> 2     2    21    22\n#> 3     3    31    32\n\nPor defecto, los nombres de las nuevas columnas provienen exclusivamente de los nombres de los elementos de la lista, pero puedes usar el argumento names_sep para solicitar que combinen el nombre de la columna y el nombre del elemento. Esto es útil para eliminar la ambigüedad de los nombres repetidos.\n\ndf1 |> \n  unnest_wider(y, names_sep = \"_\")\n#> # A tibble: 3 × 3\n#>       x   y_a   y_b\n#>   <dbl> <dbl> <dbl>\n#> 1     1    11    12\n#> 2     2    21    22\n#> 3     3    31    32\n\n\n24.3.2 unnest_longer()\n\nCuando cada fila contiene una lista sin nombre, lo más natural es poner cada elemento en su propia fila con unnest_longer():\n\ndf2 |> \n  unnest_longer(y)\n#> # A tibble: 6 × 2\n#>       x     y\n#>   <dbl> <dbl>\n#> 1     1    11\n#> 2     1    12\n#> 3     1    13\n#> 4     2    21\n#> 5     3    31\n#> 6     3    32\n\nObserve cómo x se duplica para cada elemento dentro de y: obtenemos una fila de salida para cada elemento dentro de la columna de lista. Pero, ¿qué sucede si uno de los elementos está vacío, como en el siguiente ejemplo?\n\ndf6 <- tribble(\n  ~x, ~y,\n  \"a\", list(1, 2),\n  \"b\", list(3),\n  \"c\", list()\n)\ndf6 |> unnest_longer(y)\n#> # A tibble: 3 × 2\n#>   x         y\n#>   <chr> <dbl>\n#> 1 a         1\n#> 2 a         2\n#> 3 b         3\n\nObtenemos cero filas en la salida, por lo que la fila desaparece efectivamente. Si desea conservar esa fila, agregue NA en y configurando keep_empty = TRUE.\n\n24.3.3 Tipos inconsistentes\n¿Qué sucede si anulas una columna de lista que contiene diferentes tipos de vectores? Por ejemplo, tome el siguiente conjunto de datos donde la columna de lista y contiene dos números, un factor y un lógico, que normalmente no se pueden mezclar en una sola columna.\n\ndf4 <- tribble(\n  ~x, ~y,\n  \"a\", list(1),\n  \"b\", list(\"a\", TRUE, 5)\n)\n\nunnest_longer() siempre mantiene el conjunto de columnas sin cambios, mientras cambia el número de filas. ¿Qué es lo que ocurre? ¿Cómo unnest_longer() produce cinco filas mientras mantiene todo en y?\n\ndf4 |> \n  unnest_longer(y)\n#> # A tibble: 4 × 2\n#>   x     y        \n#>   <chr> <list>   \n#> 1 a     <dbl [1]>\n#> 2 b     <chr [1]>\n#> 3 b     <lgl [1]>\n#> 4 b     <dbl [1]>\n\nComo puede ver, la salida contiene una columna de lista, pero cada elemento de la columna de lista contiene un solo elemento. Debido a que unnest_longer() no puede encontrar un tipo común de vector, mantiene los tipos originales en una columna de lista. Quizás se pregunte si esto rompe el mandamiento de que todos los elementos de una columna deben ser del mismo tipo. No lo hace: cada elemento es una lista, aunque los contenidos sean de diferentes tipos.\nTratar con tipos inconsistentes es un desafío y los detalles dependen de la naturaleza precisa del problema y sus objetivos, pero lo más probable es que necesite herramientas de Chapter 27.\n\n24.3.4 Otras funciones\ntidyr tiene algunas otras funciones útiles de rectángulos que no vamos a cubrir en este libro:\n\n\nunnest_auto() elige automáticamente entre unnest_longer() y unnest_wider() según la estructura de la columna de la lista. Es excelente para una exploración rápida, pero en última instancia es una mala idea porque no lo obliga a comprender cómo están estructurados sus datos y hace que su código sea más difícil de entender.\n\nunnest() expande filas y columnas. Es útil cuando tiene una columna de lista que contiene una estructura 2d como un marco de datos, que no ve en este libro, pero que puede encontrar si usa el ecosistema tidymodels.\n\nEs bueno conocer estas funciones, ya que puede encontrarlas al leer el código de otras personas o al abordar desafíos de rectángulos más raros.\n\n24.3.5 Ejercicios\n\n¿Qué sucede cuando usa unnest_wider() con columnas de lista sin nombre como df2? ¿Qué argumento es ahora necesario? ¿Qué sucede con los valores perdidos?\n¿Qué sucede cuando usa unnest_longer() con columnas de lista con nombre como df1? ¿Qué información adicional obtienes en la salida? ¿Cómo puedes suprimir ese detalle extra?\n\nDe vez en cuando se encuentra con marcos de datos con varias columnas de lista con valores alineados. Por ejemplo, en el siguiente marco de datos, los valores de y y z están alineados (es decir, y y z siempre tendrán la misma longitud dentro de una fila, y el primer valor de y corresponde a el primer valor de z). ¿Qué sucede si aplica dos llamadas unnest_longer() a este marco de datos? ¿Cómo puedes preservar la relación entre x e y? (Sugerencia: lea atentamente la documentación).\n\ndf4 <- tribble(\n  ~x, ~y, ~z,\n  \"a\", list(\"y-a-1\", \"y-a-2\"), list(\"z-a-1\", \"z-a-2\"),\n  \"b\", list(\"y-b-1\", \"y-b-2\", \"y-b-3\"), list(\"z-b-1\", \"z-b-2\", \"z-b-3\")\n)"
  },
  {
    "objectID": "rectangling.html#case-studies",
    "href": "rectangling.html#case-studies",
    "title": "24  Datos jerárquicos",
    "section": "\n24.4 Case studies",
    "text": "24.4 Case studies\nThe main difference between the simple examples we used above and real data is that real data typically contains multiple levels of nesting that require multiple calls to unnest_longer() and/or unnest_wider(). To show that in action, this section works through three real rectangling challenges using datasets from the repurrrsive package.\n\n24.4.1 Very wide data\nWe’ll start with gh_repos. This is a list that contains data about a collection of GitHub repositories retrieved using the GitHub API. It’s a very deeply nested list so it’s difficult to show the structure in this book; we recommend exploring a little on your own with View(gh_repos) before we continue.\ngh_repos is a list, but our tools work with list-columns, so we’ll begin by putting it into a tibble. We call this column json for reasons we’ll get to later.\n\nrepos <- tibble(json = gh_repos)\nrepos\n#> # A tibble: 6 × 1\n#>   json       \n#>   <list>     \n#> 1 <list [30]>\n#> 2 <list [30]>\n#> 3 <list [30]>\n#> 4 <list [26]>\n#> 5 <list [30]>\n#> 6 <list [30]>\n\nThis tibble contains 6 rows, one row for each child of gh_repos. Each row contains a unnamed list with either 26 or 30 rows. Since these are unnamed, we’ll start with unnest_longer() to put each child in its own row:\n\nrepos |> \n  unnest_longer(json)\n#> # A tibble: 176 × 1\n#>   json             \n#>   <list>           \n#> 1 <named list [68]>\n#> 2 <named list [68]>\n#> 3 <named list [68]>\n#> 4 <named list [68]>\n#> 5 <named list [68]>\n#> 6 <named list [68]>\n#> # ℹ 170 more rows\n\nAt first glance, it might seem like we haven’t improved the situation: while we have more rows (176 instead of 6) each element of json is still a list. However, there’s an important difference: now each element is a named list so we can use unnest_wider() to put each element into its own column:\n\nrepos |> \n  unnest_longer(json) |> \n  unnest_wider(json) \n#> # A tibble: 176 × 68\n#>         id name     full_name owner        private html_url description fork \n#>      <int> <chr>    <chr>     <list>       <lgl>   <chr>    <chr>       <lgl>\n#> 1 61160198 after    gaborcsa… <named list> FALSE   https:/… Run Code i… FALSE\n#> 2 40500181 argufy   gaborcsa… <named list> FALSE   https:/… Declarativ… FALSE\n#> 3 36442442 ask      gaborcsa… <named list> FALSE   https:/… Friendly C… FALSE\n#> 4 34924886 baseimp… gaborcsa… <named list> FALSE   https:/… Do we get … FALSE\n#> 5 61620661 citest   gaborcsa… <named list> FALSE   https:/… Test R pac… TRUE \n#> 6 33907457 clisymb… gaborcsa… <named list> FALSE   https:/… Unicode sy… FALSE\n#> # ℹ 170 more rows\n#> # ℹ 60 more variables: url <chr>, forks_url <chr>, keys_url <chr>,\n#> #   collaborators_url <chr>, teams_url <chr>, hooks_url <chr>,\n#> #   issue_events_url <chr>, events_url <chr>, assignees_url <chr>,\n#> #   branches_url <chr>, tags_url <chr>, blobs_url <chr>, git_tags_url <chr>,\n#> #   git_refs_url <chr>, trees_url <chr>, statuses_url <chr>,\n#> #   languages_url <chr>, stargazers_url <chr>, contributors_url <chr>, …\n\nThis has worked but the result is a little overwhelming: there are so many columns that tibble doesn’t even print all of them! We can see them all with names(); and here we look at the first 10:\n\nrepos |> \n  unnest_longer(json) |> \n  unnest_wider(json) |> \n  names() |> \n  head(10)\n#>  [1] \"id\"          \"name\"        \"full_name\"   \"owner\"       \"private\"    \n#>  [6] \"html_url\"    \"description\" \"fork\"        \"url\"         \"forks_url\"\n\nLet’s pull out a few that look interesting:\n\nrepos |> \n  unnest_longer(json) |> \n  unnest_wider(json) |> \n  select(id, full_name, owner, description)\n#> # A tibble: 176 × 4\n#>         id full_name               owner             description             \n#>      <int> <chr>                   <list>            <chr>                   \n#> 1 61160198 gaborcsardi/after       <named list [17]> Run Code in the Backgro…\n#> 2 40500181 gaborcsardi/argufy      <named list [17]> Declarative function ar…\n#> 3 36442442 gaborcsardi/ask         <named list [17]> Friendly CLI interactio…\n#> 4 34924886 gaborcsardi/baseimports <named list [17]> Do we get warnings for …\n#> 5 61620661 gaborcsardi/citest      <named list [17]> Test R package and repo…\n#> 6 33907457 gaborcsardi/clisymbols  <named list [17]> Unicode symbols for CLI…\n#> # ℹ 170 more rows\n\nYou can use this to work back to understand how gh_repos was structured: each child was a GitHub user containing a list of up to 30 GitHub repositories that they created.\nowner is another list-column, and since it contains a named list, we can use unnest_wider() to get at the values:\n\nrepos |> \n  unnest_longer(json) |> \n  unnest_wider(json) |> \n  select(id, full_name, owner, description) |> \n  unnest_wider(owner)\n#> Error in `unnest_wider()`:\n#> ! Can't duplicate names between the affected columns and the original\n#>   data.\n#> ✖ These names are duplicated:\n#>   ℹ `id`, from `owner`.\n#> ℹ Use `names_sep` to disambiguate using the column name.\n#> ℹ Or use `names_repair` to specify a repair strategy.\n\nUh oh, this list column also contains an id column and we can’t have two id columns in the same data frame. As suggested, lets use names_sep to resolve the problem:\n\nrepos |> \n  unnest_longer(json) |> \n  unnest_wider(json) |> \n  select(id, full_name, owner, description) |> \n  unnest_wider(owner, names_sep = \"_\")\n#> # A tibble: 176 × 20\n#>         id full_name  owner_login owner_id owner_avatar_url owner_gravatar_id\n#>      <int> <chr>      <chr>          <int> <chr>            <chr>            \n#> 1 61160198 gaborcsar… gaborcsardi   660288 https://avatars… \"\"               \n#> 2 40500181 gaborcsar… gaborcsardi   660288 https://avatars… \"\"               \n#> 3 36442442 gaborcsar… gaborcsardi   660288 https://avatars… \"\"               \n#> 4 34924886 gaborcsar… gaborcsardi   660288 https://avatars… \"\"               \n#> 5 61620661 gaborcsar… gaborcsardi   660288 https://avatars… \"\"               \n#> 6 33907457 gaborcsar… gaborcsardi   660288 https://avatars… \"\"               \n#> # ℹ 170 more rows\n#> # ℹ 14 more variables: owner_url <chr>, owner_html_url <chr>,\n#> #   owner_followers_url <chr>, owner_following_url <chr>,\n#> #   owner_gists_url <chr>, owner_starred_url <chr>,\n#> #   owner_subscriptions_url <chr>, owner_organizations_url <chr>,\n#> #   owner_repos_url <chr>, owner_events_url <chr>,\n#> #   owner_received_events_url <chr>, owner_type <chr>, …\n\nThis gives another wide dataset, but you can get the sense that owner appears to contain a lot of additional data about the person who “owns” the repository.\n\n24.4.2 Relational data\nNested data is sometimes used to represent data that we’d usually spread across multiple data frames. For example, take got_chars which contains data about characters that appear in the Game of Thrones books and TV series. Like gh_repos it’s a list, so we start by turning it into a list-column of a tibble:\n\nchars <- tibble(json = got_chars)\nchars\n#> # A tibble: 30 × 1\n#>   json             \n#>   <list>           \n#> 1 <named list [18]>\n#> 2 <named list [18]>\n#> 3 <named list [18]>\n#> 4 <named list [18]>\n#> 5 <named list [18]>\n#> 6 <named list [18]>\n#> # ℹ 24 more rows\n\nThe json column contains named elements, so we’ll start by widening it:\n\nchars |> \n  unnest_wider(json)\n#> # A tibble: 30 × 18\n#>   url         id name  gender culture born  died  alive titles aliases father\n#>   <chr>    <int> <chr> <chr>  <chr>   <chr> <chr> <lgl> <list> <list>  <chr> \n#> 1 https:/…  1022 Theo… Male   \"Ironb… \"In … \"\"    TRUE  <chr>  <chr>   \"\"    \n#> 2 https:/…  1052 Tyri… Male   \"\"      \"In … \"\"    TRUE  <chr>  <chr>   \"\"    \n#> 3 https:/…  1074 Vict… Male   \"Ironb… \"In … \"\"    TRUE  <chr>  <chr>   \"\"    \n#> 4 https:/…  1109 Will  Male   \"\"      \"\"    \"In … FALSE <chr>  <chr>   \"\"    \n#> 5 https:/…  1166 Areo… Male   \"Norvo… \"In … \"\"    TRUE  <chr>  <chr>   \"\"    \n#> 6 https:/…  1267 Chett Male   \"\"      \"At … \"In … FALSE <chr>  <chr>   \"\"    \n#> # ℹ 24 more rows\n#> # ℹ 7 more variables: mother <chr>, spouse <chr>, allegiances <list>,\n#> #   books <list>, povBooks <list>, tvSeries <list>, playedBy <list>\n\nAnd selecting a few columns to make it easier to read:\n\ncharacters <- chars |> \n  unnest_wider(json) |> \n  select(id, name, gender, culture, born, died, alive)\ncharacters\n#> # A tibble: 30 × 7\n#>      id name              gender culture    born                  died  alive\n#>   <int> <chr>             <chr>  <chr>      <chr>                 <chr> <lgl>\n#> 1  1022 Theon Greyjoy     Male   \"Ironborn\" \"In 278 AC or 279 AC… \"\"    TRUE \n#> 2  1052 Tyrion Lannister  Male   \"\"         \"In 273 AC, at Caste… \"\"    TRUE \n#> 3  1074 Victarion Greyjoy Male   \"Ironborn\" \"In 268 AC or before… \"\"    TRUE \n#> 4  1109 Will              Male   \"\"         \"\"                    \"In … FALSE\n#> 5  1166 Areo Hotah        Male   \"Norvoshi\" \"In 257 AC or before… \"\"    TRUE \n#> 6  1267 Chett             Male   \"\"         \"At Hag's Mire\"       \"In … FALSE\n#> # ℹ 24 more rows\n\nThis dataset contains also many list-columns:\n\nchars |> \n  unnest_wider(json) |> \n  select(id, where(is.list))\n#> # A tibble: 30 × 8\n#>      id titles    aliases    allegiances books     povBooks tvSeries playedBy\n#>   <int> <list>    <list>     <list>      <list>    <list>   <list>   <list>  \n#> 1  1022 <chr [2]> <chr [4]>  <chr [1]>   <chr [3]> <chr>    <chr>    <chr>   \n#> 2  1052 <chr [2]> <chr [11]> <chr [1]>   <chr [2]> <chr>    <chr>    <chr>   \n#> 3  1074 <chr [2]> <chr [1]>  <chr [1]>   <chr [3]> <chr>    <chr>    <chr>   \n#> 4  1109 <chr [1]> <chr [1]>  <NULL>      <chr [1]> <chr>    <chr>    <chr>   \n#> 5  1166 <chr [1]> <chr [1]>  <chr [1]>   <chr [3]> <chr>    <chr>    <chr>   \n#> 6  1267 <chr [1]> <chr [1]>  <NULL>      <chr [2]> <chr>    <chr>    <chr>   \n#> # ℹ 24 more rows\n\nLets explore the titles column. It’s an unnamed list-column, so we’ll unnest it into rows:\n\nchars |> \n  unnest_wider(json) |> \n  select(id, titles) |> \n  unnest_longer(titles)\n#> # A tibble: 59 × 2\n#>      id titles                                              \n#>   <int> <chr>                                               \n#> 1  1022 Prince of Winterfell                                \n#> 2  1022 Lord of the Iron Islands (by law of the green lands)\n#> 3  1052 Acting Hand of the King (former)                    \n#> 4  1052 Master of Coin (former)                             \n#> 5  1074 Lord Captain of the Iron Fleet                      \n#> 6  1074 Master of the Iron Victory                          \n#> # ℹ 53 more rows\n\nYou might expect to see this data in its own table because it would be easy to join to the characters data as needed. Let’s do that, which requires little cleaning: removing the rows containing empty strings and renaming titles to title since each row now only contains a single title.\n\ntitles <- chars |> \n  unnest_wider(json) |> \n  select(id, titles) |> \n  unnest_longer(titles) |> \n  filter(titles != \"\") |> \n  rename(title = titles)\ntitles\n#> # A tibble: 52 × 2\n#>      id title                                               \n#>   <int> <chr>                                               \n#> 1  1022 Prince of Winterfell                                \n#> 2  1022 Lord of the Iron Islands (by law of the green lands)\n#> 3  1052 Acting Hand of the King (former)                    \n#> 4  1052 Master of Coin (former)                             \n#> 5  1074 Lord Captain of the Iron Fleet                      \n#> 6  1074 Master of the Iron Victory                          \n#> # ℹ 46 more rows\n\nYou could imagine creating a table like this for each of the list-columns, then using joins to combine them with the character data as you need it.\n\n24.4.3 Deeply nested\nWe’ll finish off these case studies with a list-column that’s very deeply nested and requires repeated rounds of unnest_wider() and unnest_longer() to unravel: gmaps_cities. This is a two column tibble containing five city names and the results of using Google’s geocoding API to determine their location:\n\ngmaps_cities\n#> # A tibble: 5 × 2\n#>   city       json            \n#>   <chr>      <list>          \n#> 1 Houston    <named list [2]>\n#> 2 Washington <named list [2]>\n#> 3 New York   <named list [2]>\n#> 4 Chicago    <named list [2]>\n#> 5 Arlington  <named list [2]>\n\njson is a list-column with internal names, so we start with an unnest_wider():\n\ngmaps_cities |> \n  unnest_wider(json)\n#> # A tibble: 5 × 3\n#>   city       results    status\n#>   <chr>      <list>     <chr> \n#> 1 Houston    <list [1]> OK    \n#> 2 Washington <list [2]> OK    \n#> 3 New York   <list [1]> OK    \n#> 4 Chicago    <list [1]> OK    \n#> 5 Arlington  <list [2]> OK\n\nThis gives us the status and the results. We’ll drop the status column since they’re all OK; in a real analysis, you’d also want to capture all the rows where status != \"OK\" and figure out what went wrong. results is an unnamed list, with either one or two elements (we’ll see why shortly) so we’ll unnest it into rows:\n\ngmaps_cities |> \n  unnest_wider(json) |> \n  select(-status) |> \n  unnest_longer(results)\n#> # A tibble: 7 × 2\n#>   city       results         \n#>   <chr>      <list>          \n#> 1 Houston    <named list [5]>\n#> 2 Washington <named list [5]>\n#> 3 Washington <named list [5]>\n#> 4 New York   <named list [5]>\n#> 5 Chicago    <named list [5]>\n#> 6 Arlington  <named list [5]>\n#> # ℹ 1 more row\n\nNow results is a named list, so we’ll use unnest_wider():\n\nlocations <- gmaps_cities |> \n  unnest_wider(json) |> \n  select(-status) |> \n  unnest_longer(results) |> \n  unnest_wider(results)\nlocations\n#> # A tibble: 7 × 6\n#>   city      address_components formatted_address geometry     place_id types \n#>   <chr>     <list>             <chr>             <list>       <chr>    <list>\n#> 1 Houston   <list [4]>         Houston, TX, USA  <named list> ChIJAYW… <list>\n#> 2 Washingt… <list [2]>         Washington, USA   <named list> ChIJ-bD… <list>\n#> 3 Washingt… <list [4]>         Washington, DC, … <named list> ChIJW-T… <list>\n#> 4 New York  <list [3]>         New York, NY, USA <named list> ChIJOwg… <list>\n#> 5 Chicago   <list [4]>         Chicago, IL, USA  <named list> ChIJ7cv… <list>\n#> 6 Arlington <list [4]>         Arlington, TX, U… <named list> ChIJ05g… <list>\n#> # ℹ 1 more row\n\nNow we can see why two cities got two results: Washington matched both Washington state and Washington, DC, and Arlington matched Arlington, Virginia and Arlington, Texas.\nThere are few different places we could go from here. We might want to determine the exact location of the match, which is stored in the geometry list-column:\n\nlocations |> \n  select(city, formatted_address, geometry) |> \n  unnest_wider(geometry)\n#> # A tibble: 7 × 6\n#>   city       formatted_address   bounds           location     location_type\n#>   <chr>      <chr>               <list>           <list>       <chr>        \n#> 1 Houston    Houston, TX, USA    <named list [2]> <named list> APPROXIMATE  \n#> 2 Washington Washington, USA     <named list [2]> <named list> APPROXIMATE  \n#> 3 Washington Washington, DC, USA <named list [2]> <named list> APPROXIMATE  \n#> 4 New York   New York, NY, USA   <named list [2]> <named list> APPROXIMATE  \n#> 5 Chicago    Chicago, IL, USA    <named list [2]> <named list> APPROXIMATE  \n#> 6 Arlington  Arlington, TX, USA  <named list [2]> <named list> APPROXIMATE  \n#> # ℹ 1 more row\n#> # ℹ 1 more variable: viewport <list>\n\nThat gives us new bounds (a rectangular region) and location (a point). We can unnest location to see the latitude (lat) and longitude (lng):\n\nlocations |> \n  select(city, formatted_address, geometry) |> \n  unnest_wider(geometry) |> \n  unnest_wider(location)\n#> # A tibble: 7 × 7\n#>   city       formatted_address   bounds             lat    lng location_type\n#>   <chr>      <chr>               <list>           <dbl>  <dbl> <chr>        \n#> 1 Houston    Houston, TX, USA    <named list [2]>  29.8  -95.4 APPROXIMATE  \n#> 2 Washington Washington, USA     <named list [2]>  47.8 -121.  APPROXIMATE  \n#> 3 Washington Washington, DC, USA <named list [2]>  38.9  -77.0 APPROXIMATE  \n#> 4 New York   New York, NY, USA   <named list [2]>  40.7  -74.0 APPROXIMATE  \n#> 5 Chicago    Chicago, IL, USA    <named list [2]>  41.9  -87.6 APPROXIMATE  \n#> 6 Arlington  Arlington, TX, USA  <named list [2]>  32.7  -97.1 APPROXIMATE  \n#> # ℹ 1 more row\n#> # ℹ 1 more variable: viewport <list>\n\nExtracting the bounds requires a few more steps:\n\nlocations |> \n  select(city, formatted_address, geometry) |> \n  unnest_wider(geometry) |> \n  # focus on the variables of interest\n  select(!location:viewport) |>\n  unnest_wider(bounds)\n#> # A tibble: 7 × 4\n#>   city       formatted_address   northeast        southwest       \n#>   <chr>      <chr>               <list>           <list>          \n#> 1 Houston    Houston, TX, USA    <named list [2]> <named list [2]>\n#> 2 Washington Washington, USA     <named list [2]> <named list [2]>\n#> 3 Washington Washington, DC, USA <named list [2]> <named list [2]>\n#> 4 New York   New York, NY, USA   <named list [2]> <named list [2]>\n#> 5 Chicago    Chicago, IL, USA    <named list [2]> <named list [2]>\n#> 6 Arlington  Arlington, TX, USA  <named list [2]> <named list [2]>\n#> # ℹ 1 more row\n\nWe then rename southwest and northeast (the corners of the rectangle) so we can use names_sep to create short but evocative names:\n\nlocations |> \n  select(city, formatted_address, geometry) |> \n  unnest_wider(geometry) |> \n  select(!location:viewport) |>\n  unnest_wider(bounds) |> \n  rename(ne = northeast, sw = southwest) |> \n  unnest_wider(c(ne, sw), names_sep = \"_\") \n#> # A tibble: 7 × 6\n#>   city       formatted_address   ne_lat ne_lng sw_lat sw_lng\n#>   <chr>      <chr>                <dbl>  <dbl>  <dbl>  <dbl>\n#> 1 Houston    Houston, TX, USA      30.1  -95.0   29.5  -95.8\n#> 2 Washington Washington, USA       49.0 -117.    45.5 -125. \n#> 3 Washington Washington, DC, USA   39.0  -76.9   38.8  -77.1\n#> 4 New York   New York, NY, USA     40.9  -73.7   40.5  -74.3\n#> 5 Chicago    Chicago, IL, USA      42.0  -87.5   41.6  -87.9\n#> 6 Arlington  Arlington, TX, USA    32.8  -97.0   32.6  -97.2\n#> # ℹ 1 more row\n\nNote how we unnest two columns simultaneously by supplying a vector of variable names to unnest_wider().\nOnce you’ve discovered the path to get to the components you’re interested in, you can extract them directly using another tidyr function, hoist():\n\nlocations |> \n  select(city, formatted_address, geometry) |> \n  hoist(\n    geometry,\n    ne_lat = c(\"bounds\", \"northeast\", \"lat\"),\n    sw_lat = c(\"bounds\", \"southwest\", \"lat\"),\n    ne_lng = c(\"bounds\", \"northeast\", \"lng\"),\n    sw_lng = c(\"bounds\", \"southwest\", \"lng\"),\n  )\n\nIf these case studies have whetted your appetite for more real-life rectangling, you can see a few more examples in vignette(\"rectangling\", package = \"tidyr\").\n\n24.4.4 Exercises\n\nRoughly estimate when gh_repos was created. Why can you only roughly estimate the date?\nThe owner column of gh_repo contains a lot of duplicated information because each owner can have many repos. Can you construct a owners data frame that contains one row for each owner? (Hint: does distinct() work with list-cols?)\nFollow the steps used for titles to create similar tables for the aliases, allegiances, books, and TV series for the Game of Thrones characters.\n\nExplain the following code line-by-line. Why is it interesting? Why does it work for got_chars but might not work in general?\n\ntibble(json = got_chars) |> \n  unnest_wider(json) |> \n  select(id, where(is.list)) |> \n  pivot_longer(\n    where(is.list), \n    names_to = \"name\", \n    values_to = \"value\"\n  ) |>  \n  unnest_longer(value)\n\n\nIn gmaps_cities, what does address_components contain? Why does the length vary between rows? Unnest it appropriately to figure it out. (Hint: types always appears to contain two elements. Does unnest_wider() make it easier to work with than unnest_longer()?) ."
  },
  {
    "objectID": "rectangling.html#json",
    "href": "rectangling.html#json",
    "title": "24  Datos jerárquicos",
    "section": "\n24.5 JSON",
    "text": "24.5 JSON\nTodos los estudios de casos de la sección anterior se obtuvieron de JSON. JSON es la abreviatura de javascript object notation y es la forma en que la mayoría de las API web devuelven datos. Es importante comprenderlo porque, si bien los tipos de datos de JSON y R son bastante similares, no existe un mapeo 1 a 1 perfecto, por lo que es bueno comprender un poco acerca de JSON si algo sale mal.\n\n24.5.1 Tipos de datos\nJSON es un formato simple diseñado para ser leído y escrito fácilmente por máquinas, no por humanos. Tiene seis tipos de datos clave. Cuatro de ellos son escalares:\n\nEl tipo más simple es nulo (null) que juega el mismo papel que NA en R. Representa la ausencia de datos.\nUna cadena es muy parecida a una cadena en R, pero siempre debe usar comillas dobles.\nUn número es similar a los números de R: pueden usar notación entera (por ejemplo, 123), decimal (por ejemplo, 123,45) o científica (por ejemplo, 1,23e3). JSON no es compatible con Inf, -Inf o NaN.\nUn booleano es similar a TRUE y FALSE de R, pero usa true y false en minúsculas.\n\nLas cadenas, los números y los valores booleanos de JSON son bastante similares a los vectores de caracteres, numéricos y lógicos de R. La principal diferencia es que los escalares de JSON solo pueden representar un único valor. Para representar múltiples valores, debe usar uno de los dos tipos restantes: matrices y objetos.\nTanto las matrices como los objetos son similares a las listas en R; la diferencia es si tienen nombre o no. Una matriz es como una lista sin nombre y se escribe con []. Por ejemplo, [1, 2, 3] es una matriz que contiene 3 números, y [null, 1, \"string\", false] es una matriz que contiene un valor nulo, un número, una cadena y un valor booleano. Un objeto es como una lista con nombre y se escribe con {}. Los nombres (claves en terminología JSON) son cadenas, por lo que deben estar entre comillas. Por ejemplo, {\"x\": 1, \"y\": 2} es un objeto que asigna x a 1 e y a 2.\nTenga en cuenta que JSON no tiene ninguna forma nativa de representar fechas o fechas y horas, por lo que a menudo se almacenan como cadenas y deberá usar readr::parse_date() o readr::parse_datetime() para convertirlos en la estructura de datos correcta. De manera similar, las reglas de JSON para representar números de punto flotante en JSON son un poco imprecisas, por lo que a veces también encontrará números almacenados en cadenas. Aplique readr::parse_double() según sea necesario para obtener el tipo de variable correcto.\n\n24.5.2 jsonlite\nPara convertir JSON en estructuras de datos R, recomendamos el paquete jsonlite, de Jeroen Ooms. Usaremos solo dos funciones jsonlite: read_json() y parse_json(). En la vida real, usará read_json() para leer un archivo JSON del disco. Por ejemplo, el paquete repurrsive también proporciona la fuente de gh_user como un archivo JSON y puede leerlo con read_json():\n\n# Una ruta a un archivo json dentro del paquete:\ngh_users_json()\n#> [1] \"C:/Users/DDR/AppData/Local/R/win-library/4.2/repurrrsive/extdata/gh_users.json\"\n\n# Léalo con read_json()\ngh_users2 <- read_json(gh_users_json())\n\n# Verifique que sea igual a los datos que estábamos usando anteriormente\nidentical(gh_users, gh_users2)\n#> [1] TRUE\n\nEn este libro, también usaremos parse_json(), ya que toma una cadena que contiene JSON, lo que lo hace bueno para generar ejemplos simples. Para comenzar, aquí hay tres conjuntos de datos JSON simples, comenzando con un número, luego colocando algunos números en una matriz y luego colocando esa matriz en un objeto:\n\nstr(parse_json('1'))\n#>  int 1\nstr(parse_json('[1, 2, 3]'))\n#> List of 3\n#>  $ : int 1\n#>  $ : int 2\n#>  $ : int 3\nstr(parse_json('{\"x\": [1, 2, 3]}'))\n#> List of 1\n#>  $ x:List of 3\n#>   ..$ : int 1\n#>   ..$ : int 2\n#>   ..$ : int 3\n\njsonlite tiene otra función importante llamada fromJSON(). No lo usamos aquí porque realiza una simplificación automática (simplifyVector = TRUE). Esto a menudo funciona bien, particularmente en casos simples, pero creemos que es mejor que usted mismo haga el rectángulo para que sepa exactamente lo que está sucediendo y pueda manejar más fácilmente las estructuras anidadas más complicadas.\n\n24.5.3 Comenzando el proceso de rectangular\nEn la mayoría de los casos, los archivos JSON contienen una única matriz de nivel superior porque están diseñados para proporcionar datos sobre varias “cosas”, p. varias páginas, varios registros o varios resultados. En este caso, comenzará su rectángulo con tibble(json) para que cada elemento se convierta en una fila:\n\njson <- '[\n  {\"name\": \"John\", \"age\": 34},\n  {\"name\": \"Susan\", \"age\": 27}\n]'\ndf <- tibble(json = parse_json(json))\ndf\n#> # A tibble: 2 × 1\n#>   json            \n#>   <list>          \n#> 1 <named list [2]>\n#> 2 <named list [2]>\n\ndf |> \n  unnest_wider(json)\n#> # A tibble: 2 × 2\n#>   name    age\n#>   <chr> <int>\n#> 1 John     34\n#> 2 Susan    27\n\nEn casos más raros, el archivo JSON consta de un solo objeto JSON de nivel superior, que representa una “cosa”. En este caso, deberá iniciar el proceso de rectangular envolviéndolo en una lista, antes de colocarlo en un tibble.\n\njson <- '{\n  \"status\": \"OK\", \n  \"results\": [\n    {\"name\": \"John\", \"age\": 34},\n    {\"name\": \"Susan\", \"age\": 27}\n ]\n}\n'\ndf <- tibble(json = list(parse_json(json)))\ndf\n#> # A tibble: 1 × 1\n#>   json            \n#>   <list>          \n#> 1 <named list [2]>\n\ndf |> \n  unnest_wider(json) |> \n  unnest_longer(results) |> \n  unnest_wider(results)\n#> # A tibble: 2 × 3\n#>   status name    age\n#>   <chr>  <chr> <int>\n#> 1 OK     John     34\n#> 2 OK     Susan    27\n\nAlternativamente, puede acceder al JSON analizado y comenzar con la parte que realmente le interesa:\n\ndf <- tibble(results = parse_json(json)$results)\ndf |> \n  unnest_wider(results)\n#> # A tibble: 2 × 2\n#>   name    age\n#>   <chr> <int>\n#> 1 John     34\n#> 2 Susan    27\n\n\n24.5.4 Ejercicios\n\n\nRectángulo df_col y df_row a continuación. Representan las dos formas de codificar un marco de datos en JSON.\n\njson_col <- parse_json('\n  {\n    \"x\": [\"a\", \"x\", \"z\"],\n    \"y\": [10, null, 3]\n  }\n')\njson_row <- parse_json('\n  [\n    {\"x\": \"a\", \"y\": 10},\n    {\"x\": \"x\", \"y\": null},\n    {\"x\": \"z\", \"y\": 3}\n  ]\n')\n\ndf_col <- tibble(json = list(json_col)) \ndf_row <- tibble(json = json_row)"
  },
  {
    "objectID": "rectangling.html#summary",
    "href": "rectangling.html#summary",
    "title": "24  Datos jerárquicos",
    "section": "\n24.6 Summary",
    "text": "24.6 Summary\nIn this chapter, you learned what lists are, how you can generate them from JSON files, and how turn them into rectangular data frames. Surprisingly we only need two new functions: unnest_longer() to put list elements into rows and unnest_wider() to put list elements into columns. It doesn’t matter how deeply nested the list-column is, all you need to do is repeatedly call these two functions.\nJSON is the most common data format returned by web APIs. What happens if the website doesn’t have an API, but you can see data you want on the website? That’s the topic of the next chapter: web scraping, extracting data from HTML webpages."
  },
  {
    "objectID": "webscraping.html#introduction",
    "href": "webscraping.html#introduction",
    "title": "25  Web scraping",
    "section": "\n25.1 Introduction",
    "text": "25.1 Introduction\nThis chapter introduces you to the basics of web scraping with rvest. Web scraping is a very useful tool for extracting data from web pages. Some websites will offer an API, a set of structured HTTP requests that return data as JSON, which you handle using the techniques from Chapter 24. Where possible, you should use the API1, because typically it will give you more reliable data. Unfortunately, however, programming with web APIs is out of scope for this book. Instead, we are teaching scraping, a technique that works whether or not a site provides an API.\nIn this chapter, we’ll first discuss the ethics and legalities of scraping before we dive into the basics of HTML. You’ll then learn the basics of CSS selectors to locate specific elements on the page, and how to use rvest functions to get data from text and attributes out of HTML and into R. We’ll then discuss some techniques to figure out what CSS selector you need for the page you’re scraping, before finishing up with a couple of case studies, and a brief discussion of dynamic websites.\n\n25.1.1 Prerequisites\nIn this chapter, we’ll focus on tools provided by rvest. rvest is a member of the tidyverse, but is not a core member so you’ll need to load it explicitly. We’ll also load the full tidyverse since we’ll find it generally useful working with the data we’ve scraped.\n\nlibrary(tidyverse)\n#> Warning: package 'tibble' was built under R version 4.2.3\n#> Warning: package 'readr' was built under R version 4.2.3\n#> Warning: package 'dplyr' was built under R version 4.2.3\nlibrary(rvest)"
  },
  {
    "objectID": "webscraping.html#scraping-ethics-and-legalities",
    "href": "webscraping.html#scraping-ethics-and-legalities",
    "title": "25  Web scraping",
    "section": "\n25.2 Scraping ethics and legalities",
    "text": "25.2 Scraping ethics and legalities\nBefore we get started discussing the code you’ll need to perform web scraping, we need to talk about whether it’s legal and ethical for you to do so. Overall, the situation is complicated with regards to both of these.\nLegalities depend a lot on where you live. However, as a general principle, if the data is public, non-personal, and factual, you’re likely to be ok2. These three factors are important because they’re connected to the site’s terms and conditions, personally identifiable information, and copyright, as we’ll discuss below.\nIf the data isn’t public, non-personal, or factual or you’re scraping the data specifically to make money with it, you’ll need to talk to a lawyer. In any case, you should be respectful of the resources of the server hosting the pages you are scraping. Most importantly, this means that if you’re scraping many pages, you should make sure to wait a little between each request. One easy way to do so is to use the polite package by Dmytro Perepolkin. It will automatically pause between requests and cache the results so you never ask for the same page twice.\n\n25.2.1 Terms of service\nIf you look closely, you’ll find many websites include a “terms and conditions” or “terms of service” link somewhere on the page, and if you read that page closely you’ll often discover that the site specifically prohibits web scraping. These pages tend to be a legal land grab where companies make very broad claims. It’s polite to respect these terms of service where possible, but take any claims with a grain of salt.\nUS courts3 have generally found that simply putting the terms of service in the footer of the website isn’t sufficient for you to be bound by them. Generally, to be bound to the terms of service, you must have taken some explicit action like creating an account or checking a box. This is why whether or not the data is public is important; if you don’t need an account to access them, it is unlikely that you are bound to the terms of service. Note, however, the situation is rather different in Europe where courts have found that terms of service are enforceable even if you don’t explicitly agree to them.\n\n25.2.2 Personally identifiable information\nEven if the data is public, you should be extremely careful about scraping personally identifiable information like names, email addresses, phone numbers, dates of birth, etc. Europe has particularly strict laws about the collection or storage of such data (GDPR), and regardless of where you live you’re likely to be entering an ethical quagmire. For example, in 2016, a group of researchers scraped public profile information (e.g. usernames, age, gender, location, etc.) about 70,000 people on the dating site OkCupid and they publicly released these data without any attempts for anonymization. While the researchers felt that there was nothing wrong with this since the data were already public, this work was widely condemned due to ethics concerns around identifiability of users whose information was released in the dataset. If your work involves scraping personally identifiable information, we strongly recommend reading about the OkCupid study4 as well as similar studies with questionable research ethics involving the acquisition and release of personally identifiable information.\n\n25.2.3 Copyright\nFinally, you also need to worry about copyright law. Copyright law is complicated, but it’s worth taking a look at the US law which describes exactly what’s protected: “[…] original works of authorship fixed in any tangible medium of expression, […]”. It then goes on to describe specific categories that it applies like literary works, musical works, motion pictures and more. Notably absent from copyright protection are data. This means that as long as you limit your scraping to facts, copyright protection does not apply. (But note that Europe has a separate “sui generis” right that protects databases.)\nAs a brief example, in the US, lists of ingredients and instructions are not copyrightable, so copyright can not be used to protect a recipe. But if that list of recipes is accompanied by substantial novel literary content, that is copyrightable. This is why when you’re looking for a recipe on the internet there’s always so much content beforehand.\nIf you do need to scrape original content (like text or images), you may still be protected under the doctrine of fair use. Fair use is not a hard and fast rule, but weighs up a number of factors. It’s more likely to apply if you are collecting the data for research or non-commercial purposes and if you limit what you scrape to just what you need."
  },
  {
    "objectID": "webscraping.html#html-basics",
    "href": "webscraping.html#html-basics",
    "title": "25  Web scraping",
    "section": "\n25.3 HTML basics",
    "text": "25.3 HTML basics\nTo scrape webpages, you need to first understand a little bit about HTML, the language that describes web pages. HTML stands for HyperText Markup Language and looks something like this:\n<html>\n<head>\n  <title>Page title</title>\n</head>\n<body>\n  <h1 id='first'>A heading</h1>\n  <p>Some text &amp; <b>some bold text.</b></p>\n  <img src='myimg.png' width='100' height='100'>\n</body>\nHTML has a hierarchical structure formed by elements which consist of a start tag (e.g. <tag>), optional attributes (id='first'), an end tag5 (like </tag>), and contents (everything in between the start and end tag).\nSince < and > are used for start and end tags, you can’t write them directly. Instead you have to use the HTML escapes &gt; (greater than) and &lt; (less than). And since those escapes use &, if you want a literal ampersand you have to escape it as &amp;. There are a wide range of possible HTML escapes but you don’t need to worry about them too much because rvest automatically handles them for you.\nWeb scraping is possible because most pages that contain data that you want to scrape generally have a consistent structure.\n\n25.3.1 Elements\nThere are over 100 HTML elements. Some of the most important are:\n\nEvery HTML page must be in an <html> element, and it must have two children: <head>, which contains document metadata like the page title, and <body>, which contains the content you see in the browser.\nBlock tags like <h1> (heading 1), <section> (section), <p> (paragraph), and <ol> (ordered list) form the overall structure of the page.\nInline tags like <b> (bold), <i> (italics), and <a> (link) format text inside block tags.\n\nIf you encounter a tag that you’ve never seen before, you can find out what it does with a little googling. Another good place to start are the MDN Web Docs which describe just about every aspect of web programming.\nMost elements can have content in between their start and end tags. This content can either be text or more elements. For example, the following HTML contains paragraph of text, with one word in bold.\n<p>\n  Hi! My <b>name</b> is Hadley.\n</p>\nThe children are the elements it contains, so the <p> element above has one child, the <b> element. The <b> element has no children, but it does have contents (the text “name”).\n\n25.3.2 Attributes\nTags can have named attributes which look like name1='value1' name2='value2'. Two of the most important attributes are id and class, which are used in conjunction with CSS (Cascading Style Sheets) to control the visual appearance of the page. These are often useful when scraping data off a page. Attributes are also used to record the destination of links (the href attribute of <a> elements) and the source of images (the src attribute of the <img> element)."
  },
  {
    "objectID": "webscraping.html#extracting-data",
    "href": "webscraping.html#extracting-data",
    "title": "25  Web scraping",
    "section": "\n25.4 Extracting data",
    "text": "25.4 Extracting data\nTo get started scraping, you’ll need the URL of the page you want to scrape, which you can usually copy from your web browser. You’ll then need to read the HTML for that page into R with read_html(). This returns an xml_document6 object which you’ll then manipulate using rvest functions:\n\nhtml <- read_html(\"http://rvest.tidyverse.org/\")\nhtml\n#> {html_document}\n#> <html lang=\"en\">\n#> [1] <head>\\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UT ...\n#> [2] <body>\\n    <a href=\"#container\" class=\"visually-hidden-focusable\">Ski ...\n\nrvest also includes a function that lets you write HTML inline. We’ll use this a bunch in this chapter as we teach how the various rvest functions work with simple examples.\n\nhtml <- minimal_html(\"\n  <p>This is a paragraph<p>\n  <ul>\n    <li>This is a bulleted list</li>\n  </ul>\n\")\nhtml\n#> {html_document}\n#> <html>\n#> [1] <head>\\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UT ...\n#> [2] <body>\\n<p>This is a paragraph</p>\\n<p>\\n  </p>\\n<ul>\\n<li>This is a b ...\n\nNow that you have the HTML in R, it’s time to extract the data of interest. You’ll first learn about the CSS selectors that allow you to identify the elements of interest and the rvest functions that you can use to extract data from them. Then we’ll briefly cover HTML tables, which have some special tools.\n\n25.4.1 Find elements\nCSS is short for cascading style sheets, and is a tool for defining the visual styling of HTML documents. CSS includes a miniature language for selecting elements on a page called CSS selectors. CSS selectors define patterns for locating HTML elements, and are useful for scraping because they provide a concise way of describing which elements you want to extract.\nWe’ll come back to CSS selectors in more detail in Section 25.5, but luckily you can get a long way with just three:\n\np selects all <p> elements.\n.title selects all elements with class “title”.\n#title selects the element with the id attribute that equals “title”. Id attributes must be unique within a document, so this will only ever select a single element.\n\nLets try out these selectors with a simple example:\n\nhtml <- minimal_html(\"\n  <h1>This is a heading</h1>\n  <p id='first'>This is a paragraph</p>\n  <p class='important'>This is an important paragraph</p>\n\")\n\nUse html_elements() to find all elements that match the selector:\n\nhtml |> html_elements(\"p\")\n#> {xml_nodeset (2)}\n#> [1] <p id=\"first\">This is a paragraph</p>\n#> [2] <p class=\"important\">This is an important paragraph</p>\nhtml |> html_elements(\".important\")\n#> {xml_nodeset (1)}\n#> [1] <p class=\"important\">This is an important paragraph</p>\nhtml |> html_elements(\"#first\")\n#> {xml_nodeset (1)}\n#> [1] <p id=\"first\">This is a paragraph</p>\n\nAnother important function is html_element() which always returns the same number of outputs as inputs. If you apply it to a whole document it’ll give you the first match:\n\nhtml |> html_element(\"p\")\n#> {html_node}\n#> <p id=\"first\">\n\nThere’s an important difference between html_element() and html_elements() when you use a selector that doesn’t match any elements. html_elements() returns a vector of length 0, where html_element() returns a missing value. This will be important shortly.\n\nhtml |> html_elements(\"b\")\n#> {xml_nodeset (0)}\nhtml |> html_element(\"b\")\n#> {xml_missing}\n#> <NA>\n\n\n25.4.2 Nesting selections\nIn most cases, you’ll use html_elements() and html_element() together, typically using html_elements() to identify elements that will become observations then using html_element() to find elements that will become variables. Let’s see this in action using a simple example. Here we have an unordered list (<ul>) where each list item (<li>) contains some information about four characters from StarWars:\n\nhtml <- minimal_html(\"\n  <ul>\n    <li><b>C-3PO</b> is a <i>droid</i> that weighs <span class='weight'>167 kg</span></li>\n    <li><b>R4-P17</b> is a <i>droid</i></li>\n    <li><b>R2-D2</b> is a <i>droid</i> that weighs <span class='weight'>96 kg</span></li>\n    <li><b>Yoda</b> weighs <span class='weight'>66 kg</span></li>\n  </ul>\n  \")\n\nWe can use html_elements() to make a vector where each element corresponds to a different character:\n\ncharacters <- html |> html_elements(\"li\")\ncharacters\n#> {xml_nodeset (4)}\n#> [1] <li>\\n<b>C-3PO</b> is a <i>droid</i> that weighs <span class=\"weight\"> ...\n#> [2] <li>\\n<b>R4-P17</b> is a <i>droid</i>\\n</li>\n#> [3] <li>\\n<b>R2-D2</b> is a <i>droid</i> that weighs <span class=\"weight\"> ...\n#> [4] <li>\\n<b>Yoda</b> weighs <span class=\"weight\">66 kg</span>\\n</li>\n\nTo extract the name of each character, we use html_element(), because when applied to the output of html_elements() its guaranteed to return one response per element:\n\ncharacters |> html_element(\"b\")\n#> {xml_nodeset (4)}\n#> [1] <b>C-3PO</b>\n#> [2] <b>R4-P17</b>\n#> [3] <b>R2-D2</b>\n#> [4] <b>Yoda</b>\n\nThe distinction between html_element() and html_elements() isn’t important for name, but it is important for weight. We want to get one weight for each character, even if there’s no weight <span>. That’s what html_element() does:\n\ncharacters |> html_element(\".weight\")\n#> {xml_nodeset (4)}\n#> [1] <span class=\"weight\">167 kg</span>\n#> [2] <NA>\n#> [3] <span class=\"weight\">96 kg</span>\n#> [4] <span class=\"weight\">66 kg</span>\n\nhtml_elements() finds all weight <span>s that are children of characters. There’s only three of these, so we lose the connection between names and weights:\n\ncharacters |> html_elements(\".weight\")\n#> {xml_nodeset (3)}\n#> [1] <span class=\"weight\">167 kg</span>\n#> [2] <span class=\"weight\">96 kg</span>\n#> [3] <span class=\"weight\">66 kg</span>\n\nNow that you’ve selected the elements of interest, you’ll need to extract the data, either from the text contents or some attributes.\n\n25.4.3 Text and attributes\nhtml_text2()7 extracts the plain text contents of an HTML element:\n\ncharacters |> \n  html_element(\"b\") |> \n  html_text2()\n#> [1] \"C-3PO\"  \"R4-P17\" \"R2-D2\"  \"Yoda\"\n\ncharacters |> \n  html_element(\".weight\") |> \n  html_text2()\n#> [1] \"167 kg\" NA       \"96 kg\"  \"66 kg\"\n\nNote that any escapes will be automatically handled; you’ll only ever see HTML escapes in the source HTML, not in the data returned by rvest.\nhtml_attr() extracts data from attributes:\n\nhtml <- minimal_html(\"\n  <p><a href='https://en.wikipedia.org/wiki/Cat'>cats</a></p>\n  <p><a href='https://en.wikipedia.org/wiki/Dog'>dogs</a></p>\n\")\n\nhtml |> \n  html_elements(\"p\") |> \n  html_element(\"a\") |> \n  html_attr(\"href\")\n#> [1] \"https://en.wikipedia.org/wiki/Cat\" \"https://en.wikipedia.org/wiki/Dog\"\n\nhtml_attr() always returns a string, so if you’re extracting numbers or dates, you’ll need to do some post-processing.\n\n25.4.4 Tables\nIf you’re lucky, your data will be already stored in an HTML table, and it’ll be a matter of just reading it from that table. It’s usually straightforward to recognize a table in your browser: it’ll have a rectangular structure of rows and columns, and you can copy and paste it into a tool like Excel.\nHTML tables are built up from four main elements: <table>, <tr> (table row), <th> (table heading), and <td> (table data). Here’s a simple HTML table with two columns and three rows:\n\nhtml <- minimal_html(\"\n  <table class='mytable'>\n    <tr><th>x</th>   <th>y</th></tr>\n    <tr><td>1.5</td> <td>2.7</td></tr>\n    <tr><td>4.9</td> <td>1.3</td></tr>\n    <tr><td>7.2</td> <td>8.1</td></tr>\n  </table>\n  \")\n\nrvest provides a function that knows how to read this sort of data: html_table(). It returns a list containing one tibble for each table found on the page. Use html_element() to identify the table you want to extract:\n\nhtml |> \n  html_element(\".mytable\") |> \n  html_table()\n#> # A tibble: 3 × 2\n#>       x     y\n#>   <dbl> <dbl>\n#> 1   1.5   2.7\n#> 2   4.9   1.3\n#> 3   7.2   8.1\n\nNote that x and y have automatically been converted to numbers. This automatic conversion doesn’t always work, so in more complex scenarios you may want to turn it off with convert = FALSE and then do your own conversion."
  },
  {
    "objectID": "webscraping.html#sec-css-selectors",
    "href": "webscraping.html#sec-css-selectors",
    "title": "25  Web scraping",
    "section": "\n25.5 Finding the right selectors",
    "text": "25.5 Finding the right selectors\nFiguring out the selector you need for your data is typically the hardest part of the problem. You’ll often need to do some experimenting to find a selector that is both specific (i.e. it doesn’t select things you don’t care about) and sensitive (i.e. it does select everything you care about). Lots of trial and error is a normal part of the process! There are two main tools that are available to help you with this process: SelectorGadget and your browser’s developer tools.\nSelectorGadget is a javascript bookmarklet that automatically generates CSS selectors based on the positive and negative examples that you provide. It doesn’t always work, but when it does, it’s magic! You can learn how to install and use SelectorGadget either by reading https://rvest.tidyverse.org/articles/selectorgadget.html or watching Mine’s video at https://www.youtube.com/watch?v=PetWV5g1Xsc.\nEvery modern browser comes with some toolkit for developers, but we recommend Chrome, even if it isn’t your regular browser: its web developer tools are some of the best and they’re immediately available. Right click on an element on the page and click Inspect. This will open an expandable view of the complete HTML page, centered on the element that you just clicked. You can use this to explore the page and get a sense of what selectors might work. Pay particular attention to the class and id attributes, since these are often used to form the visual structure of the page, and hence make for good tools to extract the data that you’re looking for.\nInside the Elements view, you can also right click on an element and choose Copy as Selector to generate a selector that will uniquely identify the element of interest.\nIf either SelectorGadget or Chrome DevTools have generated a CSS selector that you don’t understand, try Selectors Explained which translates CSS selectors into plain English. If you find yourself doing this a lot, you might want to learn more about CSS selectors generally. We recommend starting with the fun CSS dinner tutorial and then referring to the MDN web docs."
  },
  {
    "objectID": "webscraping.html#putting-it-all-together",
    "href": "webscraping.html#putting-it-all-together",
    "title": "25  Web scraping",
    "section": "\n25.6 Putting it all together",
    "text": "25.6 Putting it all together\nLets put this all together to scrape some websites. There’s some risk that these examples may no longer work when you run them — that’s the fundamental challenge of web scraping; if the structure of the site changes, then you’ll have to change your scraping code.\n\n25.6.1 StarWars\nrvest includes a very simple example in vignette(\"starwars\"). This is simple page with minimal HTML so it’s a good place to start. I’d encourage you to navigate to that page now and use “Inspect Element” to inspect one of the headings that’s the title of a Star Wars movie. Use the keyboard or mouse to explore the hierarchy of the HTML and see if you can get a sense of the shared structure used by each movie.\nYou should be able to see that each movie has a shared structure that looks like this:\n<section>\n  <h2 data-id=\"1\">The Phantom Menace</h2>\n  <p>Released: 1999-05-19</p>\n  <p>Director: <span class=\"director\">George Lucas</span></p>\n  \n  <div class=\"crawl\">\n    <p>...</p>\n    <p>...</p>\n    <p>...</p>\n  </div>\n</section>\nOur goal is to turn this data into a 7 row data frame with variables title, year, director, and intro. We’ll start by reading the HTML and extracting all the <section> elements:\n\nurl <- \"https://rvest.tidyverse.org/articles/starwars.html\"\nhtml <- read_html(url)\n\nsection <- html |> html_elements(\"section\")\nsection\n#> {xml_nodeset (7)}\n#> [1] <section><h2 data-id=\"1\">\\nThe Phantom Menace\\n</h2>\\n<p>\\nReleased: 1 ...\n#> [2] <section><h2 data-id=\"2\">\\nAttack of the Clones\\n</h2>\\n<p>\\nReleased: ...\n#> [3] <section><h2 data-id=\"3\">\\nRevenge of the Sith\\n</h2>\\n<p>\\nReleased:  ...\n#> [4] <section><h2 data-id=\"4\">\\nA New Hope\\n</h2>\\n<p>\\nReleased: 1977-05-2 ...\n#> [5] <section><h2 data-id=\"5\">\\nThe Empire Strikes Back\\n</h2>\\n<p>\\nReleas ...\n#> [6] <section><h2 data-id=\"6\">\\nReturn of the Jedi\\n</h2>\\n<p>\\nReleased: 1 ...\n#> [7] <section><h2 data-id=\"7\">\\nThe Force Awakens\\n</h2>\\n<p>\\nReleased: 20 ...\n\nThis retrieves seven elements matching the seven movies found on that page, suggesting that using section as a selector is good. Extracting the individual elements is straightforward since the data is always found in the text. It’s just a matter of finding the right selector:\n\nsection |> html_element(\"h2\") |> html_text2()\n#> [1] \"The Phantom Menace\"      \"Attack of the Clones\"   \n#> [3] \"Revenge of the Sith\"     \"A New Hope\"             \n#> [5] \"The Empire Strikes Back\" \"Return of the Jedi\"     \n#> [7] \"The Force Awakens\"\n\nsection |> html_element(\".director\") |> html_text2()\n#> [1] \"George Lucas\"     \"George Lucas\"     \"George Lucas\"    \n#> [4] \"George Lucas\"     \"Irvin Kershner\"   \"Richard Marquand\"\n#> [7] \"J. J. Abrams\"\n\nOnce we’ve done that for each component, we can wrap all the results up into a tibble:\n\ntibble(\n  title = section |> \n    html_element(\"h2\") |> \n    html_text2(),\n  released = section |> \n    html_element(\"p\") |> \n    html_text2() |> \n    str_remove(\"Released: \") |> \n    parse_date(),\n  director = section |> \n    html_element(\".director\") |> \n    html_text2(),\n  intro = section |> \n    html_element(\".crawl\") |> \n    html_text2()\n)\n#> # A tibble: 7 × 4\n#>   title                   released   director         intro                  \n#>   <chr>                   <date>     <chr>            <chr>                  \n#> 1 The Phantom Menace      1999-05-19 George Lucas     \"Turmoil has engulfed …\n#> 2 Attack of the Clones    2002-05-16 George Lucas     \"There is unrest in th…\n#> 3 Revenge of the Sith     2005-05-19 George Lucas     \"War! The Republic is …\n#> 4 A New Hope              1977-05-25 George Lucas     \"It is a period of civ…\n#> 5 The Empire Strikes Back 1980-05-17 Irvin Kershner   \"It is a dark time for…\n#> 6 Return of the Jedi      1983-05-25 Richard Marquand \"Luke Skywalker has re…\n#> # ℹ 1 more row\n\nWe did a little more processing of released to get a variable that will be easy to use later in our analysis.\n\n25.6.2 IMDB top films\nFor our next task we’ll tackle something a little trickier, extracting the top 250 movies from the internet movie database (IMDb). At the time we wrote this chapter, the page looked like Figure 25.1.\n\n\n\n\nFigure 25.1: Screenshot of the IMDb top movies web page taken on 2022-12-05.\n\n\n\n\nThis data has a clear tabular structure so it’s worth starting with html_table():\n\nurl <- \"https://www.imdb.com/chart/top\"\nhtml <- read_html(url)\n\ntable <- html |> \n  html_element(\"table\") |> \n  html_table()\ntable\n#> # A tibble: 250 × 5\n#>   ``    `Rank & Title`                      `IMDb Rating` `Your Rating` ``   \n#>   <lgl> <chr>                                       <dbl> <chr>         <lgl>\n#> 1 NA    \"1.\\n      Cadena perpetua\\n      …           9.2 \"12345678910… NA   \n#> 2 NA    \"2.\\n      El padrino\\n        (19…           9.2 \"12345678910… NA   \n#> 3 NA    \"3.\\n      El caballero oscuro\\n  …           9   \"12345678910… NA   \n#> 4 NA    \"4.\\n      El padrino (parte II)\\n…           9   \"12345678910… NA   \n#> 5 NA    \"5.\\n      12 hombres sin piedad\\n…           9   \"12345678910… NA   \n#> 6 NA    \"6.\\n      La lista de Schindler\\n…           8.9 \"12345678910… NA   \n#> # ℹ 244 more rows\n\nThis includes a few empty columns, but overall does a good job of capturing the information from the table. However, we need to do some more processing to make it easier to use. First, we’ll rename the columns to be easier to work with, and remove the extraneous whitespace in rank and title. We will do this with select() (instead of rename()) to do the renaming and selecting of just these two columns in one step. Then we’ll remove the new lines and extra spaces, and then apply separate_wider_regex() (from Section 16.3.4) to pull out the title, year, and rank into their own variables.\n\nratings <- table |>\n  select(\n    rank_title_year = `Rank & Title`,\n    rating = `IMDb Rating`\n  ) |> \n  mutate(\n    rank_title_year = str_replace_all(rank_title_year, \"\\n +\", \" \")\n  ) |> \n  separate_wider_regex(\n    rank_title_year,\n    patterns = c(\n      rank = \"\\\\d+\", \"\\\\. \",\n      title = \".+\", \" +\\\\(\",\n      year = \"\\\\d+\", \"\\\\)\"\n    )\n  )\nratings\n#> # A tibble: 250 × 4\n#>   rank  title                 year  rating\n#>   <chr> <chr>                 <chr>  <dbl>\n#> 1 1     Cadena perpetua       1994     9.2\n#> 2 2     El padrino            1972     9.2\n#> 3 3     El caballero oscuro   2008     9  \n#> 4 4     El padrino (parte II) 1974     9  \n#> 5 5     12 hombres sin piedad 1957     9  \n#> 6 6     La lista de Schindler 1993     8.9\n#> # ℹ 244 more rows\n\nEven in this case where most of the data comes from table cells, it’s still worth looking at the raw HTML. If you do so, you’ll discover that we can add a little extra data by using one of the attributes. This is one of the reasons it’s worth spending a little time spelunking the source of the page; you might find extra data, or might find a parsing route that’s slightly easier.\n\nhtml |> \n  html_elements(\"td strong\") |> \n  head() |> \n  html_attr(\"title\")\n#> [1] \"9.2 based on 2,723,509 user ratings\"\n#> [2] \"9.2 based on 1,893,021 user ratings\"\n#> [3] \"9.0 based on 2,696,279 user ratings\"\n#> [4] \"9.0 based on 1,291,210 user ratings\"\n#> [5] \"9.0 based on 805,275 user ratings\"  \n#> [6] \"8.9 based on 1,375,427 user ratings\"\n\nWe can combine this with the tabular data and again apply separate_wider_regex() to extract out the bit of data we care about:\n\nratings |>\n  mutate(\n    rating_n = html |> html_elements(\"td strong\") |> html_attr(\"title\")\n  ) |> \n  separate_wider_regex(\n    rating_n,\n    patterns = c(\n      \"[0-9.]+ based on \",\n      number = \"[0-9,]+\",\n      \" user ratings\"\n    )\n  ) |> \n  mutate(\n    number = parse_number(number)\n  )\n#> # A tibble: 250 × 5\n#>   rank  title                 year  rating  number\n#>   <chr> <chr>                 <chr>  <dbl>   <dbl>\n#> 1 1     Cadena perpetua       1994     9.2 2723509\n#> 2 2     El padrino            1972     9.2 1893021\n#> 3 3     El caballero oscuro   2008     9   2696279\n#> 4 4     El padrino (parte II) 1974     9   1291210\n#> 5 5     12 hombres sin piedad 1957     9    805275\n#> 6 6     La lista de Schindler 1993     8.9 1375427\n#> # ℹ 244 more rows"
  },
  {
    "objectID": "webscraping.html#dynamic-sites",
    "href": "webscraping.html#dynamic-sites",
    "title": "25  Web scraping",
    "section": "\n25.7 Dynamic sites",
    "text": "25.7 Dynamic sites\nSo far we have focused on websites where html_elements() returns what you see in the browser and discussed how to parse what it returns and how to organize that information in tidy data frames. From time-to-time, however, you’ll hit a site where html_elements() and friends don’t return anything like what you see in the browser. In many cases, that’s because you’re trying to scrape a website that dynamically generates the content of the page with javascript. This doesn’t currently work with rvest, because rvest downloads the raw HTML and doesn’t run any javascript.\nIt’s still possible to scrape these types of sites, but rvest needs to use a more expensive process: fully simulating the web browser including running all javascript. This functionality is not available at the time of writing, but it’s something we’re actively working on and might be available by the time you read this. It uses the chromote package which actually runs the Chrome browser in the background, and gives you additional tools to interact with the site, like a human typing text and clicking buttons. Check out the rvest website for more details."
  },
  {
    "objectID": "webscraping.html#summary",
    "href": "webscraping.html#summary",
    "title": "25  Web scraping",
    "section": "\n25.8 Summary",
    "text": "25.8 Summary\nIn this chapter, you’ve learned about the why, the why not, and the how of scraping data from web pages. First, you’ve learned about the basics of HTML and using CSS selectors to refer to specific elements, then you’ve learned about using the rvest package to get data out of HTML into R. We then demonstrated web scraping with two case studies: a simpler scenario on scraping data on StarWars films from the rvest package website and a more complex scenario on scraping the top 250 films from IMDB.\nTechnical details of scraping data off the web can be complex, particularly when dealing with sites, however legal and ethical considerations can be even more complex. It’s important for you to educate yourself about both of these before setting out to scrape data.\nThis brings us to the end of the import part of the book where you’ve learned techniques to get data from where it lives (spreadsheets, databases, JSON files, and web sites) into a tidy form in R. Now it’s time to turn our sights to a new topic: making the most of R as a programming language."
  },
  {
    "objectID": "program.html",
    "href": "program.html",
    "title": "Programa",
    "section": "",
    "text": "En esta parte del libro, mejorará sus habilidades de programación. La programación es una habilidad transversal necesaria para todo el trabajo de ciencia de datos: debe usar una computadora para hacer ciencia de datos; no puedes hacerlo en tu cabeza, o con lápiz y papel.\n\n\n\n\n\n\n\nFigura 1: La programación es el agua en la que nadan todos los demás componentes.\n\n\n\n\nLa programación produce código, y el código es una herramienta de comunicación. Obviamente, el código le dice a la computadora lo que quieres que haga. Pero también comunica significado a otros humanos. Pensar en el código como un vehículo para la comunicación es importante porque cada proyecto que haces es fundamentalmente colaborativo. Incluso si no está trabajando con otras personas, ¡definitivamente estará trabajando con usted en el futuro! Escribir un código claro es importante para que otros (como usted en el futuro) puedan entender por qué abordó un análisis de la forma en que lo hizo. Eso significa que mejorar en la programación también implica mejorar en la comunicación. Con el tiempo, desea que su código sea no solo más fácil de escribir, sino más fácil de leer para los demás.\nEn los siguientes tres capítulos, aprenderá habilidades para mejorar sus habilidades de programación:\n\nCopiar y pegar es una herramienta poderosa, pero debes evitar hacerlo más de dos veces. Repetirse en el código es peligroso porque puede conducir fácilmente a errores e inconsistencias. En cambio, en sec-functions, aprenderá a escribir funciones que le permitirán extraer código tidyverse repetido para que pueda reutilizarse fácilmente.\nLas funciones extraen código repetido, pero a menudo necesita repetir las mismas acciones en diferentes entradas. Necesita herramientas para iteración que le permitan hacer cosas similares una y otra vez. Estas herramientas incluyen bucles for y programación funcional, que aprenderá en sec-iteration.\nA medida que lea más código escrito por otros, verá más código que no usa el tidyverse. En sec-base-r, aprenderá algunas de las funciones básicas de R más importantes que verá en la naturaleza.\n\nEl objetivo de estos capítulos es enseñarle lo mínimo sobre programación que necesita para la ciencia de datos. Una vez que haya dominado el material aquí, le recomendamos que continúe invirtiendo en sus habilidades de programación. Hemos escrito dos libros que pueden resultarle útiles. Hands on Programming with R, de Garrett Grolemund, es una introducción a R como lenguaje de programación y es un excelente lugar para comenzar si R es su primer lenguaje de programación. Advanced R por Hadley Wickham se sumerge en los detalles de el lenguaje de programación R; es un excelente lugar para comenzar si ya tiene experiencia en programación y un excelente próximo paso una vez que haya interiorizado las ideas de estos capítulos.",
    "crumbs": [
      "Programa"
    ]
  },
  {
    "objectID": "functions.html#introduction",
    "href": "functions.html#introduction",
    "title": "26  Functions",
    "section": "\n26.1 Introduction",
    "text": "26.1 Introduction\nOne of the best ways to improve your reach as a data scientist is to write functions. Functions allow you to automate common tasks in a more powerful and general way than copy-and-pasting. Writing a function has three big advantages over using copy-and-paste:\n\nYou can give a function an evocative name that makes your code easier to understand.\nAs requirements change, you only need to update code in one place, instead of many.\nYou eliminate the chance of making incidental mistakes when you copy and paste (i.e. updating a variable name in one place, but not in another).\nIt makes it easier to reuse work from project-to-project, increasing your productivity over time.\n\nA good rule of thumb is to consider writing a function whenever you’ve copied and pasted a block of code more than twice (i.e. you now have three copies of the same code). In this chapter, you’ll learn about three useful types of functions:\n\nVector functions take one or more vectors as input and return a vector as output.\nData frame functions take a data frame as input and return a data frame as output.\nPlot functions that take a data frame as input and return a plot as output.\n\nEach of these sections include many examples to help you generalize the patterns that you see. These examples wouldn’t be possible without the help of folks of twitter, and we encourage follow the links in the comment to see original inspirations. You might also want to read the original motivating tweets for general functions and plotting functions to see even more functions.\n\n26.1.1 Prerequisites\nWe’ll wrap up a variety of functions from around the tidyverse. We’ll also use nycflights13 as a source of familiar data to use our functions with.\n\nlibrary(tidyverse)\n#> Warning: package 'tibble' was built under R version 4.2.3\n#> Warning: package 'readr' was built under R version 4.2.3\n#> Warning: package 'dplyr' was built under R version 4.2.3\nlibrary(nycflights13)"
  },
  {
    "objectID": "functions.html#vector-functions",
    "href": "functions.html#vector-functions",
    "title": "26  Functions",
    "section": "\n26.2 Vector functions",
    "text": "26.2 Vector functions\nWe’ll begin with vector functions: functions that take one or more vectors and return a vector result. For example, take a look at this code. What does it do?\n\ndf <- tibble(\n  a = rnorm(5),\n  b = rnorm(5),\n  c = rnorm(5),\n  d = rnorm(5),\n)\n\ndf |> mutate(\n  a = (a - min(a, na.rm = TRUE)) / \n    (max(a, na.rm = TRUE) - min(a, na.rm = TRUE)),\n  b = (b - min(b, na.rm = TRUE)) / \n    (max(b, na.rm = TRUE) - min(a, na.rm = TRUE)),\n  c = (c - min(c, na.rm = TRUE)) / \n    (max(c, na.rm = TRUE) - min(c, na.rm = TRUE)),\n  d = (d - min(d, na.rm = TRUE)) / \n    (max(d, na.rm = TRUE) - min(d, na.rm = TRUE)),\n)\n#> # A tibble: 5 × 4\n#>       a     b     c     d\n#>   <dbl> <dbl> <dbl> <dbl>\n#> 1 0.339  2.59 0.291 0    \n#> 2 0.880  0    0.611 0.557\n#> 3 0      1.37 1     0.752\n#> 4 0.795  1.37 0     1    \n#> 5 1      1.34 0.580 0.394\n\nYou might be able to puzzle out that this rescales each column to have a range from 0 to 1. But did you spot the mistake? When Hadley wrote this code he made an error when copying-and-pasting and forgot to change an a to a b. Preventing this type of mistake is one very good reason to learn how to write functions.\n\n26.2.1 Writing a function\nTo write a function you need to first analyse your repeated code to figure what parts are constant and what parts vary. If we take the code above and pull it outside of mutate(), it’s a little easier to see the pattern because each repetition is now one line:\n\n(a - min(a, na.rm = TRUE)) / (max(a, na.rm = TRUE) - min(a, na.rm = TRUE))\n(b - min(b, na.rm = TRUE)) / (max(b, na.rm = TRUE) - min(b, na.rm = TRUE))\n(c - min(c, na.rm = TRUE)) / (max(c, na.rm = TRUE) - min(c, na.rm = TRUE))\n(d - min(d, na.rm = TRUE)) / (max(d, na.rm = TRUE) - min(d, na.rm = TRUE))  \n\nTo make this a bit clearer we can replace the bit that varies with █:\n\n(█ - min(█, na.rm = TRUE)) / (max(█, na.rm = TRUE) - min(█, na.rm = TRUE))\n\nTo turn this into a function you need three things:\n\nA name. Here we’ll use rescale01 because this function rescales a vector to lie between 0 and 1.\nThe arguments. The arguments are things that vary across calls and our analysis above tells us that we have just one. We’ll call it x because this is the conventional name for a numeric vector.\nThe body. The body is the code that’s repeated across all the calls.\n\nThen you create a function by following the template:\n\nname <- function(arguments) {\n  body\n}\n\nFor this case that leads to:\n\nrescale01 <- function(x) {\n  (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))\n}\n\nAt this point you might test with a few simple inputs to make sure you’ve captured the logic correctly:\n\nrescale01(c(-10, 0, 10))\n#> [1] 0.0 0.5 1.0\nrescale01(c(1, 2, 3, NA, 5))\n#> [1] 0.00 0.25 0.50   NA 1.00\n\nThen you can rewrite the call to mutate() as:\n\ndf |> mutate(\n  a = rescale01(a),\n  b = rescale01(b),\n  c = rescale01(c),\n  d = rescale01(d),\n)\n#> # A tibble: 5 × 4\n#>       a     b     c     d\n#>   <dbl> <dbl> <dbl> <dbl>\n#> 1 0.339 1     0.291 0    \n#> 2 0.880 0     0.611 0.557\n#> 3 0     0.530 1     0.752\n#> 4 0.795 0.531 0     1    \n#> 5 1     0.518 0.580 0.394\n\n(In Chapter 27, you’ll learn how to use across() to reduce the duplication even further so all you need is df |> mutate(across(a:d, rescale01))).\n\n26.2.2 Improving our function\nYou might notice that the rescale01() function does some unnecessary work — instead of computing min() twice and max() once we could instead compute both the minimum and maximum in one step with range():\n\nrescale01 <- function(x) {\n  rng <- range(x, na.rm = TRUE)\n  (x - rng[1]) / (rng[2] - rng[1])\n}\n\nOr you might try this function on a vector that includes an infinite value:\n\nx <- c(1:10, Inf)\nrescale01(x)\n#>  [1]   0   0   0   0   0   0   0   0   0   0 NaN\n\nThat result is not particularly useful so we could ask range() to ignore infinite values:\n\nrescale01 <- function(x) {\n  rng <- range(x, na.rm = TRUE, finite = TRUE)\n  (x - rng[1]) / (rng[2] - rng[1])\n}\n\nrescale01(x)\n#>  [1] 0.0000000 0.1111111 0.2222222 0.3333333 0.4444444 0.5555556 0.6666667\n#>  [8] 0.7777778 0.8888889 1.0000000       Inf\n\nThese changes illustrate an important benefit of functions: because we’ve moved the repeated code into a function, we only need to make the change in one place.\n\n26.2.3 Mutate functions\nNow you’ve got the basic idea of functions, let’s take a look at a whole bunch of examples. We’ll start by looking at “mutate” functions, i.e. functions that work well inside of mutate() and filter() because they return an output of the same length as the input.\nLet’s start with a simple variation of rescale01(). Maybe you want to compute the Z-score, rescaling a vector to have a mean of zero and a standard deviation of one:\n\nz_score <- function(x) {\n  (x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE)\n}\n\nOr maybe you want to wrap up a straightforward case_when() and give it a useful name. For example, this clamp() function ensures all values of a vector lie in between a minimum or a maximum:\n\nclamp <- function(x, min, max) {\n  case_when(\n    x < min ~ min,\n    x > max ~ max,\n    .default = x\n  )\n}\n\nclamp(1:10, min = 3, max = 7)\n#>  [1] 3 3 3 4 5 6 7 7 7 7\n\nOf course functions don’t just need to work with numeric variables. You might want to do some repeated string manipulation. Maybe you need to make the first character upper case:\n\nfirst_upper <- function(x) {\n  str_sub(x, 1, 1) <- str_to_upper(str_sub(x, 1, 1))\n  x\n}\n\nfirst_upper(\"hello\")\n#> [1] \"Hello\"\n\nOr maybe you want to strip percent signs, commas, and dollar signs from a string before converting it into a number:\n\n# https://twitter.com/NVlabormarket/status/1571939851922198530\nclean_number <- function(x) {\n  is_pct <- str_detect(x, \"%\")\n  num <- x |> \n    str_remove_all(\"%\") |> \n    str_remove_all(\",\") |> \n    str_remove_all(fixed(\"$\")) |> \n    as.numeric(x)\n  if_else(is_pct, num / 100, num)\n}\n\nclean_number(\"$12,300\")\n#> [1] 12300\nclean_number(\"45%\")\n#> [1] 0.45\n\nSometimes your functions will be highly specialized for one data analysis step. For example, if you have a bunch of variables that record missing values as 997, 998, or 999, you might want to write a function to replace them with NA:\n\nfix_na <- function(x) {\n  if_else(x %in% c(997, 998, 999), NA, x)\n}\n\nWe’ve focused on examples that take a single vector because we think they’re the most common. But there’s no reason that your function can’t take multiple vector inputs.\n\n26.2.4 Summary functions\nAnother important family of vector functions is summary functions, functions that return a single value for use in summarize(). Sometimes this can just be a matter of setting a default argument or two:\n\ncommas <- function(x) {\n  str_flatten(x, collapse = \", \", last = \" and \")\n}\n\ncommas(c(\"cat\", \"dog\", \"pigeon\"))\n#> [1] \"cat, dog and pigeon\"\n\nOr you might wrap up a simple computation, like for the coefficient of variation, which divides the standard deviation by the mean:\n\ncv <- function(x, na.rm = FALSE) {\n  sd(x, na.rm = na.rm) / mean(x, na.rm = na.rm)\n}\n\ncv(runif(100, min = 0, max = 50))\n#> [1] 0.5196276\ncv(runif(100, min = 0, max = 500))\n#> [1] 0.5652554\n\nOr maybe you just want to make a common pattern easier to remember by giving it a memorable name:\n\n# https://twitter.com/gbganalyst/status/1571619641390252033\nn_missing <- function(x) {\n  sum(is.na(x))\n} \n\nYou can also write functions with multiple vector inputs. For example, maybe you want to compute the mean absolute prediction error to help you compare model predictions with actual values:\n\n# https://twitter.com/neilgcurrie/status/1571607727255834625\nmape <- function(actual, predicted) {\n  sum(abs((actual - predicted) / actual)) / length(actual)\n}\n\n\n\n\n\n\n\nRStudio\n\n\n\nOnce you start writing functions, there are two RStudio shortcuts that are super useful:\n\nTo find the definition of a function that you’ve written, place the cursor on the name of the function and press F2.\nTo quickly jump to a function, press Ctrl + . to open the fuzzy file and function finder and type the first few letters of your function name. You can also navigate to files, Quarto sections, and more, making it a very handy navigation tool.\n\n\n\n\n26.2.5 Exercises\n\n\nPractice turning the following code snippets into functions. Think about what each function does. What would you call it? How many arguments does it need?\n\nmean(is.na(x))\nmean(is.na(y))\nmean(is.na(z))\n\nx / sum(x, na.rm = TRUE)\ny / sum(y, na.rm = TRUE)\nz / sum(z, na.rm = TRUE)\n\nround(x / sum(x, na.rm = TRUE) * 100, 1)\nround(y / sum(y, na.rm = TRUE) * 100, 1)\nround(z / sum(z, na.rm = TRUE) * 100, 1)\n\n\nIn the second variant of rescale01(), infinite values are left unchanged. Can you rewrite rescale01() so that -Inf is mapped to 0, and Inf is mapped to 1?\nGiven a vector of birthdates, write a function to compute the age in years.\nWrite your own functions to compute the variance and skewness of a numeric vector. You can look up the definitions on Wikipedia or elsewhere.\nWrite both_na(), a summary function that takes two vectors of the same length and returns the number of positions that have an NA in both vectors.\n\nRead the documentation to figure out what the following functions do. Why are they useful even though they are so short?\n\nis_directory <- function(x) {\n  file.info(x)$isdir\n}\nis_readable <- function(x) {\n  file.access(x, 4) == 0\n}"
  },
  {
    "objectID": "functions.html#data-frame-functions",
    "href": "functions.html#data-frame-functions",
    "title": "26  Functions",
    "section": "\n26.3 Data frame functions",
    "text": "26.3 Data frame functions\nVector functions are useful for pulling out code that’s repeated within a dplyr verb. But you’ll often also repeat the verbs themselves, particularly within a large pipeline. When you notice yourself copying and pasting multiple verbs multiple times, you might think about writing a data frame function. Data frame functions work like dplyr verbs: they take a data frame as the first argument, some extra arguments that say what to do with it, and return a data frame or vector.\nTo let you write a function that uses dplyr verbs, we’ll first introduce you to the challenge of indirection and how you can overcome it with embracing, {{ }}. With this theory under your belt, we’ll then show you a bunch of examples to illustrate what you might do with it.\n\n26.3.1 Indirection and tidy evaluation\nWhen you start writing functions that use dplyr verbs you rapidly hit the problem of indirection. Let’s illustrate the problem with a very simple function: grouped_mean(). The goal of this function is compute the mean of mean_var grouped by group_var:\n\ngrouped_mean <- function(df, group_var, mean_var) {\n  df |> \n    group_by(group_var) |> \n    summarize(mean(mean_var))\n}\n\nIf we try and use it, we get an error:\n\ndiamonds |> grouped_mean(cut, carat)\n#> Error in `group_by()`:\n#> ! Must group by variables found in `.data`.\n#> ✖ Column `group_var` is not found.\n\nTo make the problem a bit more clear, we can use a made up data frame:\n\ndf <- tibble(\n  mean_var = 1,\n  group_var = \"g\",\n  group = 1,\n  x = 10,\n  y = 100\n)\n\ndf |> grouped_mean(group, x)\n#> # A tibble: 1 × 2\n#>   group_var `mean(mean_var)`\n#>   <chr>                <dbl>\n#> 1 g                        1\ndf |> grouped_mean(group, y)\n#> # A tibble: 1 × 2\n#>   group_var `mean(mean_var)`\n#>   <chr>                <dbl>\n#> 1 g                        1\n\nRegardless of how we call grouped_mean() it always does df |> group_by(group_var) |> summarize(mean(mean_var)), instead of df |> group_by(group) |> summarize(mean(x)) or df |> group_by(group) |> summarize(mean(y)). This is a problem of indirection, and it arises because dplyr uses tidy evaluation to allow you to refer to the names of variables inside your data frame without any special treatment.\nTidy evaluation is great 95% of the time because it makes your data analyses very concise as you never have to say which data frame a variable comes from; it’s obvious from the context. The downside of tidy evaluation comes when we want to wrap up repeated tidyverse code into a function. Here we need some way to tell group_mean() and summarize() not to treat group_var and mean_var as the name of the variables, but instead look inside them for the variable we actually want to use.\nTidy evaluation includes a solution to this problem called embracing 🤗. Embracing a variable means to wrap it in braces so (e.g.) var becomes {{ var }}. Embracing a variable tells dplyr to use the value stored inside the argument, not the argument as the literal variable name. One way to remember what’s happening is to think of {{ }} as looking down a tunnel — {{ var }} will make a dplyr function look inside of var rather than looking for a variable called var.\nSo to make grouped_mean() work, we need to surround group_var and mean_var() with {{ }}:\n\ngrouped_mean <- function(df, group_var, mean_var) {\n  df |> \n    group_by({{ group_var }}) |> \n    summarize(mean({{ mean_var }}))\n}\n\ndf |> grouped_mean(group, x)\n#> # A tibble: 1 × 2\n#>   group `mean(x)`\n#>   <dbl>     <dbl>\n#> 1     1        10\n\nSuccess!\n\n26.3.2 When to embrace?\nSo the key challenge in writing data frame functions is figuring out which arguments need to be embraced. Fortunately, this is easy because you can look it up from the documentation 😄. There are two terms to look for in the docs which correspond to the two most common sub-types of tidy evaluation:\n\nData-masking: this is used in functions like arrange(), filter(), and summarize() that compute with variables.\nTidy-selection: this is used for functions like select(), relocate(), and rename() that select variables.\n\nYour intuition about which arguments use tidy evaluation should be good for many common functions — just think about whether you can compute (e.g. x + 1) or select (e.g. a:x).\nIn the following sections, we’ll explore the sorts of handy functions you might write once you understand embracing.\n\n26.3.3 Common use cases\nIf you commonly perform the same set of summaries when doing initial data exploration, you might consider wrapping them up in a helper function:\n\nsummary6 <- function(data, var) {\n  data |> summarize(\n    min = min({{ var }}, na.rm = TRUE),\n    mean = mean({{ var }}, na.rm = TRUE),\n    median = median({{ var }}, na.rm = TRUE),\n    max = max({{ var }}, na.rm = TRUE),\n    n = n(),\n    n_miss = sum(is.na({{ var }})),\n    .groups = \"drop\"\n  )\n}\n\ndiamonds |> summary6(carat)\n#> # A tibble: 1 × 6\n#>     min  mean median   max     n n_miss\n#>   <dbl> <dbl>  <dbl> <dbl> <int>  <int>\n#> 1   0.2 0.798    0.7  5.01 53940      0\n\n(Whenever you wrap summarize() in a helper, we think it’s good practice to set .groups = \"drop\" to both avoid the message and leave the data in an ungrouped state.)\nThe nice thing about this function is, because it wraps summarize(), you can use it on grouped data:\n\ndiamonds |> \n  group_by(cut) |> \n  summary6(carat)\n#> # A tibble: 5 × 7\n#>   cut         min  mean median   max     n n_miss\n#>   <ord>     <dbl> <dbl>  <dbl> <dbl> <int>  <int>\n#> 1 Fair       0.22 1.05    1     5.01  1610      0\n#> 2 Good       0.23 0.849   0.82  3.01  4906      0\n#> 3 Very Good  0.2  0.806   0.71  4    12082      0\n#> 4 Premium    0.2  0.892   0.86  4.01 13791      0\n#> 5 Ideal      0.2  0.703   0.54  3.5  21551      0\n\nFurthermore, since the arguments to summarize are data-masking also means that the var argument to summary6() is data-masking. That means you can also summarize computed variables:\n\ndiamonds |> \n  group_by(cut) |> \n  summary6(log10(carat))\n#> # A tibble: 5 × 7\n#>   cut          min    mean  median   max     n n_miss\n#>   <ord>      <dbl>   <dbl>   <dbl> <dbl> <int>  <int>\n#> 1 Fair      -0.658 -0.0273  0      0.700  1610      0\n#> 2 Good      -0.638 -0.133  -0.0862 0.479  4906      0\n#> 3 Very Good -0.699 -0.164  -0.149  0.602 12082      0\n#> 4 Premium   -0.699 -0.125  -0.0655 0.603 13791      0\n#> 5 Ideal     -0.699 -0.225  -0.268  0.544 21551      0\n\nTo summarize multiple variables, you’ll need to wait until Section 27.2, where you’ll learn how to use across().\nAnother popular summarize() helper function is a version of count() that also computes proportions:\n\n# https://twitter.com/Diabb6/status/1571635146658402309\ncount_prop <- function(df, var, sort = FALSE) {\n  df |>\n    count({{ var }}, sort = sort) |>\n    mutate(prop = n / sum(n))\n}\n\ndiamonds |> count_prop(clarity)\n#> # A tibble: 8 × 3\n#>   clarity     n   prop\n#>   <ord>   <int>  <dbl>\n#> 1 I1        741 0.0137\n#> 2 SI2      9194 0.170 \n#> 3 SI1     13065 0.242 \n#> 4 VS2     12258 0.227 \n#> 5 VS1      8171 0.151 \n#> 6 VVS2     5066 0.0939\n#> # ℹ 2 more rows\n\nThis function has three arguments: df, var, and sort, and only var needs to be embraced because it’s passed to count() which uses data-masking for all variables. Note that we use a default value for sort so that if the user doesn’t supply their own value it will default to FALSE.\nOr maybe you want to find the sorted unique values of a variable for a subset of the data. Rather than supplying a variable and a value to do the filtering, we’ll allow the user to supply a condition:\n\nunique_where <- function(df, condition, var) {\n  df |> \n    filter({{ condition }}) |> \n    distinct({{ var }}) |> \n    arrange({{ var }})\n}\n\n# Find all the destinations in December\nflights |> unique_where(month == 12, dest)\n#> # A tibble: 96 × 1\n#>   dest \n#>   <chr>\n#> 1 ABQ  \n#> 2 ALB  \n#> 3 ATL  \n#> 4 AUS  \n#> 5 AVL  \n#> 6 BDL  \n#> # ℹ 90 more rows\n\nHere we embrace condition because it’s passed to filter() and var because it’s passed to distinct() and arrange().\nWe’ve made all these examples to take a data frame as the first argument, but if you’re working repeatedly with the same data, it can make sense to hardcode it. For example, the following function always works with the flights dataset and always selects time_hour, carrier, and flight since they form the compound primary key that allows you to identify a row.\n\nsubset_flights <- function(rows, cols) {\n  flights |> \n    filter({{ rows }}) |> \n    select(time_hour, carrier, flight, {{ cols }})\n}\n\n\n26.3.4 Data-masking vs. tidy-selection\nSometimes you want to select variables inside a function that uses data-masking. For example, imagine you want to write a count_missing() that counts the number of missing observations in rows. You might try writing something like:\n\ncount_missing <- function(df, group_vars, x_var) {\n  df |> \n    group_by({{ group_vars }}) |> \n    summarize(\n      n_miss = sum(is.na({{ x_var }})),\n      .groups = \"drop\"\n    )\n}\n\nflights |> \n  count_missing(c(year, month, day), dep_time)\n#> Error in `group_by()`:\n#> ℹ In argument: `c(year, month, day)`.\n#> Caused by error:\n#> ! `c(year, month, day)` must be size 336776 or 1, not 1010328.\n\nThis doesn’t work because group_by() uses data-masking, not tidy-selection. We can work around that problem by using the handy pick() function, which allows you to use tidy-selection inside data-masking functions:\n\ncount_missing <- function(df, group_vars, x_var) {\n  df |> \n    group_by(pick({{ group_vars }})) |> \n    summarize(\n      n_miss = sum(is.na({{ x_var }})),\n      .groups = \"drop\"\n  )\n}\n\nflights |> \n  count_missing(c(year, month, day), dep_time)\n#> # A tibble: 365 × 4\n#>    year month   day n_miss\n#>   <int> <int> <int>  <int>\n#> 1  2013     1     1      4\n#> 2  2013     1     2      8\n#> 3  2013     1     3     10\n#> 4  2013     1     4      6\n#> 5  2013     1     5      3\n#> 6  2013     1     6      1\n#> # ℹ 359 more rows\n\nAnother convenient use of pick() is to make a 2d table of counts. Here we count using all the variables in the rows and columns, then use pivot_wider() to rearrange the counts into a grid:\n\n# https://twitter.com/pollicipes/status/1571606508944719876\ncount_wide <- function(data, rows, cols) {\n  data |> \n    count(pick(c({{ rows }}, {{ cols }}))) |> \n    pivot_wider(\n      names_from = {{ cols }}, \n      values_from = n,\n      names_sort = TRUE,\n      values_fill = 0\n    )\n}\n\ndiamonds |> count_wide(c(clarity, color), cut)\n#> # A tibble: 56 × 7\n#>   clarity color  Fair  Good `Very Good` Premium Ideal\n#>   <ord>   <ord> <int> <int>       <int>   <int> <int>\n#> 1 I1      D         4     8           5      12    13\n#> 2 I1      E         9    23          22      30    18\n#> 3 I1      F        35    19          13      34    42\n#> 4 I1      G        53    19          16      46    16\n#> 5 I1      H        52    14          12      46    38\n#> 6 I1      I        34     9           8      24    17\n#> # ℹ 50 more rows\n\nWhile our examples have mostly focused on dplyr, tidy evaluation also underpins tidyr, and if you look at the pivot_wider() docs you can see that names_from uses tidy-selection.\n\n26.3.5 Exercises\n\n\nUsing the datasets from nycflights13, write a function that:\n\n\nFinds all flights that were cancelled (i.e. is.na(arr_time)) or delayed by more than an hour.\n\nflights |> filter_severe()\n\n\n\nCounts the number of cancelled flights and the number of flights delayed by more than an hour.\n\nflights |> group_by(dest) |> summarize_severe()\n\n\n\nFinds all flights that were cancelled or delayed by more than a user supplied number of hours:\n\nflights |> filter_severe(hours = 2)\n\n\n\nSummarizes the weather to compute the minimum, mean, and maximum, of a user supplied variable:\n\nweather |> summarize_weather(temp)\n\n\n\nConverts the user supplied variable that uses clock time (e.g. dep_time, arr_time, etc.) into a decimal time (i.e. hours + (minutes / 60)).\n\nflights |> standardize_time(sched_dep_time)\n\n\n\n\nFor each of the following functions list all arguments that use tidy evaluation and describe whether they use data-masking or tidy-selection: distinct(), count(), group_by(), rename_with(), slice_min(), slice_sample().\n\nGeneralize the following function so that you can supply any number of variables to count.\n\ncount_prop <- function(df, var, sort = FALSE) {\n  df |>\n    count({{ var }}, sort = sort) |>\n    mutate(prop = n / sum(n))\n}"
  },
  {
    "objectID": "functions.html#plot-functions",
    "href": "functions.html#plot-functions",
    "title": "26  Functions",
    "section": "\n26.4 Plot functions",
    "text": "26.4 Plot functions\nInstead of returning a data frame, you might want to return a plot. Fortunately, you can use the same techniques with ggplot2, because aes() is a data-masking function. For example, imagine that you’re making a lot of histograms:\n\ndiamonds |> \n  ggplot(aes(x = carat)) +\n  geom_histogram(binwidth = 0.1)\n\ndiamonds |> \n  ggplot(aes(x = carat)) +\n  geom_histogram(binwidth = 0.05)\n\nWouldn’t it be nice if you could wrap this up into a histogram function? This is easy as pie once you know that aes() is a data-masking function and you need to embrace:\n\nhistogram <- function(df, var, binwidth = NULL) {\n  df |> \n    ggplot(aes(x = {{ var }})) + \n    geom_histogram(binwidth = binwidth)\n}\n\ndiamonds |> histogram(carat, 0.1)\n\n\n\n\nNote that histogram() returns a ggplot2 plot, meaning you can still add on additional components if you want. Just remember to switch from |> to +:\n\ndiamonds |> \n  histogram(carat, 0.1) +\n  labs(x = \"Size (in carats)\", y = \"Number of diamonds\")\n\n\n26.4.1 More variables\nIt’s straightforward to add more variables to the mix. For example, maybe you want an easy way to eyeball whether or not a dataset is linear by overlaying a smooth line and a straight line:\n\n# https://twitter.com/tyler_js_smith/status/1574377116988104704\nlinearity_check <- function(df, x, y) {\n  df |>\n    ggplot(aes(x = {{ x }}, y = {{ y }})) +\n    geom_point() +\n    geom_smooth(method = \"loess\", formula = y ~ x, color = \"red\", se = FALSE) +\n    geom_smooth(method = \"lm\", formula = y ~ x, color = \"blue\", se = FALSE) \n}\n\nstarwars |> \n  filter(mass < 1000) |> \n  linearity_check(mass, height)\n\n\n\n\nOr maybe you want an alternative to colored scatterplots for very large datasets where overplotting is a problem:\n\n# https://twitter.com/ppaxisa/status/1574398423175921665\nhex_plot <- function(df, x, y, z, bins = 20, fun = \"mean\") {\n  df |> \n    ggplot(aes(x = {{ x }}, y = {{ y }}, z = {{ z }})) + \n    stat_summary_hex(\n      aes(color = after_scale(fill)), # make border same color as fill\n      bins = bins, \n      fun = fun,\n    )\n}\n\ndiamonds |> hex_plot(carat, price, depth)\n\n\n\n\n\n26.4.2 Combining with other tidyverse\nSome of the most useful helpers combine a dash of data manipulation with ggplot2. For example, if you might want to do a vertical bar chart where you automatically sort the bars in frequency order using fct_infreq(). Since the bar chart is vertical, we also need to reverse the usual order to get the highest values at the top:\n\nsorted_bars <- function(df, var) {\n  df |> \n    mutate({{ var }} := fct_rev(fct_infreq({{ var }})))  |>\n    ggplot(aes(y = {{ var }})) +\n    geom_bar()\n}\n\ndiamonds |> sorted_bars(clarity)\n\n\n\n\nWe have to use a new operator here, :=, because we are generating the variable name based on user-supplied data. Variable names go on the left hand side of =, but R’s syntax doesn’t allow anything to the left of = except for a single literal name. To work around this problem, we use the special operator := which tidy evaluation treats in exactly the same way as =.\nOr maybe you want to make it easy to draw a bar plot just for a subset of the data:\n\nconditional_bars <- function(df, condition, var) {\n  df |> \n    filter({{ condition }}) |> \n    ggplot(aes(x = {{ var }})) + \n    geom_bar()\n}\n\ndiamonds |> conditional_bars(cut == \"Good\", clarity)\n\n\n\n\nYou can also get creative and display data summaries in other ways. You can find a cool application at https://gist.github.com/GShotwell/b19ef520b6d56f61a830fabb3454965b; it uses the axis labels to display the highest value. As you learn more about ggplot2, the power of your functions will continue to increase.\nWe’ll finish with a more complicated case: labelling the plots you create.\n\n26.4.3 Labeling\nRemember the histogram function we showed you earlier?\n\nhistogram <- function(df, var, binwidth = NULL) {\n  df |> \n    ggplot(aes(x = {{ var }})) + \n    geom_histogram(binwidth = binwidth)\n}\n\nWouldn’t it be nice if we could label the output with the variable and the bin width that was used? To do so, we’re going to have to go under the covers of tidy evaluation and use a function from the package we haven’t talked about yet: rlang. rlang is a low-level package that’s used by just about every other package in the tidyverse because it implements tidy evaluation (as well as many other useful tools).\nTo solve the labeling problem we can use rlang::englue(). This works similarly to str_glue(), so any value wrapped in { } will be inserted into the string. But it also understands {{ }}, which automatically inserts the appropriate variable name:\n\nhistogram <- function(df, var, binwidth) {\n  label <- rlang::englue(\"A histogram of {{var}} with binwidth {binwidth}\")\n  \n  df |> \n    ggplot(aes(x = {{ var }})) + \n    geom_histogram(binwidth = binwidth) + \n    labs(title = label)\n}\n\ndiamonds |> histogram(carat, 0.1)\n\n\n\n\nYou can use the same approach in any other place where you want to supply a string in a ggplot2 plot.\n\n26.4.4 Exercises\nBuild up a rich plotting function by incrementally implementing each of the steps below:\n\nDraw a scatterplot given dataset and x and y variables.\nAdd a line of best fit (i.e. a linear model with no standard errors).\nAdd a title."
  },
  {
    "objectID": "functions.html#style",
    "href": "functions.html#style",
    "title": "26  Functions",
    "section": "\n26.5 Style",
    "text": "26.5 Style\nR doesn’t care what your function or arguments are called but the names make a big difference for humans. Ideally, the name of your function will be short, but clearly evoke what the function does. That’s hard! But it’s better to be clear than short, as RStudio’s autocomplete makes it easy to type long names.\nGenerally, function names should be verbs, and arguments should be nouns. There are some exceptions: nouns are ok if the function computes a very well known noun (i.e. mean() is better than compute_mean()), or accessing some property of an object (i.e. coef() is better than get_coefficients()). Use your best judgement and don’t be afraid to rename a function if you figure out a better name later.\n\n# Too short\nf()\n\n# Not a verb, or descriptive\nmy_awesome_function()\n\n# Long, but clear\nimpute_missing()\ncollapse_years()\n\nR also doesn’t care about how you use white space in your functions but future readers will. Continue to follow the rules from Chapter 5. Additionally, function() should always be followed by squiggly brackets ({}), and the contents should be indented by an additional two spaces. This makes it easier to see the hierarchy in your code by skimming the left-hand margin.\n\n# missing extra two spaces\ndensity <- function(color, facets, binwidth = 0.1) {\ndiamonds |> \n  ggplot(aes(x = carat, y = after_stat(density), color = {{ color }})) +\n  geom_freqpoly(binwidth = binwidth) +\n  facet_wrap(vars({{ facets }}))\n}\n\n# Pipe indented incorrectly\ndensity <- function(color, facets, binwidth = 0.1) {\n  diamonds |> \n  ggplot(aes(x = carat, y = after_stat(density), color = {{ color }})) +\n  geom_freqpoly(binwidth = binwidth) +\n  facet_wrap(vars({{ facets }}))\n}\n\nAs you can see we recommend putting extra spaces inside of {{ }}. This makes it very obvious that something unusual is happening.\n\n26.5.1 Exercises\n\n\nRead the source code for each of the following two functions, puzzle out what they do, and then brainstorm better names.\n\nf1 <- function(string, prefix) {\n  str_sub(string, 1, str_length(prefix)) == prefix\n}\n\nf3 <- function(x, y) {\n  rep(y, length.out = length(x))\n}\n\n\nTake a function that you’ve written recently and spend 5 minutes brainstorming a better name for it and its arguments.\nMake a case for why norm_r(), norm_d() etc. would be better than rnorm(), dnorm(). Make a case for the opposite. How could you make the names even clearer?"
  },
  {
    "objectID": "functions.html#summary",
    "href": "functions.html#summary",
    "title": "26  Functions",
    "section": "\n26.6 Summary",
    "text": "26.6 Summary\nIn this chapter, you learned how to write functions for three useful scenarios: creating a vector, creating a data frames, or creating a plot. Along the way you saw many examples, which hopefully started to get your creative juices flowing, and gave you some ideas for where functions might help your analysis code.\nWe have only shown you the bare minimum to get started with functions and there’s much more to learn. A few places to learn more are:\n\nTo learn more about programming with tidy evaluation, see useful recipes in programming with dplyr and programming with tidyr and learn more about the theory in What is data-masking and why do I need {{?.\nTo learn more about reducing duplication in your ggplot2 code, read the Programming with ggplot2 chapter of the ggplot2 book.\nFor more advice on function style, see the tidyverse style guide.\n\nIn the next chapter, we’ll dive into some of the details of R’s vector data structures that we’ve omitted so far. These are not immediately useful by themselves, but are a necessary foundation for the following chapter on iteration which gives you further tools for reducing code duplication."
  },
  {
    "objectID": "iteration.html#introduction",
    "href": "iteration.html#introduction",
    "title": "27  Iteration",
    "section": "\n27.1 Introduction",
    "text": "27.1 Introduction\nIn this chapter, you’ll learn tools for iteration, repeatedly performing the same action on different objects. Iteration in R generally tends to look rather different from other programming languages because so much of it is implicit and we get it for free. For example, if you want to double a numeric vector x in R, you can just write 2 * x. In most other languages, you’d need to explicitly double each element of x using some sort of for loop.\nThis book has already given you a small but powerful number of tools that perform the same action for multiple “things”:\n\n\nfacet_wrap() and facet_grid() draws a plot for each subset.\n\ngroup_by() plus summarize() computes a summary statistics for each subset.\n\nunnest_wider() and unnest_longer() create new rows and columns for each element of a list-column.\n\nNow it’s time to learn some more general tools, often called functional programming tools because they are built around functions that take other functions as inputs. Learning functional programming can easily veer into the abstract, but in this chapter we’ll keep things concrete by focusing on three common tasks: modifying multiple columns, reading multiple files, and saving multiple objects.\n\n27.1.1 Prerequisites\nIn this chapter, we’ll focus on tools provided by dplyr and purrr, both core members of the tidyverse. You’ve seen dplyr before, but purrr is new. We’re just going to use a couple of purrr functions in this chapter, but it’s a great package to explore as you improve your programming skills.\n\nlibrary(tidyverse)\n#> Warning: package 'tibble' was built under R version 4.2.3\n#> Warning: package 'readr' was built under R version 4.2.3\n#> Warning: package 'dplyr' was built under R version 4.2.3"
  },
  {
    "objectID": "iteration.html#sec-across",
    "href": "iteration.html#sec-across",
    "title": "27  Iteración",
    "section": "\n27.2 Modificar varias columnas",
    "text": "27.2 Modificar varias columnas\nImagina que tienes este tibble simple y quieres contar el número de observaciones y calcular la mediana de cada columna.\n\ndf &lt;- tibble(\n  a = rnorm(10),\n  b = rnorm(10),\n  c = rnorm(10),\n  d = rnorm(10)\n)\n\nPodrías hacerlo con copiar y pegar:\n\ndf |&gt; summarize(\n  n = n(),\n  a = median(a),\n  b = median(b),\n  c = median(c),\n  d = median(d),\n)\n#&gt; # A tibble: 1 × 5\n#&gt;       n      a      b       c     d\n#&gt;   &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1    10 -0.246 -0.287 -0.0567 0.144\n\nEso rompe nuestra regla general de nunca copiar y pegar más de dos veces, y puedes imaginar que esto se volverá muy tedioso si tienes decenas o incluso cientos de columnas. En su lugar, puedes usar across():\n\ndf |&gt; summarize(\n  n = n(),\n  across(a:d, median),\n)\n#&gt; # A tibble: 1 × 5\n#&gt;       n      a      b       c     d\n#&gt;   &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1    10 -0.246 -0.287 -0.0567 0.144\n\nacross() tiene tres argumentos particularmente importantes, que discutiremos en detalle en las siguientes secciones. Usará los dos primeros cada vez que use across(): el primer argumento, .cols, especifica sobre qué columnas desea iterar, y el segundo argumento, .fns, especifica qué hacer con cada columna Puedes usar el argumento .names cuando necesites un control adicional sobre los nombres de las columnas de salida, lo cual es particularmente importante cuando usas across() con mutate(). También discutiremos dos variaciones importantes, if_any() y if_all(), que funcionan con filter().\n\n27.2.1 Selección de columnas con .cols\n\nEl primer argumento de across(), .cols, selecciona las columnas para transformar. Esto usa las mismas especificaciones que select(), Sección 4.3.2, por lo que puede usar funciones como starts_with() y ends_with() para seleccionar columnas según su nombre.\nHay dos técnicas de selección adicionales que son particularmente útiles para across(): everything() y where(). everything() es sencillo: selecciona todas las columnas (no agrupadas):\n\ndf &lt;- tibble(\n  grp = sample(2, 10, replace = TRUE),\n  a = rnorm(10),\n  b = rnorm(10),\n  c = rnorm(10),\n  d = rnorm(10)\n)\n\ndf |&gt; \n  group_by(grp) |&gt; \n  summarize(across(everything(), median))\n#&gt; # A tibble: 2 × 5\n#&gt;     grp       a       b     c     d\n#&gt;   &lt;int&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1 -0.0935 -0.0163 0.363 0.364\n#&gt; 2     2  0.312  -0.0576 0.208 0.565\n\nTenga en cuenta que las columnas de agrupación (grp aquí) no se incluyen en across(), porque summarize() las conserva automáticamente.\nwhere() le permite seleccionar columnas según su tipo:\n\n\nwhere(is.numeric) selecciona todas las columnas numéricas.\n\nwhere(is.character) selecciona todas las columnas de cadena.\n\nwhere(is.Date) selecciona todas las columnas de fecha.\n\nwhere(is.POSIXct) selecciona todas las columnas de fecha y hora.\n\nwhere(is.logical) selecciona todas las columnas lógicas.\n\nAl igual que otros selectores, puede combinarlos con álgebra booleana. Por ejemplo, !where(is.numeric) selecciona todas las columnas no numéricas, y starts_with(\"a\") & where(is.logical) selecciona todas las columnas lógicas cuyo nombre comienza con “a”.\n\n27.2.2 Llamar a una sola función\nEl segundo argumento de across() define cómo se transformará cada columna. En casos simples, como el anterior, esta será una sola función existente. Esta es una característica bastante especial de R: estamos pasando una función (median, mean, str_flatten, …) a otra función (across). Esta es una de las características que hace de R un lenguaje de programación funcional.\nEs importante tener en cuenta que estamos pasando esta función a across(), por lo que across() puede llamarla; no lo estamos llamando nosotros mismos. Eso significa que el nombre de la función nunca debe ir seguido de (). Si lo olvida, obtendrá un error:\n\ndf |&gt; \n  group_by(grp) |&gt; \n  summarize(across(everything(), median()))\n#&gt; Error in `summarize()`:\n#&gt; ℹ In argument: `across(everything(), median())`.\n#&gt; Caused by error in `median.default()`:\n#&gt; ! el argumento \"x\" está ausente, sin valor por omisión\n\nEste error surge porque está llamando a la función sin entrada, por ejemplo:\n\nmedian()\n#&gt; Error in median.default(): el argumento \"x\" está ausente, sin valor por omisión\n\n\n27.2.3 Llamar a múltiples funciones\nEn casos más complejos, es posible que desee proporcionar argumentos adicionales o realizar varias transformaciones. Motivemos este problema con un ejemplo simple: ¿qué sucede si tenemos algunos valores faltantes en nuestros datos? median() propaga esos valores perdidos, dándonos un resultado subóptimo:\n\nrnorm_na &lt;- function(n, n_na, mean = 0, sd = 1) {\n  sample(c(rnorm(n - n_na, mean = mean, sd = sd), rep(NA, n_na)))\n}\n\ndf_miss &lt;- tibble(\n  a = rnorm_na(5, 1),\n  b = rnorm_na(5, 1),\n  c = rnorm_na(5, 2),\n  d = rnorm(5)\n)\ndf_miss |&gt; \n  summarize(\n    across(a:d, median),\n    n = n()\n  )\n#&gt; # A tibble: 1 × 5\n#&gt;       a     b     c     d     n\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n#&gt; 1    NA    NA    NA  1.15     5\n\nSería bueno si pudiéramos pasar na.rm = TRUE a median() para eliminar estos valores faltantes. Para hacerlo, en lugar de llamar a median() directamente, necesitamos crear una nueva función que llame a median() con los argumentos deseados:\n\ndf_miss |&gt; \n  summarize(\n    across(a:d, function(x) median(x, na.rm = TRUE)),\n    n = n()\n  )\n#&gt; # A tibble: 1 × 5\n#&gt;       a     b      c     d     n\n#&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n#&gt; 1 0.139 -1.11 -0.387  1.15     5\n\nEsto es un poco detallado, por lo que R viene con un atajo útil: para este tipo de función desechable, o anónima1, puede reemplazar función con \\[^iteration-2 ]:\n\ndf_miss |&gt; \n  summarize(\n    across(a:d, \\(x) median(x, na.rm = TRUE)),\n    n = n()\n  )\n\nEn cualquier caso, across() se expande efectivamente al siguiente código:\n\ndf_miss |&gt; \n  summarize(\n    a = median(a, na.rm = TRUE),\n    b = median(b, na.rm = TRUE),\n    c = median(c, na.rm = TRUE),\n    d = median(d, na.rm = TRUE),\n    n = n()\n  )\n\nCuando eliminamos los valores que faltan de la mediana, median(), sería bueno saber cuántos valores se eliminaron. Podemos averiguarlo proporcionando dos funciones a across(): una para calcular la mediana y la otra para contar los valores que faltan. Proporciona múltiples funciones usando una lista con nombre para .fns:\n\ndf_miss |&gt; \n  summarize(\n    across(a:d, list(\n      median = \\(x) median(x, na.rm = TRUE),\n      n_miss = \\(x) sum(is.na(x))\n    )),\n    n = n()\n  )\n#&gt; # A tibble: 1 × 9\n#&gt;   a_median a_n_miss b_median b_n_miss c_median c_n_miss d_median d_n_miss\n#&gt;      &lt;dbl&gt;    &lt;int&gt;    &lt;dbl&gt;    &lt;int&gt;    &lt;dbl&gt;    &lt;int&gt;    &lt;dbl&gt;    &lt;int&gt;\n#&gt; 1    0.139        1    -1.11        1   -0.387        2     1.15        0\n#&gt; # ℹ 1 more variable: n &lt;int&gt;\n\nSi observa detenidamente, puede intuir que las columnas se nombran utilizando una especificación de pegamento (Sección 15.3.2) como {.col}_{.fn} donde .col es el nombre de la columna original y . fn es el nombre de la función. ¡Eso no es una coincidencia! Como aprenderá en la siguiente sección, puede usar el argumento .names para proporcionar su propia especificación de pegamento.\n\n27.2.4 Nombres de columna\nEl resultado de across() se nombra de acuerdo con la especificación provista en el argumento .names. Podríamos especificar el nuestro si quisiéramos que el nombre de la función fuera primero 2:\n\ndf_miss |&gt; \n  summarize(\n    across(\n      a:d,\n      list(\n        median = \\(x) median(x, na.rm = TRUE),\n        n_miss = \\(x) sum(is.na(x))\n      ),\n      .names = \"{.fn}_{.col}\"\n    ),\n    n = n(),\n  )\n#&gt; # A tibble: 1 × 9\n#&gt;   median_a n_miss_a median_b n_miss_b median_c n_miss_c median_d n_miss_d\n#&gt;      &lt;dbl&gt;    &lt;int&gt;    &lt;dbl&gt;    &lt;int&gt;    &lt;dbl&gt;    &lt;int&gt;    &lt;dbl&gt;    &lt;int&gt;\n#&gt; 1    0.139        1    -1.11        1   -0.387        2     1.15        0\n#&gt; # ℹ 1 more variable: n &lt;int&gt;\n\nEl argumento .names es particularmente importante cuando usas across() con mutate(). Por defecto, la salida de across() recibe los mismos nombres que las entradas. Esto significa que across() dentro de mutate() reemplazará las columnas existentes. Por ejemplo, aquí usamos coalesce() para reemplazar NAs con 0:\n\ndf_miss |&gt; \n  mutate(\n    across(a:d, \\(x) coalesce(x, 0))\n  )\n#&gt; # A tibble: 5 × 4\n#&gt;        a      b      c     d\n#&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1  0.434 -1.25   0     1.60 \n#&gt; 2  0     -1.43  -0.297 0.776\n#&gt; 3 -0.156 -0.980  0     1.15 \n#&gt; 4 -2.61  -0.683 -0.785 2.13 \n#&gt; 5  1.11   0     -0.387 0.704\n\nSi desea crear nuevas columnas, puede usar el argumento .names para dar nuevos nombres a la salida:\n\ndf_miss |&gt; \n  mutate(\n    across(a:d, \\(x) coalesce(x), .names = \"{.col}_na_zeros\")\n  )\n#&gt; # A tibble: 5 × 8\n#&gt;        a      b      c     d a_na_zeros b_na_zeros c_na_zeros d_na_zeros\n#&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n#&gt; 1  0.434 -1.25  NA     1.60       0.434     -1.25      NA          1.60 \n#&gt; 2 NA     -1.43  -0.297 0.776     NA         -1.43      -0.297      0.776\n#&gt; 3 -0.156 -0.980 NA     1.15      -0.156     -0.980     NA          1.15 \n#&gt; 4 -2.61  -0.683 -0.785 2.13      -2.61      -0.683     -0.785      2.13 \n#&gt; 5  1.11  NA     -0.387 0.704      1.11      NA         -0.387      0.704\n\n\n27.2.5 Filtrando\nacross() es una gran combinación para summarize() y mutate(), pero es más incómodo de usar con filter(), porque generalmente combina varias condiciones con | o &. Está claro que across() puede ayudar a crear varias columnas lógicas, pero ¿entonces qué? Así que dplyr proporciona dos variantes de across() llamadas if_any() y if_all():\n\n# igual que df_miss |&gt; filter(is.na(a) | is.na(b) | is.na(c) | is.na(d))\ndf_miss |&gt; filter(if_any(a:d, is.na))\n#&gt; # A tibble: 4 × 4\n#&gt;        a      b      c     d\n#&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1  0.434 -1.25  NA     1.60 \n#&gt; 2 NA     -1.43  -0.297 0.776\n#&gt; 3 -0.156 -0.980 NA     1.15 \n#&gt; 4  1.11  NA     -0.387 0.704\n\n# igual que df_miss |&gt; filter(is.na(a) & is.na(b) & is.na(c) & is.na(d))\ndf_miss |&gt; filter(if_all(a:d, is.na))\n#&gt; # A tibble: 0 × 4\n#&gt; # ℹ 4 variables: a &lt;dbl&gt;, b &lt;dbl&gt;, c &lt;dbl&gt;, d &lt;dbl&gt;\n\n\n27.2.6 across() en funciones\nacross() es particularmente útil para programar porque te permite operar en múltiples columnas. Por ejemplo, Jacob Scott usa este pequeño ayudante que envuelve un montón de funciones de lubridate para expandir todas las columnas de fecha en columnas de año, mes y día:\n\nexpand_dates &lt;- function(df) {\n  df |&gt; \n    mutate(\n      across(where(is.Date), list(year = year, month = month, day = mday))\n    )\n}\n\ndf_date &lt;- tibble(\n  name = c(\"Amy\", \"Bob\"),\n  date = ymd(c(\"2009-08-03\", \"2010-01-16\"))\n)\n\ndf_date |&gt; \n  expand_dates()\n#&gt; # A tibble: 2 × 5\n#&gt;   name  date       date_year date_month date_day\n#&gt;   &lt;chr&gt; &lt;date&gt;         &lt;dbl&gt;      &lt;dbl&gt;    &lt;int&gt;\n#&gt; 1 Amy   2009-08-03      2009          8        3\n#&gt; 2 Bob   2010-01-16      2010          1       16\n\nacross() también facilita el suministro de múltiples columnas en un solo argumento porque el primer argumento usa tidy-select; solo necesita recordar abrazar ese argumento, como discutimos en Sección 26.3.2. Por ejemplo, esta función calculará las medias de las columnas numéricas de forma predeterminada. Pero al proporcionar el segundo argumento, puede optar por resumir solo las columnas seleccionadas:\n\nsummarize_means &lt;- function(df, summary_vars = where(is.numeric)) {\n  df |&gt; \n    summarize(\n      across({{ summary_vars }}, \\(x) mean(x, na.rm = TRUE)),\n      n = n(),\n      .groups = \"drop\"\n    )\n}\ndiamonds |&gt; \n  group_by(cut) |&gt; \n  summarize_means()\n#&gt; # A tibble: 5 × 9\n#&gt;   cut       carat depth table price     x     y     z     n\n#&gt;   &lt;ord&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n#&gt; 1 Fair      1.05   64.0  59.1 4359.  6.25  6.18  3.98  1610\n#&gt; 2 Good      0.849  62.4  58.7 3929.  5.84  5.85  3.64  4906\n#&gt; 3 Very Good 0.806  61.8  58.0 3982.  5.74  5.77  3.56 12082\n#&gt; 4 Premium   0.892  61.3  58.7 4584.  5.97  5.94  3.65 13791\n#&gt; 5 Ideal     0.703  61.7  56.0 3458.  5.51  5.52  3.40 21551\n\ndiamonds |&gt; \n  group_by(cut) |&gt; \n  summarize_means(c(carat, x:z))\n#&gt; # A tibble: 5 × 6\n#&gt;   cut       carat     x     y     z     n\n#&gt;   &lt;ord&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n#&gt; 1 Fair      1.05   6.25  6.18  3.98  1610\n#&gt; 2 Good      0.849  5.84  5.85  3.64  4906\n#&gt; 3 Very Good 0.806  5.74  5.77  3.56 12082\n#&gt; 4 Premium   0.892  5.97  5.94  3.65 13791\n#&gt; 5 Ideal     0.703  5.51  5.52  3.40 21551\n\n\n27.2.7 Vs pivot_longer()\n\nAntes de continuar, vale la pena señalar una conexión interesante entre across() y pivot_longer() (Sección 6.3). En muchos casos, usted realiza los mismos cálculos girando primero los datos y luego realizando las operaciones por grupo en lugar de por columna. Por ejemplo, tome este resumen multifunción:\n\ndf |&gt; \n  summarize(across(a:d, list(median = median, mean = mean)))\n#&gt; # A tibble: 1 × 8\n#&gt;   a_median a_mean b_median b_mean c_median c_mean d_median d_mean\n#&gt;      &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1   0.0380  0.205  -0.0163 0.0910    0.260 0.0716    0.540  0.508\n\nPodríamos calcular los mismos valores girando más y luego resumiendo:\n\nlong &lt;- df |&gt; \n  pivot_longer(a:d) |&gt; \n  group_by(name) |&gt; \n  summarize(\n    median = median(value),\n    mean = mean(value)\n  )\nlong\n#&gt; # A tibble: 4 × 3\n#&gt;   name   median   mean\n#&gt;   &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1 a      0.0380 0.205 \n#&gt; 2 b     -0.0163 0.0910\n#&gt; 3 c      0.260  0.0716\n#&gt; 4 d      0.540  0.508\n\nY si quisieras la misma estructura que across(), podrías pivotar de nuevo:\n\nlong |&gt; \n  pivot_wider(\n    names_from = name,\n    values_from = c(median, mean),\n    names_vary = \"slowest\",\n    names_glue = \"{name}_{.value}\"\n  )\n#&gt; # A tibble: 1 × 8\n#&gt;   a_median a_mean b_median b_mean c_median c_mean d_median d_mean\n#&gt;      &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n#&gt; 1   0.0380  0.205  -0.0163 0.0910    0.260 0.0716    0.540  0.508\n\nEsta es una técnica útil para conocer porque a veces te encontrarás con un problema que actualmente no es posible resolver con across(): cuando tienes grupos de columnas con las que quieres calcular simultáneamente. Por ejemplo, imagine que nuestro data frame contiene valores y pesos y queremos calcular una media ponderada:\n\ndf_paired &lt;- tibble(\n  a_val = rnorm(10),\n  a_wts = runif(10),\n  b_val = rnorm(10),\n  b_wts = runif(10),\n  c_val = rnorm(10),\n  c_wts = runif(10),\n  d_val = rnorm(10),\n  d_wts = runif(10)\n)\n\nActualmente no hay forma de hacer esto con across()3, pero es relativamente sencillo con pivot_longer():\n\ndf_long &lt;- df_paired |&gt; \n  pivot_longer(\n    everything(), \n    names_to = c(\"group\", \".value\"), \n    names_sep = \"_\"\n  )\ndf_long\n#&gt; # A tibble: 40 × 3\n#&gt;   group    val   wts\n#&gt;   &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 a      0.715 0.518\n#&gt; 2 b     -0.709 0.691\n#&gt; 3 c      0.718 0.216\n#&gt; 4 d     -0.217 0.733\n#&gt; 5 a     -1.09  0.979\n#&gt; 6 b     -0.209 0.675\n#&gt; # ℹ 34 more rows\n\ndf_long |&gt; \n  group_by(group) |&gt; \n  summarize(mean = weighted.mean(val, wts))\n#&gt; # A tibble: 4 × 2\n#&gt;   group    mean\n#&gt;   &lt;chr&gt;   &lt;dbl&gt;\n#&gt; 1 a      0.126 \n#&gt; 2 b     -0.0704\n#&gt; 3 c     -0.360 \n#&gt; 4 d     -0.248\n\nSi es necesario, puede pivot_wider() para devolverlo a la forma original.\n\n27.2.8 Ejercicios\n\n\nPractica tus habilidades across() al:\n\nCalcular el número de valores únicos en cada columna de palmerpenguins::penguins.\nCalcular la media de cada columna en mtcars.\nAgrupar ‘diamantes’ por ‘corte’, ‘claridad’ y ‘color’ y luego contar el número de observaciones y calcular la media de cada columna numérica.\n\n\n¿Qué pasa si usas una lista de funciones en across(), pero no las nombras? ¿Cómo se llama la salida?\nAjuste expand_dates() para eliminar automáticamente las columnas de fecha después de que se hayan expandido. ¿Necesitas aceptar algún argumento?\n\nExplique qué hace cada paso de la tubería en esta función. ¿Qué característica especial de where() estamos aprovechando?\n\nshow_missing &lt;- function(df, group_vars, summary_vars = everything()) {\n  df |&gt; \n    group_by(pick({{ group_vars }})) |&gt; \n    summarize(\n      across({{ summary_vars }}, \\(x) sum(is.na(x))),\n      .groups = \"drop\"\n    ) |&gt;\n    select(where(\\(x) any(x &gt; 0)))\n}\nnycflights13::flights |&gt; show_missing(c(year, month, day))"
  },
  {
    "objectID": "iteration.html#reading-multiple-files",
    "href": "iteration.html#reading-multiple-files",
    "title": "27  Iteration",
    "section": "\n27.3 Reading multiple files",
    "text": "27.3 Reading multiple files\nIn the previous section, you learned how to use dplyr::across() to repeat a transformation on multiple columns. In this section, you’ll learn how to use purrr::map() to do something to every file in a directory. Let’s start with a little motivation: imagine you have a directory full of excel spreadsheets5 you want to read. You could do it with copy and paste:\n\ndata2019 <- readxl::read_excel(\"data/y2019.xlsx\")\ndata2020 <- readxl::read_excel(\"data/y2020.xlsx\")\ndata2021 <- readxl::read_excel(\"data/y2021.xlsx\")\ndata2022 <- readxl::read_excel(\"data/y2022.xlsx\")\n\nAnd then use dplyr::bind_rows() to combine them all together:\n\ndata <- bind_rows(data2019, data2020, data2021, data2022)\n\nYou can imagine that this would get tedious quickly, especially if you had hundreds of files, not just four. The following sections show you how to automate this sort of task. There are three basic steps: use list.files() to list all the files in a directory, then use purrr::map() to read each of them into a list, then use purrr::list_rbind() to combine them into a single data frame. We’ll then discuss how you can handle situations of increasing heterogeneity, where you can’t do exactly the same thing to every file.\n\n27.3.1 Listing files in a directory\nAs the name suggests, list.files() lists the files in a directory. You’ll almost always use three arguments:\n\nThe first argument, path, is the directory to look in.\npattern is a regular expression used to filter the file names. The most common pattern is something like [.]xlsx$ or [.]csv$ to find all files with a specified extension.\nfull.names determines whether or not the directory name should be included in the output. You almost always want this to be TRUE.\n\nTo make our motivating example concrete, this book contains a folder with 12 excel spreadsheets containing data from the gapminder package. Each file contains one year’s worth of data for 142 countries. We can list them all with the appropriate call to list.files():\n\npaths <- list.files(\"data/gapminder\", pattern = \"[.]xlsx$\", full.names = TRUE)\npaths\n#>  [1] \"data/gapminder/1952.xlsx\" \"data/gapminder/1957.xlsx\"\n#>  [3] \"data/gapminder/1962.xlsx\" \"data/gapminder/1967.xlsx\"\n#>  [5] \"data/gapminder/1972.xlsx\" \"data/gapminder/1977.xlsx\"\n#>  [7] \"data/gapminder/1982.xlsx\" \"data/gapminder/1987.xlsx\"\n#>  [9] \"data/gapminder/1992.xlsx\" \"data/gapminder/1997.xlsx\"\n#> [11] \"data/gapminder/2002.xlsx\" \"data/gapminder/2007.xlsx\"\n\n\n27.3.2 Lists\nNow that we have these 12 paths, we could call read_excel() 12 times to get 12 data frames:\n\ngapminder_1952 <- readxl::read_excel(\"data/gapminder/1952.xlsx\")\ngapminder_1957 <- readxl::read_excel(\"data/gapminder/1957.xlsx\")\ngapminder_1962 <- readxl::read_excel(\"data/gapminder/1962.xlsx\")\n ...,\ngapminder_2007 <- readxl::read_excel(\"data/gapminder/2007.xlsx\")\n\nBut putting each sheet into its own variable is going to make it hard to work with them a few steps down the road. Instead, they’ll be easier to work with if we put them into a single object. A list is the perfect tool for this job:\n\nfiles <- list(\n  readxl::read_excel(\"data/gapminder/1952.xlsx\"),\n  readxl::read_excel(\"data/gapminder/1957.xlsx\"),\n  readxl::read_excel(\"data/gapminder/1962.xlsx\"),\n  ...,\n  readxl::read_excel(\"data/gapminder/2007.xlsx\")\n)\n\nNow that you have these data frames in a list, how do you get one out? You can use files[[i]] to extract the i-th element:\n\nfiles[[3]]\n#> # A tibble: 142 × 5\n#>   country     continent lifeExp      pop gdpPercap\n#>   <chr>       <chr>       <dbl>    <dbl>     <dbl>\n#> 1 Afghanistan Asia         32.0 10267083      853.\n#> 2 Albania     Europe       64.8  1728137     2313.\n#> 3 Algeria     Africa       48.3 11000948     2551.\n#> 4 Angola      Africa       34    4826015     4269.\n#> 5 Argentina   Americas     65.1 21283783     7133.\n#> 6 Australia   Oceania      70.9 10794968    12217.\n#> # ℹ 136 more rows\n\nWe’ll come back to [[ in more detail in Section 28.3.\n\n27.3.3 purrr::map() and list_rbind()\n\nThe code to collect those data frames in a list “by hand” is basically just as tedious to type as code that reads the files one-by-one. Happily, we can use purrr::map() to make even better use of our paths vector. map() is similar toacross(), but instead of doing something to each column in a data frame, it does something to each element of a vector.map(x, f) is shorthand for:\n\nlist(\n  f(x[[1]]),\n  f(x[[2]]),\n  ...,\n  f(x[[n]])\n)\n\nSo we can use map() to get a list of 12 data frames:\n\nfiles <- map(paths, readxl::read_excel)\nlength(files)\n#> [1] 12\n\nfiles[[1]]\n#> # A tibble: 142 × 5\n#>   country     continent lifeExp      pop gdpPercap\n#>   <chr>       <chr>       <dbl>    <dbl>     <dbl>\n#> 1 Afghanistan Asia         28.8  8425333      779.\n#> 2 Albania     Europe       55.2  1282697     1601.\n#> 3 Algeria     Africa       43.1  9279525     2449.\n#> 4 Angola      Africa       30.0  4232095     3521.\n#> 5 Argentina   Americas     62.5 17876956     5911.\n#> 6 Australia   Oceania      69.1  8691212    10040.\n#> # ℹ 136 more rows\n\n(This is another data structure that doesn’t display particularly compactly with str() so you might want to load it into RStudio and inspect it with View()).\nNow we can use purrr::list_rbind() to combine that list of data frames into a single data frame:\n\nlist_rbind(files)\n#> # A tibble: 1,704 × 5\n#>   country     continent lifeExp      pop gdpPercap\n#>   <chr>       <chr>       <dbl>    <dbl>     <dbl>\n#> 1 Afghanistan Asia         28.8  8425333      779.\n#> 2 Albania     Europe       55.2  1282697     1601.\n#> 3 Algeria     Africa       43.1  9279525     2449.\n#> 4 Angola      Africa       30.0  4232095     3521.\n#> 5 Argentina   Americas     62.5 17876956     5911.\n#> 6 Australia   Oceania      69.1  8691212    10040.\n#> # ℹ 1,698 more rows\n\nOr we could do both steps at once in a pipeline:\n\npaths |> \n  map(readxl::read_excel) |> \n  list_rbind()\n\nWhat if we want to pass in extra arguments to read_excel()? We use the same technique that we used with across(). For example, it’s often useful to peak at the first few rows of the data with n_max = 1:\n\npaths |> \n  map(\\(path) readxl::read_excel(path, n_max = 1)) |> \n  list_rbind()\n#> # A tibble: 12 × 5\n#>   country     continent lifeExp      pop gdpPercap\n#>   <chr>       <chr>       <dbl>    <dbl>     <dbl>\n#> 1 Afghanistan Asia         28.8  8425333      779.\n#> 2 Afghanistan Asia         30.3  9240934      821.\n#> 3 Afghanistan Asia         32.0 10267083      853.\n#> 4 Afghanistan Asia         34.0 11537966      836.\n#> 5 Afghanistan Asia         36.1 13079460      740.\n#> 6 Afghanistan Asia         38.4 14880372      786.\n#> # ℹ 6 more rows\n\nThis makes it clear that something is missing: there’s no year column because that value is recorded in the path, not the individual files. We’ll tackle that problem next.\n\n27.3.4 Data in the path\nSometimes the name of the file is data itself. In this example, the file name contains the year, which is not otherwise recorded in the individual files. To get that column into the final data frame, we need to do two things:\nFirst, we name the vector of paths. The easiest way to do this is with the set_names() function, which can take a function. Here we use basename() to extract just the file name from the full path:\n\npaths |> set_names(basename) \n#>                  1952.xlsx                  1957.xlsx \n#> \"data/gapminder/1952.xlsx\" \"data/gapminder/1957.xlsx\" \n#>                  1962.xlsx                  1967.xlsx \n#> \"data/gapminder/1962.xlsx\" \"data/gapminder/1967.xlsx\" \n#>                  1972.xlsx                  1977.xlsx \n#> \"data/gapminder/1972.xlsx\" \"data/gapminder/1977.xlsx\" \n#>                  1982.xlsx                  1987.xlsx \n#> \"data/gapminder/1982.xlsx\" \"data/gapminder/1987.xlsx\" \n#>                  1992.xlsx                  1997.xlsx \n#> \"data/gapminder/1992.xlsx\" \"data/gapminder/1997.xlsx\" \n#>                  2002.xlsx                  2007.xlsx \n#> \"data/gapminder/2002.xlsx\" \"data/gapminder/2007.xlsx\"\n\nThose names are automatically carried along by all the map functions, so the list of data frames will have those same names:\n\nfiles <- paths |> \n  set_names(basename) |> \n  map(readxl::read_excel)\n\nThat makes this call to map() shorthand for:\n\nfiles <- list(\n  \"1952.xlsx\" = readxl::read_excel(\"data/gapminder/1952.xlsx\"),\n  \"1957.xlsx\" = readxl::read_excel(\"data/gapminder/1957.xlsx\"),\n  \"1962.xlsx\" = readxl::read_excel(\"data/gapminder/1962.xlsx\"),\n  ...,\n  \"2007.xlsx\" = readxl::read_excel(\"data/gapminder/2007.xlsx\")\n)\n\nYou can also use [[ to extract elements by name:\n\nfiles[[\"1962.xlsx\"]]\n#> # A tibble: 142 × 5\n#>   country     continent lifeExp      pop gdpPercap\n#>   <chr>       <chr>       <dbl>    <dbl>     <dbl>\n#> 1 Afghanistan Asia         32.0 10267083      853.\n#> 2 Albania     Europe       64.8  1728137     2313.\n#> 3 Algeria     Africa       48.3 11000948     2551.\n#> 4 Angola      Africa       34    4826015     4269.\n#> 5 Argentina   Americas     65.1 21283783     7133.\n#> 6 Australia   Oceania      70.9 10794968    12217.\n#> # ℹ 136 more rows\n\nThen we use the names_to argument to list_rbind() to tell it to save the names into a new column called year then use readr::parse_number() to extract the number from the string.\n\npaths |> \n  set_names(basename) |> \n  map(readxl::read_excel) |> \n  list_rbind(names_to = \"year\") |> \n  mutate(year = parse_number(year))\n#> # A tibble: 1,704 × 6\n#>    year country     continent lifeExp      pop gdpPercap\n#>   <dbl> <chr>       <chr>       <dbl>    <dbl>     <dbl>\n#> 1  1952 Afghanistan Asia         28.8  8425333      779.\n#> 2  1952 Albania     Europe       55.2  1282697     1601.\n#> 3  1952 Algeria     Africa       43.1  9279525     2449.\n#> 4  1952 Angola      Africa       30.0  4232095     3521.\n#> 5  1952 Argentina   Americas     62.5 17876956     5911.\n#> 6  1952 Australia   Oceania      69.1  8691212    10040.\n#> # ℹ 1,698 more rows\n\nIn more complicated cases, there might be other variables stored in the directory name, or maybe the file name contains multiple bits of data. In that case, use set_names() (without any arguments) to record the full path, and then use tidyr::separate_wider_delim() and friends to turn them into useful columns.\n\npaths |> \n  set_names() |> \n  map(readxl::read_excel) |> \n  list_rbind(names_to = \"year\") |> \n  separate_wider_delim(year, delim = \"/\", names = c(NA, \"dir\", \"file\")) |> \n  separate_wider_delim(file, delim = \".\", names = c(\"file\", \"ext\"))\n#> # A tibble: 1,704 × 8\n#>   dir       file  ext   country     continent lifeExp      pop gdpPercap\n#>   <chr>     <chr> <chr> <chr>       <chr>       <dbl>    <dbl>     <dbl>\n#> 1 gapminder 1952  xlsx  Afghanistan Asia         28.8  8425333      779.\n#> 2 gapminder 1952  xlsx  Albania     Europe       55.2  1282697     1601.\n#> 3 gapminder 1952  xlsx  Algeria     Africa       43.1  9279525     2449.\n#> 4 gapminder 1952  xlsx  Angola      Africa       30.0  4232095     3521.\n#> 5 gapminder 1952  xlsx  Argentina   Americas     62.5 17876956     5911.\n#> 6 gapminder 1952  xlsx  Australia   Oceania      69.1  8691212    10040.\n#> # ℹ 1,698 more rows\n\n\n27.3.5 Save your work\nNow that you’ve done all this hard work to get to a nice tidy data frame, it’s a great time to save your work:\n\ngapminder <- paths |> \n  set_names(basename) |> \n  map(readxl::read_excel) |> \n  list_rbind(names_to = \"year\") |> \n  mutate(year = parse_number(year))\n\nwrite_csv(gapminder, \"gapminder.csv\")\n\nNow when you come back to this problem in the future, you can read in a single csv file. For large and richer datasets, using parquet might be a better choice than .csv, as discussed in ?sec-parquet.\nIf you’re working in a project, we’d suggest calling the file that does this sort of data prep work something like 0-cleanup.R. The 0 in the file name suggests that this should be run before anything else.\nIf your input data files change over time, you might consider learning a tool like targets to set up your data cleaning code to automatically re-run whenever one of the input files is modified.\n\n27.3.6 Many simple iterations\nHere we’ve just loaded the data directly from disk, and were lucky enough to get a tidy dataset. In most cases, you’ll need to do some additional tidying, and you have two basic options: you can do one round of iteration with a complex function, or do multiple rounds of iteration with simple functions. In our experience most folks reach first for one complex iteration, but you’re often better by doing multiple simple iterations.\nFor example, imagine that you want to read in a bunch of files, filter out missing values, pivot, and then combine. One way to approach the problem is to write a function that takes a file and does all those steps then call map() once:\n\nprocess_file <- function(path) {\n  df <- read_csv(path)\n  \n  df |> \n    filter(!is.na(id)) |> \n    mutate(id = tolower(id)) |> \n    pivot_longer(jan:dec, names_to = \"month\")\n}\n\npaths |> \n  map(process_file) |> \n  list_rbind()\n\nAlternatively, you could perform each step of process_file() to every file:\n\npaths |> \n  map(read_csv) |> \n  map(\\(df) df |> filter(!is.na(id))) |> \n  map(\\(df) df |> mutate(id = tolower(id))) |> \n  map(\\(df) df |> pivot_longer(jan:dec, names_to = \"month\")) |> \n  list_rbind()\n\nWe recommend this approach because it stops you getting fixated on getting the first file right before moving on to the rest. By considering all of the data when doing tidying and cleaning, you’re more likely to think holistically and end up with a higher quality result.\nIn this particular example, there’s another optimization you could make, by binding all the data frames together earlier. Then you can rely on regular dplyr behavior:\n\npaths |> \n  map(read_csv) |> \n  list_rbind() |> \n  filter(!is.na(id)) |> \n  mutate(id = tolower(id)) |> \n  pivot_longer(jan:dec, names_to = \"month\")\n\n\n27.3.7 Heterogeneous data\nUnfortunately, sometimes it’s not possible to go from map() straight to list_rbind() because the data frames are so heterogeneous that list_rbind() either fails or yields a data frame that’s not very useful. In that case, it’s still useful to start by loading all of the files:\n\nfiles <- paths |> \n  map(readxl::read_excel) \n\nThen a very useful strategy is to capture the structure of the data frames so that you can explore it using your data science skills. One way to do so is with this handy df_types function6 that returns a tibble with one row for each column:\n\ndf_types <- function(df) {\n  tibble(\n    col_name = names(df), \n    col_type = map_chr(df, vctrs::vec_ptype_full),\n    n_miss = map_int(df, \\(x) sum(is.na(x)))\n  )\n}\n\ndf_types(gapminder)\n#> # A tibble: 6 × 3\n#>   col_name  col_type  n_miss\n#>   <chr>     <chr>      <int>\n#> 1 year      double         0\n#> 2 country   character      0\n#> 3 continent character      0\n#> 4 lifeExp   double         0\n#> 5 pop       double         0\n#> 6 gdpPercap double         0\n\nYou can then apply this function to all of the files, and maybe do some pivoting to make it easier to see where the differences are. For example, this makes it easy to verify that the gapminder spreadsheets that we’ve been working with are all quite homogeneous:\n\nfiles |> \n  map(df_types) |> \n  list_rbind(names_to = \"file_name\") |> \n  select(-n_miss) |> \n  pivot_wider(names_from = col_name, values_from = col_type)\n#> # A tibble: 12 × 6\n#>   file_name country   continent lifeExp pop    gdpPercap\n#>   <chr>     <chr>     <chr>     <chr>   <chr>  <chr>    \n#> 1 1952.xlsx character character double  double double   \n#> 2 1957.xlsx character character double  double double   \n#> 3 1962.xlsx character character double  double double   \n#> 4 1967.xlsx character character double  double double   \n#> 5 1972.xlsx character character double  double double   \n#> 6 1977.xlsx character character double  double double   \n#> # ℹ 6 more rows\n\nIf the files have heterogeneous formats, you might need to do more processing before you can successfully merge them. Unfortunately, we’re now going to leave you to figure that out on your own, but you might want to read about map_if() and map_at(). map_if() allows you to selectively modify elements of a list based on their values; map_at() allows you to selectively modify elements based on their names.\n\n27.3.8 Handling failures\nSometimes the structure of your data might be sufficiently wild that you can’t even read all the files with a single command. And then you’ll encounter one of the downsides of map: it succeeds or fails as a whole. map() will either successfully read all of the files in a directory or fail with an error, reading zero files. This is annoying: why does one failure prevent you from accessing all the other successes?\nLuckily, purrr comes with a helper to tackle this problem: possibly(). possibly() is what’s known as a function operator: it takes a function and returns a function with modified behavior. In particular, possibly() changes a function from erroring to returning a value that you specify:\n\nfiles <- paths |> \n  map(possibly(\\(path) readxl::read_excel(path), NULL))\n\ndata <- files |> list_rbind()\n\nThis works particularly well here because list_rbind(), like many tidyverse functions, automatically ignores NULLs.\nNow you have all the data that can be read easily, and it’s time to tackle the hard part of figuring out why some files failed to load and what do to about it. Start by getting the paths that failed:\n\nfailed <- map_vec(files, is.null)\npaths[failed]\n#> character(0)\n\nThen call the import function again for each failure and figure out what went wrong."
  },
  {
    "objectID": "iteration.html#saving-multiple-outputs",
    "href": "iteration.html#saving-multiple-outputs",
    "title": "27  Iteration",
    "section": "\n27.4 Saving multiple outputs",
    "text": "27.4 Saving multiple outputs\nIn the last section, you learned about map(), which is useful for reading multiple files into a single object. In this section, we’ll now explore sort of the opposite problem: how can you take one or more R objects and save it to one or more files? We’ll explore this challenge using three examples:\n\nSaving multiple data frames into one database.\nSaving multiple data frames into multiple .csv files.\nSaving multiple plots to multiple .png files.\n\n\n27.4.1 Writing to a database\nSometimes when working with many files at once, it’s not possible to fit all your data into memory at once, and you can’t do map(files, read_csv). One approach to deal with this problem is to load your data into a database so you can access just the bits you need with dbplyr.\nIf you’re lucky, the database package you’re using will provide a handy function that takes a vector of paths and loads them all into the database. This is the case with duckdb’s duckdb_read_csv():\n\ncon <- DBI::dbConnect(duckdb::duckdb())\nduckdb::duckdb_read_csv(con, \"gapminder\", paths)\n\nThis would work well here, but we don’t have csv files, instead we have excel spreadsheets. So we’re going to have to do it “by hand”. Learning to do it by hand will also help you when you have a bunch of csvs and the database that you’re working with doesn’t have one function that will load them all in.\nWe need to start by creating a table that will fill in with data. The easiest way to do this is by creating a template, a dummy data frame that contains all the columns we want, but only a sampling of the data. For the gapminder data, we can make that template by reading a single file and adding the year to it:\n\ntemplate <- readxl::read_excel(paths[[1]])\ntemplate$year <- 1952\ntemplate\n#> # A tibble: 142 × 6\n#>   country     continent lifeExp      pop gdpPercap  year\n#>   <chr>       <chr>       <dbl>    <dbl>     <dbl> <dbl>\n#> 1 Afghanistan Asia         28.8  8425333      779.  1952\n#> 2 Albania     Europe       55.2  1282697     1601.  1952\n#> 3 Algeria     Africa       43.1  9279525     2449.  1952\n#> 4 Angola      Africa       30.0  4232095     3521.  1952\n#> 5 Argentina   Americas     62.5 17876956     5911.  1952\n#> 6 Australia   Oceania      69.1  8691212    10040.  1952\n#> # ℹ 136 more rows\n\nNow we can connect to the database, and use DBI::dbCreateTable() to turn our template into a database table:\n\ncon <- DBI::dbConnect(duckdb::duckdb())\nDBI::dbCreateTable(con, \"gapminder\", template)\n\ndbCreateTable() doesn’t use the data in template, just the variable names and types. So if we inspect the gapminder table now you’ll see that it’s empty but it has the variables we need with the types we expect:\n\ncon |> tbl(\"gapminder\")\n#> # Source:   table<gapminder> [0 x 6]\n#> # Database: DuckDB 0.7.1 [DDR@Windows 10 x64:R 4.2.2/:memory:]\n#> # ℹ 6 variables: country <chr>, continent <chr>, lifeExp <dbl>, pop <dbl>,\n#> #   gdpPercap <dbl>, year <dbl>\n\nNext, we need a function that takes a single file path, reads it into R, and adds the result to the gapminder table. We can do that by combining read_excel() with DBI::dbAppendTable():\n\nappend_file <- function(path) {\n  df <- readxl::read_excel(path)\n  df$year <- parse_number(basename(path))\n  \n  DBI::dbAppendTable(con, \"gapminder\", df)\n}\n\nNow we need to call append_file() once for each element of paths. That’s certainly possible with map():\n\npaths |> map(append_file)\n\nBut we don’t care about the output of append_file(), so instead of map() it’s slightly nicer to use walk(). walk() does exactly the same thing as map() but throws the output away:\n\npaths |> walk(append_file)\n\nNow we can see if we have all the data in our table:\n\ncon |> \n  tbl(\"gapminder\") |> \n  count(year)\n#> # Source:   SQL [?? x 2]\n#> # Database: DuckDB 0.7.1 [DDR@Windows 10 x64:R 4.2.2/:memory:]\n#>    year     n\n#>   <dbl> <dbl>\n#> 1  1952   142\n#> 2  1957   142\n#> 3  1962   142\n#> 4  1967   142\n#> 5  1972   142\n#> 6  1977   142\n#> # ℹ more rows\n\n\n27.4.2 Writing csv files\nThe same basic principle applies if we want to write multiple csv files, one for each group. Let’s imagine that we want to take the ggplot2::diamonds data and save one csv file for each clarity. First we need to make those individual datasets. There are many ways you could do that, but there’s one way we particularly like: group_nest().\n\nby_clarity <- diamonds |> \n  group_nest(clarity)\n\nby_clarity\n#> # A tibble: 8 × 2\n#>   clarity               data\n#>   <ord>   <list<tibble[,9]>>\n#> 1 I1               [741 × 9]\n#> 2 SI2            [9,194 × 9]\n#> 3 SI1           [13,065 × 9]\n#> 4 VS2           [12,258 × 9]\n#> 5 VS1            [8,171 × 9]\n#> 6 VVS2           [5,066 × 9]\n#> # ℹ 2 more rows\n\nThis gives us a new tibble with eight rows and two columns. clarity is our grouping variable and data is a list-column containing one tibble for each unique value of clarity:\n\nby_clarity$data[[1]]\n#> # A tibble: 741 × 9\n#>   carat cut       color depth table price     x     y     z\n#>   <dbl> <ord>     <ord> <dbl> <dbl> <int> <dbl> <dbl> <dbl>\n#> 1  0.32 Premium   E      60.9    58   345  4.38  4.42  2.68\n#> 2  1.17 Very Good J      60.2    61  2774  6.83  6.9   4.13\n#> 3  1.01 Premium   F      61.8    60  2781  6.39  6.36  3.94\n#> 4  1.01 Fair      E      64.5    58  2788  6.29  6.21  4.03\n#> 5  0.96 Ideal     F      60.7    55  2801  6.37  6.41  3.88\n#> 6  1.04 Premium   G      62.2    58  2801  6.46  6.41  4   \n#> # ℹ 735 more rows\n\nWhile we’re here, let’s create a column that gives the name of output file, using mutate() and str_glue():\n\nby_clarity <- by_clarity |> \n  mutate(path = str_glue(\"diamonds-{clarity}.csv\"))\n\nby_clarity\n#> # A tibble: 8 × 3\n#>   clarity               data path             \n#>   <ord>   <list<tibble[,9]>> <glue>           \n#> 1 I1               [741 × 9] diamonds-I1.csv  \n#> 2 SI2            [9,194 × 9] diamonds-SI2.csv \n#> 3 SI1           [13,065 × 9] diamonds-SI1.csv \n#> 4 VS2           [12,258 × 9] diamonds-VS2.csv \n#> 5 VS1            [8,171 × 9] diamonds-VS1.csv \n#> 6 VVS2           [5,066 × 9] diamonds-VVS2.csv\n#> # ℹ 2 more rows\n\nSo if we were going to save these data frames by hand, we might write something like:\n\nwrite_csv(by_clarity$data[[1]], by_clarity$path[[1]])\nwrite_csv(by_clarity$data[[2]], by_clarity$path[[2]])\nwrite_csv(by_clarity$data[[3]], by_clarity$path[[3]])\n...\nwrite_csv(by_clarity$by_clarity[[8]], by_clarity$path[[8]])\n\nThis is a little different to our previous uses of map() because there are two arguments that are changing, not just one. That means we need a new function: map2(), which varies both the first and second arguments. And because we again don’t care about the output, we want walk2() rather than map2(). That gives us:\n\nwalk2(by_clarity$data, by_clarity$path, write_csv)\n\n\n27.4.3 Saving plots\nWe can take the same basic approach to create many plots. Let’s first make a function that draws the plot we want:\n\ncarat_histogram <- function(df) {\n  ggplot(df, aes(x = carat)) + geom_histogram(binwidth = 0.1)  \n}\n\ncarat_histogram(by_clarity$data[[1]])\n\n\n\n\nNow we can use map() to create a list of many plots7 and their eventual file paths:\n\nby_clarity <- by_clarity |> \n  mutate(\n    plot = map(data, carat_histogram),\n    path = str_glue(\"clarity-{clarity}.png\")\n  )\n\nThen use walk2() with ggsave() to save each plot:\n\nwalk2(\n  by_clarity$path,\n  by_clarity$plot,\n  \\(path, plot) ggsave(path, plot, width = 6, height = 6)\n)\n\nThis is shorthand for:\n\nggsave(by_clarity$path[[1]], by_clarity$plot[[1]], width = 6, height = 6)\nggsave(by_clarity$path[[2]], by_clarity$plot[[2]], width = 6, height = 6)\nggsave(by_clarity$path[[3]], by_clarity$plot[[3]], width = 6, height = 6)\n...\nggsave(by_clarity$path[[8]], by_clarity$plot[[8]], width = 6, height = 6)"
  },
  {
    "objectID": "iteration.html#summary",
    "href": "iteration.html#summary",
    "title": "27  Iteration",
    "section": "\n27.5 Summary",
    "text": "27.5 Summary\nIn this chapter, you’ve seen how to use explicit iteration to solve three problems that come up frequently when doing data science: manipulating multiple columns, reading multiple files, and saving multiple outputs. But in general, iteration is a super power: if you know the right iteration technique, you can easily go from fixing one problem to fixing all the problems. Once you’ve mastered the techniques in this chapter, we highly recommend learning more by reading the Functionals chapter of Advanced R and consulting the purrr website.\nIf you know much about iteration in other languages, you might be surprised that we didn’t discuss the for loop. That’s because R’s orientation towards data analysis changes how we iterate: in most cases you can rely on an existing idiom to do something to each columns or each group. And when you can’t, you can often use a functional programming tool like map() that does something to each element of a list. However, you will see for loops in wild-caught code, so you’ll learn about them in the next chapter where we’ll discuss some important base R tools."
  },
  {
    "objectID": "quarto.html#summary",
    "href": "quarto.html#summary",
    "title": "29  Quarto",
    "section": "\n29.10 Summary",
    "text": "29.10 Summary\nIn this chapter introduced you to Quarto for authoring and publishing reproducible computational documents that include your code and your prose in one place. You’ve learned about writing Quarto documents in RStudio with the visual or the source editor, how code chunks work and how to customize options for them, how to include figures and tables in your Quarto documents, and options for caching for computations. Additionally, you’ve learned about adjusting YAML header options for creating self-contained or parametrized documents as well as including citations and bibliography. We have also given you some troubleshooting and workflow tips.\nWhile this introduction should be sufficient to get you started with Quarto, there is still a lot more to learn. Quarto is still relatively young, and is still growing rapidly. The best place to stay on top of innovations is the official Quarto website: https://quarto.org.\nThere are two important topics that we haven’t covered here: collaboration and the details of accurately communicating your ideas to other humans. Collaboration is a vital part of modern data science, and you can make your life much easier by using version control tools, like Git and GitHub. We recommend “Happy Git with R”, a user friendly introduction to Git and GitHub from R users, by Jenny Bryan. The book is freely available online: https://happygitwithr.com.\nWe have also not touched on what you should actually write in order to clearly communicate the results of your analysis. To improve your writing, we highly recommend reading either Style: Lessons in Clarity and Grace by Joseph M. Williams & Joseph Bizup, or The Sense of Structure: Writing from the Reader’s Perspective by George Gopen. Both books will help you understand the structure of sentences and paragraphs, and give you the tools to make your writing more clear. (These books are rather expensive if purchased new, but they’re used by many English classes so there are plenty of cheap second-hand copies). George Gopen also has a number of short articles on writing at https://www.georgegopen.com/the-litigation-articles.html. They are aimed at lawyers, but almost everything applies to data scientists too."
  },
  {
    "objectID": "quarto-formats.html#summary",
    "href": "quarto-formats.html#summary",
    "title": "30  Quarto formats",
    "section": "\n30.8 Summary",
    "text": "30.8 Summary\nIn this chapter we presented you a variety of options for communicating your results with Quarto, from static and interactive documents to presentations to websites and books.\nTo learn more about effective communication in these different formats, we recommend the following resources:\n\nTo improve your presentation skills, try Presentation Patterns by Neal Ford, Matthew McCollough, and Nathaniel Schutta. It provides a set of effective patterns (both low- and high-level) that you can apply to improve your presentations.\nIf you give academic talks, you might like the Leek group guide to giving talks.\nWe haven’t taken it ourselves, but we’ve heard good things about Matt McGarrity’s online course on public speaking: https://www.coursera.org/learn/public-speaking.\nIf you are creating many dashboards, make sure to read Stephen Few’s Information Dashboard Design: The Effective Visual Communication of Data. It will help you create dashboards that are truly useful, not just pretty to look at.\nEffectively communicating your ideas often benefits from some knowledge of graphic design. Robin Williams’ The Non-Designer’s Design Book is a great place to start."
  },
  {
    "objectID": "webscraping.html#introducción",
    "href": "webscraping.html#introducción",
    "title": "25  Web scraping",
    "section": "\n25.1 Introducción",
    "text": "25.1 Introducción\nEste capítulo le presenta los conceptos básicos del web scraping con rvest. El web scraping es una herramienta muy útil para extraer datos de páginas web. Algunos sitios web ofrecerán una API, un conjunto de solicitudes HTTP estructuradas que devuelven datos como JSON, que usted maneja utilizando las técnicas de Chapter 24. Siempre que sea posible, debe utilizar la API1, ya que, por lo general, le brindará datos más confiables. Desafortunadamente, sin embargo, la programación con API web está fuera del alcance de este libro. En cambio, estamos enseñando scraping, una técnica que funciona ya sea que un sitio proporcione o no una API.\nEn este capítulo, primero discutiremos la ética y la legalidad del scraping antes de sumergirnos en los conceptos básicos de HTML. Luego, aprenderá los conceptos básicos de los selectores de CSS para ubicar elementos específicos en la página y cómo usar funciones rvest para obtener datos de texto y atributos de HTML y en R. Luego discutiremos algunas técnicas para descubrir qué selector de CSS necesita para la página de la que desee extraer los datos, antes de terminar verá un par de casos de estudio y una breve discusión de sitios web dinámicos.\n\n25.1.1 Prerequisites\nIn this chapter, we’ll focus on tools provided by rvest. rvest is a member of the tidyverse, but is not a core member so you’ll need to load it explicitly. We’ll also load the full tidyverse since we’ll find it generally useful working with the data we’ve scraped.\n\nlibrary(tidyverse)\n#> Warning: package 'tibble' was built under R version 4.2.3\n#> Warning: package 'readr' was built under R version 4.2.3\n#> Warning: package 'dplyr' was built under R version 4.2.3\nlibrary(rvest)"
  },
  {
    "objectID": "rectangling.html#casos-de-estudio",
    "href": "rectangling.html#casos-de-estudio",
    "title": "24  Datos jerárquicos",
    "section": "\n24.4 Casos de estudio",
    "text": "24.4 Casos de estudio\nLa principal diferencia entre los ejemplos simples que usamos anteriormente y los datos reales es que los datos reales generalmente contienen múltiples niveles de anidamiento que requieren múltiples llamadas a unnest_longer() y/o unnest_wider(). Para mostrar eso en acción, esta sección trabaja a través de tres desafíos reales de rectángulos utilizando conjuntos de datos del paquete repurrrsive.\n\n24.4.1 Datos muy amplios\nEmpezaremos con gh_repos. Esta es una lista que contiene datos sobre una colección de repositorios de GitHub recuperados mediante la API de GitHub. Es una lista muy anidada, por lo que es difícil mostrar la estructura en este libro; recomendamos explorar un poco por su cuenta con View(gh_repos) antes de continuar.\ngh_repos es una lista, pero nuestras herramientas funcionan con columnas de lista, por lo que comenzaremos poniéndola en un tibble. Llamamos a esta columna json por razones que veremos más adelante.\n\nrepos <- tibble(json = gh_repos)\nrepos\n#> # A tibble: 6 × 1\n#>   json       \n#>   <list>     \n#> 1 <list [30]>\n#> 2 <list [30]>\n#> 3 <list [30]>\n#> 4 <list [26]>\n#> 5 <list [30]>\n#> 6 <list [30]>\n\nEste tibble contiene 6 filas, una fila para cada hijo de gh_repos. Cada fila contiene una lista sin nombre con 26 o 30 filas. Como estos no tienen nombre, comenzaremos con unnest_longer() para poner a cada niño en su propia fila:\n\nrepos |> \n  unnest_longer(json)\n#> # A tibble: 176 × 1\n#>   json             \n#>   <list>           \n#> 1 <named list [68]>\n#> 2 <named list [68]>\n#> 3 <named list [68]>\n#> 4 <named list [68]>\n#> 5 <named list [68]>\n#> 6 <named list [68]>\n#> # ℹ 170 more rows\n\nA primera vista, puede parecer que no hemos mejorado la situación: aunque tenemos más filas (176 en lugar de 6), cada elemento de json sigue siendo una lista. Sin embargo, hay una diferencia importante: ahora cada elemento es una lista nombrada, por lo que podemos usar unnest_wider() para poner cada elemento en su propia columna:\n\nrepos |> \n  unnest_longer(json) |> \n  unnest_wider(json) \n#> # A tibble: 176 × 68\n#>         id name     full_name owner        private html_url description fork \n#>      <int> <chr>    <chr>     <list>       <lgl>   <chr>    <chr>       <lgl>\n#> 1 61160198 after    gaborcsa… <named list> FALSE   https:/… Run Code i… FALSE\n#> 2 40500181 argufy   gaborcsa… <named list> FALSE   https:/… Declarativ… FALSE\n#> 3 36442442 ask      gaborcsa… <named list> FALSE   https:/… Friendly C… FALSE\n#> 4 34924886 baseimp… gaborcsa… <named list> FALSE   https:/… Do we get … FALSE\n#> 5 61620661 citest   gaborcsa… <named list> FALSE   https:/… Test R pac… TRUE \n#> 6 33907457 clisymb… gaborcsa… <named list> FALSE   https:/… Unicode sy… FALSE\n#> # ℹ 170 more rows\n#> # ℹ 60 more variables: url <chr>, forks_url <chr>, keys_url <chr>,\n#> #   collaborators_url <chr>, teams_url <chr>, hooks_url <chr>,\n#> #   issue_events_url <chr>, events_url <chr>, assignees_url <chr>,\n#> #   branches_url <chr>, tags_url <chr>, blobs_url <chr>, git_tags_url <chr>,\n#> #   git_refs_url <chr>, trees_url <chr>, statuses_url <chr>,\n#> #   languages_url <chr>, stargazers_url <chr>, contributors_url <chr>, …\n\nEsto ha funcionado, pero el resultado es un poco abrumador: ¡hay tantas columnas que tibble ni siquiera las imprime todas! Podemos verlos todos con names(); y aquí nos fijamos en los 10 primeros:\n\nrepos |> \n  unnest_longer(json) |> \n  unnest_wider(json) |> \n  names() |> \n  head(10)\n#>  [1] \"id\"          \"name\"        \"full_name\"   \"owner\"       \"private\"    \n#>  [6] \"html_url\"    \"description\" \"fork\"        \"url\"         \"forks_url\"\n\nVamos a sacar algunos que parecen interesantes:\n\nrepos |> \n  unnest_longer(json) |> \n  unnest_wider(json) |> \n  select(id, full_name, owner, description)\n#> # A tibble: 176 × 4\n#>         id full_name               owner             description             \n#>      <int> <chr>                   <list>            <chr>                   \n#> 1 61160198 gaborcsardi/after       <named list [17]> Run Code in the Backgro…\n#> 2 40500181 gaborcsardi/argufy      <named list [17]> Declarative function ar…\n#> 3 36442442 gaborcsardi/ask         <named list [17]> Friendly CLI interactio…\n#> 4 34924886 gaborcsardi/baseimports <named list [17]> Do we get warnings for …\n#> 5 61620661 gaborcsardi/citest      <named list [17]> Test R package and repo…\n#> 6 33907457 gaborcsardi/clisymbols  <named list [17]> Unicode symbols for CLI…\n#> # ℹ 170 more rows\n\nPuede usar esto para volver a comprender cómo se estructuró gh_repos: cada niño era un usuario de GitHub que contenía una lista de hasta 30 repositorios de GitHub que crearon.\nowner es otra columna de lista, y dado que contiene una lista con nombre, podemos usar unnest_wider() para obtener los valores:\n\nrepos |> \n  unnest_longer(json) |> \n  unnest_wider(json) |> \n  select(id, full_name, owner, description) |> \n  unnest_wider(owner)\n#> Error in `unnest_wider()`:\n#> ! Can't duplicate names between the affected columns and the original\n#>   data.\n#> ✖ These names are duplicated:\n#>   ℹ `id`, from `owner`.\n#> ℹ Use `names_sep` to disambiguate using the column name.\n#> ℹ Or use `names_repair` to specify a repair strategy.\n\nOh, oh, esta columna de lista también contiene una columna id y no podemos tener dos columnas id en el mismo marco de datos. Como se sugiere, usemos names_sep para resolver el problema:\n\nrepos |> \n  unnest_longer(json) |> \n  unnest_wider(json) |> \n  select(id, full_name, owner, description) |> \n  unnest_wider(owner, names_sep = \"_\")\n#> # A tibble: 176 × 20\n#>         id full_name  owner_login owner_id owner_avatar_url owner_gravatar_id\n#>      <int> <chr>      <chr>          <int> <chr>            <chr>            \n#> 1 61160198 gaborcsar… gaborcsardi   660288 https://avatars… \"\"               \n#> 2 40500181 gaborcsar… gaborcsardi   660288 https://avatars… \"\"               \n#> 3 36442442 gaborcsar… gaborcsardi   660288 https://avatars… \"\"               \n#> 4 34924886 gaborcsar… gaborcsardi   660288 https://avatars… \"\"               \n#> 5 61620661 gaborcsar… gaborcsardi   660288 https://avatars… \"\"               \n#> 6 33907457 gaborcsar… gaborcsardi   660288 https://avatars… \"\"               \n#> # ℹ 170 more rows\n#> # ℹ 14 more variables: owner_url <chr>, owner_html_url <chr>,\n#> #   owner_followers_url <chr>, owner_following_url <chr>,\n#> #   owner_gists_url <chr>, owner_starred_url <chr>,\n#> #   owner_subscriptions_url <chr>, owner_organizations_url <chr>,\n#> #   owner_repos_url <chr>, owner_events_url <chr>,\n#> #   owner_received_events_url <chr>, owner_type <chr>, …\n\nEsto proporciona otro amplio conjunto de datos, pero puede tener la sensación de que owner parece contener una gran cantidad de datos adicionales sobre la persona que “posee” el repositorio.\n\n24.4.2 Datos relacionales\nLos datos anidados a veces se usan para representar datos que normalmente distribuiríamos en varios marcos de datos. Por ejemplo, tome got_chars que contiene datos sobre los personajes que aparecen en los libros y series de televisión de Game of Thrones. Al igual que gh_repos, es una lista, por lo que comenzamos convirtiéndola en una columna de lista de un tibble:\n\nchars <- tibble(json = got_chars)\nchars\n#> # A tibble: 30 × 1\n#>   json             \n#>   <list>           \n#> 1 <named list [18]>\n#> 2 <named list [18]>\n#> 3 <named list [18]>\n#> 4 <named list [18]>\n#> 5 <named list [18]>\n#> 6 <named list [18]>\n#> # ℹ 24 more rows\n\nLa columna json contiene elementos con nombre, por lo que comenzaremos ampliándola:\n\nchars |> \n  unnest_wider(json)\n#> # A tibble: 30 × 18\n#>   url         id name  gender culture born  died  alive titles aliases father\n#>   <chr>    <int> <chr> <chr>  <chr>   <chr> <chr> <lgl> <list> <list>  <chr> \n#> 1 https:/…  1022 Theo… Male   \"Ironb… \"In … \"\"    TRUE  <chr>  <chr>   \"\"    \n#> 2 https:/…  1052 Tyri… Male   \"\"      \"In … \"\"    TRUE  <chr>  <chr>   \"\"    \n#> 3 https:/…  1074 Vict… Male   \"Ironb… \"In … \"\"    TRUE  <chr>  <chr>   \"\"    \n#> 4 https:/…  1109 Will  Male   \"\"      \"\"    \"In … FALSE <chr>  <chr>   \"\"    \n#> 5 https:/…  1166 Areo… Male   \"Norvo… \"In … \"\"    TRUE  <chr>  <chr>   \"\"    \n#> 6 https:/…  1267 Chett Male   \"\"      \"At … \"In … FALSE <chr>  <chr>   \"\"    \n#> # ℹ 24 more rows\n#> # ℹ 7 more variables: mother <chr>, spouse <chr>, allegiances <list>,\n#> #   books <list>, povBooks <list>, tvSeries <list>, playedBy <list>\n\nY seleccionando algunas columnas para que sea más fácil de leer:\n\ncharacters <- chars |> \n  unnest_wider(json) |> \n  select(id, name, gender, culture, born, died, alive)\ncharacters\n#> # A tibble: 30 × 7\n#>      id name              gender culture    born                  died  alive\n#>   <int> <chr>             <chr>  <chr>      <chr>                 <chr> <lgl>\n#> 1  1022 Theon Greyjoy     Male   \"Ironborn\" \"In 278 AC or 279 AC… \"\"    TRUE \n#> 2  1052 Tyrion Lannister  Male   \"\"         \"In 273 AC, at Caste… \"\"    TRUE \n#> 3  1074 Victarion Greyjoy Male   \"Ironborn\" \"In 268 AC or before… \"\"    TRUE \n#> 4  1109 Will              Male   \"\"         \"\"                    \"In … FALSE\n#> 5  1166 Areo Hotah        Male   \"Norvoshi\" \"In 257 AC or before… \"\"    TRUE \n#> 6  1267 Chett             Male   \"\"         \"At Hag's Mire\"       \"In … FALSE\n#> # ℹ 24 more rows\n\nEste conjunto de datos también contiene muchas columnas de lista:\n\nchars |> \n  unnest_wider(json) |> \n  select(id, where(is.list))\n#> # A tibble: 30 × 8\n#>      id titles    aliases    allegiances books     povBooks tvSeries playedBy\n#>   <int> <list>    <list>     <list>      <list>    <list>   <list>   <list>  \n#> 1  1022 <chr [2]> <chr [4]>  <chr [1]>   <chr [3]> <chr>    <chr>    <chr>   \n#> 2  1052 <chr [2]> <chr [11]> <chr [1]>   <chr [2]> <chr>    <chr>    <chr>   \n#> 3  1074 <chr [2]> <chr [1]>  <chr [1]>   <chr [3]> <chr>    <chr>    <chr>   \n#> 4  1109 <chr [1]> <chr [1]>  <NULL>      <chr [1]> <chr>    <chr>    <chr>   \n#> 5  1166 <chr [1]> <chr [1]>  <chr [1]>   <chr [3]> <chr>    <chr>    <chr>   \n#> 6  1267 <chr [1]> <chr [1]>  <NULL>      <chr [2]> <chr>    <chr>    <chr>   \n#> # ℹ 24 more rows\n\nExploremos la columna títulos. Es una columna de lista sin nombre, por lo que la dividiremos en filas:\n\nchars |> \n  unnest_wider(json) |> \n  select(id, titles) |> \n  unnest_longer(titles)\n#> # A tibble: 59 × 2\n#>      id titles                                              \n#>   <int> <chr>                                               \n#> 1  1022 Prince of Winterfell                                \n#> 2  1022 Lord of the Iron Islands (by law of the green lands)\n#> 3  1052 Acting Hand of the King (former)                    \n#> 4  1052 Master of Coin (former)                             \n#> 5  1074 Lord Captain of the Iron Fleet                      \n#> 6  1074 Master of the Iron Victory                          \n#> # ℹ 53 more rows\n\nEs posible que espere ver estos datos en su propia tabla porque sería fácil unirlos a los datos de los caracteres según sea necesario. Hagámoslo, lo que requiere poca limpieza: eliminar las filas que contienen cadenas vacías y cambiar el nombre de titles a title ya que cada fila ahora solo contiene un solo título.\n\ntitles <- chars |> \n  unnest_wider(json) |> \n  select(id, titles) |> \n  unnest_longer(titles) |> \n  filter(titles != \"\") |> \n  rename(title = titles)\ntitles\n#> # A tibble: 52 × 2\n#>      id title                                               \n#>   <int> <chr>                                               \n#> 1  1022 Prince of Winterfell                                \n#> 2  1022 Lord of the Iron Islands (by law of the green lands)\n#> 3  1052 Acting Hand of the King (former)                    \n#> 4  1052 Master of Coin (former)                             \n#> 5  1074 Lord Captain of the Iron Fleet                      \n#> 6  1074 Master of the Iron Victory                          \n#> # ℹ 46 more rows\n\nPodría imaginarse crear una tabla como esta para cada una de las columnas de la lista y luego usar uniones para combinarlas con los datos de los caracteres según lo necesite.\n\n24.4.3 Profundamente anidado\nTerminaremos estos estudios de caso con una columna de lista que está muy anidada y requiere rondas repetidas de unnest_wider() y unnest_longer() para desentrañar: gmaps_cities. Este es un tibble de dos columnas que contiene cinco nombres de ciudades y los resultados del uso de la API de codificación geográfica de Google para determinar su ubicación:\n\ngmaps_cities\n#> # A tibble: 5 × 2\n#>   city       json            \n#>   <chr>      <list>          \n#> 1 Houston    <named list [2]>\n#> 2 Washington <named list [2]>\n#> 3 New York   <named list [2]>\n#> 4 Chicago    <named list [2]>\n#> 5 Arlington  <named list [2]>\n\njson es una columna de lista con nombres internos, por lo que comenzamos con un unnest_wider():\n\ngmaps_cities |> \n  unnest_wider(json)\n#> # A tibble: 5 × 3\n#>   city       results    status\n#>   <chr>      <list>     <chr> \n#> 1 Houston    <list [1]> OK    \n#> 2 Washington <list [2]> OK    \n#> 3 New York   <list [1]> OK    \n#> 4 Chicago    <list [1]> OK    \n#> 5 Arlington  <list [2]> OK\n\nEsto nos da el estado, status, y los resultados, results. Dejaremos la columna de estado ya que todos están OK; en un análisis real, también querrá capturar todas las filas donde status != \"OK\" y descubrir qué salió mal. results es una lista sin nombre, con uno o dos elementos (veremos por qué en breve), así que la dividiremos en filas:\n\ngmaps_cities |> \n  unnest_wider(json) |> \n  select(-status) |> \n  unnest_longer(results)\n#> # A tibble: 7 × 2\n#>   city       results         \n#>   <chr>      <list>          \n#> 1 Houston    <named list [5]>\n#> 2 Washington <named list [5]>\n#> 3 Washington <named list [5]>\n#> 4 New York   <named list [5]>\n#> 5 Chicago    <named list [5]>\n#> 6 Arlington  <named list [5]>\n#> # ℹ 1 more row\n\nAhora results es una lista con nombre, así que usaremos unnest_wider():\n\nlocations <- gmaps_cities |> \n  unnest_wider(json) |> \n  select(-status) |> \n  unnest_longer(results) |> \n  unnest_wider(results)\nlocations\n#> # A tibble: 7 × 6\n#>   city      address_components formatted_address geometry     place_id types \n#>   <chr>     <list>             <chr>             <list>       <chr>    <list>\n#> 1 Houston   <list [4]>         Houston, TX, USA  <named list> ChIJAYW… <list>\n#> 2 Washingt… <list [2]>         Washington, USA   <named list> ChIJ-bD… <list>\n#> 3 Washingt… <list [4]>         Washington, DC, … <named list> ChIJW-T… <list>\n#> 4 New York  <list [3]>         New York, NY, USA <named list> ChIJOwg… <list>\n#> 5 Chicago   <list [4]>         Chicago, IL, USA  <named list> ChIJ7cv… <list>\n#> 6 Arlington <list [4]>         Arlington, TX, U… <named list> ChIJ05g… <list>\n#> # ℹ 1 more row\n\nAhora podemos ver por qué dos ciudades obtuvieron dos resultados: Washington igualó tanto al estado de Washington como a Washington, DC, y Arlington igualó a Arlington, Virginia y Arlington, Texas.\nHay pocos lugares diferentes a los que podríamos ir desde aquí. Es posible que deseemos determinar la ubicación exacta de la coincidencia, que se almacena en la columna de la lista geometry:\n\nlocations |> \n  select(city, formatted_address, geometry) |> \n  unnest_wider(geometry)\n#> # A tibble: 7 × 6\n#>   city       formatted_address   bounds           location     location_type\n#>   <chr>      <chr>               <list>           <list>       <chr>        \n#> 1 Houston    Houston, TX, USA    <named list [2]> <named list> APPROXIMATE  \n#> 2 Washington Washington, USA     <named list [2]> <named list> APPROXIMATE  \n#> 3 Washington Washington, DC, USA <named list [2]> <named list> APPROXIMATE  \n#> 4 New York   New York, NY, USA   <named list [2]> <named list> APPROXIMATE  \n#> 5 Chicago    Chicago, IL, USA    <named list [2]> <named list> APPROXIMATE  \n#> 6 Arlington  Arlington, TX, USA  <named list [2]> <named list> APPROXIMATE  \n#> # ℹ 1 more row\n#> # ℹ 1 more variable: viewport <list>\n\nEso nos da nuevos límites, bounds, (una región rectangular) y ubicación, location, (un punto). Podemos anular location para ver la latitud (lat) y la longitud (lng):\n\nlocations |> \n  select(city, formatted_address, geometry) |> \n  unnest_wider(geometry) |> \n  unnest_wider(location)\n#> # A tibble: 7 × 7\n#>   city       formatted_address   bounds             lat    lng location_type\n#>   <chr>      <chr>               <list>           <dbl>  <dbl> <chr>        \n#> 1 Houston    Houston, TX, USA    <named list [2]>  29.8  -95.4 APPROXIMATE  \n#> 2 Washington Washington, USA     <named list [2]>  47.8 -121.  APPROXIMATE  \n#> 3 Washington Washington, DC, USA <named list [2]>  38.9  -77.0 APPROXIMATE  \n#> 4 New York   New York, NY, USA   <named list [2]>  40.7  -74.0 APPROXIMATE  \n#> 5 Chicago    Chicago, IL, USA    <named list [2]>  41.9  -87.6 APPROXIMATE  \n#> 6 Arlington  Arlington, TX, USA  <named list [2]>  32.7  -97.1 APPROXIMATE  \n#> # ℹ 1 more row\n#> # ℹ 1 more variable: viewport <list>\n\nExtraer los límites requiere algunos pasos más:\n\nlocations |> \n  select(city, formatted_address, geometry) |> \n  unnest_wider(geometry) |> \n  # focus on the variables of interest\n  select(!location:viewport) |>\n  unnest_wider(bounds)\n#> # A tibble: 7 × 4\n#>   city       formatted_address   northeast        southwest       \n#>   <chr>      <chr>               <list>           <list>          \n#> 1 Houston    Houston, TX, USA    <named list [2]> <named list [2]>\n#> 2 Washington Washington, USA     <named list [2]> <named list [2]>\n#> 3 Washington Washington, DC, USA <named list [2]> <named list [2]>\n#> 4 New York   New York, NY, USA   <named list [2]> <named list [2]>\n#> 5 Chicago    Chicago, IL, USA    <named list [2]> <named list [2]>\n#> 6 Arlington  Arlington, TX, USA  <named list [2]> <named list [2]>\n#> # ℹ 1 more row\n\nLuego renombramos southwest y northeast (las esquinas del rectángulo) para que podamos usar names_sep para crear nombres cortos pero evocadores:\n\nlocations |> \n  select(city, formatted_address, geometry) |> \n  unnest_wider(geometry) |> \n  select(!location:viewport) |>\n  unnest_wider(bounds) |> \n  rename(ne = northeast, sw = southwest) |> \n  unnest_wider(c(ne, sw), names_sep = \"_\") \n#> # A tibble: 7 × 6\n#>   city       formatted_address   ne_lat ne_lng sw_lat sw_lng\n#>   <chr>      <chr>                <dbl>  <dbl>  <dbl>  <dbl>\n#> 1 Houston    Houston, TX, USA      30.1  -95.0   29.5  -95.8\n#> 2 Washington Washington, USA       49.0 -117.    45.5 -125. \n#> 3 Washington Washington, DC, USA   39.0  -76.9   38.8  -77.1\n#> 4 New York   New York, NY, USA     40.9  -73.7   40.5  -74.3\n#> 5 Chicago    Chicago, IL, USA      42.0  -87.5   41.6  -87.9\n#> 6 Arlington  Arlington, TX, USA    32.8  -97.0   32.6  -97.2\n#> # ℹ 1 more row\n\nTenga en cuenta cómo desanidamos dos columnas simultáneamente proporcionando un vector de nombres de variables a unnest_wider().\nUna vez que haya descubierto la ruta para llegar a los componentes que le interesan, puede extraerlos directamente usando otra función tidyr, hoist():\n\nlocations |> \n  select(city, formatted_address, geometry) |> \n  hoist(\n    geometry,\n    ne_lat = c(\"bounds\", \"northeast\", \"lat\"),\n    sw_lat = c(\"bounds\", \"southwest\", \"lat\"),\n    ne_lng = c(\"bounds\", \"northeast\", \"lng\"),\n    sw_lng = c(\"bounds\", \"southwest\", \"lng\"),\n  )\n\nSi estos casos de estudio han abierto su apetito por más rectangulares de la vida real, puede ver algunos ejemplos más en `vignette(“rectangling”, package = “tidyr”)\n\n24.4.4 Ejercicios\n\nCalcula aproximadamente cuándo se creó gh_repos. ¿Por qué solo puedes estimar aproximadamente la fecha?\nLa columna owners de gh_repo contiene mucha información duplicada porque cada propietario puede tener muchos repositorios. ¿Puede construir un marco de datos de owners que contenga una fila para cada propietario? (Pista: ¿distinct() funciona con list-cols?)\nSiga los pasos utilizados para los titles para crear tablas similares para los alias, lealtades, libros y series de televisión de los personajes de Game of Thrones.\n\nExplique el siguiente código línea por línea. ¿Por qué es interesante? ¿Por qué funciona para got_chars pero podría no funciona en general?\n\ntibble(json = got_chars) |> \n  unnest_wider(json) |> \n  select(id, where(is.list)) |> \n  pivot_longer(\n    where(is.list), \n    names_to = \"name\", \n    values_to = \"value\"\n  ) |>  \n  unnest_longer(value)\n\n\nEn gmaps_cities, ¿qué contiene address_components? ¿Por qué varía la longitud entre filas? Des anidalo apropiadamente para averiguarlo. (Pista: types siempre parece contener dos elementos. ¿Hace que sea más fácil trabajar con unnest_wider() que con unnest_longer()?) ."
  },
  {
    "objectID": "rectangling.html#resumen",
    "href": "rectangling.html#resumen",
    "title": "24  Datos jerárquicos",
    "section": "\n24.6 Resumen",
    "text": "24.6 Resumen\nEn este capítulo, aprendió qué son las listas, cómo puede generarlas a partir de archivos JSON y cómo convertirlas en marcos de datos rectangulares. Sorprendentemente, solo necesitamos dos funciones nuevas: unnest_longer() para colocar los elementos de la lista en filas y unnest_wider() para colocar los elementos de la lista en columnas. No importa cuán profundamente anidada esté la columna de la lista, todo lo que necesita hacer es llamar repetidamente a estas dos funciones.\nJSON es el formato de datos más común devuelto por las API web. ¿Qué sucede si el sitio web no tiene una API, pero puede ver los datos que desea en el sitio web? Ese es el tema del próximo capítulo: web scraping, extracción de datos de páginas web HTML."
  },
  {
    "objectID": "index.html#sobre-la-traducción",
    "href": "index.html#sobre-la-traducción",
    "title": "R para la Ciencia de Datos (2e)",
    "section": "Sobre la traducción",
    "text": "Sobre la traducción\n Esta traducción de “R para la Ciencia de Datos” es un proyecto personal de David Díaz Rodríguez con el objetivo de facilitar el estudio de la Ciencia de Datos con R, tanto al propio traductor como a todas aquellas personas de habla hispana que deseen aprender a realizar Ciencia de Datos con R.\nSeñalar que esta es una traducción textual del libro por lo que cuando los autores se refieren así mismo en primera persona, será Hadley Wickham, Mine Çetinkaya-Rundel & Garrett Grolemund y no el traductor.\nLa traducción fue realizada usando Google Translate y fueron corregidos algunos errores gramaticales y de coherencia. Si detecta algún error relacionado con contenido de la traducción, siéntase libre de abrir un issue o un pull request en este repositorio.",
    "crumbs": [
      "Bienvenida"
    ]
  },
  {
    "objectID": "quarto-formats.html#introducción",
    "href": "quarto-formats.html#introducción",
    "title": "30  Formatos Quarto",
    "section": "",
    "text": "De forma permanente, modificando el encabezado YAML:\ntitle: \"Diamond sizes\"\nformat: html\n\n\nDe forma transitoria, llamando quarto::quarto_render() a mano:\n\nquarto::quarto_render(\"diamond-sizes.qmd\", output_format = \"docx\")\n\nEsto es útil si desea producir múltiples tipos de salida mediante programación, ya que el argumento output_format también puede tomar una lista de valores.\n\nquarto::quarto_render(\"diamond-sizes.qmd\", output_format = c(\"docx\", \"pdf\"))",
    "crumbs": [
      "Comunicar",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Formatos Quarto</span>"
    ]
  },
  {
    "objectID": "quarto-formats.html#opciones-de-salida",
    "href": "quarto-formats.html#opciones-de-salida",
    "title": "30  Formatos Quarto",
    "section": "\n30.2 Opciones de salida",
    "text": "30.2 Opciones de salida\nQuarto ofrece una amplia gama de formatos de salida. Puedes encontrar la lista completa en https://quarto.org/docs/output-formats/all-formats.html. Muchos formatos comparten algunas opciones de salida (p. ej., toc: true para incluir una tabla de contenido), pero otros tienen opciones que son específicas del formato (p. ej., code-fold: true colapsa fragmentos de código en un &lt;details&gt; etiqueta para la salida HTML para que el usuario pueda mostrarla a pedido, no es aplicable en un documento PDF o Word).\nPara anular las opciones predeterminadas, debe usar un campo format expandido. Por ejemplo, si quisiera representar un html con una tabla de contenido flotante, usaría:\nformat:\n  html:\n    toc: true\n    toc_float: true\nIncluso puede renderizar en múltiples salidas proporcionando una lista de formatos:\nformat:\n  html:\n    toc: true\n    toc_float: true\n  pdf: default\n  docx: default\nTenga en cuenta la sintaxis especial (pdf: default) si no desea anular ninguna opción predeterminada.\nPara representar todos los formatos especificados en el YAML de un documento, puede usar output_format = \"all\".\n\nquarto::quarto_render(\"diamond-sizes.qmd\", output_format = \"all\")",
    "crumbs": [
      "Comunicar",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Formatos Quarto</span>"
    ]
  },
  {
    "objectID": "quarto-formats.html#documentos",
    "href": "quarto-formats.html#documentos",
    "title": "30  Formatos Quarto",
    "section": "\n30.3 Documentos",
    "text": "30.3 Documentos\nEl capítulo anterior se centró en la salida html predeterminada. Hay varias variaciones básicas sobre ese tema, generando diferentes tipos de documentos. Por ejemplo:\n\npdf crea un PDF con LaTeX (un sistema de diseño de documentos de código abierto), que deberá instalar. RStudio le preguntará si aún no lo tiene.\ndocx para documentos de Microsoft Word (.docx).\nodt para documentos OpenDocument Text (.odt).\nrtf para documentos en formato de texto enriquecido (.rtf).\ngfm para un documento Markdown de GitHub (.md).\nipynb para Jupyter Notebooks (.ipynb).\n\nRecuerde, al generar un documento para compartir con los responsables de la toma de decisiones, puede desactivar la visualización predeterminada del código configurando las opciones globales en el documento YAML:\nexecute:\n  echo: false\nPara los documentos html, otra opción es hacer que los fragmentos de código estén ocultos de forma predeterminada, pero visibles con un clic:\nformat:\n  html:\n    code: true",
    "crumbs": [
      "Comunicar",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Formatos Quarto</span>"
    ]
  },
  {
    "objectID": "quarto-formats.html#presentaciones",
    "href": "quarto-formats.html#presentaciones",
    "title": "30  Formatos Quarto",
    "section": "\n30.4 Presentaciones",
    "text": "30.4 Presentaciones\nTambién puede usar Quarto para producir presentaciones. Obtiene menos control visual que con una herramienta como Keynote o PowerPoint, pero insertar automáticamente los resultados de su código R en una presentación puede ahorrar una gran cantidad de tiempo. Las presentaciones funcionan dividiendo su contenido en diapositivas, con una nueva diapositiva que comienza en cada segundo encabezado de nivel (##). Además, los encabezados de primer nivel (#) indican el comienzo de una nueva sección con una diapositiva de título de sección que, de manera predeterminada, está centrada en el medio.\nQuarto admite una variedad de formatos de presentación, que incluyen:\n\nrevealjs - Presentación HTML con revealjs\npptx - Presentación de PowerPoint\nbeamer - Presentación en PDF con LaTeX Beamer.\n\nPuede leer más sobre la creación de presentaciones con Quarto en https://quarto.org/docs/presentations.",
    "crumbs": [
      "Comunicar",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Formatos Quarto</span>"
    ]
  },
  {
    "objectID": "quarto-formats.html#interactividad",
    "href": "quarto-formats.html#interactividad",
    "title": "30  Formatos Quarto",
    "section": "\n30.5 Interactividad",
    "text": "30.5 Interactividad\nAl igual que cualquier documento HTML, los documentos HTML creados con Quarto también pueden contener componentes interactivos. Aquí presentamos dos opciones para incluir interactividad en sus documentos Quarto: htmlwidgets y Shiny.\n\n30.5.1 htmlwidgets\nHTML es un formato interactivo y puede aprovechar esa interactividad con htmlwidgets, funciones de R que producen visualizaciones HTML interactivas. Por ejemplo, tome el mapa del leaflet a continuación. Si está viendo esta página en la web, puede arrastrar el mapa, acercar y alejar, etc. Obviamente, no puede hacer eso en un libro, por lo que Quarto inserta automáticamente una captura de pantalla estática para usted.\n\nlibrary(leaflet)\nleaflet() |&gt;\n  setView(174.764, -36.877, zoom = 16) |&gt; \n  addTiles() |&gt;\n  addMarkers(174.764, -36.877, popup = \"Maungawhau\") \n\n\n\n\n\nLo mejor de los htmlwidgets es que no necesita saber nada sobre HTML o JavaScript para usarlos. Todos los detalles están envueltos dentro del paquete, por lo que no necesita preocuparse por eso.\nHay muchos paquetes que proporcionan htmlwidgets, incluidos:\n\ndygraphs para visualizaciones interactivas de series de tiempo.\nDT para tablas interactivas.\nthreejs para gráficos 3d interactivos.\nDiagrammeR para diagramas (como diagramas de flujo y diagramas de enlace de nodo simples).\n\nPara obtener más información sobre los htmlwidgets y ver una lista completa de los paquetes que los proporcionan, visite https://www.htmlwidgets.org.\n\n30.5.2 Shiny\nhtmlwidgets proporcionar interactividad del lado del cliente — toda la interactividad ocurre en el navegador, independientemente de R. Por un lado, eso es genial porque puedes distribuir el archivo HTML sin ninguna conexión con R. Sin embargo, eso limita fundamentalmente lo que puede hacer con las cosas que se han implementado en HTML y JavaScript. Un enfoque alternativo es usar shiny, un paquete que le permite crear interactividad usando código R, no JavaScript.\nPara llamar al código Shiny desde un documento Quarto, agregue server: shiny al encabezado YAML:\ntitle: \"Shiny Web App\"\nformat: html\nserver: shiny\nLuego puede usar las funciones de entrada “input” para agregar componentes interactivos al documento:\n\nlibrary(shiny)\n\ntextInput(\"name\", \"What is your name?\")\nnumericInput(\"age\", \"How old are you?\", NA, min = 0, max = 150)\n\nY también necesita un fragmento de código con la opción de fragmento context: server que contiene el código que debe ejecutarse en un servidor Shiny.\n\n\n\n\n\n\n\n\nLuego puede hacer referencia a los valores con input$name y input$age, y el código que los usa se volverá a ejecutar automáticamente cada vez que cambien.\nNo podemos mostrarle una aplicación brillante en vivo aquí porque las interacciones brillantes ocurren en el lado del servidor. Esto significa que puede escribir aplicaciones interactivas sin saber JavaScript, pero necesita un servidor para ejecutarlas. Esto introduce un problema logístico: las aplicaciones Shiny necesitan un servidor Shiny para ejecutarse en línea. Cuando ejecuta aplicaciones Shiny en su propia computadora, Shiny configura automáticamente un servidor Shiny para usted, pero necesita un servidor Shiny público si desea publicar este tipo de interactividad en línea. Esa es la compensación fundamental de shiny: puede hacer cualquier cosa en un documento brillante que pueda hacer en R, pero requiere que alguien esté ejecutando R.\nPara aprender más sobre Shiny, recomendamos leer Mastering Shiny de Hadley Wickham, https://mastering-shiny.org.",
    "crumbs": [
      "Comunicar",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Formatos Quarto</span>"
    ]
  },
  {
    "objectID": "quarto-formats.html#sitios-web-y-libros",
    "href": "quarto-formats.html#sitios-web-y-libros",
    "title": "30  Formatos Quarto",
    "section": "\n30.6 Sitios web y libros",
    "text": "30.6 Sitios web y libros\nCon un poco de infraestructura adicional, puede usar Quarto para generar un sitio web completo o un libro:\n\nColoque sus archivos .qmd en un solo directorio. index.qmd se convertirá en la página de inicio.\n\nAgregue un archivo YAML llamado _quarto.yml que proporciona la navegación para el sitio. En este archivo, establezca el tipo de project en book o website, por ejemplo:\nproject:\n  type: book\n\n\nPor ejemplo, el siguiente archivo _quarto.yml crea un sitio web a partir de tres archivos fuente: index.qmd (la página de inicio), viridis-colors.qmd y terrain-colors.qmd.\n\nproject:\n  type: website\n\nwebsite:\n  title: \"A website on color scales\"\n  navbar:\n    left:\n      - href: index.qmd\n        text: Home\n      - href: viridis-colors.qmd\n        text: Viridis colors\n      - href: terrain-colors.qmd\n        text: Terrain colors\n\nEl archivo _quarto.yml que necesita para un libro tiene una estructura muy similar. El siguiente ejemplo muestra cómo puede crear un libro con cuatro capítulos que se muestra en tres salidas diferentes (html, pdf y epub). Una vez más, los archivos de origen son archivos .qmd.\n\nproject:\n  type: book\n\nbook:\n  title: \"A book on color scales\"\n  author: \"Jane Coloriste\"\n  chapters:\n    - index.qmd\n    - intro.qmd\n    - viridis-colors.qmd\n    - terrain-colors.qmd\n\nformat:\n  html:\n    theme: cosmo\n  pdf: default\n  epub: default\n\nLe recomendamos que utilice un proyecto de RStudio para sus sitios web y libros. Basado en el archivo _quarto.yml, RStudio reconocerá el tipo de proyecto en el que está trabajando y agregará una pestaña Build al IDE que puede usar para renderizar y obtener una vista previa de sus sitios web y libros. Tanto los sitios web como los libros también se pueden renderizar usando quarto::quarto_render().\nLea más sobre sitios web de Quarto en https://quarto.org/docs/websites y sobre libros en https://quarto.org/docs/books.",
    "crumbs": [
      "Comunicar",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Formatos Quarto</span>"
    ]
  },
  {
    "objectID": "quarto-formats.html#otros-formatos",
    "href": "quarto-formats.html#otros-formatos",
    "title": "30  Formatos Quarto",
    "section": "\n30.7 Otros formatos",
    "text": "30.7 Otros formatos\nQuarto ofrece aún más formatos de salida:\n\nPuede escribir artículos de revistas usando Plantillas de revistas en cuarto: https://quarto.org/docs/journals/templates.html.\nPuede exportar documentos Quarto a Jupyter Notebooks con formato: ipynb: https://quarto.org/docs/reference/formats/ipynb.html.\n\nVea https://quarto.org/docs/output-formats/all-formats.html para una lista de incluso más formatos.",
    "crumbs": [
      "Comunicar",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Formatos Quarto</span>"
    ]
  },
  {
    "objectID": "quarto-formats.html#resumen",
    "href": "quarto-formats.html#resumen",
    "title": "30  Formatos Quarto",
    "section": "\n30.8 Resumen",
    "text": "30.8 Resumen\nEn este capítulo le presentamos una variedad de opciones para comunicar sus resultados con Quarto, desde documentos estáticos e interactivos hasta presentaciones, sitios web y libros.\nPara aprender más sobre la comunicación efectiva en estos diferentes formatos, recomendamos los siguientes recursos:\n\nPara mejorar sus habilidades de presentación, intente Presentation Patterns de Neal Ford, Matthew McCollough, y Nathaniel Schutta. Proporciona un conjunto de patrones efectivos (tanto de bajo como de alto nivel) que puede aplicar para mejorar sus presentaciones.\nSi das charlas académicas, tal vez te gusten las Leek group guide to giving talks.\nNo lo hemos tomado nosotros mismos, pero hemos escuchado cosas buenas sobre el curso en línea de Matt McGarrity sobre hablar en público: https://www.coursera.org/learn/public-speaking.\nSi está creando muchos tableros, asegúrese de leer Stephen Few’s Information Dashboard Design: The Effective Visual Communication of Data. Le ayudará a crear tableros que sean realmente útiles, no solo bonitos a la vista.\nLa comunicación efectiva de sus ideas a menudo se beneficia de algún conocimiento de diseño gráfico. Robin Williams’ The Non-Designer’s Design Book es un gran lugar para comenzar.",
    "crumbs": [
      "Comunicar",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Formatos Quarto</span>"
    ]
  },
  {
    "objectID": "intro.html#footnotes",
    "href": "intro.html#footnotes",
    "title": "1  Introducción",
    "section": "",
    "text": "Si desea obtener una descripción general completa de todas las funciones de RStudio, consulte la Guía del usuario de RStudio en https://docs.posit.co/ide/user.↩︎"
  },
  {
    "objectID": "data-transform.html#introducción",
    "href": "data-transform.html#introducción",
    "title": "4  Transformación de datos",
    "section": "\n4.1 Introducción",
    "text": "4.1 Introducción\nLa visualización es una herramienta importante para generar información, pero es raro que obtenga los datos exactamente en la forma correcta que necesita para hacer el gráfico que desea. A menudo, necesitará crear nuevas variables o resúmenes para responder a tus preguntas con tus datos, o tal vez solo quiera cambiar el nombre de las variables o reordenar las observaciones para que sea un poco más fácil trabajar con los datos. Aprenderá cómo hacer todo eso (¡y más!) en este capítulo, que lo introducirá a la transformación de datos utilizando el paquete dplyr y un nuevo conjunto de datos en vuelos que partieron de la ciudad de Nueva York en 2013.\nEl objetivo de este capítulo es brindarle una descripción general de todas las herramientas clave para transformar un data frame. Comenzaremos con funciones que operan en filas y luego columnas de un data frame, luego regresamos para hablar más sobre las canalizaciones o pipe, una herramienta importante que usa para combinar verbos. A continuación, introduciremos la capacidad de trabajar con grupos. Terminaremos el capítulo con un caso de estudio que muestra estas funciones en acción y volveremos a las funciones con más detalle en capítulos posteriores, a medida que comencemos a profundizar en tipos específicos de datos (por ejemplo, números, cadenas, fechas).\n\n4.1.1 Requisitos previos\nEn este capítulo nos centraremos en el paquete dplyr, otro miembro central de tidyverse. Ilustraremos las ideas clave usando datos del paquete nycflights13 y usaremos ggplot2 para ayudarnos a comprender los datos.\n\nlibrary(nycflights13)\nlibrary(tidyverse)\n#&gt; ── Attaching core tidyverse packages ───────────────────── tidyverse 2.0.0 ──\n#&gt; ✔ dplyr     1.1.4     ✔ readr     2.1.4\n#&gt; ✔ forcats   1.0.0     ✔ stringr   1.5.1\n#&gt; ✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n#&gt; ✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n#&gt; ✔ purrr     1.0.2     \n#&gt; ── Conflicts ─────────────────────────────────────── tidyverse_conflicts() ──\n#&gt; ✖ dplyr::filter() masks stats::filter()\n#&gt; ✖ dplyr::lag()    masks stats::lag()\n#&gt; ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nTome nota del mensaje de conflictos que se imprime cuando carga el tidyverse. Te dice que dplyr sobrescribe algunas funciones en base R. Si desea utilizar la versión base de estas funciones después de cargar dplyr, deberá utilizar sus nombres completos: stats::filter() y stats::lag(). Hasta ahora hemos ignorado en su mayoría de qué paquete proviene una función porque la mayoría de las veces no importa. Sin embargo, conocer el paquete puede ayudarlo a encontrar ayuda y funciones relacionadas, por lo que cuando necesitemos ser precisos sobre de qué paquete proviene una función, usaremos la misma sintaxis que R: nombrepaquete::nombrefuncion().\n\n4.1.2 nycflights13\nPara explorar los verbos básicos de dplyr, usaremos nycflights13::flights. Este conjunto de datos contiene todos los 336,776 vuelos que partieron de la ciudad de Nueva York en 2013. Los datos provienen de la Oficina de Estadísticas de Transporte de EE. UU. y están documentados en ?flights.\n\nflights\n#&gt; # A tibble: 336,776 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\nflights es un tibble, un tipo especial de data frame utilizado por tidyverse para evitar algunos errores comunes. La diferencia más importante entre los tibbles y los data frames es la forma en que se imprimen los tibbles; están diseñados para grandes conjuntos de datos, por lo que solo muestran las primeras filas y solo las columnas que caben en una pantalla. Hay algunas opciones para ver todo. Si está utilizando RStudio, lo más conveniente es probablemente View(flights), que abrirá una vista interactiva desplazable y filtrable. De lo contrario, puede usar print(flights, width = Inf) para mostrar todas las columnas, o usar glimpse():\n\nglimpse(flights)\n#&gt; Rows: 336,776\n#&gt; Columns: 19\n#&gt; $ year           &lt;int&gt; 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013…\n#&gt; $ month          &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n#&gt; $ day            &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n#&gt; $ dep_time       &lt;int&gt; 517, 533, 542, 544, 554, 554, 555, 557, 557, 558, 55…\n#&gt; $ sched_dep_time &lt;int&gt; 515, 529, 540, 545, 600, 558, 600, 600, 600, 600, 60…\n#&gt; $ dep_delay      &lt;dbl&gt; 2, 4, 2, -1, -6, -4, -5, -3, -3, -2, -2, -2, -2, -2,…\n#&gt; $ arr_time       &lt;int&gt; 830, 850, 923, 1004, 812, 740, 913, 709, 838, 753, 8…\n#&gt; $ sched_arr_time &lt;int&gt; 819, 830, 850, 1022, 837, 728, 854, 723, 846, 745, 8…\n#&gt; $ arr_delay      &lt;dbl&gt; 11, 20, 33, -18, -25, 12, 19, -14, -8, 8, -2, -3, 7,…\n#&gt; $ carrier        &lt;chr&gt; \"UA\", \"UA\", \"AA\", \"B6\", \"DL\", \"UA\", \"B6\", \"EV\", \"B6\"…\n#&gt; $ flight         &lt;int&gt; 1545, 1714, 1141, 725, 461, 1696, 507, 5708, 79, 301…\n#&gt; $ tailnum        &lt;chr&gt; \"N14228\", \"N24211\", \"N619AA\", \"N804JB\", \"N668DN\", \"N…\n#&gt; $ origin         &lt;chr&gt; \"EWR\", \"LGA\", \"JFK\", \"JFK\", \"LGA\", \"EWR\", \"EWR\", \"LG…\n#&gt; $ dest           &lt;chr&gt; \"IAH\", \"IAH\", \"MIA\", \"BQN\", \"ATL\", \"ORD\", \"FLL\", \"IA…\n#&gt; $ air_time       &lt;dbl&gt; 227, 227, 160, 183, 116, 150, 158, 53, 140, 138, 149…\n#&gt; $ distance       &lt;dbl&gt; 1400, 1416, 1089, 1576, 762, 719, 1065, 229, 944, 73…\n#&gt; $ hour           &lt;dbl&gt; 5, 5, 5, 5, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6…\n#&gt; $ minute         &lt;dbl&gt; 15, 29, 40, 45, 0, 58, 0, 0, 0, 0, 0, 0, 0, 0, 0, 59…\n#&gt; $ time_hour      &lt;dttm&gt; 2013-01-01 05:00:00, 2013-01-01 05:00:00, 2013-01-0…\n\nEn ambas vistas, los nombres de las variables van seguidos de abreviaturas que indican el tipo de cada variable: &lt;int&gt; es la abreviatura de entero, &lt;dbl&gt; es la abreviatura de doble (también conocido como número real), &lt;chr&gt; para carácter (también conocido como cadenas) y &lt;dttm&gt; para fecha y hora. Estos son importantes porque las operaciones que puede realizar en una columna dependen mucho de su “tipo”.\n\n4.1.3 Básicos de dplyr\nEstá a punto de aprender los principales verbos (funciones) de dplyr que le permitirán resolver la gran mayoría de sus desafíos de manipulación de datos. Pero antes de discutir sus diferencias individuales, vale la pena señalar lo que tienen en común:\n\nEl primer argumento es siempre un data frame.\nLos argumentos subsiguientes normalmente describen en qué columnas operar, utilizando los nombres de las variables (sin comillas).\nLa salida es siempre un nuevo data frame.\n\nDebido a que cada verbo hace una cosa bien, resolver problemas complejos generalmente requerirá combinar varios verbos, y lo haremos con la canalización |&gt;. Hablaremos más sobre las canalizaciones en Sección 4.4, pero en resumen, una canalización toma la cosa a su izquierda y la pasa a la función a su derecha para que x |&gt; f(y) sea equivalente a f(x, y), y x |&gt; f(y) |&gt; g(z) es equivalente a g(f(x, y), z). La forma más fácil de leer pipe es “entonces”. Eso hace posible tener una idea del siguiente código aunque aún no haya aprendido los detalles:\n\nflights |&gt;\n  filter(dest == \"IAH\") |&gt; \n  group_by(year, month, day) |&gt; \n  summarize(\n    arr_delay = mean(arr_delay, na.rm = TRUE)\n  )\n\nLos verbos de dplyr están organizados en cuatro grupos según lo que operan: filas, columnas, grupos o tablas. En las siguientes secciones, aprenderá los verbos más importantes para filas, columnas y grupos, luego regresaremos a los verbos de unión que funcionan en tablas en Capítulo 20. ¡Vamos a empezar!"
  },
  {
    "objectID": "data-transform.html#filas",
    "href": "data-transform.html#filas",
    "title": "4  Transformación de datos",
    "section": "\n4.2 Filas",
    "text": "4.2 Filas\nLos verbos más importantes que operan en las filas de un conjunto de datos son filter(), que cambia qué filas están presentes sin cambiar su orden, y arrange(), que cambia el orden de las filas sin cambiar cuáles están presentes. Ambas funciones solo afectan a las filas y las columnas no se modifican. También hablaremos de distinct(), que encuentra filas con valores únicos pero, a diferencia de arrange() y filter(), también puede modificar opcionalmente las columnas.\n\n4.2.1 filter()\n\nfilter() le permite mantener filas en función de los valores de las columnas 1. El primer argumento es el data frame. El segundo argumento y los subsiguientes son las condiciones que deben cumplirse para mantener la fila. Por ejemplo, podríamos encontrar todos los vuelos que salieron con más de 120 minutos (dos horas) de retraso:\n\nflights |&gt; \n  filter(dep_delay &gt; 120)\n#&gt; # A tibble: 9,723 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      848           1835       853     1001           1950\n#&gt; 2  2013     1     1      957            733       144     1056            853\n#&gt; 3  2013     1     1     1114            900       134     1447           1222\n#&gt; 4  2013     1     1     1540           1338       122     2020           1825\n#&gt; 5  2013     1     1     1815           1325       290     2120           1542\n#&gt; 6  2013     1     1     1842           1422       260     1958           1535\n#&gt; # ℹ 9,717 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\nAdemás de &gt; (mayor que), puede usar &gt;= (mayor o igual que), &lt; (menor que), &lt;= (menor o igual que), == (igual a) y != (no igual a). También puede combinar condiciones con & o , para indicar “y” (verifique ambas condiciones) o con | para indicar “o” (verifique cualquiera de las dos condiciones):\n\n# Vuelos que partieron el 1 de enero\nflights |&gt; \n  filter(month == 1 & day == 1)\n#&gt; # A tibble: 842 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # ℹ 836 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\n# Vuelos que salieron en enero o febrero\nflights |&gt; \n  filter(month == 1 | month == 2)\n#&gt; # A tibble: 51,955 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # ℹ 51,949 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\nHay un atajo útil cuando estás combinando | y ==: %in%. Mantiene filas donde la variable es igual a uno de los valores de la derecha:\n\n# Una forma más corta de seleccionar vuelos que partieron en enero o febrero\nflights |&gt; \n  filter(month %in% c(1, 2))\n#&gt; # A tibble: 51,955 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # ℹ 51,949 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\nVolveremos a estas comparaciones y operadores lógicos con más detalle en Capítulo 13.\nCuando ejecuta filter(), dplyr ejecuta la operación de filtrado, crea un nuevo data frame y luego lo imprime. No modifica el conjunto de datos flights existente porque las funciones dplyr nunca modifican sus entradas. Para guardar el resultado, debe usar el operador de asignación, &lt;-:\n\nene1 &lt;- flights |&gt; \n  filter(month == 1 & day == 1)\n\n\n4.2.2 Errores comunes\nCuando comienza con R, el error más fácil de cometer es usar = en lugar de == al probar la igualdad. filter() te avisará cuando esto suceda:\n\nflights |&gt; \n  filter(month = 1)\n#&gt; Error in `filter()`:\n#&gt; ! We detected a named input.\n#&gt; ℹ This usually means that you've used `=` instead of `==`.\n#&gt; ℹ Did you mean `month == 1`?\n\nOtro error es escribir declaraciones “o” como lo haría en español:\n\nflights |&gt; \n  filter(month == 1 | 2)\n\nEsto “funciona”, en el sentido de que no arroja un error, pero no hace lo que quieres porque | primero verifica la condición month == 1 y luego verifica la condición 2, que no es una condición sensata para comprobar. Aprenderemos más sobre lo que sucede aquí y por qué en Sección 16.6.2.\n\n4.2.3 arrange()\n\narrange() cambia el orden de las filas según el valor de las columnas. Se necesita un data frame y un conjunto de nombres de columna (o expresiones más complicadas) para ordenar. Si proporciona más de un nombre de columna, cada columna adicional se usará para desempatar los valores de las columnas anteriores. Por ejemplo, el siguiente código ordena por hora de salida, que se distribuye en cuatro columnas. Obtenemos primero los primeros años, luego, dentro de un año, los primeros meses, etc.\n\nflights |&gt; \n  arrange(year, month, day, dep_time)\n#&gt; # A tibble: 336,776 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\nPuede usar desc() en una columna dentro de arrange() para reordenar el marco de datos en función de esa columna en orden descendente (de mayor a menor). Por ejemplo, este código ordena los vuelos de mayor a menor retraso:\n\nflights |&gt; \n  arrange(desc(dep_delay))\n#&gt; # A tibble: 336,776 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     9      641            900      1301     1242           1530\n#&gt; 2  2013     6    15     1432           1935      1137     1607           2120\n#&gt; 3  2013     1    10     1121           1635      1126     1239           1810\n#&gt; 4  2013     9    20     1139           1845      1014     1457           2210\n#&gt; 5  2013     7    22      845           1600      1005     1044           1815\n#&gt; 6  2013     4    10     1100           1900       960     1342           2211\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\nTenga en cuenta que la cantidad de filas no ha cambiado: solo estamos organizando los datos, no los estamos filtrando.\n\n4.2.4 distinct()\n\ndistinct() encuentra todas las filas únicas en un conjunto de datos, por lo que, en un sentido técnico, opera principalmente en las filas. Sin embargo, la mayoría de las veces, querrá la combinación distinta de algunas variables, por lo que también puede proporcionar opcionalmente nombres de columna:\n\n# Eliminar filas duplicadas, si las hay\nflights |&gt; \n  distinct()\n#&gt; # A tibble: 336,776 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\n# Encuentre todos los pares únicos de origen y destino\nflights |&gt; \n  distinct(origin, dest)\n#&gt; # A tibble: 224 × 2\n#&gt;   origin dest \n#&gt;   &lt;chr&gt;  &lt;chr&gt;\n#&gt; 1 EWR    IAH  \n#&gt; 2 LGA    IAH  \n#&gt; 3 JFK    MIA  \n#&gt; 4 JFK    BQN  \n#&gt; 5 LGA    ATL  \n#&gt; 6 EWR    ORD  \n#&gt; # ℹ 218 more rows\n\nAlternativamente, si desea mantener otras columnas al filtrar filas únicas, puede usar la opción .keep_all = TRUE.\n\nflights |&gt; \n  distinct(origin, dest, .keep_all = TRUE)\n#&gt; # A tibble: 224 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # ℹ 218 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\nNo es una coincidencia que todos estos vuelos distintos sean el 1 de enero: distinct() encontrará la primera aparición de una fila única en el conjunto de datos y descartará el resto.\nSi quieres encontrar el número de ocurrencias, es mejor que cambies distinct() por count(), y con el argumento sort = TRUE puedes organizarlas en orden descendente según el número de ocurrencias. Aprenderá más sobre el conteo en ?sec-counts.\n\nflights |&gt;\n  count(origin, dest, sort = TRUE)\n#&gt; # A tibble: 224 × 3\n#&gt;   origin dest      n\n#&gt;   &lt;chr&gt;  &lt;chr&gt; &lt;int&gt;\n#&gt; 1 JFK    LAX   11262\n#&gt; 2 LGA    ATL   10263\n#&gt; 3 LGA    ORD    8857\n#&gt; 4 JFK    SFO    8204\n#&gt; 5 LGA    CLT    6168\n#&gt; 6 EWR    ORD    6100\n#&gt; # ℹ 218 more rows\n\n\n4.2.5 Ejercicios\n\n\nEn una canalización única para cada condición, busque todos los vuelos que cumplan la condición:\n\nTuvo un retraso de llegada de dos o más horas.\nVoló a Houston (IAH o HOU) C. Fueron operados por United, American o Delta\nSalida en verano (julio, agosto y septiembre)\nLlegó más de dos horas tarde, pero no se fue tarde\nSe retrasaron al menos una hora, pero recuperaron más de 30 minutos en vuelo\n\n\nOrdene flights para encontrar los vuelos con mayores retrasos en la salida. Encuentra los vuelos que salieron más temprano en la mañana.\nOrdene flights para encontrar los vuelos más rápidos (Sugerencia: intente ordenar por un cálculo).\n¿Hubo un vuelo todos los días de 2013?\n¿Qué vuelos viajaron la mayor distancia? ¿Cuál recorrió la menor distancia?\n¿Importa en qué orden usó filter() y arrange() si está usando ambos? ¿Por qué/por qué no? Piense en los resultados y cuánto trabajo tendrían que hacer las funciones."
  },
  {
    "objectID": "data-transform.html#columnas",
    "href": "data-transform.html#columnas",
    "title": "4  Transformación de datos",
    "section": "\n4.3 Columnas",
    "text": "4.3 Columnas\nHay cuatro verbos importantes que afectan las columnas sin cambiar las filas: mutate() crea nuevas columnas que se derivan de las columnas existentes, select() cambia qué columnas están presentes, rename() cambia los nombres de las columnas, y relocate() cambia las posiciones de las columnas.\n\n4.3.1 mutate()\n\nEl trabajo de mutate() es agregar nuevas columnas que se calculan a partir de las columnas existentes. En los capítulos de transformación, aprenderá un gran conjunto de funciones que puede usar para manipular diferentes tipos de variables. Por ahora, nos apegaremos al álgebra básica, que nos permite calcular la ganancia, cuánto tiempo recuperó un vuelo retrasado en el aire y la velocidad en millas por hora:\n\nflights |&gt; \n  mutate(\n    ganancia = dep_delay - arr_delay,\n    velocidad = distance / air_time * 60\n  )\n#&gt; # A tibble: 336,776 × 21\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 13 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\nDe forma predeterminada, mutate() agrega nuevas columnas en el lado derecho de su conjunto de datos, lo que dificulta ver lo que está sucediendo aquí. Podemos usar el argumento .before para agregar las variables al lado izquierdo 2:\n\nflights |&gt; \n  mutate(\n    ganancia = dep_delay - arr_delay,\n    velocidad = distance / air_time * 60,\n    .before = 1\n  )\n#&gt; # A tibble: 336,776 × 21\n#&gt;   ganancia velocidad  year month   day dep_time sched_dep_time dep_delay\n#&gt;      &lt;dbl&gt;     &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;\n#&gt; 1       -9      370.  2013     1     1      517            515         2\n#&gt; 2      -16      374.  2013     1     1      533            529         4\n#&gt; 3      -31      408.  2013     1     1      542            540         2\n#&gt; 4       17      517.  2013     1     1      544            545        -1\n#&gt; 5       19      394.  2013     1     1      554            600        -6\n#&gt; 6      -16      288.  2013     1     1      554            558        -4\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 13 more variables: arr_time &lt;int&gt;, sched_arr_time &lt;int&gt;, …\n\nEl . es un signo de que .before es un argumento para la función, no el nombre de una tercera variable nueva que estamos creando. También puede usar .after para agregar después de una variable, y tanto en .before como en .after puede usar el nombre de la variable en lugar de una posición. Por ejemplo, podríamos agregar las nuevas variables después de day:\n\nflights |&gt; \n  mutate(\n    ganancia = dep_delay - arr_delay,\n    velocidad = distance / air_time * 60,\n    .after = day\n  )\n\nAlternativamente, puede controlar qué variables se mantienen con el argumento .keep. Un argumento particularmente útil es \"used\", que especifica que solo mantenemos las columnas involucradas o creadas en el paso mutate(). Por ejemplo, la siguiente salida contendrá solo las variables dep_delay, arr_delay, air_time, gain, hours y gain_per_hour.\n\nflights |&gt; \n  mutate(\n    ganancia = dep_delay - arr_delay,\n    horas = air_time / 60,\n    ganancia_por_hora = ganancia / horas,\n    .keep = \"used\"\n  )\n\nTenga en cuenta que, dado que no hemos asignado el resultado del cálculo anterior a flights, las nuevas variables ganancia, horas y ganancia_por_hora solo se imprimirán, pero no se almacenarán en un data frame. Y si queremos que estén disponibles en un data frame para uso futuro, debemos pensar detenidamente si queremos que el resultado se asigne de nuevo a “vuelos”, sobrescribiendo el data frame original con muchas más variables, o a un nuevo objeto. A menudo, la respuesta correcta es un nuevo objeto que se nombra de manera informativa para indicar su contenido, por ejemplo, delay_gain, pero también puede tener buenas razones para sobrescribir flights.\n\n4.3.2 select()\n\nNo es raro obtener conjuntos de datos con cientos o incluso miles de variables. En esta situación, el primer desafío suele ser centrarse en las variables que le interesan. select() le permite acercarse rápidamente a un subconjunto útil utilizando operaciones basadas en los nombres de las variables:\n\nSeleccionar columnas por nombre\n\n\nflights |&gt;\n  select(year, month, day)\n\n\nSeleccionar todas las columnas entre year y day\n\n\nflights |&gt; \n  select(year:day)\n\n\nSeleccionar todas las columnas excepto aquellas entre year y day (incluyendolas)\n\n\nflights |&gt; \n  select(!year:day)\n\nHistóricamente, esta operación se realizaba con - en lugar de !, por lo que es probable que la veas en la naturaleza. Estos dos operadores tienen el mismo propósito pero con sutiles diferencias de comportamiento. Recomendamos usar ! porque se lee como “no” y combina bien con & y |.\n\nSeleccionar todas las columnas que son caracteres\n\n\nflights |&gt; \n  select(where(is.character))\n\nHay una serie de funciones auxiliares que puede usar dentro de select():\n\n\nstarts_with(\"abc\"): coincide con los nombres que comienzan con “abc”.\n\nends_with(\"xyz\"): encuentra nombres que terminan en “xyz”.\n\ncontains(\"ijk\"): encuentra nombres que contienen “ijk”.\n\nnum_range(\"x\", 1:3): coincide con x1, x2 y x3.\n\nVer ?select para más detalles. Una vez que conozca las expresiones regulares (el tema de Capítulo 16), también podrá usar matches() para seleccionar variables que coincidan con un patrón.\nPuede cambiar el nombre de las variables a medida que las selecciona con select() usando =. El nuevo nombre aparece en el lado izquierdo de =, y la variable antigua aparece en el lado derecho:\n\nflights |&gt; \n  select(tail_num = tailnum)\n#&gt; # A tibble: 336,776 × 1\n#&gt;   tail_num\n#&gt;   &lt;chr&gt;   \n#&gt; 1 N14228  \n#&gt; 2 N24211  \n#&gt; 3 N619AA  \n#&gt; 4 N804JB  \n#&gt; 5 N668DN  \n#&gt; 6 N39463  \n#&gt; # ℹ 336,770 more rows\n\n\n4.3.3 rename()\n\nSi desea conservar todas las variables existentes y cambiar el nombre de algunas, puede usar rename() en lugar de select():\n\nflights |&gt; \n  rename(tail_num = tailnum)\n#&gt; # A tibble: 336,776 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\nSi tiene un montón de columnas con nombres inconsistentes y sería doloroso arreglarlas todas a mano, consulte janitor::clean_names() que proporciona una limpieza automatizada útil.\n\n4.3.4 relocate()\n\nUsa relocate() para mover las variables. Es posible que desee recopilar variables relacionadas juntas o mover variables importantes al frente. Por defecto relocate() mueve las variables al frente:\n\nflights |&gt; \n  relocate(time_hour, air_time)\n#&gt; # A tibble: 336,776 × 19\n#&gt;   time_hour           air_time  year month   day dep_time sched_dep_time\n#&gt;   &lt;dttm&gt;                 &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1 2013-01-01 05:00:00      227  2013     1     1      517            515\n#&gt; 2 2013-01-01 05:00:00      227  2013     1     1      533            529\n#&gt; 3 2013-01-01 05:00:00      160  2013     1     1      542            540\n#&gt; 4 2013-01-01 05:00:00      183  2013     1     1      544            545\n#&gt; 5 2013-01-01 06:00:00      116  2013     1     1      554            600\n#&gt; 6 2013-01-01 05:00:00      150  2013     1     1      554            558\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 12 more variables: dep_delay &lt;dbl&gt;, arr_time &lt;int&gt;, …\n\nTambién puedes especificar dónde ponerlos usando los argumentos .before y .after, al igual que en mutate():\n\nflights |&gt; \n  relocate(year:dep_time, .after = time_hour)\nflights |&gt; \n  relocate(starts_with(\"arr\"), .before = dep_time)\n\n\n4.3.5 Ejercicios\n\nCompare dep_time, sched_dep_time, and dep_delay.\nHaga una lluvia de ideas sobre tantas formas como sea posible para seleccionar dep_time, dep_delay, arr_time y arr_delay de flights.\n¿Qué sucede si especifica el nombre de la misma variable varias veces en una llamada select()?\n\n¿Qué hace la función any_of()? ¿Por qué podría ser útil junto con este vector?\n\nvariables &lt;- c(\"year\", \"month\", \"day\", \"dep_delay\", \"arr_delay\")\n\n\n\n¿Te sorprende el resultado de ejecutar el siguiente código? ¿Cómo tratan los ayudantes de select con las mayúsculas y minúsculas de forma predeterminada? ¿Cómo se puede cambiar ese valor predeterminado?\n\nflights |&gt; select(contains(\"TIME\"))\n\n\nCambie el nombre de air_time a air_time_min para indicar las unidades de medida y muévalo al comienzo del data frame.\n\n¿Por qué no funciona lo siguiente y qué significa el error?\n\nflights |&gt; \n  select(tailnum) |&gt; \n  arrange(arr_delay)\n#&gt; Error in `arrange()`:\n#&gt; ℹ In argument: `..1 = arr_delay`.\n#&gt; Caused by error:\n#&gt; ! objeto 'arr_delay' no encontrado"
  },
  {
    "objectID": "data-transform.html#sec-the-pipe",
    "href": "data-transform.html#sec-the-pipe",
    "title": "4  Transformación de datos",
    "section": "\n4.4 Canalizaciones o pipe",
    "text": "4.4 Canalizaciones o pipe\nLe mostramos ejemplos simples de las canalizaciones anteriormente, pero su verdadero poder surge cuando comienza a combinar varios verbos. Por ejemplo, imagine que desea encontrar vuelos rápidos al aeropuerto IAH de Houston: debe combinar filter(), mutate(), select() y arrange():\n\nflights |&gt; \n  filter(dest == \"IAH\") |&gt; \n  mutate(speed = distance / air_time * 60) |&gt;\n  select(year:day, dep_time, carrier, flight, speed) |&gt;\n  arrange(desc(speed))\n#&gt; # A tibble: 7,198 × 7\n#&gt;    year month   day dep_time carrier flight speed\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt; &lt;chr&gt;    &lt;int&gt; &lt;dbl&gt;\n#&gt; 1  2013     7     9      707 UA         226  522.\n#&gt; 2  2013     8    27     1850 UA        1128  521.\n#&gt; 3  2013     8    28      902 UA        1711  519.\n#&gt; 4  2013     8    28     2122 UA        1022  519.\n#&gt; 5  2013     6    11     1628 UA        1178  515.\n#&gt; 6  2013     8    27     1017 UA         333  515.\n#&gt; # ℹ 7,192 more rows\n\nAunque esta canalización tiene cuatro pasos, es fácil de hojear porque los verbos aparecen al comienzo de cada línea: comience con los datos de flights, luego filtra por destino, luego crea la columana speed con mutate, luego selecciona las columnas deseadas y culmina ordenandolas en orden descendente por la columna speed.\n¿Qué pasaría si no tuviéramos la canalización? Podríamos anidar cada llamada de función dentro de la llamada anterior:\n\narrange(\n  select(\n    mutate(\n      filter(\n        flights,\n        dest == \"IAH\"\n      ),\n      speed = distance / air_time * 60\n    ),\n    year:day, dep_time, carrier, flight, speed\n  ),\n  desc(speed)\n)\n\nO podríamos usar un montón de objetos intermedios:\n\nflights1 &lt;- filter(flights, dest == \"IAH\")\nflights2 &lt;- mutate(flights1, speed = distance / air_time * 60)\nflights3 &lt;- select(flights2, year:day, dep_time, carrier, flight, speed)\narrange(flights3, desc(speed))\n\nSi bien ambas formas tienen su tiempo y lugar, la canalización generalmente produce un código de análisis de datos que es más fácil de escribir y leer.\nPara agregar la canalización a su código, recomendamos usar el atajo de teclado incorporado Ctrl/Cmd + Shift + M. Deberá realizar un cambio en sus opciones de RStudio para usar |&gt; en lugar de %&gt;% como se muestra en Figura 4.1; más sobre %&gt;% en breve.\n485\n\n\n\n\nFigura 4.1: Para insertar |&gt;, asegúrese de que la opción “Use native pipe operator” esté marcada.\n\n\n\n\n\n\n\n\n\nmagrittr\n\n\n\nSi ha estado usando tidyverse por un tiempo, es posible que esté familiarizado con la canalización %&gt;% proporcionada por el paquete magrittr. El paquete magrittr está incluido en el tidyverse principal, por lo que puede usar %&gt;% siempre que cargue el tidyverse:\n\nlibrary(tidyverse)\n\nmtcars %&gt;% \n  group_by(cyl) %&gt;%\n  summarize(n = n())\n\nPara casos simples, |&gt; y %&gt;% se comportan de manera idéntica. Entonces, ¿por qué recomendamos la canalización base? En primer lugar, debido a que es parte de la base R, siempre está disponible para su uso, incluso cuando no está utilizando el tidyverse. En segundo lugar, |&gt; es un poco más simple que %&gt;%: en el tiempo entre la invención de %&gt;% en 2014 y la inclusión de |&gt; en R 4.1.0 en 2021, ganamos una mejor comprensión de la canalización. Esto permitió que la implementación base desechara características poco utilizadas y menos importantes."
  },
  {
    "objectID": "data-transform.html#grupos",
    "href": "data-transform.html#grupos",
    "title": "4  Transformación de datos",
    "section": "\n4.5 Grupos",
    "text": "4.5 Grupos\nHasta ahora ha aprendido acerca de las funciones que funcionan con filas y columnas. dplyr se vuelve aún más poderoso cuando agrega la capacidad de trabajar con grupos. En esta sección, nos centraremos en las funciones más importantes: group_by(), summarize() y la familia de funciones slice.\n\n4.5.1 group_by()\n\nUse group_by() para dividir su conjunto de datos en grupos significativos para su análisis:\n\nflights |&gt; \n  group_by(month)\n#&gt; # A tibble: 336,776 × 19\n#&gt; # Groups:   month [12]\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\ngroup_by() no cambia los datos pero, si observa detenidamente el resultado, notará que la salida indica que está “agrupado por” mes (Groups: month [12]). Esto significa que las operaciones posteriores ahora funcionarán “por mes”. group_by() agrega esta característica agrupada (referida como clase) al marco de datos, lo que cambia el comportamiento de los verbos subsiguientes aplicados a los datos.\n\n4.5.2 summarize()\n\nLa operación agrupada más importante es un resumen, que, si se usa para calcular una sola estadística de resumen, reduce el data frame para tener una sola fila para cada grupo. En dplyr, esta operación la realiza summarize()3, como se muestra en el siguiente ejemplo, que calcula el retraso de salida promedio por mes:\n\nflights |&gt; \n  group_by(month) |&gt; \n  summarize(\n    avg_delay = mean(dep_delay)\n  )\n#&gt; # A tibble: 12 × 2\n#&gt;   month avg_delay\n#&gt;   &lt;int&gt;     &lt;dbl&gt;\n#&gt; 1     1        NA\n#&gt; 2     2        NA\n#&gt; 3     3        NA\n#&gt; 4     4        NA\n#&gt; 5     5        NA\n#&gt; 6     6        NA\n#&gt; # ℹ 6 more rows\n\n¡UH oh! Algo salió mal y todos nuestros resultados son NAs (pronunciado “N-A”), el símbolo de R para el valor faltante. Esto sucedió porque a algunos de los vuelos observados les faltaban datos en la columna de demora, por lo que cuando calculamos la media que incluye esos valores, obtuvimos un resultado NA. Volveremos a discutir los valores faltantes en detalle en Capítulo 19, pero por ahora le diremos a la función mean() que ignore todos los valores faltantes configurando el argumento na.rm en TRUE:\n\nflights |&gt; \n  group_by(month) |&gt; \n  summarize(\n    avg_delay = mean(dep_delay, na.rm = TRUE)\n  )\n#&gt; # A tibble: 12 × 2\n#&gt;   month avg_delay\n#&gt;   &lt;int&gt;     &lt;dbl&gt;\n#&gt; 1     1      10.0\n#&gt; 2     2      10.8\n#&gt; 3     3      13.2\n#&gt; 4     4      13.9\n#&gt; 5     5      13.0\n#&gt; 6     6      20.8\n#&gt; # ℹ 6 more rows\n\nPuede crear cualquier cantidad de resúmenes en una sola llamada a summarize(). Aprenderá varios resúmenes útiles en los próximos capítulos, pero un resumen muy útil es n(), que devuelve el número de filas en cada grupo:\n\nflights |&gt; \n  group_by(month) |&gt; \n  summarize(\n    avg_delay = mean(dep_delay, na.rm = TRUE), \n    n = n()\n  )\n#&gt; # A tibble: 12 × 3\n#&gt;   month avg_delay     n\n#&gt;   &lt;int&gt;     &lt;dbl&gt; &lt;int&gt;\n#&gt; 1     1      10.0 27004\n#&gt; 2     2      10.8 24951\n#&gt; 3     3      13.2 28834\n#&gt; 4     4      13.9 28330\n#&gt; 5     5      13.0 28796\n#&gt; 6     6      20.8 28243\n#&gt; # ℹ 6 more rows\n\n¡Los medios y los conteos pueden llevarlo sorprendentemente lejos en la ciencia de datos!\n\n4.5.3 Las funciones slice_\n\nHay cinco funciones útiles que le permiten extraer filas específicas dentro de cada grupo:\n\n\ndf |&gt; slice_head(n = 1) toma la primera fila de cada grupo.\n\ndf |&gt; slice_tail(n = 1) toma la última fila de cada grupo.\n\ndf |&gt; slice_min(x, n = 1) toma la fila con el valor más pequeño de la columna x.\n\ndf |&gt; slice_max(x, n = 1) toma la fila con el mayor valor de la columna x.\n\ndf |&gt; slice_sample(n = 1) toma una fila aleatoria.\n\nPuede variar n para seleccionar más de una fila, o en lugar de n =, puede usar prop = 0.1 para seleccionar (p. ej.) el 10 % de las filas de cada grupo. Por ejemplo, el siguiente código encuentra los vuelos que se retrasan más al llegar a cada destino:\n\nflights |&gt; \n  group_by(dest) |&gt; \n  slice_max(arr_delay, n = 1) |&gt; \n  relocate(dest)\n#&gt; # A tibble: 108 × 19\n#&gt; # Groups:   dest [105]\n#&gt;   dest   year month   day dep_time sched_dep_time dep_delay arr_time\n#&gt;   &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;\n#&gt; 1 ABQ    2013     7    22     2145           2007        98      132\n#&gt; 2 ACK    2013     7    23     1139            800       219     1250\n#&gt; 3 ALB    2013     1    25      123           2000       323      229\n#&gt; 4 ANC    2013     8    17     1740           1625        75     2042\n#&gt; 5 ATL    2013     7    22     2257            759       898      121\n#&gt; 6 AUS    2013     7    10     2056           1505       351     2347\n#&gt; # ℹ 102 more rows\n#&gt; # ℹ 11 more variables: sched_arr_time &lt;int&gt;, arr_delay &lt;dbl&gt;, …\n\nTenga en cuenta que hay 105 destinos, pero aquí tenemos 108 filas. ¿Qué pasa? slice_min() y slice_max() mantienen valores empatados por lo que n = 1 significa darme todas las filas con el valor más alto. Si desea exactamente una fila por grupo, puede configurar whit_ties = FALSE.\nEsto es similar a calcular el retraso máximo con summarize(), pero obtienes la fila correspondiente completa (o filas si hay un empate) en lugar de la estadística de resumen única.\n\n4.5.4 Agrupación por múltiples variables\nPuede crear grupos utilizando más de una variable. Por ejemplo, podríamos hacer un grupo para cada fecha.\n\ndaily &lt;- flights |&gt;  \n  group_by(year, month, day)\ndaily\n#&gt; # A tibble: 336,776 × 19\n#&gt; # Groups:   year, month, day [365]\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\nCuando resume un tibble agrupado por más de una variable, cada resumen elimina el último grupo. En retrospectiva, esta no fue una excelente manera de hacer que esta función funcionara, pero es difícil cambiarla sin romper el código existente. Para que sea obvio lo que sucede, dplyr muestra un mensaje que le indica cómo puede cambiar este comportamiento:\n\ndaily_flights &lt;- daily |&gt; \n  summarize(n = n())\n#&gt; `summarise()` has grouped output by 'year', 'month'. You can override using\n#&gt; the `.groups` argument.\n\nSi está satisfecho con este comportamiento, puede solicitarlo explícitamente para suprimir el mensaje:\n\ndaily_flights &lt;- daily |&gt; \n  summarize(\n    n = n(), \n    .groups = \"drop_last\"\n  )\n\nAlternativamente, cambie el comportamiento predeterminado configurando un valor diferente, por ejemplo, \"drop\" para eliminar todas las agrupaciones o \"keep\" para conservar los mismos grupos.\n\n4.5.5 Desagrupar\nTambién es posible que desee eliminar la agrupación de un data frame sin utilizar summarize(). Puedes hacer esto con ungroup().\n\ndaily |&gt; \n  ungroup()\n#&gt; # A tibble: 336,776 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\nAhora veamos qué sucede cuando resume un data frame no agrupado.\n\ndaily |&gt; \n  ungroup() |&gt;\n  summarize(\n    avg_delay = mean(dep_delay, na.rm = TRUE), \n    flights = n()\n  )\n#&gt; # A tibble: 1 × 2\n#&gt;   avg_delay flights\n#&gt;       &lt;dbl&gt;   &lt;int&gt;\n#&gt; 1      12.6  336776\n\nComo puede ver, cuando resume un data frame sin agrupar, obtiene una sola fila porque dplyr trata todas las filas en un data frame sin agrupar como pertenecientes a un grupo.\n\n4.5.6 .by\n\ndplyr 1.1.0 incluye una nueva sintaxis experimental para la agrupación por operación, el argumento .by. group_by() y ungroup() no van a desaparecer, pero ahora también puedes usar el argumento .by para agrupar dentro de una sola operación:\n\nflights |&gt; \n  summarize(\n    delay = mean(dep_delay, na.rm = TRUE), \n    n = n(),\n    .by = month\n  )\n\nO si desea agrupar por múltiples variables:\n\nflights |&gt; \n  summarize(\n    delay = mean(dep_delay, na.rm = TRUE), \n    n = n(),\n    .by = c(origin, dest)\n  )\n\n.by funciona con todos los verbos y tiene la ventaja de que no necesita usar el argumento .groups para suprimir el mensaje de agrupación o ungroup() cuando haya terminado.\nNo nos enfocamos en esta sintaxis en este capítulo porque era muy nueva cuando se escribió el libro. Queríamos mencionarlo porque creemos que es muy prometedor y es probable que sea bastante popular. Puede obtener más información al respecto en la [publicación de blog de dplyr 1.1.0] (https://www.tidyverse.org/blog/2023/02/dplyr-1-1-0-per-operation-grouping/).\n\n4.5.7 Ejercicios\n\n¿Qué operador tiene el peor promedio de retrasos? Desafío: ¿puede desentrañar los efectos de los malos aeropuertos frente a los malos transportistas? ¿Por qué/por qué no? (Pista: piense en flights |&gt; group_by(carrier, dest) |&gt; summarize(n()))\nEncuentra los vuelos que más se retrasan a la salida de cada destino.\n¿Cómo varían los retrasos a lo largo del día? Ilustra tu respuesta con un gráfico.\n¿Qué sucede si proporcionas una n negativa a slice_min() y amigos?\nExplique lo que hace count() en términos de los verbos dplyr que acaba de aprender. ¿Qué hace el argumento sort para count()?\n\nSupongamos que tenemos el siguiente data frame diminuto:\n\ndf &lt;- tibble(\n  x = 1:5,\n  y = c(\"a\", \"b\", \"a\", \"a\", \"b\"),\n  z = c(\"K\", \"K\", \"L\", \"L\", \"K\")\n)\n\n\n\nEscriba cómo cree que se verá la salida, luego verifique si estuvo en lo correcto y describa qué hace group_by().\n\ndf |&gt;\n  group_by(y)\n\n\n\nEscriba cómo cree que se verá la salida, luego verifique si estuvo en lo correcto y describa qué hace arrange(). También comente en qué se diferencia del group_by() en la parte (a)?\n\ndf |&gt;\n  arrange(y)\n\n\n\nEscriba cómo cree que se verá la salida, luego verifique si estuvo en lo correcto y describa qué hace la canalización.\n\ndf |&gt;\n  group_by(y) |&gt;\n  summarize(mean_x = mean(x))\n\n\n\n¿Escriba cómo cree que se verá la salida, luego verifique si estuvo en lo correcto y describa qué hace la canalización. Luego, comenta lo que dice el mensaje.\n\ndf |&gt;\n  group_by(y, z) |&gt;\n  summarize(mean_x = mean(x))\n\n\n\nEscriba cómo cree que se verá la salida, luego verifique si estuvo en lo correcto y describa qué hace la canalización. ¿En qué se diferencia la salida de la del inciso d).\n\ndf |&gt;\n  group_by(y, z) |&gt;\n  summarize(mean_x = mean(x), .groups = \"drop\")\n\n\n\nEscriba cómo cree que se verá la salida, luego verifique si estuvo en lo correcto y describa qué hace la canalización. ¿En qué se diferencian las salidas de las dos pipes?\n\ndf |&gt;\n  group_by(y, z) |&gt;\n  summarize(mean_x = mean(x))\n\ndf |&gt;\n  group_by(y, z) |&gt;\n  mutate(mean_x = mean(x))"
  },
  {
    "objectID": "data-transform.html#sec-sample-size",
    "href": "data-transform.html#sec-sample-size",
    "title": "4  Transformación de datos",
    "section": "\n4.6 Caso de estudio: agregados y tamaño de la muestra",
    "text": "4.6 Caso de estudio: agregados y tamaño de la muestra\nSiempre que realice una agregación, siempre es una buena idea incluir un conteo (n()). De esa manera, puede asegurarse de no sacar conclusiones basadas en cantidades muy pequeñas de datos. Demostraremos esto con algunos datos de béisbol del paquete Lahman. En concreto, compararemos la proporción de veces que un jugador acierta (H) frente al número de veces que intenta poner la pelota en juego (AB):\n\nbatters &lt;- Lahman::Batting |&gt; \n  group_by(playerID) |&gt; \n  summarize(\n    performance = sum(H, na.rm = TRUE) / sum(AB, na.rm = TRUE),\n    n = sum(AB, na.rm = TRUE)\n  )\nbatters\n#&gt; # A tibble: 20,469 × 3\n#&gt;   playerID  performance     n\n#&gt;   &lt;chr&gt;           &lt;dbl&gt; &lt;int&gt;\n#&gt; 1 aardsda01      0          4\n#&gt; 2 aaronha01      0.305  12364\n#&gt; 3 aaronto01      0.229    944\n#&gt; 4 aasedo01       0          5\n#&gt; 5 abadan01       0.0952    21\n#&gt; 6 abadfe01       0.111      9\n#&gt; # ℹ 20,463 more rows\n\nCuando graficamos la habilidad del bateador (medida por el promedio de bateo, performance) contra el número de oportunidades para batear la pelota (medida por veces al bate, n), se ven dos patrones:\n\nLa variación en el performance es mayor entre los jugadores con menos turnos al bate. La forma de esta gráfica es muy característica: cada vez que grafica una media (u otras estadísticas de resumen) frente al tamaño del grupo, verá que la variación disminuye a medida que aumenta el tamaño de la muestra 4.\nHay una correlación positiva entre la habilidad (performance) y las oportunidades de golpear la pelota (n) porque los equipos quieren dar a sus mejores bateadores la mayor cantidad de oportunidades para golpear la pelota.\n\n\nbatters |&gt; \n  filter(n &gt; 100) |&gt; \n  ggplot(aes(x = n, y = performance)) +\n  geom_point(alpha = 1 / 10) + \n  geom_smooth(se = FALSE)\n\n\n\n\nTenga en cuenta el práctico patrón para combinar ggplot2 y dplyr. Solo debe recordar cambiar de |&gt;, para el procesamiento de conjuntos de datos, a + para agregar capas a su gráfico.\nEsto también tiene implicaciones importantes para la clasificación. Si clasifica ingenuamente en desc (performance), las personas con los mejores promedios de bateo son claramente las que intentaron poner la pelota en juego muy pocas veces y dieron un hit, no son necesariamente los jugadores más hábiles :\n\nbatters |&gt; \n  arrange(desc(performance))\n#&gt; # A tibble: 20,469 × 3\n#&gt;   playerID  performance     n\n#&gt;   &lt;chr&gt;           &lt;dbl&gt; &lt;int&gt;\n#&gt; 1 abramge01           1     1\n#&gt; 2 alberan01           1     1\n#&gt; 3 banisje01           1     1\n#&gt; 4 bartocl01           1     1\n#&gt; 5 bassdo01            1     1\n#&gt; 6 birasst01           1     2\n#&gt; # ℹ 20,463 more rows\n\nPuede encontrar una buena explicación de este problema y cómo superarlo en http://varianceexplained.org/r/empirical_bayes_baseball/ y https://www.evanmiller.org/how-not-to-sort-by-average-rating.html."
  },
  {
    "objectID": "data-transform.html#resumen",
    "href": "data-transform.html#resumen",
    "title": "4  Transformación de datos",
    "section": "\n4.7 Resumen",
    "text": "4.7 Resumen\nEn este capítulo, ha aprendido las herramientas que proporciona dplyr para trabajar con data frames. Las herramientas se agrupan aproximadamente en tres categorías: las que manipulan las filas (como filter() y arrange(), las que manipulan las columnas (como select() y mutate()), y las que que manipulan grupos (como group_by() y summarize()). En este capítulo, nos hemos centrado en estas herramientas de “data frame completo”, pero aún no ha aprendido mucho sobre lo que puede hacer con la variable individual. Volveremos a eso en la parte Transformar del libro, donde cada capítulo le brindará herramientas para un tipo específico de variable.\nEn el próximo capítulo, regresaremos al flujo de trabajo para discutir la importancia del estilo del código, manteniendo su código bien organizado para que usted y otros puedan leerlo y comprenderlo fácilmente."
  },
  {
    "objectID": "data-transform.html#footnotes",
    "href": "data-transform.html#footnotes",
    "title": "4  Transformación de datos",
    "section": "",
    "text": "Más adelante, aprenderá sobre la familia slice_*(), que le permite elegir filas en función de sus posiciones.↩︎\nRecuerde que en RStudio, la forma más fácil de ver un conjunto de datos con muchas columnas es View().↩︎\nO summarise(), si prefiere inglés británico.↩︎\n*cough* the law of large numbers *cough*.↩︎"
  },
  {
    "objectID": "logicals.html#introducción",
    "href": "logicals.html#introducción",
    "title": "13  Vectores lógicos",
    "section": "",
    "text": "13.1.1 Requisitos previos\nLa mayoría de las funciones que aprenderá en este capítulo son proporcionadas por la base R, por lo que no necesitamos el tidyverse, pero igual lo cargaremos para poder usar mutate(), filter(), y amigos para trabajar con data frames. También continuaremos extrayendo ejemplos del conjunto de datos nycflights13::flights.\n\nlibrary(tidyverse)\nlibrary(nycflights13)\n\nSin embargo, a medida que empecemos a cubrir más herramientas, no siempre habrá un ejemplo real perfecto. Así que empezaremos a inventar algunos datos ficticios con c():\n\nx &lt;- c(1, 2, 3, 5, 7, 11, 13)\nx * 2\n#&gt; [1]  2  4  6 10 14 22 26\n\nEsto facilita la explicación de funciones individuales a costa de dificultar ver cómo podría aplicarse a sus problemas de datos. Solo recuerda que cualquier manipulación que hagamos a un vector flotante, puedes hacerla a una variable dentro de un data frame con mutate() y amigos.\n\ndf &lt;- tibble(x)\ndf |&gt; \n  mutate(y = x * 2)\n#&gt; # A tibble: 7 × 2\n#&gt;       x     y\n#&gt;   &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     1     2\n#&gt; 2     2     4\n#&gt; 3     3     6\n#&gt; 4     5    10\n#&gt; 5     7    14\n#&gt; 6    11    22\n#&gt; # ℹ 1 more row",
    "crumbs": [
      "Transformar",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Vectores lógicos</span>"
    ]
  },
  {
    "objectID": "logicals.html#comparaciones",
    "href": "logicals.html#comparaciones",
    "title": "13  Vectores lógicos",
    "section": "\n13.2 Comparaciones",
    "text": "13.2 Comparaciones\nUna forma muy común de crear un vector lógico es a través de una comparación numérica con &lt;, &lt;=, &gt;, &gt;=, != y ==. Hasta ahora, en su mayoría hemos creado variables lógicas de manera transitoria dentro de filter() — se calculan, usan y luego se descartan. Por ejemplo, el siguiente filtro encuentra todas las salidas diurnas que llegan aproximadamente a tiempo:\n\nflights |&gt; \n  filter(dep_time &gt; 600 & dep_time &lt; 2000 & abs(arr_delay) &lt; 20)\n#&gt; # A tibble: 172,286 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      601            600         1      844            850\n#&gt; 2  2013     1     1      602            610        -8      812            820\n#&gt; 3  2013     1     1      602            605        -3      821            805\n#&gt; 4  2013     1     1      606            610        -4      858            910\n#&gt; 5  2013     1     1      606            610        -4      837            845\n#&gt; 6  2013     1     1      607            607         0      858            915\n#&gt; # ℹ 172,280 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\nEs útil saber que este es un atajo y que puedes crear explícitamente las variables lógicas subyacentes con mutate():\n\nflights |&gt; \n  mutate(\n    daytime = dep_time &gt; 600 & dep_time &lt; 2000,\n    approx_ontime = abs(arr_delay) &lt; 20,\n    .keep = \"used\"\n  )\n#&gt; # A tibble: 336,776 × 4\n#&gt;   dep_time arr_delay daytime approx_ontime\n#&gt;      &lt;int&gt;     &lt;dbl&gt; &lt;lgl&gt;   &lt;lgl&gt;        \n#&gt; 1      517        11 FALSE   TRUE         \n#&gt; 2      533        20 FALSE   FALSE        \n#&gt; 3      542        33 FALSE   FALSE        \n#&gt; 4      544       -18 FALSE   TRUE         \n#&gt; 5      554       -25 FALSE   FALSE        \n#&gt; 6      554        12 FALSE   TRUE         \n#&gt; # ℹ 336,770 more rows\n\nEsto es particularmente útil para la lógica más complicada porque nombrar los pasos intermedios facilita la lectura del código y la verificación de que cada paso se haya calculado correctamente.\nCon todo, el filtro inicial es equivalente a:\n\nflights |&gt; \n  mutate(\n    daytime = dep_time &gt; 600 & dep_time &lt; 2000,\n    approx_ontime = abs(arr_delay) &lt; 20,\n  ) |&gt; \n  filter(daytime & approx_ontime)\n\n\n13.2.1 Comparación de punto flotante\nCuidado con usar == con números. Por ejemplo, parece que este vector contiene los números 1 y 2:\n\nx &lt;- c(1 / 49 * 49, sqrt(2) ^ 2)\nx\n#&gt; [1] 1 2\n\nPero si los prueba para la igualdad, obtiene FALSE, FALSE:\n\nx == c(1, 2)\n#&gt; [1] FALSE FALSE\n\n¿Qué está sucediendo? Las computadoras almacenan números con un número fijo de posiciones decimales, por lo que no hay forma de representar exactamente 1/49 o sqrt(2) y los cálculos subsiguientes estarán ligeramente desviados. Podemos ver los valores exactos llamando a print() con el argumento digits1:\n\nprint(x, digits = 16)\n#&gt; [1] 0.9999999999999999 2.0000000000000004\n\nPuede ver por qué R por defecto redondea estos números; realmente están muy cerca de lo que esperas.\nAhora que ha visto por qué == está fallando, ¿qué puede hacer al respecto? Una opción es usar dplyr::near() que ignora las pequeñas diferencias:\n\nnear(x, c(1, 2))\n#&gt; [1] TRUE TRUE\n\n\n13.2.2 Valores faltantes\nLos valores faltantes representan lo desconocido, por lo que son “contagiosos”: casi cualquier operación que involucre un valor desconocido también será desconocida:\n\nNA &gt; 5\n#&gt; [1] NA\n10 == NA\n#&gt; [1] NA\n\nEl resultado más confuso es este:\n\nNA == NA\n#&gt; [1] NA\n\nEs más fácil entender por qué esto es cierto si proporcionamos artificialmente un poco más de contexto:\n\n# No sabemos cuántos años tiene María.\nedad_maria &lt;- NA\n\n# No sabemos cuántos años tiene Juan.\nedad_juan &lt;- NA\n\n# ¿María y Juan tienen la misma edad?\nedad_maria == edad_juan\n#&gt; [1] NA\n# ¡No sabemos!\n\nEntonces, si desea encontrar todos los vuelos en los que falta dep_time, el siguiente código no funciona porque dep_time == NA generará NA para cada fila, y filter() elimina automáticamente los valores faltantes:\n\nflights |&gt; \n  filter(dep_time == NA)\n#&gt; # A tibble: 0 × 19\n#&gt; # ℹ 19 variables: year &lt;int&gt;, month &lt;int&gt;, day &lt;int&gt;, dep_time &lt;int&gt;,\n#&gt; #   sched_dep_time &lt;int&gt;, dep_delay &lt;dbl&gt;, arr_time &lt;int&gt;, …\n\nEn su lugar, necesitaremos una nueva herramienta: is.na().\n\n13.2.3 is.na()\n\nis.na(x) funciona con cualquier tipo de vector y devuelve TRUE, TRUE, para los valores faltantes y FALSE, FALSE, para todo lo demás:\n\nis.na(c(TRUE, NA, FALSE))\n#&gt; [1] FALSE  TRUE FALSE\nis.na(c(1, NA, 3))\n#&gt; [1] FALSE  TRUE FALSE\nis.na(c(\"a\", NA, \"b\"))\n#&gt; [1] FALSE  TRUE FALSE\n\nPodemos usar is.na() para encontrar todas las filas a las que les falta dep_time:\n\nflights |&gt; \n  filter(is.na(dep_time))\n#&gt; # A tibble: 8,255 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1       NA           1630        NA       NA           1815\n#&gt; 2  2013     1     1       NA           1935        NA       NA           2240\n#&gt; 3  2013     1     1       NA           1500        NA       NA           1825\n#&gt; 4  2013     1     1       NA            600        NA       NA            901\n#&gt; 5  2013     1     2       NA           1540        NA       NA           1747\n#&gt; 6  2013     1     2       NA           1620        NA       NA           1746\n#&gt; # ℹ 8,249 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\nis.na() también puede ser útil en arrange(). arrange() generalmente coloca todos los valores faltantes al final, pero puede anular este valor predeterminado ordenando primero por is.na():\n\nflights |&gt; \n  filter(month == 1, day == 1) |&gt; \n  arrange(dep_time)\n#&gt; # A tibble: 842 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # ℹ 836 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\nflights |&gt; \n  filter(month == 1, day == 1) |&gt; \n  arrange(desc(is.na(dep_time)), dep_time)\n#&gt; # A tibble: 842 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1       NA           1630        NA       NA           1815\n#&gt; 2  2013     1     1       NA           1935        NA       NA           2240\n#&gt; 3  2013     1     1       NA           1500        NA       NA           1825\n#&gt; 4  2013     1     1       NA            600        NA       NA            901\n#&gt; 5  2013     1     1      517            515         2      830            819\n#&gt; 6  2013     1     1      533            529         4      850            830\n#&gt; # ℹ 836 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\nVolveremos para cubrir los valores faltantes con más profundidad en Capítulo 19.\n\n13.2.4 Ejercicios\n\n¿Cómo funciona dplyr::near()? Escribe near para ver el código fuente. ¿Es sqrt(2)^2 cerca de 2?\nUse mutate(), is.na() y count() juntos para describir cómo se conectan los valores que faltan en dep_time, sched_dep_time y dep_delay.",
    "crumbs": [
      "Transformar",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Vectores lógicos</span>"
    ]
  },
  {
    "objectID": "logicals.html#álgebra-booleana",
    "href": "logicals.html#álgebra-booleana",
    "title": "13  Vectores lógicos",
    "section": "\n13.3 Álgebra booleana",
    "text": "13.3 Álgebra booleana\nUna vez que tenga varios vectores lógicos, puede combinarlos usando álgebra booleana. En R, & es “y”, | es “o”, ! es “no”, y xor() es exclusivo o 2. Por ejemplo, df |&gt; filter(!is.na(x)) encuentra todas las filas donde no falta x y df |&gt; filter(x &lt; -10 | x &gt; 0) encuentra todas las filas donde x es menor que -10 o mayor que 0. Figura 13.1 muestra el conjunto completo de operaciones booleanas y cómo funcionan.\n\n\n\n\n\n\n\nFigura 13.1: El conjunto completo de operaciones booleanas. x es el círculo a la izquierda, y es el círculo de la derecha, y la región sombreada muestra qué partes selecciona cada operador.\n\n\n\n\nAdemás de & y |, R también tiene && y ||. ¡No los use en funciones dplyr! Estos se denominan operadores de cortocircuito y solo devuelven un solo TRUE o FALSE. Son importantes para la programación, no para la ciencia de datos.\n\n13.3.1 Valores Faltantes\nLas reglas para los valores faltantes en el álgebra booleana son un poco difíciles de explicar porque parecen inconsistentes a primera vista:\n\ndf &lt;- tibble(x = c(TRUE, FALSE, NA))\n\ndf |&gt; \n  mutate(\n    and = x & NA,\n    or = x | NA\n  )\n#&gt; # A tibble: 3 × 3\n#&gt;   x     and   or   \n#&gt;   &lt;lgl&gt; &lt;lgl&gt; &lt;lgl&gt;\n#&gt; 1 TRUE  NA    TRUE \n#&gt; 2 FALSE FALSE NA   \n#&gt; 3 NA    NA    NA\n\nPara entender lo que está pasando, piense en NA | TRUE (NA o TRUE). Un valor faltante en un vector lógico significa que el valor podría ser TRUE o FALSE. TRUE | TRUE y FALSE | TRUE son ambos TRUE porque al menos uno de ellos es TRUE. NA | TRUE también debe ser TRUE porque NA puede ser TRUE o FALSE. Sin embargo NA | FALSE es FALSE porque NA puede ser TRUE o FALSE Se aplica un razonamiento similar con NA & FALSE.\n\n13.3.2 Orden de operaciones\nTenga en cuenta que el orden de las operaciones no funciona como en inglés. Tome el siguiente código que encuentra todos los vuelos que salieron en noviembre o diciembre:\n\nflights |&gt; \n   filter(month == 11 | month == 12)\n\nEs posible que tenga la tentación de escribirlo como diría en inglés: “Buscar todos los vuelos que partieron en noviembre o diciembre”.:\n\nflights |&gt; \n   filter(month == 11 | 12)\n#&gt; # A tibble: 336,776 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1      533            529         4      850            830\n#&gt; 3  2013     1     1      542            540         2      923            850\n#&gt; 4  2013     1     1      544            545        -1     1004           1022\n#&gt; 5  2013     1     1      554            600        -6      812            837\n#&gt; 6  2013     1     1      554            558        -4      740            728\n#&gt; # ℹ 336,770 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\nEste código no da error, pero tampoco parece haber funcionado. ¿Qué está sucediendo? Aquí, R primero evalúa month == 11 creando un vector lógico, al que llamamos nov. Calcula nov | 12. Cuando usa un número con un operador lógico, convierte todo menos 0 en TRUE, por lo que esto es equivalente a nov | TRUE que siempre será TRUE, por lo que se seleccionarán todas las filas:\n\nflights |&gt; \n  mutate(\n    nov = month == 11,\n    final = nov | 12,\n    .keep = \"used\"\n  )\n#&gt; # A tibble: 336,776 × 3\n#&gt;   month nov   final\n#&gt;   &lt;int&gt; &lt;lgl&gt; &lt;lgl&gt;\n#&gt; 1     1 FALSE TRUE \n#&gt; 2     1 FALSE TRUE \n#&gt; 3     1 FALSE TRUE \n#&gt; 4     1 FALSE TRUE \n#&gt; 5     1 FALSE TRUE \n#&gt; 6     1 FALSE TRUE \n#&gt; # ℹ 336,770 more rows\n\n\n13.3.3 %in%\n\nUna manera fácil de evitar el problema de poner tus ==s y |s en el orden correcto es usar %in%. x %in% y devuelve un vector lógico de la misma longitud que x que es TRUE cada vez que un valor en x está en cualquier parte de y.\n\n1:12 %in% c(1, 5, 11)\n#&gt;  [1]  TRUE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE\nletters[1:10] %in% c(\"a\", \"e\", \"i\", \"o\", \"u\")\n#&gt;  [1]  TRUE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE  TRUE FALSE\n\nEntonces, para encontrar todos los vuelos en noviembre y diciembre, podríamos escribir:\n\nflights |&gt; \n  filter(month %in% c(11, 12))\n\nTenga en cuenta que %in% obedece reglas diferentes para NA y ==, ya que NA %in% NA es TRUE.\n\nc(1, 2, NA) == NA\n#&gt; [1] NA NA NA\nc(1, 2, NA) %in% NA\n#&gt; [1] FALSE FALSE  TRUE\n\nEsto puede ser un atajo útil:\n\nflights |&gt; \n  filter(dep_time %in% c(NA, 0800))\n#&gt; # A tibble: 8,803 × 19\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      800            800         0     1022           1014\n#&gt; 2  2013     1     1      800            810       -10      949            955\n#&gt; 3  2013     1     1       NA           1630        NA       NA           1815\n#&gt; 4  2013     1     1       NA           1935        NA       NA           2240\n#&gt; 5  2013     1     1       NA           1500        NA       NA           1825\n#&gt; 6  2013     1     1       NA            600        NA       NA            901\n#&gt; # ℹ 8,797 more rows\n#&gt; # ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\n\n13.3.4 Ejercicios\n\nEncuentre todos los vuelos en los que falte arr_delay pero no dep_delay. Encuentre todos los vuelos en los que no falten ni arr_time ni sched_arr_time, pero sí arr_delay.\n¿A cuántos vuelos les falta dep_time? ¿Qué otras variables faltan en estas filas? ¿Qué podrían representar estas filas?\nSuponiendo que la falta de dep_time implica que se canceló un vuelo, mire la cantidad de vuelos cancelados por día. ¿Hay un patrón? ¿Existe una conexión entre la proporción de vuelos cancelados y el retraso promedio de los vuelos no cancelados?",
    "crumbs": [
      "Transformar",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Vectores lógicos</span>"
    ]
  },
  {
    "objectID": "logicals.html#sec-logical-summaries",
    "href": "logicals.html#sec-logical-summaries",
    "title": "13  Vectores lógicos",
    "section": "\n13.4 Resúmenes",
    "text": "13.4 Resúmenes\nLas siguientes secciones describen algunas técnicas útiles para resumir vectores lógicos. Además de funciones que solo funcionan específicamente con vectores lógicos, también puede usar funciones que funcionan con vectores numéricos.\n\n13.4.1 Resúmenes lógicos\nHay dos resúmenes lógicos principales: any() y all(). any(x) es el equivalente de |; devolverá TRUE si hay algún TRUE en x. all(x) es equivalente a &; devolverá TRUE solo si todos los valores de x son TRUE. Como todas las funciones de resumen, devolverán NA si hay algún valor faltante presente y, como de costumbre, puede hacer que los valores faltantes desaparezcan con na.rm = TRUE.\nPor ejemplo, podríamos usar all() y any() para averiguar si todos los vuelos se retrasaron a la salida como máximo una hora o si algún vuelo se retrasó a la llegada cinco horas o más. Y usar group_by() nos permite hacer eso por día:\n\nflights |&gt; \n  group_by(year, month, day) |&gt; \n  summarize(\n    all_delayed = all(dep_delay &lt;= 60, na.rm = TRUE),\n    any_long_delay = any(arr_delay &gt;= 300, na.rm = TRUE),\n    .groups = \"drop\"\n  )\n#&gt; # A tibble: 365 × 5\n#&gt;    year month   day all_delayed any_long_delay\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;lgl&gt;       &lt;lgl&gt;         \n#&gt; 1  2013     1     1 FALSE       TRUE          \n#&gt; 2  2013     1     2 FALSE       TRUE          \n#&gt; 3  2013     1     3 FALSE       FALSE         \n#&gt; 4  2013     1     4 FALSE       FALSE         \n#&gt; 5  2013     1     5 FALSE       TRUE          \n#&gt; 6  2013     1     6 FALSE       FALSE         \n#&gt; # ℹ 359 more rows\n\nEn la mayoría de los casos, sin embargo, any() y all() son un poco toscos, y sería bueno poder obtener un poco más de detalles sobre cuántos valores son TRUE o FALSE. Eso nos lleva a los resúmenes numéricos.\n\n13.4.2 Resúmenes numéricos de vectores lógicos\nCuando usa un vector lógico en un contexto numérico, TRUE se convierte en 1 y FALSE se convierte en 0. Esto hace que sum() y mean() sean muy útiles con vectores lógicos porque sum(x) da el número de TRUEs y mean(x) da la proporción de TRUEs (porque mean() es simplemente sum() dividido por length().\nEso, por ejemplo, nos permite ver la proporción de vuelos que se retrasaron a la salida como máximo una hora y la cantidad de vuelos que se retrasaron a la llegada cinco horas o más:\n\nflights |&gt; \n  group_by(year, month, day) |&gt; \n  summarize(\n    proportion_delayed = mean(dep_delay &lt;= 60, na.rm = TRUE),\n    count_long_delay = sum(arr_delay &gt;= 300, na.rm = TRUE),\n    .groups = \"drop\"\n  )\n#&gt; # A tibble: 365 × 5\n#&gt;    year month   day proportion_delayed count_long_delay\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;              &lt;dbl&gt;            &lt;int&gt;\n#&gt; 1  2013     1     1              0.939                3\n#&gt; 2  2013     1     2              0.914                3\n#&gt; 3  2013     1     3              0.941                0\n#&gt; 4  2013     1     4              0.953                0\n#&gt; 5  2013     1     5              0.964                1\n#&gt; 6  2013     1     6              0.959                0\n#&gt; # ℹ 359 more rows\n\n\n13.4.3 Subconjunto lógico\nHay un uso final para los vectores lógicos en los resúmenes: puede usar un vector lógico para filtrar una sola variable a un subconjunto de interés. Esto hace uso del operador base [ (subconjunto pronunciado), sobre el que obtendrá más información en Sección 28.2.\nImagine que quisiéramos ver el retraso promedio solo para los vuelos que realmente se retrasaron. Una forma de hacerlo sería filtrar primero los vuelos y luego calcular el retraso promedio:\n\nflights |&gt; \n  filter(arr_delay &gt; 0) |&gt; \n  group_by(year, month, day) |&gt; \n  summarize(\n    behind = mean(arr_delay),\n    n = n(),\n    .groups = \"drop\"\n  )\n#&gt; # A tibble: 365 × 5\n#&gt;    year month   day behind     n\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;  &lt;dbl&gt; &lt;int&gt;\n#&gt; 1  2013     1     1   32.5   461\n#&gt; 2  2013     1     2   32.0   535\n#&gt; 3  2013     1     3   27.7   460\n#&gt; 4  2013     1     4   28.3   297\n#&gt; 5  2013     1     5   22.6   238\n#&gt; 6  2013     1     6   24.4   381\n#&gt; # ℹ 359 more rows\n\nEsto funciona, pero ¿y si también quisiéramos calcular el retraso promedio de los vuelos que llegaron temprano? Tendríamos que realizar un paso de filtro por separado y luego descubrir cómo combinar los dos marcos de datos juntos [^ lógicos-3]. En su lugar, podría usar [ para realizar un filtrado en línea: arr_delay[arr_delay &gt; 0] generará solo los retrasos de llegada positivos.\nEsto lleva a:\n\nflights |&gt; \n  group_by(year, month, day) |&gt; \n  summarize(\n    behind = mean(arr_delay[arr_delay &gt; 0], na.rm = TRUE),\n    ahead = mean(arr_delay[arr_delay &lt; 0], na.rm = TRUE),\n    n = n(),\n    .groups = \"drop\"\n  )\n#&gt; # A tibble: 365 × 6\n#&gt;    year month   day behind ahead     n\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n#&gt; 1  2013     1     1   32.5 -12.5   842\n#&gt; 2  2013     1     2   32.0 -14.3   943\n#&gt; 3  2013     1     3   27.7 -18.2   914\n#&gt; 4  2013     1     4   28.3 -17.0   915\n#&gt; 5  2013     1     5   22.6 -14.0   720\n#&gt; 6  2013     1     6   24.4 -13.6   832\n#&gt; # ℹ 359 more rows\n\nTambién tenga en cuenta la diferencia en el tamaño del grupo: en el primer fragmento n() da el número de vuelos retrasados por día; en el segundo, n() da el número total de vuelos.\n\n13.4.4 Ejercicios\n\n¿Qué te dirá sum(is.na(x))? ¿Qué tal mean(is.na(x))?\n¿Qué devuelve prod() cuando se aplica a un vector lógico? ¿A qué función de resumen lógico es equivalente? ¿Qué devuelve min() cuando se aplica a un vector lógico? ¿A qué función de resumen lógico es equivalente? Lea la documentación y realice algunos experimentos.",
    "crumbs": [
      "Transformar",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Vectores lógicos</span>"
    ]
  },
  {
    "objectID": "logicals.html#transformaciones-condicionales",
    "href": "logicals.html#transformaciones-condicionales",
    "title": "13  Vectores lógicos",
    "section": "\n13.5 Transformaciones condicionales",
    "text": "13.5 Transformaciones condicionales\nUna de las características más poderosas de los vectores lógicos es su uso para transformaciones condicionales, es decir, hacer una cosa para la condición x y algo diferente para la condición y. Hay dos herramientas importantes para esto: if_else() y case_when().\n\n13.5.1 if_else()\n\nSi quiere usar un valor cuando una condición es TRUE y otro valor cuando es FALSE, puede usar dplyr::if_else()3. Siempre usarás los tres primeros argumentos de if_else(). El primer argumento, condition, es un vector lógico, el segundo, true, da la salida cuando la condición es verdadera, y el tercero, false, da la salida si la condición es falsa.\nComencemos con un ejemplo simple de etiquetar un vector numérico como “+ve” (positivo) o “-ve” (negativo):\n\nx &lt;- c(-3:3, NA)\nif_else(x &gt; 0, \"+ve\", \"-ve\")\n#&gt; [1] \"-ve\" \"-ve\" \"-ve\" \"-ve\" \"+ve\" \"+ve\" \"+ve\" NA\n\nHay un cuarto argumento opcional, missing que se usará si la entrada es NA:\n\nif_else(x &gt; 0, \"+ve\", \"-ve\", \"???\")\n#&gt; [1] \"-ve\" \"-ve\" \"-ve\" \"-ve\" \"+ve\" \"+ve\" \"+ve\" \"???\"\n\nTambién puede usar vectores para los argumentos true y false. Por ejemplo, esto nos permite crear una implementación mínima de abs():\n\nif_else(x &lt; 0, -x, x)\n#&gt; [1]  3  2  1  0  1  2  3 NA\n\nHasta ahora, todos los argumentos han usado los mismos vectores, pero, por supuesto, puede mezclarlos y combinarlos. Por ejemplo, podría implementar una versión simple de coalesce() como esta:\n\nx1 &lt;- c(NA, 1, 2, NA)\ny1 &lt;- c(3, NA, 4, 6)\nif_else(is.na(x1), y1, x1)\n#&gt; [1] 3 1 2 6\n\nEs posible que haya notado una pequeña infelicidad en nuestro ejemplo de etiquetado anterior: cero no es ni positivo ni negativo. Podríamos resolver esto agregando un if_else() adicional:\n\nif_else(x == 0, \"0\", if_else(x &lt; 0, \"-ve\", \"+ve\"), \"???\")\n#&gt; [1] \"-ve\" \"-ve\" \"-ve\" \"0\"   \"+ve\" \"+ve\" \"+ve\" \"???\"\n\nEsto ya es un poco difícil de leer, y puedes imaginar que solo sería más difícil si tuvieras más condiciones. En su lugar, puede cambiar a dplyr::case_when().\n\n13.5.2 case_when()\n\ncase_when() de dplyr está inspirado en la declaración CASE de SQL y proporciona una forma flexible de realizar diferentes cálculos para diferentes condiciones. Tiene una sintaxis especial que, lamentablemente, no se parece a nada que vayas a usar en tidyverse. Toma pares que parecen condition ~ output. condition debe ser un vector lógico; cuando es TRUE, se usará output.\nEsto significa que podríamos recrear nuestro anterior if_else() anidado de la siguiente manera:\n\nx &lt;- c(-3:3, NA)\ncase_when(\n  x == 0   ~ \"0\",\n  x &lt; 0    ~ \"-ve\", \n  x &gt; 0    ~ \"+ve\",\n  is.na(x) ~ \"???\"\n)\n#&gt; [1] \"-ve\" \"-ve\" \"-ve\" \"0\"   \"+ve\" \"+ve\" \"+ve\" \"???\"\n\nEsto es más código, pero también es más explícito.\nPara explicar cómo funciona case_when(), exploremos algunos casos más simples. Si ninguno de los casos coincide, la salida obtiene un NA:\n\ncase_when(\n  x &lt; 0 ~ \"-ve\",\n  x &gt; 0 ~ \"+ve\"\n)\n#&gt; [1] \"-ve\" \"-ve\" \"-ve\" NA    \"+ve\" \"+ve\" \"+ve\" NA\n\nUse .default si desea crear un valor catch all “predeterminado”:\n\ncase_when(\n  x &lt; 0 ~ \"-ve\",\n  x &gt; 0 ~ \"+ve\",\n  .default = \"???\"\n)\n#&gt; [1] \"-ve\" \"-ve\" \"-ve\" \"???\" \"+ve\" \"+ve\" \"+ve\" \"???\"\n\nY tenga en cuenta que si coinciden varias condiciones, solo se utilizará la primera:\n\ncase_when(\n  x &gt; 0 ~ \"+ve\",\n  x &gt; 2 ~ \"big\"\n)\n#&gt; [1] NA    NA    NA    NA    \"+ve\" \"+ve\" \"+ve\" NA\n\nAl igual que con if_else(), puede usar variables en ambos lados de ~ y puede mezclar y combinar variables según sea necesario para su problema. Por ejemplo, podríamos usar case_when() para proporcionar algunas etiquetas legibles por humanos para el retraso de llegada:\n\nflights |&gt; \n  mutate(\n    status = case_when(\n      is.na(arr_delay)      ~ \"cancelado\",\n      arr_delay &lt; -30       ~ \"muy temprano\",\n      arr_delay &lt; -15       ~ \"temprano\",\n      abs(arr_delay) &lt;= 15  ~ \"a tiempo\",\n      arr_delay &lt; 60        ~ \"tarde\",\n      arr_delay &lt; Inf       ~ \"muy tarde\",\n    ),\n    .keep = \"used\"\n  )\n#&gt; # A tibble: 336,776 × 2\n#&gt;   arr_delay status  \n#&gt;       &lt;dbl&gt; &lt;chr&gt;   \n#&gt; 1        11 a tiempo\n#&gt; 2        20 tarde   \n#&gt; 3        33 tarde   \n#&gt; 4       -18 temprano\n#&gt; 5       -25 temprano\n#&gt; 6        12 a tiempo\n#&gt; # ℹ 336,770 more rows\n\nTenga cuidado al escribir este tipo de declaraciones complejas case_when(); mis primeros dos intentos usaron una combinación de &lt; y &gt; y seguí creando accidentalmente condiciones superpuestas.\n\n13.5.3 Tipos compatibles\nTenga en cuenta que tanto if_else() como case_when() requieren tipos compatibles en la salida. Si no son compatibles, verá errores como este:\n\nif_else(TRUE, \"a\", 1)\n#&gt; Error in `if_else()`:\n#&gt; ! Can't combine `true` &lt;character&gt; and `false` &lt;double&gt;.\n\ncase_when(\n  x &lt; -1 ~ TRUE,  \n  x &gt; 0  ~ now()\n)\n#&gt; Error in `case_when()`:\n#&gt; ! Can't combine `..1 (right)` &lt;logical&gt; and `..2 (right)` &lt;datetime&lt;local&gt;&gt;.\n\nEn general, relativamente pocos tipos son compatibles, porque la conversión automática de un tipo de vector a otro es una fuente común de errores. Estos son los casos más importantes que son compatibles:\n\nLos vectores numéricos y lógicos son compatibles, como discutimos en Sección 13.4.2.\nLas cadenas y los factores (Capítulo 17) son compatibles, porque puede pensar en un factor como una cadena con un conjunto restringido de valores.\nLas fechas y las fechas y horas, de las que hablaremos en Capítulo 18, son compatibles porque puede pensar en una fecha como un caso especial de fecha y hora.\n\nNA, que técnicamente es un vector lógico, es compatible con todo porque cada vector tiene alguna forma de representar un valor faltante.\n\nNo esperamos que memorices estas reglas, pero deberían convertirse en una segunda naturaleza con el tiempo porque se aplican de manera consistente en todo el tidyverse.\n\n13.5.4 Ejercicios\n\nUn número es par si es divisible por dos, lo cual en R puedes averiguar con x %% 2 == 0. Usa este hecho y if_else() para determinar si cada número entre 0 y 20 es par o impar.\nDado un vector de días como x &lt;- c(\"Lunes\", \"Sábado\", \"Miércoles\"), use una instrucción if_else() para etiquetarlos como fines de semana o días de semana.\nUsa if_else() para calcular el valor absoluto de un vector numérico llamado x.\nEscriba una instrucción case_when() que use las columnas month y day de flights para etiquetar una selección de días festivos importantes de EE. UU. (por ejemplo, Año Nuevo, 4 de julio, Acción de Gracias y Navidad). Primero cree una columna lógica que sea TRUE o FALSE, y luego cree una columna de caracteres que dé el nombre de la festividad o sea NA.",
    "crumbs": [
      "Transformar",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Vectores lógicos</span>"
    ]
  },
  {
    "objectID": "logicals.html#resumen",
    "href": "logicals.html#resumen",
    "title": "13  Vectores lógicos",
    "section": "\n13.6 Resumen",
    "text": "13.6 Resumen\nLa definición de un vector lógico es simple porque cada valor debe ser TRUE, FALSE o NA. Pero los vectores lógicos proporcionan una gran cantidad de posibilidades. En este capítulo, aprendió a crear vectores lógicos con &gt;, &lt;, &lt;=, &gt;=, ==, != y is.na(), cómo combinarlos con !, & y |, y cómo resumirlos con any(), all(), sum() y mean(). También aprendiste las poderosas funciones if_else() y case_when() que te permiten devolver valores dependiendo del valor de un vector lógico.\nVeremos vectores lógicos una y otra vez en los siguientes capítulos. Por ejemplo, en Capítulo 15 aprenderá sobre str_detect(x, pattern) que devuelve un vector lógico que es TRUE para los elementos de x que coinciden con el patrón, pattern, y en ?sec-dates- and-times creará vectores lógicos a partir de la comparación de fechas y horas. Pero por ahora, vamos a pasar al siguiente tipo de vector más importante: los vectores numéricos.",
    "crumbs": [
      "Transformar",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Vectores lógicos</span>"
    ]
  },
  {
    "objectID": "logicals.html#footnotes",
    "href": "logicals.html#footnotes",
    "title": "13  Vectores lógicos",
    "section": "",
    "text": "R normalmente llama a print por usted (es decir, x es un atajo para print(x)), pero llamarlo explícitamente es útil si desea proporcionar otros argumentos.↩︎\nEs decir, xor(x, y) es TRUE si x es TRUE, o y es TRUE, pero no ambos. Así es como solemos usar “o” en inglés. “Ambos” no suele ser una respuesta aceptable a la pregunta “¿quieres un helado o un pastel?”.↩︎\nEl if_else() de dplyr es muy similar al ifelse() de base R. Hay dos ventajas principales de if_else() sobre ifelse(): puede elegir qué debería pasar con los valores faltantes, y es mucho más probable que if_else() le dé un error significativo si sus variables tienen tipos incompatibles.↩︎",
    "crumbs": [
      "Transformar",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Vectores lógicos</span>"
    ]
  },
  {
    "objectID": "strings.html#introducción",
    "href": "strings.html#introducción",
    "title": "15  Caracteres",
    "section": "\n15.1 Introducción",
    "text": "15.1 Introducción\nHasta ahora, ha usado un montón de cadenas de caracteres sin aprender mucho sobre los detalles. Ahora es el momento de sumergirse en ellas, aprender qué hace que las cadenas de caracteres funcionen y dominar algunas de las poderosas herramientas de manipulación de caracteres que tiene a su disposición.\nComenzaremos con los detalles de la creación de cadenas y vectores de caracteres. Luego se sumergirá en la creación de cadenas a partir de datos, luego lo contrario; extraer cadenas de datos. Luego hablaremos de las herramientas que funcionan con letras individuales. El capítulo finaliza con funciones que funcionan con letras individuales y una breve discusión sobre dónde podrían equivocarse sus expectativas del inglés al trabajar con otros idiomas.\nSeguiremos trabajando con cadenas en el próximo capítulo, donde aprenderá más sobre el poder de las expresiones regulares.\n\n15.1.1 Requisitos previos\nEn este capítulo, usaremos funciones del paquete stringr, que forma parte del núcleo tidyverse. También usaremos los datos de babynames ya que proporciona algunas cadenas divertidas para manipular.\n\nlibrary(tidyverse)\nlibrary(babynames)\n\nPuede saber rápidamente cuándo está usando una función stringr porque todas las funciones stringr comienzan con str_. Esto es particularmente útil si usa RStudio porque escribir str_ activará el autocompletado, lo que le permitirá refrescar su memoria de las funciones disponibles."
  },
  {
    "objectID": "strings.html#creando-una-cadena-de-caracteres",
    "href": "strings.html#creando-una-cadena-de-caracteres",
    "title": "15  Caracteres",
    "section": "\n15.2 Creando una cadena de caracteres",
    "text": "15.2 Creando una cadena de caracteres\nHemos creado cadenas de pasada anteriormente en el libro, pero no discutimos los detalles. En primer lugar, puede crear una cadena usando comillas simples (') o comillas dobles (\"). No hay diferencia en el comportamiento entre los dos, así que en aras de la coherencia, la guía de estilo de tidyverse recomienda usar \", a menos que la cadena contiene múltiples \".\n\nstring1 &lt;- \"Esta es una cadena de caracteres\"\nstring2 &lt;- 'Si quiero incluir una \"comilla\" dentro de una cadena, uso comillas simples'\n\nSi olvida cerrar una comilla, verá +, el indicador de continuación:\n&gt; \"Esta es una cadena sin comillas de cierre\n+ \n+ \n+ AYUDA ESTOY ATRAPADO EN UNA CADENA\nSi esto le sucede y no sabe qué comilla cerrar, presione Escape para cancelar y vuelva a intentarlo.\n\n15.2.1 Escapadas\nPara incluir una comilla simple o doble literal en una cadena, puede usar \\ para “escaparla”:\n\ndouble_quote &lt;- \"\\\"\" # o '\"'\nsingle_quote &lt;- '\\'' # o \"'\"\n\nEntonces, si desea incluir una barra invertida literal en su cadena, deberá escapar: \"\\\\\":\n\nbackslash &lt;- \"\\\\\"\n\nTenga en cuenta que la representación impresa de una cadena no es la misma que la cadena misma porque la representación impresa muestra los escapes (en otras palabras, cuando imprime una cadena, puede copiar y pegar la salida para recrear esa cadena). Para ver el contenido sin procesar de la cadena, use str_view()1:\n\nx &lt;- c(single_quote, double_quote, backslash)\nx\n#&gt; [1] \"'\"  \"\\\"\" \"\\\\\"\n\nstr_view(x)\n#&gt; [1] │ '\n#&gt; [2] │ \"\n#&gt; [3] │ \\\n\n\n15.2.2 Cadenas de caracteres sin procesar\nCrear una cadena con múltiples comillas o barras invertidas se vuelve confuso rápidamente. Para ilustrar el problema, creemos una cadena que contenga el contenido del bloque de código donde definimos las variables double_quote y single_quote:\n\ntricky &lt;- \"double_quote &lt;- \\\"\\\\\\\"\\\" # o '\\\"'\nsingle_quote &lt;- '\\\\'' # o \\\"'\\\"\"\nstr_view(tricky)\n#&gt; [1] │ double_quote &lt;- \"\\\"\" # o '\"'\n#&gt;     │ single_quote &lt;- '\\'' # o \"'\"\n\n¡Eso es un montón de barras invertidas! (Esto a veces se llama [síndrome del palillo inclinado] (https://en.wikipedia.org/wiki/Leaning_toothpick_syndrome).) Para eliminar el escape, puede usar una cadena de caracteres sin procesar2:\n\ntricky &lt;- r\"(double_quote &lt;- \"\\\"\" # or '\"'\nsingle_quote &lt;- '\\'' # or \"'\")\"\nstr_view(tricky)\n#&gt; [1] │ double_quote &lt;- \"\\\"\" # or '\"'\n#&gt;     │ single_quote &lt;- '\\'' # or \"'\"\n\nUna cadena sin procesar generalmente comienza con r\"( y termina con )\". Pero si su cadena contiene )\", puede usar r\"[]\" o r\"{}\", y si eso aún no es suficiente, puede insertar cualquier número de guiones para hacer los pares de apertura y cierre único, por ejemplo, r\"--()--\", r\"---()---\", etc. Las cadenas sin procesar son lo suficientemente flexibles para manejar cualquier texto.\n\n15.2.3 Otros caracteres especiales\nAdemás de \\\", \\' y \\\\, hay otros caracteres especiales que pueden ser útiles. Los más comunes son \\n, una nueva línea y \\t, tabulador. A veces también verá cadenas que contienen escapes Unicode que comienzan con \\u o \\U. Esta es una forma de escribir caracteres no ingleses que funcionan en todos los sistemas. Puede ver la lista completa de otros caracteres especiales en ?Quote.\n\nx &lt;- c(\"one\\ntwo\", \"one\\ttwo\", \"\\u00b5\", \"\\U0001f604\")\nx\n#&gt; [1] \"one\\ntwo\" \"one\\ttwo\" \"µ\"        \"😄\"\nstr_view(x)\n#&gt; [1] │ one\n#&gt;     │ two\n#&gt; [2] │ one{\\t}two\n#&gt; [3] │ µ\n#&gt; [4] │ 😄\n\nTenga en cuenta que str_view() usa llaves para las pestañas para que sean más fáciles de detectar 3. Uno de los desafíos de trabajar con texto es que hay una variedad de formas en que los espacios en blanco pueden terminar en el texto, por lo que este fondo lo ayuda a reconocer que algo extraño está sucediendo.\n\n15.2.4 Ejercicios\n\n\nCree cadenas que contengan los siguientes valores:\n\nÉl dijo: \"¡Eso es increíble!\"\n\\a\\b\\c\\d\n\\\\\\\\\\\\\n\n\n\nCree la cadena en su sesión R e imprímala. ¿Qué sucede con el especial “\\u00a0”? ¿Cómo lo muestra str_view()? ¿Puedes googlear un poco para averiguar qué es este carácter especial?\n\nx &lt;- \"Esto\\u00a0es\\u00a0complicado\""
  },
  {
    "objectID": "strings.html#crear-muchas-cadenas-de-caracteres-a-partir-de-datos",
    "href": "strings.html#crear-muchas-cadenas-de-caracteres-a-partir-de-datos",
    "title": "15  Caracteres",
    "section": "\n15.3 Crear muchas cadenas de caracteres a partir de datos",
    "text": "15.3 Crear muchas cadenas de caracteres a partir de datos\nAhora que ha aprendido los conceptos básicos para crear una o dos cadenas “a mano”, entraremos en los detalles de la creación de cadenas a partir de otras cadenas. Esto lo ayudará a resolver el problema común en el que tiene un texto que escribió que desea combinar con cadenas de un data frame. Por ejemplo, puede combinar “Hola” con una variable name para crear un saludo. Le mostraremos cómo hacer esto con str_c() y str_glue() y cómo puede usarlos con mutate(). Naturalmente, eso plantea la pregunta de qué funciones de stringr podría usar con summarize(), por lo que terminaremos esta sección con una discusión de str_flatten(), que es una función de resumen para cadenas.\n\n15.3.1 str_c()\n\nstr_c() toma cualquier número de vectores como argumentos y devuelve un vector de caracteres:\n\nstr_c(\"x\", \"y\")\n#&gt; [1] \"xy\"\nstr_c(\"x\", \"y\", \"z\")\n#&gt; [1] \"xyz\"\nstr_c(\"Hola \", c(\"Juan\", \"Susana\"))\n#&gt; [1] \"Hola Juan\"   \"Hola Susana\"\n\nstr_c() es muy similar a la base paste0(), pero está diseñado para usarse con mutate() obedeciendo las reglas habituales de tidyverse para reciclar y propagar valores faltantes:\n\ndf &lt;- tibble(name = c(\"Flora\", \"David\", \"Terra\", NA))\ndf |&gt; mutate(greeting = str_c(\"Hi \", name, \"!\"))\n#&gt; # A tibble: 4 × 2\n#&gt;   name  greeting \n#&gt;   &lt;chr&gt; &lt;chr&gt;    \n#&gt; 1 Flora Hi Flora!\n#&gt; 2 David Hi David!\n#&gt; 3 Terra Hi Terra!\n#&gt; 4 &lt;NA&gt;  &lt;NA&gt;\n\nSi desea que los valores faltantes se muestren de otra manera, use coalesce() para reemplazarlos. Dependiendo de lo que quieras, puedes usarlo dentro o fuera de str_c():\n\ndf |&gt; \n  mutate(\n    greeting1 = str_c(\"Hi \", coalesce(name, \"you\"), \"!\"),\n    greeting2 = coalesce(str_c(\"Hi \", name, \"!\"), \"Hi!\")\n  )\n#&gt; # A tibble: 4 × 3\n#&gt;   name  greeting1 greeting2\n#&gt;   &lt;chr&gt; &lt;chr&gt;     &lt;chr&gt;    \n#&gt; 1 Flora Hi Flora! Hi Flora!\n#&gt; 2 David Hi David! Hi David!\n#&gt; 3 Terra Hi Terra! Hi Terra!\n#&gt; 4 &lt;NA&gt;  Hi you!   Hi!\n\n\n15.3.2 str_glue()\n\nSi está mezclando muchas cadenas fijas y variables con str_c(), notará que escribe muchas \"s, lo que dificulta ver el objetivo general del código. Un enfoque alternativo es proporcionado por el paquete glue a través de str_glue()4. Le das una sola cadena que tiene una característica especial: cualquier cosa dentro de {} se evaluará como que está fuera de las comillas:\n\ndf |&gt; mutate(greeting = str_glue(\"Hola {name}!\"))\n#&gt; # A tibble: 4 × 2\n#&gt;   name  greeting   \n#&gt;   &lt;chr&gt; &lt;glue&gt;     \n#&gt; 1 Flora Hola Flora!\n#&gt; 2 David Hola David!\n#&gt; 3 Terra Hola Terra!\n#&gt; 4 &lt;NA&gt;  Hola NA!\n\nComo puede ver, str_glue() actualmente convierte los valores faltantes a la cadena \"NA\", desafortunadamente, lo que lo hace inconsistente con str_c().\nTambién puede preguntarse qué sucede si necesita incluir un { o } regular en su cadena. Estás en el camino correcto si crees que necesitarás escapar de alguna manera. El truco es que el pegamento usa una técnica de escape ligeramente diferente; en lugar de anteponer un carácter especial como \\, se duplican los caracteres especiales:\n\ndf |&gt; mutate(greeting = str_glue(\"{{Hola {name}!}}\"))\n#&gt; # A tibble: 4 × 2\n#&gt;   name  greeting     \n#&gt;   &lt;chr&gt; &lt;glue&gt;       \n#&gt; 1 Flora {Hola Flora!}\n#&gt; 2 David {Hola David!}\n#&gt; 3 Terra {Hola Terra!}\n#&gt; 4 &lt;NA&gt;  {Hola NA!}\n\n\n15.3.3 str_flatten()\n\nstr_c() y str_glue() funciona bien con mutate() porque su salida tiene la misma longitud que sus entradas. ¿Qué pasa si quieres una función que funcione bien con summarize(), es decir, algo que siempre devuelva una sola cadena? Ese es el trabajo de str_flatten()5: toma un vector de caracteres y combina cada elemento del vector en una sola cadena:\n\nstr_flatten(c(\"x\", \"y\", \"z\"))\n#&gt; [1] \"xyz\"\nstr_flatten(c(\"x\", \"y\", \"z\"), \", \")\n#&gt; [1] \"x, y, z\"\nstr_flatten(c(\"x\", \"y\", \"z\"), \", \", last = \", and \")\n#&gt; [1] \"x, y, and z\"\n\nEsto hace que funcione bien con summarize():\n\ndf &lt;- tribble(\n  ~ name, ~ fruit,\n  \"Carmen\", \"banana\",\n  \"Carmen\", \"apple\",\n  \"Marvin\", \"nectarine\",\n  \"Terence\", \"cantaloupe\",\n  \"Terence\", \"papaya\",\n  \"Terence\", \"mandarin\"\n)\ndf |&gt;\n  group_by(name) |&gt; \n  summarize(fruits = str_flatten(fruit, \", \"))\n#&gt; # A tibble: 3 × 2\n#&gt;   name    fruits                      \n#&gt;   &lt;chr&gt;   &lt;chr&gt;                       \n#&gt; 1 Carmen  banana, apple               \n#&gt; 2 Marvin  nectarine                   \n#&gt; 3 Terence cantaloupe, papaya, mandarin\n\n\n15.3.4 Ejercicios\n\n\nCompare y contraste los resultados de paste0() con str_c() para las siguientes entradas:\n\nstr_c(\"hi \", NA)\nstr_c(letters[1:2], letters[1:3])\n\n\n¿Cuál es la diferencia entre paste() y paste0()? ¿Cómo puedes recrear el equivalente de paste() con str_c()?\n\nConvierta las siguientes expresiones de str_c() a str_glue() o viceversa:\n\nstr_c(\"El precio de \", food, \" es \", price)\nstr_glue(\"Yo tengo {age} años y vivo en {country}\")\nstr_c(\"\\\\section{\", title, \"}\")"
  },
  {
    "objectID": "strings.html#extraer-datos-de-cadenas-de-caracteres",
    "href": "strings.html#extraer-datos-de-cadenas-de-caracteres",
    "title": "15  Caracteres",
    "section": "\n15.4 Extraer datos de cadenas de caracteres",
    "text": "15.4 Extraer datos de cadenas de caracteres\nEs muy común que varias variables se amontonen en una sola cadena. En esta sección, aprenderá a utilizar cuatro funciones tidyr para extraerlas:\n\ndf |&gt; separate_longer_delim(col, delim)\ndf |&gt; separate_longer_position(col, width)\ndf |&gt; separate_wider_delim(col, delim, names)\ndf |&gt; separate_wider_position(col, widths)\n\nSi miras de cerca, puedes ver que hay un patrón común aquí: separate_, luego longer o wider, luego _, luego por delim o position. Eso es porque estas cuatro funciones se componen de dos primitivas más simples: - Al igual que con pivot_longer() y pivot_wider(), las funciones _longer hacen que el data frame de entrada sea más largo al crear nuevas filas y las funciones _wider hacen que el data frame de entrada sea más ancho al generar nuevas columnas. - delim divide una cadena con un delimitador como \", \" o \" \"; position se divide en anchos específicos, como c(3, 5, 2).\nVolveremos al último miembro de esta familia, separate_wider_regex(), en Capítulo 16. Es la más flexible de las funciones wider, pero necesita saber algo acerca de las expresiones regulares antes de poder usarla.\nLas siguientes dos secciones le darán la idea básica detrás de estas funciones separadas, primero separándolas en filas (que es un poco más simple) y luego separándolas en columnas. Terminaremos discutiendo las herramientas que le brindan las funciones wider para diagnosticar problemas.\n\n15.4.1 Separando en filas\nSeparar una cadena en filas tiende a ser más útil cuando el número de componentes varía de una fila a otra. El caso más común requiere que separate_longer_delim() se divida en función de un delimitador:\n\ndf1 &lt;- tibble(x = c(\"a,b,c\", \"d,e\", \"f\"))\ndf1 |&gt; \n  separate_longer_delim(x, delim = \",\")\n#&gt; # A tibble: 6 × 1\n#&gt;   x    \n#&gt;   &lt;chr&gt;\n#&gt; 1 a    \n#&gt; 2 b    \n#&gt; 3 c    \n#&gt; 4 d    \n#&gt; 5 e    \n#&gt; 6 f\n\nEs más raro ver separate_longer_position() en la naturaleza, pero algunos conjuntos de datos más antiguos usan un formato muy compacto donde cada carácter se usa para registrar un valor:\n\ndf2 &lt;- tibble(x = c(\"1211\", \"131\", \"21\"))\ndf2 |&gt; \n  separate_longer_position(x, width = 1)\n#&gt; # A tibble: 9 × 1\n#&gt;   x    \n#&gt;   &lt;chr&gt;\n#&gt; 1 1    \n#&gt; 2 2    \n#&gt; 3 1    \n#&gt; 4 1    \n#&gt; 5 1    \n#&gt; 6 3    \n#&gt; # ℹ 3 more rows\n\n\n15.4.2 Separando en columnas\nSeparar una cadena en columnas tiende a ser más útil cuando hay un número fijo de componentes en cada cadena y desea distribuirlos en columnas. Son un poco más complicados que sus equivalentes longer porque necesitas nombrar las columnas. Por ejemplo, en el siguiente conjunto de datos, x se compone de un código, un número de edición y un año, separados por \".\". Para usar separate_wider_delim(), proporcionamos el delimitador y los nombres en dos argumentos:\n\ndf3 &lt;- tibble(x = c(\"a10.1.2022\", \"b10.2.2011\", \"e15.1.2015\"))\ndf3 |&gt; \n  separate_wider_delim(\n    x,\n    delim = \".\",\n    names = c(\"code\", \"edition\", \"year\")\n  )\n#&gt; # A tibble: 3 × 3\n#&gt;   code  edition year \n#&gt;   &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;\n#&gt; 1 a10   1       2022 \n#&gt; 2 b10   2       2011 \n#&gt; 3 e15   1       2015\n\nSi una pieza específica no es útil, puede usar un nombre NA para omitirla de los resultados:\n\ndf3 |&gt; \n  separate_wider_delim(\n    x,\n    delim = \".\",\n    names = c(\"code\", NA, \"year\")\n  )\n#&gt; # A tibble: 3 × 2\n#&gt;   code  year \n#&gt;   &lt;chr&gt; &lt;chr&gt;\n#&gt; 1 a10   2022 \n#&gt; 2 b10   2011 \n#&gt; 3 e15   2015\n\nseparate_wider_position() funciona un poco diferente porque normalmente desea especificar el ancho de cada columna. Entonces le das un vector entero con nombre, donde el nombre da el nombre de la nueva columna, y el valor es la cantidad de caracteres que ocupa. Puede omitir valores de la salida si no los nombra:\n\ndf4 &lt;- tibble(x = c(\"202215TX\", \"202122LA\", \"202325CA\")) \ndf4 |&gt; \n  separate_wider_position(\n    x,\n    widths = c(year = 4, age = 2, state = 2)\n  )\n#&gt; # A tibble: 3 × 3\n#&gt;   year  age   state\n#&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n#&gt; 1 2022  15    TX   \n#&gt; 2 2021  22    LA   \n#&gt; 3 2023  25    CA\n\n\n15.4.3 Diagnóstico de problemas de ensanchamiento\nseparate_wider_delim()6 requiere un conjunto fijo y conocido de columnas. ¿Qué sucede si alguna de las filas no tiene el número esperado de piezas? Hay dos posibles problemas, muy pocas o demasiadas piezas, por lo que separate_wider_delim() proporciona dos argumentos para ayudar: too_few y too_many. Primero veamos el caso too_few con el siguiente conjunto de datos de muestra:\n\ndf &lt;- tibble(x = c(\"1-1-1\", \"1-1-2\", \"1-3\", \"1-3-2\", \"1\"))\n\ndf |&gt; \n  separate_wider_delim(\n    x,\n    delim = \"-\",\n    names = c(\"x\", \"y\", \"z\")\n  )\n#&gt; Error in `separate_wider_delim()`:\n#&gt; ! Expected 3 pieces in each element of `x`.\n#&gt; ! 2 values were too short.\n#&gt; ℹ Use `too_few = \"debug\"` to diagnose the problem.\n#&gt; ℹ Use `too_few = \"align_start\"/\"align_end\"` to silence this message.\n\nNotará que recibimos un error, pero el error nos da algunas sugerencias sobre cómo puede proceder. Comencemos por depurar el problema:\n\ndebug &lt;- df |&gt; \n  separate_wider_delim(\n    x,\n    delim = \"-\",\n    names = c(\"x\", \"y\", \"z\"),\n    too_few = \"debug\"\n  )\n#&gt; Warning: Debug mode activated: adding variables `x_ok`, `x_pieces`, and\n#&gt; `x_remainder`.\ndebug\n#&gt; # A tibble: 5 × 6\n#&gt;   x     y     z     x_ok  x_pieces x_remainder\n#&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;lgl&gt;    &lt;int&gt; &lt;chr&gt;      \n#&gt; 1 1-1-1 1     1     TRUE         3 \"\"         \n#&gt; 2 1-1-2 1     2     TRUE         3 \"\"         \n#&gt; 3 1-3   3     &lt;NA&gt;  FALSE        2 \"\"         \n#&gt; 4 1-3-2 3     2     TRUE         3 \"\"         \n#&gt; 5 1     &lt;NA&gt;  &lt;NA&gt;  FALSE        1 \"\"\n\nCuando usa el modo de depuración, obtiene tres columnas adicionales agregadas a la salida: x_ok, x_pieces y x_remainder (si separa una variable con un nombre diferente, obtendrá un prefijo diferente). Aquí, x_ok te permite encontrar rápidamente las entradas que fallaron:\n\ndebug |&gt; filter(!x_ok)\n#&gt; # A tibble: 2 × 6\n#&gt;   x     y     z     x_ok  x_pieces x_remainder\n#&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;lgl&gt;    &lt;int&gt; &lt;chr&gt;      \n#&gt; 1 1-3   3     &lt;NA&gt;  FALSE        2 \"\"         \n#&gt; 2 1     &lt;NA&gt;  &lt;NA&gt;  FALSE        1 \"\"\n\nx_pieces nos dice cuántas piezas se encontraron, en comparación con las 3 esperadas (la longitud de names). x_remainder no es útil cuando hay muy pocas piezas, pero lo veremos de nuevo en breve.\nA veces, mirar esta información de depuración revelará un problema con su estrategia de delimitación o sugerirá que necesita hacer más preprocesamiento antes de separarse. En ese caso, solucione el problema aguas arriba y asegúrese de eliminar too_few = \"debug\" para asegurarse de que los nuevos problemas se conviertan en errores.\nEn otros casos, es posible que desee completar las piezas que faltan con “NA” y seguir adelante. Ese es el trabajo de too_few = \"align_start\" y too_few = \"align_end\" que le permiten controlar dónde deben ir los NA:\n\ndf |&gt; \n  separate_wider_delim(\n    x,\n    delim = \"-\",\n    names = c(\"x\", \"y\", \"z\"),\n    too_few = \"align_start\"\n  )\n#&gt; # A tibble: 5 × 3\n#&gt;   x     y     z    \n#&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n#&gt; 1 1     1     1    \n#&gt; 2 1     1     2    \n#&gt; 3 1     3     &lt;NA&gt; \n#&gt; 4 1     3     2    \n#&gt; 5 1     &lt;NA&gt;  &lt;NA&gt;\n\nLos mismos principios se aplican si tiene demasiadas piezas:\n\ndf &lt;- tibble(x = c(\"1-1-1\", \"1-1-2\", \"1-3-5-6\", \"1-3-2\", \"1-3-5-7-9\"))\n\ndf |&gt; \n  separate_wider_delim(\n    x,\n    delim = \"-\",\n    names = c(\"x\", \"y\", \"z\")\n  )\n#&gt; Error in `separate_wider_delim()`:\n#&gt; ! Expected 3 pieces in each element of `x`.\n#&gt; ! 2 values were too long.\n#&gt; ℹ Use `too_many = \"debug\"` to diagnose the problem.\n#&gt; ℹ Use `too_many = \"drop\"/\"merge\"` to silence this message.\n\nPero ahora, cuando depuramos el resultado, puedes ver el propósito de x_remainder:\n\ndebug &lt;- df |&gt; \n  separate_wider_delim(\n    x,\n    delim = \"-\",\n    names = c(\"x\", \"y\", \"z\"),\n    too_many = \"debug\"\n  )\n#&gt; Warning: Debug mode activated: adding variables `x_ok`, `x_pieces`, and\n#&gt; `x_remainder`.\ndebug |&gt; filter(!x_ok)\n#&gt; # A tibble: 2 × 6\n#&gt;   x         y     z     x_ok  x_pieces x_remainder\n#&gt;   &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt; &lt;lgl&gt;    &lt;int&gt; &lt;chr&gt;      \n#&gt; 1 1-3-5-6   3     5     FALSE        4 -6         \n#&gt; 2 1-3-5-7-9 3     5     FALSE        5 -7-9\n\nTiene un conjunto ligeramente diferente de opciones para manejar demasiadas piezas: puede “soltar” silenciosamente cualquier pieza adicional o “fusionarlas” todas en la columna final:\n\ndf |&gt; \n  separate_wider_delim(\n    x,\n    delim = \"-\",\n    names = c(\"x\", \"y\", \"z\"),\n    too_many = \"drop\"\n  )\n#&gt; # A tibble: 5 × 3\n#&gt;   x     y     z    \n#&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n#&gt; 1 1     1     1    \n#&gt; 2 1     1     2    \n#&gt; 3 1     3     5    \n#&gt; 4 1     3     2    \n#&gt; 5 1     3     5\n\n\ndf |&gt; \n  separate_wider_delim(\n    x,\n    delim = \"-\",\n    names = c(\"x\", \"y\", \"z\"),\n    too_many = \"merge\"\n  )\n#&gt; # A tibble: 5 × 3\n#&gt;   x     y     z    \n#&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n#&gt; 1 1     1     1    \n#&gt; 2 1     1     2    \n#&gt; 3 1     3     5-6  \n#&gt; 4 1     3     2    \n#&gt; 5 1     3     5-7-9"
  },
  {
    "objectID": "strings.html#letras",
    "href": "strings.html#letras",
    "title": "15  Caracteres",
    "section": "\n15.5 Letras",
    "text": "15.5 Letras\nEn esta sección, le presentaremos funciones que le permitirán trabajar con letras individuales dentro de una cadena. Aprenderá a encontrar la longitud de una cadena, extraer subcadenas y manejar cadenas largas en diagramas y tablas.\n\n15.5.1 Longitud\nstr_length() te dice el número de letras en la cadena:\n\nstr_length(c(\"a\", \"R for data science\", NA))\n#&gt; [1]  1 18 NA\n\nPodría usar esto con count() para encontrar la distribución de las longitudes de los nombres de bebés de EE. UU. y luego con filter() para ver los nombres más largos, que tienen 15 letras 7:\n\nbabynames |&gt;\n  count(length = str_length(name), wt = n)\n#&gt; # A tibble: 14 × 2\n#&gt;   length        n\n#&gt;    &lt;int&gt;    &lt;int&gt;\n#&gt; 1      2   338150\n#&gt; 2      3  8589596\n#&gt; 3      4 48506739\n#&gt; 4      5 87011607\n#&gt; 5      6 90749404\n#&gt; 6      7 72120767\n#&gt; # ℹ 8 more rows\n\nbabynames |&gt; \n  filter(str_length(name) == 15) |&gt; \n  count(name, wt = n, sort = TRUE)\n#&gt; # A tibble: 34 × 2\n#&gt;   name                n\n#&gt;   &lt;chr&gt;           &lt;int&gt;\n#&gt; 1 Franciscojavier   123\n#&gt; 2 Christopherjohn   118\n#&gt; 3 Johnchristopher   118\n#&gt; 4 Christopherjame   108\n#&gt; 5 Christophermich    52\n#&gt; 6 Ryanchristopher    45\n#&gt; # ℹ 28 more rows\n\n\n15.5.2 Subconjunto\nPuedes extraer partes de una cadena usando str_sub(string, start, end), donde start y end son las posiciones donde la subcadena debe comenzar y terminar. Los argumentos start y end son inclusivos, por lo que la longitud de la cadena devuelta será end - start + 1:\n\nx &lt;- c(\"Apple\", \"Banana\", \"Pear\")\nstr_sub(x, 1, 3)\n#&gt; [1] \"App\" \"Ban\" \"Pea\"\n\nPuede usar valores negativos para contar hacia atrás desde el final de la cadena: -1 es el último carácter, -2 es el penúltimo carácter, etc.\n\nstr_sub(x, -3, -1)\n#&gt; [1] \"ple\" \"ana\" \"ear\"\n\nTenga en cuenta que str_sub() no fallará si la cadena es demasiado corta: solo devolverá tanto como sea posible:\n\nstr_sub(\"a\", 1, 5)\n#&gt; [1] \"a\"\n\nPodríamos usar str_sub() con mutate() para encontrar la primera y última letra de cada nombre:\n\nbabynames |&gt; \n  mutate(\n    first = str_sub(name, 1, 1),\n    last = str_sub(name, -1, -1)\n  )\n#&gt; # A tibble: 1,924,665 × 7\n#&gt;    year sex   name          n   prop first last \n#&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;     &lt;int&gt;  &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;\n#&gt; 1  1880 F     Mary       7065 0.0724 M     y    \n#&gt; 2  1880 F     Anna       2604 0.0267 A     a    \n#&gt; 3  1880 F     Emma       2003 0.0205 E     a    \n#&gt; 4  1880 F     Elizabeth  1939 0.0199 E     h    \n#&gt; 5  1880 F     Minnie     1746 0.0179 M     e    \n#&gt; 6  1880 F     Margaret   1578 0.0162 M     t    \n#&gt; # ℹ 1,924,659 more rows\n\n\n15.5.3 Ejercicios\n\n¿Cuando calculamos la distribución de la longitud de los nombres de los bebés, ¿por qué usamos wt = n?\nUse str_length() y str_sub() para extraer la letra del medio de cada nombre de bebé. ¿Qué harás si la cadena tiene un número par de caracteres?\n¿Existen tendencias importantes en la longitud de los nombres de bebés a lo largo del tiempo? ¿Qué pasa con la popularidad de las primeras y últimas letras?"
  },
  {
    "objectID": "strings.html#sec-other-languages",
    "href": "strings.html#sec-other-languages",
    "title": "15  Caracteres",
    "section": "\n15.6 Texto no inglés",
    "text": "15.6 Texto no inglés\nHasta ahora, nos hemos centrado en el texto en inglés, con el que es particularmente fácil trabajar por dos razones. En primer lugar, el alfabeto inglés es relativamente simple: solo hay 26 letras. En segundo lugar (y quizás más importante), la infraestructura informática que usamos hoy en día fue diseñada predominantemente por angloparlantes. Desafortunadamente, no tenemos espacio para un tratamiento completo de los idiomas distintos del inglés. Aún así, queríamos llamar su atención sobre algunos de los mayores desafíos que podría encontrar: codificación, variaciones de letras y funciones dependientes de la configuración regional.\n\n15.6.1 Codificación\nCuando se trabaja con texto que no está en inglés, el primer desafío suele ser la codificación. Para entender lo que está pasando, necesitamos sumergirnos en cómo las computadoras representan cadenas. En R, podemos llegar a la representación subyacente de una cadena usando charToRaw():\n\ncharToRaw(\"Hadley\")\n#&gt; [1] 48 61 64 6c 65 79\n\nCada uno de estos seis números hexadecimales representa una letra: 48 es H, 61 es a, y así sucesivamente. La asignación de un número hexadecimal a un carácter se denomina codificación y, en este caso, la codificación se denomina ASCII. ASCII hace un gran trabajo al representar los caracteres ingleses porque es el código estándar estadounidense para el intercambio de información.\nLas cosas no son tan fáciles para otros idiomas además del inglés. En los primeros días de la informática, existían muchos estándares en competencia para codificar caracteres no ingleses. Por ejemplo, había dos codificaciones diferentes para Europa: Latin1 (también conocido como ISO-8859-1) se usaba para los idiomas de Europa occidental, y Latin2 (también conocido como ISO-8859-2) se usaba para los idiomas de Europa Central. En Latin1, el byte b1 es “±”, pero en Latin2, ¡es “±”! Afortunadamente, hoy en día existe un estándar que se admite en casi todas partes: UTF-8. UTF-8 puede codificar casi todos los caracteres utilizados por los humanos en la actualidad y muchos símbolos adicionales como emojis.\nreadr usa UTF-8 en todas partes. Este es un buen valor predeterminado, pero fallará para los datos producidos por sistemas más antiguos que no usan UTF-8. Si esto sucede, sus cadenas se verán raras cuando las imprima. A veces, solo uno o dos caracteres pueden estar en mal estado; otras veces, obtendrás un completo galimatías. Por ejemplo, aquí hay dos CSV en línea con codificaciones inusuales 8:\n\nx1 &lt;- \"text\\nEl Ni\\xf1o fue particularmente malo este año\"\nread_csv(x1)$text\n#&gt; [1] \"El Ni\\xf1o fue particularmente malo este año\"\n\nx2 &lt;- \"text\\n\\x82\\xb1\\x82\\xf1\\x82\\xc9\\x82\\xbf\\x82\\xcd\"\nread_csv(x2)$text\n#&gt; [1] \"\\x82\\xb1\\x82\\xf1\\x82ɂ\\xbf\\x82\\xcd\"\n\nPara leerlos correctamente, especifica la codificación a través del argumento locale:\n\nread_csv(x1, locale = locale(encoding = \"Latin1\"))$text\n#&gt; [1] \"El Ni\\xf1o fue particularmente malo este año\"\n\nread_csvread_csv(x2, locale = locale(encoding = \"Shift-JIS\"))$text\n#&gt; [1] \"こんにちは\"\n\n¿Cómo encuentras la codificación correcta? Si tiene suerte, se incluirá en algún lugar de la documentación de datos. Desafortunadamente, ese rara vez es el caso, por lo que readr proporciona guess_encoding() para ayudarlo a resolverlo. No es infalible y funciona mejor cuando tiene mucho texto (a diferencia de aquí), pero es un lugar razonable para comenzar. Espere probar algunas codificaciones diferentes antes de encontrar la correcta.\nLas codificaciones son un tema rico y complejo; solo hemos arañado la superficie aquí. Si desea obtener más información, le recomendamos leer la explicación detallada en http://kunststube.net/encoding/.\n\n15.6.2 Variaciones de letras\nTrabajar en idiomas con acentos plantea un desafío significativo al determinar la posición de las letras (por ejemplo, con str_length() y str_sub()), ya que las letras acentuadas pueden codificarse como un solo carácter individual (por ejemplo, ü) o como dos caracteres por combinar una letra sin acento (por ejemplo, u) con un signo diacrítico (por ejemplo, ¨). Por ejemplo, este código muestra dos formas de representar ü que parecen idénticas:\n\nu &lt;- c(\"\\u00fc\", \"u\\u0308\")\nstr_view(u)\n#&gt; [1] │ ü\n#&gt; [2] │ ü\n\nPero ambas cadenas difieren en longitud y sus primeros caracteres son diferentes:\n\nstr_length(u)\n#&gt; [1] 1 2\nstr_sub(u, 1, 1)\n#&gt; [1] \"ü\" \"u\"\n\nFinalmente, tenga en cuenta que una comparación de estas cadenas con == interpreta estas cadenas como diferentes, mientras que la práctica función str_equal() en stringr reconoce que ambas tienen la misma apariencia:\n\nu[[1]] == u[[2]]\n#&gt; [1] FALSE\n\nstr_equal(u[[1]], u[[2]])\n#&gt; [1] TRUE\n\n\n15.6.3 Funciones dependientes de la configuración regional\nFinalmente, hay un puñado de funciones stringr cuyo comportamiento depende de tu locale. Una configuración regional es similar a un idioma, pero incluye un especificador de región opcional para manejar las variaciones regionales dentro de un idioma. Una configuración regional se especifica mediante una abreviatura de idioma en minúsculas, seguida opcionalmente por un _ y un identificador de región en mayúsculas. Por ejemplo, “en” es inglés, “en_GB” es inglés británico y “en_US” es inglés americano. Si aún no conoce el código de su idioma, Wikipedia tiene una buena lista, y puede ver cuáles son compatibles con stringr mirando stringi::stri_locale_list().\nLas funciones de cadena base R utilizan automáticamente la configuración regional establecida por su sistema operativo. Esto significa que las funciones base de cadena R hacen lo que espera para su idioma, pero su código podría funcionar de manera diferente si lo comparte con alguien que vive en un país diferente. Para evitar este problema, stringr utiliza por defecto las reglas en inglés utilizando la configuración regional “en” y requiere que especifique el argumento locale para anularlo. Afortunadamente, hay dos conjuntos de funciones donde la configuración regional realmente importa: cambio de mayúsculas y minúsculas y clasificación.\nLas reglas para cambiar entre mayúsculas y minúsculas difieren entre idiomas. Por ejemplo, el turco tiene dos i: con y sin punto. Como son dos letras distintas, se escriben en mayúsculas de manera diferente:\n\nstr_to_upper(c(\"i\", \"ı\"))\n#&gt; [1] \"I\" \"I\"\nstr_to_upper(c(\"i\", \"ı\"), locale = \"tr\")\n#&gt; [1] \"İ\" \"I\"\n\n¡La clasificación de las cadenas depende del orden del alfabeto, y el orden del alfabeto no es el mismo en todos los idiomas 9! He aquí un ejemplo: en checo, “ch” es una letra compuesta que aparece después de la h en el alfabeto.\n\nstr_sort(c(\"a\", \"c\", \"ch\", \"h\", \"z\"))\n#&gt; [1] \"a\"  \"c\"  \"ch\" \"h\"  \"z\"\nstr_sort(c(\"a\", \"c\", \"ch\", \"h\", \"z\"), locale = \"cs\")\n#&gt; [1] \"a\"  \"c\"  \"h\"  \"ch\" \"z\"\n\nEsto también surge al ordenar cadenas con dplyr::arrange(), por lo que también tiene un argumento locale."
  },
  {
    "objectID": "strings.html#resumen",
    "href": "strings.html#resumen",
    "title": "15  Caracteres",
    "section": "\n15.7 Resumen",
    "text": "15.7 Resumen\nEn este capítulo, aprendió algo sobre el poder del paquete stringr: cómo crear, combinar y extraer cadenas, y sobre algunos de los desafíos que puede enfrentar con cadenas que no están en inglés. Ahora es el momento de aprender una de las herramientas más importantes y poderosas para trabajar con cadenas: las expresiones regulares. Las expresiones regulares son un lenguaje muy conciso pero muy expresivo para describir patrones dentro de cadenas y son el tema del próximo capítulo."
  },
  {
    "objectID": "strings.html#footnotes",
    "href": "strings.html#footnotes",
    "title": "15  Caracteres",
    "section": "",
    "text": "O usa la función base R writeLines().↩︎\nDisponible en R 4.0.0 y superior.↩︎\nstr_view() también usa colores para llamar su atención sobre tabulaciones, espacios, coincidencias, etc. Los colores no aparecen actualmente en el libro, pero los notará cuando ejecute el código de forma interactiva.↩︎\nSi no está usando stringr, también puede acceder a él directamente con glue::glue().↩︎\nEl equivalente base de R es paste() usado con el argumento collapse.↩︎\nLos mismos principios se aplican a separate_wider_position() y separate_wider_regex().↩︎\nMirando estas entradas, supondríamos que los datos de babynames eliminan espacios o guiones y se truncan después de 15 letras.↩︎\nAquí estoy usando el \\x especial para codificar datos binarios directamente en una cadena.↩︎\nClasificar en idiomas que no tienen alfabeto, como el chino, es aún más complicado.↩︎"
  },
  {
    "objectID": "regexps.html#introducción",
    "href": "regexps.html#introducción",
    "title": "16  Expresiones regulares",
    "section": "",
    "text": "16.1.1 Requisitos previos\nEn este capítulo, usaremos funciones de expresiones regulares de stringr y tidyr, ambos miembros centrales de tidyverse, así como datos del paquete babynames.\n\nlibrary(tidyverse)\nlibrary(babynames)\n\nA lo largo de este capítulo, usaremos una combinación de ejemplos en línea muy simples para que pueda obtener la idea básica, los datos de nombres de bebés y tres vectores de caracteres de stringr:\n\n\nfruit contiene los nombres de 80 frutas.\n\nwords contiene 980 palabras comunes del ideoma inglés.\n\nsentences contiene 720 oraciones cortas.",
    "crumbs": [
      "Transformar",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Expresiones regulares</span>"
    ]
  },
  {
    "objectID": "regexps.html#sec-reg-basics",
    "href": "regexps.html#sec-reg-basics",
    "title": "16  Expresiones regulares",
    "section": "\n16.2 Conceptos básicos de patrones",
    "text": "16.2 Conceptos básicos de patrones\nUsaremos str_view() para aprender cómo funcionan los patrones de expresiones regulares. Usamos str_view() en el último capítulo para comprender mejor una cadena en comparación con su representación impresa, y ahora la usaremos con su segundo argumento, una expresión regular. Cuando se proporciona, str_view() mostrará solo los elementos del vector de cadena que coincidan, rodeando cada coincidencia con &lt;&gt; y, donde sea posible, resaltando la coincidencia en azul.\nLos patrones más simples consisten en letras y números que coinciden exactamente con esos caracteres:\n\nstr_view(fruit, \"berry\")\n#&gt;  [6] │ bil&lt;berry&gt;\n#&gt;  [7] │ black&lt;berry&gt;\n#&gt; [10] │ blue&lt;berry&gt;\n#&gt; [11] │ boysen&lt;berry&gt;\n#&gt; [19] │ cloud&lt;berry&gt;\n#&gt; [21] │ cran&lt;berry&gt;\n#&gt; ... and 8 more\n\nLas letras y los números coinciden exactamente y se denominan caracteres literales. La mayoría de los caracteres de puntuación, como ., +, *, [, ], y ?, tienen significados especiales2 y se denominan metacaracteres. Por ejemplo, . coincidirá con cualquier carácter3, por lo que \"a.\" coincidirá con cualquier cadena que contenga una “a” seguida de otro carácter :\n\nstr_view(c(\"a\", \"ab\", \"ae\", \"bd\", \"ea\", \"eab\"), \"a.\")\n#&gt; [2] │ &lt;ab&gt;\n#&gt; [3] │ &lt;ae&gt;\n#&gt; [6] │ e&lt;ab&gt;\n\nO podríamos encontrar todas las frutas que contienen una “a”, seguida de tres letras, seguidas de una “e”:\n\nstr_view(fruit, \"a...e\")\n#&gt;  [1] │ &lt;apple&gt;\n#&gt;  [7] │ bl&lt;ackbe&gt;rry\n#&gt; [48] │ mand&lt;arine&gt;\n#&gt; [51] │ nect&lt;arine&gt;\n#&gt; [62] │ pine&lt;apple&gt;\n#&gt; [64] │ pomegr&lt;anate&gt;\n#&gt; ... and 2 more\n\nQuantifiers controla cuántas veces puede coincidir un patrón:\n\n\n? hace que un patrón sea opcional (es decir, coincide 0 o 1 veces)\n\n+ permite que un patrón se repita (es decir, coincide al menos una vez)\n\n* permite que un patrón sea opcional o se repita (es decir, coincide con cualquier número de veces, incluido 0).\n\n\n# ab? coincide con una \"a\", opcionalmente seguida de una \"b\".\nstr_view(c(\"a\", \"ab\", \"abb\"), \"ab?\")\n#&gt; [1] │ &lt;a&gt;\n#&gt; [2] │ &lt;ab&gt;\n#&gt; [3] │ &lt;ab&gt;b\n\n# ab+ Coincide con una \"a\", seguida de al menos una \"b\".\nstr_view(c(\"a\", \"ab\", \"abb\"), \"ab+\")\n#&gt; [2] │ &lt;ab&gt;\n#&gt; [3] │ &lt;abb&gt;\n\n# ab* coincide con una \"a\", seguida de cualquier número de \"b\".\nstr_view(c(\"a\", \"ab\", \"abb\"), \"ab*\")\n#&gt; [1] │ &lt;a&gt;\n#&gt; [2] │ &lt;ab&gt;\n#&gt; [3] │ &lt;abb&gt;\n\nLas clases de caracteres están definidas por [] y le permiten hacer coincidir un conjunto de caracteres, p.ej., [abcd] coincide con “a”, “b”, “c” o “d”. También puede invertir la coincidencia comenzando con ^: [^abcd] coincide con cualquier cosa excepto “a”, “b”, “c” o “d”. Podemos usar esta idea para encontrar las palabras que contienen una “x” rodeada de vocales, o una “y” rodeada de consonantes:\n\nstr_view(words, \"[aeiou]x[aeiou]\")\n#&gt; [284] │ &lt;exa&gt;ct\n#&gt; [285] │ &lt;exa&gt;mple\n#&gt; [288] │ &lt;exe&gt;rcise\n#&gt; [289] │ &lt;exi&gt;st\nstr_view(words, \"[^aeiou]y[^aeiou]\")\n#&gt; [836] │ &lt;sys&gt;tem\n#&gt; [901] │ &lt;typ&gt;e\n\nPuede usar alternancia, |, para elegir entre uno o más patrones alternativos. Por ejemplo, los siguientes patrones buscan frutas que contengan “manzana”, “melón” o “nuez”, o una vocal repetida.\n\nstr_view(fruit, \"apple|melon|nut\")\n#&gt;  [1] │ &lt;apple&gt;\n#&gt; [13] │ canary &lt;melon&gt;\n#&gt; [20] │ coco&lt;nut&gt;\n#&gt; [52] │ &lt;nut&gt;\n#&gt; [62] │ pine&lt;apple&gt;\n#&gt; [72] │ rock &lt;melon&gt;\n#&gt; ... and 1 more\nstr_view(fruit, \"aa|ee|ii|oo|uu\")\n#&gt;  [9] │ bl&lt;oo&gt;d orange\n#&gt; [33] │ g&lt;oo&gt;seberry\n#&gt; [47] │ lych&lt;ee&gt;\n#&gt; [66] │ purple mangost&lt;ee&gt;n\n\nLas expresiones regulares son muy compactas y utilizan muchos caracteres de puntuación, por lo que al principio pueden parecer abrumadoras y difíciles de leer. No te preocupes; mejorará con la práctica, y los patrones simples pronto se convertirán en una segunda naturaleza. Comencemos ese proceso practicando con algunas funciones útiles de stringr.",
    "crumbs": [
      "Transformar",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Expresiones regulares</span>"
    ]
  },
  {
    "objectID": "regexps.html#sec-stringr-regex-funs",
    "href": "regexps.html#sec-stringr-regex-funs",
    "title": "16  Expresiones regulares",
    "section": "\n16.3 Funciones clave",
    "text": "16.3 Funciones clave\nAhora que tiene los conceptos básicos de las expresiones regulares bajo su cinturón, usémoslos con algunas funciones stringr y tidyr. En la siguiente sección, aprenderá cómo detectar la presencia o ausencia de una coincidencia, cómo contar el número de coincidencias, cómo reemplazar una coincidencia con texto fijo y cómo extraer texto usando un patrón.\n\n16.3.1 Detectar coincidencias\nstr_detect() devuelve un vector lógico que es TRUE si el patrón coincide con un elemento del vector de caracteres y FALSE en caso contrario:\n\nstr_detect(c(\"a\", \"b\", \"c\"), \"[aeiou]\")\n#&gt; [1]  TRUE FALSE FALSE\n\nDado que str_detect() devuelve un vector lógico de la misma longitud que el vector inicial, se empareja bien con filter(). Por ejemplo, este código encuentra todos los nombres más populares que contienen una “x” minúscula:\n\nbabynames |&gt; \n  filter(str_detect(name, \"x\")) |&gt; \n  count(name, wt = n, sort = TRUE)\n#&gt; # A tibble: 974 × 2\n#&gt;   name           n\n#&gt;   &lt;chr&gt;      &lt;int&gt;\n#&gt; 1 Alexander 665492\n#&gt; 2 Alexis    399551\n#&gt; 3 Alex      278705\n#&gt; 4 Alexandra 232223\n#&gt; 5 Max       148787\n#&gt; 6 Alexa     123032\n#&gt; # ℹ 968 more rows\n\nTambién podemos usar str_detect() con summarize() combinándolo con sum() o mean(): sum(str_detect(x, pattern)) te dice el número de observaciones que coinciden y mean(str_detect(x, pattern)) te dice la proporción que coincide. Por ejemplo, el siguiente fragmento calcula y visualiza la proporción de nombres de bebés4 que contienen “x”, desglosados por año. ¡Parece que su popularidad ha aumentado radicalmente últimamente!\n\nbabynames |&gt; \n  group_by(year) |&gt; \n  summarize(prop_x = mean(str_detect(name, \"x\"))) |&gt; \n  ggplot(aes(x = year, y = prop_x)) + \n  geom_line()\n\n\n\n\n\n\n\nHay dos funciones que están estrechamente relacionadas con str_detect(): str_subset() y str_which(). str_subset() devuelve solo las cadenas que contienen coincidencia. str_which() devuelve los índices de las cadenas que tienen coincidencia:\n\n16.3.2 Contar coincidencias\nEl siguiente paso en complejidad de str_detect() es str_count(): en lugar de verdadero o falso, le dice cuántas coincidencias hay en cada cadena.\n\nx &lt;- c(\"apple\", \"banana\", \"pear\")\nstr_count(x, \"p\")\n#&gt; [1] 2 0 1\n\nTenga en cuenta que cada coincidencia comienza al final de la coincidencia anterior, es decir, las coincidencias de expresiones regulares nunca se superponen. Por ejemplo, en \"abababa\", ¿cuántas veces coincidirá el patrón \"aba\"? Las expresiones regulares dicen dos, no tres:\n\nstr_count(\"abababa\", \"aba\")\n#&gt; [1] 2\nstr_view(\"abababa\", \"aba\")\n#&gt; [1] │ &lt;aba&gt;b&lt;aba&gt;\n\nEs natural usar str_count() con mutate(). El siguiente ejemplo usa str_count() con clases de caracteres para contar el número de vocales y consonantes en cada nombre.\n\nbabynames |&gt; \n  count(name) |&gt; \n  mutate(\n    vowels = str_count(name, \"[aeiou]\"),\n    consonants = str_count(name, \"[^aeiou]\")\n  )\n#&gt; # A tibble: 97,310 × 4\n#&gt;   name          n vowels consonants\n#&gt;   &lt;chr&gt;     &lt;int&gt;  &lt;int&gt;      &lt;int&gt;\n#&gt; 1 Aaban        10      2          3\n#&gt; 2 Aabha         5      2          3\n#&gt; 3 Aabid         2      2          3\n#&gt; 4 Aabir         1      2          3\n#&gt; 5 Aabriella     5      4          5\n#&gt; 6 Aada          1      2          2\n#&gt; # ℹ 97,304 more rows\n\nSi miras de cerca, notarás que hay algo mal con nuestros cálculos: “Aaban” contiene tres “a”, pero nuestro resumen solo reporta dos vocales. Eso es porque las expresiones regulares distinguen entre mayúsculas y minúsculas. Hay tres formas en las que podemos arreglar esto:\n\nAgregue las vocales mayúsculas a la clase de carácter: str_count(name, \"[aeiouAEIOU]\").\nDígale a la expresión regular que ignore el tamaño: str_count(name, regex(\"[aeiou]\", ignore_case = TRUE)). Hablaremos de más en Sección 16.5.1.\nUsa str_to_lower() para convertir los nombres a minúsculas: str_count(str_to_lower(name), \"[aeiou]\").\n\nEsta variedad de enfoques es bastante típica cuando se trabaja con cadenas; a menudo, hay varias formas de alcanzar su objetivo, ya sea haciendo que su patrón sea más complicado o haciendo un preprocesamiento en su cadena. Si se queda atascado intentando un enfoque, a menudo puede ser útil cambiar de marcha y abordar el problema desde una perspectiva diferente.\nEn este caso, dado que estamos aplicando dos funciones al nombre, creo que es más fácil transformarlo primero:\n\nbabynames |&gt; \n  count(name) |&gt; \n  mutate(\n    name = str_to_lower(name),\n    vowels = str_count(name, \"[aeiou]\"),\n    consonants = str_count(name, \"[^aeiou]\")\n  )\n#&gt; # A tibble: 97,310 × 4\n#&gt;   name          n vowels consonants\n#&gt;   &lt;chr&gt;     &lt;int&gt;  &lt;int&gt;      &lt;int&gt;\n#&gt; 1 aaban        10      3          2\n#&gt; 2 aabha         5      3          2\n#&gt; 3 aabid         2      3          2\n#&gt; 4 aabir         1      3          2\n#&gt; 5 aabriella     5      5          4\n#&gt; 6 aada          1      3          1\n#&gt; # ℹ 97,304 more rows\n\n\n16.3.3 Reemplazar valores\nAdemás de detectar y contar coincidencias, también podemos modificarlas con str_replace() y str_replace_all(). str_replace() reemplaza la primera coincidencia y, como sugiere el nombre, str_replace_all() reemplaza todas las coincidencias.\n\nx &lt;- c(\"apple\", \"pear\", \"banana\")\nstr_replace_all(x, \"[aeiou]\", \"-\")\n#&gt; [1] \"-ppl-\"  \"p--r\"   \"b-n-n-\"\n\nstr_remove() y str_remove_all() son atajos útiles para str_replace(x, patrón, \"\"):\n\nx &lt;- c(\"apple\", \"pear\", \"banana\")\nstr_remove_all(x, \"[aeiou]\")\n#&gt; [1] \"ppl\" \"pr\"  \"bnn\"\n\nEstas funciones se combinan de forma natural con mutate() al realizar la limpieza de datos y, a menudo, las aplicará repetidamente para quitar capas de formato inconsistente.\n\n16.3.4 Extraer variables\nLa última función que discutiremos usa expresiones regulares para extraer datos de una columna en una o más columnas nuevas: separate_wider_regex(). Es un par de las funciones separate_wider_position() y separate_wider_delim() que aprendiste en Sección 15.4.2. Estas funciones viven en tidyr porque operan en (columnas de) data frames, en lugar de vectores individuales.\nVamos a crear un conjunto de datos simple para mostrar cómo funciona. Aquí tenemos algunos datos derivados de babynames donde tenemos el nombre, el género y la edad de un grupo de personas en un formato bastante extraño 5:\n\ndf &lt;- tribble(\n  ~str,\n  \"&lt;Sheryl&gt;-F_34\",\n  \"&lt;Kisha&gt;-F_45\", \n  \"&lt;Brandon&gt;-N_33\",\n  \"&lt;Sharon&gt;-F_38\", \n  \"&lt;Penny&gt;-F_58\",\n  \"&lt;Justin&gt;-M_41\", \n  \"&lt;Patricia&gt;-F_84\", \n)\n\nPara extraer estos datos usando separate_wider_regex() solo necesitamos construir una secuencia de expresiones regulares que coincidan con cada pieza. Si queremos que el contenido de esa pieza aparezca en la salida, le damos un nombre:\n\ndf |&gt; \n  separate_wider_regex(\n    str,\n    patterns = c(\n      \"&lt;\", \n      name = \"[A-Za-z]+\", \n      \"&gt;-\", \n      gender = \".\",\n      \"_\", \n      age = \"[0-9]+\"\n    )\n  )\n#&gt; # A tibble: 7 × 3\n#&gt;   name    gender age  \n#&gt;   &lt;chr&gt;   &lt;chr&gt;  &lt;chr&gt;\n#&gt; 1 Sheryl  F      34   \n#&gt; 2 Kisha   F      45   \n#&gt; 3 Brandon N      33   \n#&gt; 4 Sharon  F      38   \n#&gt; 5 Penny   F      58   \n#&gt; 6 Justin  M      41   \n#&gt; # ℹ 1 more row\n\nSi la coincidencia falla, puede usar too_few = \"debug\" para descubrir qué salió mal, al igual que separate_wider_delim() y separate_wider_position().\n\n16.3.5 Ejercicios\n\n¿Qué nombre de bebé tiene más vocales? ¿Qué nombre tiene la mayor proporción de vocales? (Pista: ¿cuál es el denominador?)\nReemplace todas las barras diagonales en \"a/b/c/d/e\" con barras invertidas. ¿Qué sucede si intenta deshacer la transformación reemplazando todas las barras diagonales inversas con barras diagonales? (Discutiremos el problema muy pronto).\nImplemente una versión simple de str_to_lower() usando str_replace_all().\nCree una expresión regular que coincida con los números de teléfono tal como se escriben comúnmente en su país.",
    "crumbs": [
      "Transformar",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Expresiones regulares</span>"
    ]
  },
  {
    "objectID": "regexps.html#detalles-del-patrón",
    "href": "regexps.html#detalles-del-patrón",
    "title": "16  Expresiones regulares",
    "section": "\n16.4 Detalles del patrón",
    "text": "16.4 Detalles del patrón\nAhora que comprende los conceptos básicos del lenguaje de patrones y cómo usarlo con algunas funciones stringr y tidyr, es hora de profundizar en más detalles. Primero, comenzaremos con escapar, lo que le permite unir metacaracteres que de otro modo serían tratados de manera especial. A continuación, aprenderá sobre anclajes que le permiten hacer coincidir el inicio o el final de la cadena. Luego, aprenderá más sobre las clases de caracteres y sus accesos directos que le permiten hacer coincidir cualquier carácter de un conjunto. A continuación, conocerá los detalles finales de los cuantificadores que controlan cuántas veces puede coincidir un patrón. Luego, tenemos que cubrir el tema importante (pero complejo) de precedencia de operadores y paréntesis. Y terminaremos con algunos detalles de agrupación de componentes de patrones.\nLos términos que usamos aquí son los nombres técnicos de cada componente. No siempre son los más evocadores de su propósito, pero es muy útil conocer los términos correctos si luego desea buscar en Google para obtener más detalles.\n\n16.4.1 Escapar\nPara hacer coincidir un . literal, necesita un escape que le indique a la expresión regular que coincida con los metacaracteres6 literalmente. Al igual que las cadenas, las expresiones regulares usan la barra invertida para escapar. Entonces, para hacer coincidir un ., necesita la expresión regular \\.. Desafortunadamente esto crea un problema. Usamos cadenas para representar expresiones regulares, y \\ también se usa como símbolo de escape en cadenas. Así que para crear la expresión regular \\. necesitamos la cadena \"\\\\.\", como muestra el siguiente ejemplo.\n\n# Para crear la expresión regular \\., necesitamos usar \\\\.\ndot &lt;- \"\\\\.\"\n\n# Pero la expresión en sí solo contiene una \\\nstr_view(dot)\n#&gt; [1] │ \\.\n\n# Y esto le dice a R que busque una explicita.\nstr_view(c(\"abc\", \"a.c\", \"bef\"), \"a\\\\.c\")\n#&gt; [2] │ &lt;a.c&gt;\n\nEn este libro, normalmente escribiremos expresiones regulares sin comillas, como \\.. Si necesitamos enfatizar lo que realmente escribirá, lo rodearemos con comillas y agregaremos escapes adicionales, como \"\\\\.\".\nSi \\ se usa como un carácter de escape en expresiones regulares, ¿cómo hace coincidir un literal \\? Bueno, necesitas escapar, creando la expresión regular \\\\. Para crear esa expresión regular, debe usar una cadena, que también debe escapar de \\. Eso significa que para hacer coincidir un \\ literal, debe escribir \"\\\\\\\\\" — ¡necesita cuatro barras diagonales inversas para que coincida con uno!\n\nx &lt;- \"a\\\\b\"\nstr_view(x)\n#&gt; [1] │ a\\b\nstr_view(x, \"\\\\\\\\\")\n#&gt; [1] │ a&lt;\\&gt;b\n\nAlternativamente, puede que le resulte más fácil usar las cadenas sin formato que aprendió en Sección 15.2.2). Eso le permite evitar una capa de escape:\n\nstr_view(x, r\"{\\\\}\")\n#&gt; [1] │ a&lt;\\&gt;b\n\nSi está tratando de hacer coincidir un literal ., $, |, *, +, ?, {, }, (, ), hay una alternativa al uso de un escape de barra invertida: puede usar una clase de carácter: [.], [$], [|], … todos coinciden con los valores literales.\n\nstr_view(c(\"abc\", \"a.c\", \"a*c\", \"a c\"), \"a[.]c\")\n#&gt; [2] │ &lt;a.c&gt;\nstr_view(c(\"abc\", \"a.c\", \"a*c\", \"a c\"), \".[*]c\")\n#&gt; [3] │ &lt;a*c&gt;\n\n\n16.4.2 Anclajes\nDe forma predeterminada, las expresiones regulares coincidirán con cualquier parte de una cadena. Si desea hacer coincidir al principio del final, necesita anclar la expresión regular usando ^ para que coincida con el comienzo de la cadena o $ para que coincida con el final:\n\nstr_view(fruit, \"^a\")\n#&gt; [1] │ &lt;a&gt;pple\n#&gt; [2] │ &lt;a&gt;pricot\n#&gt; [3] │ &lt;a&gt;vocado\nstr_view(fruit, \"a$\")\n#&gt;  [4] │ banan&lt;a&gt;\n#&gt; [15] │ cherimoy&lt;a&gt;\n#&gt; [30] │ feijo&lt;a&gt;\n#&gt; [36] │ guav&lt;a&gt;\n#&gt; [56] │ papay&lt;a&gt;\n#&gt; [74] │ satsum&lt;a&gt;\n\nEs tentador pensar que $ debería coincidir con el comienzo de una cadena, porque así es como escribimos cantidades en dólares, pero no es lo que quieren las expresiones regulares.\nPara obligar a una expresión regular a coincidir solo con la cadena completa, asegúrela con ^ y $:\n\nstr_view(fruit, \"apple\")\n#&gt;  [1] │ &lt;apple&gt;\n#&gt; [62] │ pine&lt;apple&gt;\nstr_view(fruit, \"^apple$\")\n#&gt; [1] │ &lt;apple&gt;\n\nTambién puede hacer coincidir el límite entre palabras (es decir, el comienzo o el final de una palabra) con \\b. Esto puede ser particularmente útil cuando se usa la herramienta de búsqueda y reemplazo de RStudio. Por ejemplo, si para encontrar todos los usos de sum(), puede buscar \\bsum\\b para evitar la coincidencia de summarize, summary, rowsum y así sucesivamente:\n\nx &lt;- c(\"summary(x)\", \"summarize(df)\", \"rowsum(x)\", \"sum(x)\")\nstr_view(x, \"sum\")\n#&gt; [1] │ &lt;sum&gt;mary(x)\n#&gt; [2] │ &lt;sum&gt;marize(df)\n#&gt; [3] │ row&lt;sum&gt;(x)\n#&gt; [4] │ &lt;sum&gt;(x)\nstr_view(x, \"\\\\bsum\\\\b\")\n#&gt; [4] │ &lt;sum&gt;(x)\n\nCuando se usan solos, los anclajes producirán una coincidencia de ancho cero:\n\nstr_view(\"abc\", c(\"$\", \"^\", \"\\\\b\"))\n#&gt; [1] │ abc&lt;&gt;\n#&gt; [2] │ &lt;&gt;abc\n#&gt; [3] │ &lt;&gt;abc&lt;&gt;\n\nEsto lo ayuda a comprender lo que sucede cuando reemplaza un ancla independiente:\n\nstr_replace_all(\"abc\", c(\"$\", \"^\", \"\\\\b\"), \"--\")\n#&gt; [1] \"abc--\"   \"--abc\"   \"--abc--\"\n\n\n16.4.3 Clases de caracteres\nUna clase de carácter, o un conjunto de caracteres, le permite hacer coincidir cualquier carácter en un conjunto. Como discutimos anteriormente, puede construir sus propios conjuntos con [], donde [abc] coincide con “a”, “b” o “c” y [^abc] coincide con cualquier carácter excepto “a”. , “b” o “c”. Además de ^, hay otros dos caracteres que tienen un significado especial dentro de []:\n\n\n- define un rango, p.ej., [a-z] coincide con cualquier letra minúscula y [0-9] coincide con cualquier número.\n\n\\ eescapa a los caracteres especiales, por lo que [\\^\\-\\]] coincide ^, -, o ].\n\nAquí hay algunos ejemplos:\n\nx &lt;- \"abcd ABCD 12345 -!@#%.\"\nstr_view(x, \"[abc]+\")\n#&gt; [1] │ &lt;abc&gt;d ABCD 12345 -!@#%.\nstr_view(x, \"[a-z]+\")\n#&gt; [1] │ &lt;abcd&gt; ABCD 12345 -!@#%.\nstr_view(x, \"[^a-z0-9]+\")\n#&gt; [1] │ abcd&lt; ABCD &gt;12345&lt; -!@#%.&gt;\n\n# Necesita un escape para hacer coincidir caracteres que de otro modo son\n# especial dentro de []\nstr_view(\"a-b-c\", \"[a-c]\")\n#&gt; [1] │ &lt;a&gt;-&lt;b&gt;-&lt;c&gt;\nstr_view(\"a-b-c\", \"[a\\\\-c]\")\n#&gt; [1] │ &lt;a&gt;&lt;-&gt;b&lt;-&gt;&lt;c&gt;\n\nAlgunas clases de caracteres se usan con tanta frecuencia que obtienen su propio atajo. Ya has visto ., que coincide con cualquier carácter excepto una nueva línea. Hay otros tres pares particularmente útiles7:\n\n\n\\d coincide con cualquier dígito;\\D coincide con cualquier cosa que no sea un dígito.\n\n\\s coincide con cualquier espacio en blanco (por ejemplo, espacio, tabulador, nueva línea);\\S coincide con cualquier cosa que no sea un espacio en blanco.\n\n\\w coincide con cualquier carácter de “palabra”, es decir, letras y números;\\W coincide con cualquier carácter “no palabra”.\n\nEl siguiente código muestra los seis atajos con una selección de letras, números y signos de puntuación.\n\nx &lt;- \"abcd ABCD 12345 -!@#%.\"\nstr_view(x, \"\\\\d+\")\n#&gt; [1] │ abcd ABCD &lt;12345&gt; -!@#%.\nstr_view(x, \"\\\\D+\")\n#&gt; [1] │ &lt;abcd ABCD &gt;12345&lt; -!@#%.&gt;\nstr_view(x, \"\\\\s+\")\n#&gt; [1] │ abcd&lt; &gt;ABCD&lt; &gt;12345&lt; &gt;-!@#%.\nstr_view(x, \"\\\\S+\")\n#&gt; [1] │ &lt;abcd&gt; &lt;ABCD&gt; &lt;12345&gt; &lt;-!@#%.&gt;\nstr_view(x, \"\\\\w+\")\n#&gt; [1] │ &lt;abcd&gt; &lt;ABCD&gt; &lt;12345&gt; -!@#%.\nstr_view(x, \"\\\\W+\")\n#&gt; [1] │ abcd&lt; &gt;ABCD&lt; &gt;12345&lt; -!@#%.&gt;\n\n\n16.4.4 Cuantificadores\nLos cuantificadores controlan cuántas veces coincide un patrón. En Sección 16.2, aprendió sobre ? (0 o 1 coincidencias), + (1 o más coincidencias) y * (0 o más coincidencias). Por ejemplo, colou?r coincidirá con la ortografía estadounidense o británica, \\d+ coincidirá con uno o más dígitos y \\s? coincidirá opcionalmente con un único elemento de espacio en blanco. También puede especificar el número de coincidencias con precisión con {}:\n\n\n{n} coincide exactamente n veces.\n\n{n,} coincide al menos n veces.\n\n{n,m} coincide entre n y m veces.\n\n16.4.5 Precedencia de operadores y paréntesis\n¿Con qué coincide ab+? ¿Coincide con “a” seguido de una o más “b”, o coincide con “ab” repetido cualquier número de veces? ¿Con qué coincide ^a|b$? ¿Coincide con la cadena completa a o la cadena completa b, o coincide con una cadena que comienza con a o una cadena que termina con b?\nLa respuesta a estas preguntas está determinada por la precedencia de operadores, similar a las reglas PEMDAS o BEDMAS que quizás haya aprendido en la escuela. Sabes que a + b * c es equivalente a a + (b * c) y no (a + b) * c porque * tiene mayor precedencia y + tiene menor precedencia: calculas * antes de +.\nDe manera similar, las expresiones regulares tienen sus propias reglas de precedencia: los cuantificadores tienen una precedencia alta y la alternancia tiene una precedencia baja, lo que significa que ab+ es equivalente a a(b+), y ^a|b$ es equivalente a (^a )|(b$). Al igual que con el álgebra, puede usar paréntesis para anular el orden habitual. Pero a diferencia del álgebra, es poco probable que recuerdes las reglas de precedencia para las expresiones regulares, así que siéntete libre de usar paréntesis libremente.\n\n16.4.6 Agrupación y captura\nAdemás de anular la precedencia de los operadores, los paréntesis tienen otro efecto importante: crean grupos de captura que le permiten usar subcomponentes de la coincidencia.\nLa primera forma de usar un grupo de captura es hacer referencia a él dentro de una coincidencia con referencia posterior: \\1 se refiere a la coincidencia contenida en el primer paréntesis, \\2 en el segundo paréntesis, y así sucesivamente. Por ejemplo, el siguiente patrón encuentra todas las frutas que tienen un par de letras repetido:\n\nstr_view(fruit, \"(..)\\\\1\")\n#&gt;  [4] │ b&lt;anan&gt;a\n#&gt; [20] │ &lt;coco&gt;nut\n#&gt; [22] │ &lt;cucu&gt;mber\n#&gt; [41] │ &lt;juju&gt;be\n#&gt; [56] │ &lt;papa&gt;ya\n#&gt; [73] │ s&lt;alal&gt; berry\n\nY este encuentra todas las palabras que comienzan y terminan con el mismo par de letras:\n\nstr_view(words, \"^(..).*\\\\1$\")\n#&gt; [152] │ &lt;church&gt;\n#&gt; [217] │ &lt;decide&gt;\n#&gt; [617] │ &lt;photograph&gt;\n#&gt; [699] │ &lt;require&gt;\n#&gt; [739] │ &lt;sense&gt;\n\nTambién puede usar referencias anteriores en str_replace(). Por ejemplo, este código cambia el orden de la segunda y tercera palabra en sentences:\n\nsentences |&gt; \n  str_replace(\"(\\\\w+) (\\\\w+) (\\\\w+)\", \"\\\\1 \\\\3 \\\\2\") |&gt; \n  str_view()\n#&gt; [1] │ The canoe birch slid on the smooth planks.\n#&gt; [2] │ Glue sheet the to the dark blue background.\n#&gt; [3] │ It's to easy tell the depth of a well.\n#&gt; [4] │ These a days chicken leg is a rare dish.\n#&gt; [5] │ Rice often is served in round bowls.\n#&gt; [6] │ The of juice lemons makes fine punch.\n#&gt; ... and 714 more\n\nSi desea extraer las coincidencias para cada grupo, puede usar str_match(). Pero str_match() devuelve una matriz, por lo que no es particularmente fácil trabajar con 8:\n\nsentences |&gt; \n  str_match(\"the (\\\\w+) (\\\\w+)\") |&gt; \n  head()\n#&gt;      [,1]                [,2]     [,3]    \n#&gt; [1,] \"the smooth planks\" \"smooth\" \"planks\"\n#&gt; [2,] \"the sheet to\"      \"sheet\"  \"to\"    \n#&gt; [3,] \"the depth of\"      \"depth\"  \"of\"    \n#&gt; [4,] NA                  NA       NA      \n#&gt; [5,] NA                  NA       NA      \n#&gt; [6,] NA                  NA       NA\n\nPuede convertir a un tibble y nombrar las columnas:\n\nsentences |&gt; \n  str_match(\"the (\\\\w+) (\\\\w+)\") |&gt; \n  as_tibble(.name_repair = \"minimal\") |&gt; \n  set_names(\"match\", \"word1\", \"word2\")\n#&gt; # A tibble: 720 × 3\n#&gt;   match             word1  word2 \n#&gt;   &lt;chr&gt;             &lt;chr&gt;  &lt;chr&gt; \n#&gt; 1 the smooth planks smooth planks\n#&gt; 2 the sheet to      sheet  to    \n#&gt; 3 the depth of      depth  of    \n#&gt; 4 &lt;NA&gt;              &lt;NA&gt;   &lt;NA&gt;  \n#&gt; 5 &lt;NA&gt;              &lt;NA&gt;   &lt;NA&gt;  \n#&gt; 6 &lt;NA&gt;              &lt;NA&gt;   &lt;NA&gt;  \n#&gt; # ℹ 714 more rows\n\nPero luego básicamente ha recreado su propia versión de separate_wider_regex(). De hecho, detrás de escena, separate_wider_regex() convierte su vector de patrones en una sola expresión regular que utiliza la agrupación para capturar los componentes nombrados.\nOcasionalmente, querrá usar paréntesis sin crear grupos coincidentes. Puede crear un grupo que no captura con (?:).\n\nx &lt;- c(\"a gray cat\", \"a grey dog\")\nstr_match(x, \"gr(e|a)y\")\n#&gt;      [,1]   [,2]\n#&gt; [1,] \"gray\" \"a\" \n#&gt; [2,] \"grey\" \"e\"\nstr_match(x, \"gr(?:e|a)y\")\n#&gt;      [,1]  \n#&gt; [1,] \"gray\"\n#&gt; [2,] \"grey\"\n\n\n16.4.7 Ejercicios\n\n¿Cómo haría coincidir la cadena literal \"'\\? ¿Qué tal \"$^$\"?\nExplique por qué cada uno de estos patrones no coincide con \\: \"\\\", \"\\\\\", \"\\\\\\\".\n\nDado el corpus de palabras comunes en stringr::words, cree expresiones regulares que encuentren todas las palabras que:\n\nEmpiezan con “y”.\nNo empiezan con “y”.\nTerminan con “x”.\nTienen exactamente tres letras de largo. (¡No hagas trampa usando str_length()!)\nTener siete letras o más.\nContienen un par de vocales y consonantes.\nContener al menos dos pares de vocales y consonantes seguidos.\nSólo consisten en pares repetidos de vocales y consonantes.\n\n\nCree 11 expresiones regulares que coincidan con la ortografía británica o estadounidense para cada una de las siguientes palabras: airplane/aeroplane, aluminum/aluminium, analog/analogue, ass/arse, center/centre, defense/defence, donut/doughnut, gray/grey, modeling/modelling, skeptic/sceptic, summarize/summarise. ¡Intenta hacer la expresión regular más corta posible!\nCambia la primera y la última letra en palabras. ¿Cuáles de esas cadenas siguen siendo palabras?\n\nDescriba con palabras con qué coinciden estas expresiones regulares: (lea atentamente para ver si cada entrada es una expresión regular o una cadena que define una expresión regular).\n\n^.*$\n\"\\\\{.+\\\\}\"\n\\d{4}-\\d{2}-\\d{2}\n\"\\\\\\\\{4}\"\n\\..\\..\\..\n(.)\\1\\1\n\"(..)\\\\1\"\n\n\nResuelva los crucigramas de expresiones regulares para principiantes en https://regexcrossword.com/challenges/beginner.",
    "crumbs": [
      "Transformar",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Expresiones regulares</span>"
    ]
  },
  {
    "objectID": "regexps.html#control-de-patrones",
    "href": "regexps.html#control-de-patrones",
    "title": "16  Expresiones regulares",
    "section": "\n16.5 Control de patrones",
    "text": "16.5 Control de patrones\nEs posible ejercer un control adicional sobre los detalles de la coincidencia mediante el uso de un objeto de patrón en lugar de solo una cadena. Esto le permite controlar los llamados indicadores de expresiones regulares y hacer coincidir varios tipos de cadenas fijas, como se describe a continuación.\n\n16.5.1 Banderas de expresiones regulares\nHay una serie de configuraciones que se pueden usar para controlar los detalles de la expresión regular. Estas configuraciones a menudo se denominan banderas en otros lenguajes de programación. En stringr, puede usarlos envolviendo el patrón en una llamada a regex(). La bandera más útil es probablemente ignore_case = TRUE porque permite que los caracteres coincidan con sus formas mayúsculas o minúsculas:\n\nbananas &lt;- c(\"banana\", \"Banana\", \"BANANA\")\nstr_view(bananas, \"banana\")\n#&gt; [1] │ &lt;banana&gt;\nstr_view(bananas, regex(\"banana\", ignore_case = TRUE))\n#&gt; [1] │ &lt;banana&gt;\n#&gt; [2] │ &lt;Banana&gt;\n#&gt; [3] │ &lt;BANANA&gt;\n\nSi está trabajando mucho con cadenas multilínea (es decir, cadenas que contienen \\n), dotall y multiline también pueden ser útiles:\n\n\ndotall = TRUE permite que . coincida con todo, incluido \\n:\n\nx &lt;- \"Line 1\\nLine 2\\nLine 3\"\nstr_view(x, \".Line\")\nstr_view(x, regex(\".Line\", dotall = TRUE))\n#&gt; [1] │ Line 1&lt;\n#&gt;     │ Line&gt; 2&lt;\n#&gt;     │ Line&gt; 3\n\n\n\nmultiline = TRUE hace que ^ y $ coincidan con el inicio y el final de cada línea en lugar del inicio y el final de la cadena completa:\n\nx &lt;- \"Line 1\\nLine 2\\nLine 3\"\nstr_view(x, \"^Line\")\n#&gt; [1] │ &lt;Line&gt; 1\n#&gt;     │ Line 2\n#&gt;     │ Line 3\nstr_view(x, regex(\"^Line\", multiline = TRUE))\n#&gt; [1] │ &lt;Line&gt; 1\n#&gt;     │ &lt;Line&gt; 2\n#&gt;     │ &lt;Line&gt; 3\n\n\n\nFinalmente, si está escribiendo una expresión regular complicada y le preocupa no entenderla en el futuro, puede probar comentarios = TRUE. Ajusta el lenguaje de patrones para ignorar los espacios y las líneas nuevas, así como todo lo que se encuentra después de #. Esto le permite usar comentarios y espacios en blanco para hacer que las expresiones regulares complejas sean más comprensibles9, como en el siguiente ejemplo:\n\nphone &lt;- regex(\n  r\"(\n    \\(?     # paréntesis de apertura opcionales\n    (\\d{3}) # área de codigo\n    [)\\-]?  # paréntesis o guión de cierre opcionales\n    \\ ?     # spacio opcional\n    (\\d{3}) # otros tres números\n    [\\ -]?  # espacio o guión opcional\n    (\\d{4}) # cuatro números más\n  )\", \n  comments = TRUE\n)\n\nstr_extract(c(\"514-791-8141\", \"(123) 456 7890\", \"123456\"), phone)\n#&gt; [1] \"514-791-8141\"   \"(123) 456 7890\" NA\n\nSi está utilizando comentarios y desea hacer coincidir un espacio, una nueva línea o #, deberá escapar con \\.\n\n16.5.2 Coincidencias fijas\nPuede optar por no participar en las reglas de expresiones regulares utilizando fixed():\n\nstr_view(c(\"\", \"a\", \".\"), fixed(\".\"))\n#&gt; [3] │ &lt;.&gt;\n\nfixed() también le da la posibilidad de ignorar mayúsculas y minúsculas:\n\nstr_view(\"x X\", \"X\")\n#&gt; [1] │ x &lt;X&gt;\nstr_view(\"x X\", fixed(\"X\", ignore_case = TRUE))\n#&gt; [1] │ &lt;x&gt; &lt;X&gt;\n\nSi está trabajando con texto que no está en inglés, probablemente querrá coll() en lugar de fixed(), ya que implementa las reglas completas para el uso de mayúsculas tal como las usa el locale que especifique. Consulte Sección 15.6 para obtener más detalles sobre las configuraciones regionales.\n\nstr_view(\"i İ ı I\", fixed(\"İ\", ignore_case = TRUE))\n#&gt; [1] │ i &lt;İ&gt; ı I\nstr_view(\"i İ ı I\", coll(\"İ\", ignore_case = TRUE, locale = \"tr\"))\n#&gt; [1] │ &lt;i&gt; &lt;İ&gt; ı I",
    "crumbs": [
      "Transformar",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Expresiones regulares</span>"
    ]
  },
  {
    "objectID": "regexps.html#práctica",
    "href": "regexps.html#práctica",
    "title": "16  Expresiones regulares",
    "section": "\n16.6 Práctica",
    "text": "16.6 Práctica\nPara poner en práctica estas ideas, resolveremos a continuación algunos problemas semiauténticos. Discutiremos tres técnicas generales:\n\nComprobar su trabajo mediante la creación de controles positivos y negativos simples\nCombinar expresiones regulares con álgebra booleana\nCrear patrones complejos usando la manipulación de cadenas\n\n\n16.6.1 Revisa tu trabajo\nPrimero, encontremos todas las oraciones que comienzan con The. Usar el ancla ^ solo no es suficiente:\n\nstr_view(sentences, \"^The\")\n#&gt;  [1] │ &lt;The&gt; birch canoe slid on the smooth planks.\n#&gt;  [4] │ &lt;The&gt;se days a chicken leg is a rare dish.\n#&gt;  [6] │ &lt;The&gt; juice of lemons makes fine punch.\n#&gt;  [7] │ &lt;The&gt; box was thrown beside the parked truck.\n#&gt;  [8] │ &lt;The&gt; hogs were fed chopped corn and garbage.\n#&gt; [11] │ &lt;The&gt; boy was there when the sun rose.\n#&gt; ... and 271 more\n\nPorque ese patrón también coincide con oraciones que comienzan con palabras como They o These. Necesitamos asegurarnos de que la “e” sea la última letra de la palabra, lo que podemos hacer agregando un límite de palabra:\n\nstr_view(sentences, \"^The\\\\b\")\n#&gt;  [1] │ &lt;The&gt; birch canoe slid on the smooth planks.\n#&gt;  [6] │ &lt;The&gt; juice of lemons makes fine punch.\n#&gt;  [7] │ &lt;The&gt; box was thrown beside the parked truck.\n#&gt;  [8] │ &lt;The&gt; hogs were fed chopped corn and garbage.\n#&gt; [11] │ &lt;The&gt; boy was there when the sun rose.\n#&gt; [13] │ &lt;The&gt; source of the huge river is the clear spring.\n#&gt; ... and 250 more\n\n¿Qué hay de encontrar todas las oraciones que comienzan con un pronombre?\n\nstr_view(sentences, \"^She|He|It|They\\\\b\")\n#&gt;  [3] │ &lt;It&gt;'s easy to tell the depth of a well.\n#&gt; [15] │ &lt;He&gt;lp the woman get back to her feet.\n#&gt; [27] │ &lt;He&gt;r purse was full of useless trash.\n#&gt; [29] │ &lt;It&gt; snowed, rained, and hailed the same morning.\n#&gt; [63] │ &lt;He&gt; ran half way to the hardware store.\n#&gt; [90] │ &lt;He&gt; lay prone and hardly moved a limb.\n#&gt; ... and 57 more\n\nUna inspección rápida de los resultados muestra que estamos obteniendo algunas coincidencias falsas. Eso es porque nos hemos olvidado de usar paréntesis:\n\nstr_view(sentences, \"^(She|He|It|They)\\\\b\")\n#&gt;   [3] │ &lt;It&gt;'s easy to tell the depth of a well.\n#&gt;  [29] │ &lt;It&gt; snowed, rained, and hailed the same morning.\n#&gt;  [63] │ &lt;He&gt; ran half way to the hardware store.\n#&gt;  [90] │ &lt;He&gt; lay prone and hardly moved a limb.\n#&gt; [116] │ &lt;He&gt; ordered peach pie with ice cream.\n#&gt; [127] │ &lt;It&gt; caught its hind paw in a rusty trap.\n#&gt; ... and 51 more\n\nQuizás se pregunte cómo podría detectar tal error si no ocurrió en las primeras coincidencias. Una buena técnica es crear algunas coincidencias positivas y negativas y usarlas para probar que su patrón funciona como se esperaba:\n\npos &lt;- c(\"He is a boy\", \"She had a good time\")\nneg &lt;- c(\"Shells come from the sea\", \"Hadley said 'It's a great day'\")\n\npattern &lt;- \"^(She|He|It|They)\\\\b\"\nstr_detect(pos, pattern)\n#&gt; [1] TRUE TRUE\nstr_detect(neg, pattern)\n#&gt; [1] FALSE FALSE\n\nPor lo general, es mucho más fácil encontrar buenos ejemplos positivos que ejemplos negativos, porque toma un tiempo antes de que seas lo suficientemente bueno con las expresiones regulares para predecir dónde están tus debilidades. Sin embargo, siguen siendo útiles: a medida que trabaja en el problema, puede acumular lentamente una colección de sus errores, asegurándose de que nunca cometerá el mismo error dos veces.\n\n16.6.2 Operaciones booleanas\nImagina que queremos encontrar palabras que solo contengan consonantes. Una técnica es crear una clase de carácter que contenga todas las letras excepto las vocales ([^aeiou]), luego permitir que coincida con cualquier número de letras ([^aeiou]+), luego forzarlo a que coincida con el toda la cadena anclándola al principio y al final (^[^aeiou]+$):\n\nstr_view(words, \"^[^aeiou]+$\")\n#&gt; [123] │ &lt;by&gt;\n#&gt; [249] │ &lt;dry&gt;\n#&gt; [328] │ &lt;fly&gt;\n#&gt; [538] │ &lt;mrs&gt;\n#&gt; [895] │ &lt;try&gt;\n#&gt; [952] │ &lt;why&gt;\n\nPero puedes hacer que este problema sea un poco más fácil dándole la vuelta al problema. En lugar de buscar palabras que contengan solo consonantes, podríamos buscar palabras que no contengan vocales:\n\nstr_view(words[!str_detect(words, \"[aeiou]\")])\n#&gt; [1] │ by\n#&gt; [2] │ dry\n#&gt; [3] │ fly\n#&gt; [4] │ mrs\n#&gt; [5] │ try\n#&gt; [6] │ why\n\nEsta es una técnica útil siempre que se trate de combinaciones lógicas, particularmente aquellas que involucran “y” o “no”. Por ejemplo, imagina si quieres encontrar todas las palabras que contienen “a” y “b”. No hay un operador “y” integrado en las expresiones regulares, por lo que debemos abordarlo buscando todas las palabras que contengan una “a” seguida de una “b” o una “b” seguida de una “a”:\n\nstr_view(words, \"a.*b|b.*a\")\n#&gt;  [2] │ &lt;ab&gt;le\n#&gt;  [3] │ &lt;ab&gt;out\n#&gt;  [4] │ &lt;ab&gt;solute\n#&gt; [62] │ &lt;availab&gt;le\n#&gt; [66] │ &lt;ba&gt;by\n#&gt; [67] │ &lt;ba&gt;ck\n#&gt; ... and 24 more\n\nEs más sencillo combinar los resultados de dos llamadas para str_detect():\n\nwords[str_detect(words, \"a\") & str_detect(words, \"b\")]\n#&gt;  [1] \"able\"      \"about\"     \"absolute\"  \"available\" \"baby\"      \"back\"     \n#&gt;  [7] \"bad\"       \"bag\"       \"balance\"   \"ball\"      \"bank\"      \"bar\"      \n#&gt; [13] \"base\"      \"basis\"     \"bear\"      \"beat\"      \"beauty\"    \"because\"  \n#&gt; [19] \"black\"     \"board\"     \"boat\"      \"break\"     \"brilliant\" \"britain\"  \n#&gt; [25] \"debate\"    \"husband\"   \"labour\"    \"maybe\"     \"probable\"  \"table\"\n\n¿Qué pasaría si quisiéramos ver si hay una palabra que contiene todas las vocales? ¡Si lo hiciéramos con patrones, necesitaríamos generar 5! (120) patrones diferentes:\n\nwords[str_detect(words, \"a.*e.*i.*o.*u\")]\n# ...\nwords[str_detect(words, \"u.*o.*i.*e.*a\")]\n\nEs mucho más sencillo combinar cinco llamadas para str_detect():\n\nwords[\n  str_detect(words, \"a\") &\n  str_detect(words, \"e\") &\n  str_detect(words, \"i\") &\n  str_detect(words, \"o\") &\n  str_detect(words, \"u\")\n]\n#&gt; character(0)\n\nEn general, si te quedas atascado tratando de crear una única expresión regular que resuelva tu problema, da un paso atrás y piensa si podrías dividir el problema en partes más pequeñas, resolviendo cada desafío antes de pasar al siguiente.\n\n16.6.3 Crear un patrón con código\n¿Qué pasaría si quisiéramos encontrar todas las ‘oraciones’ que mencionan un color? La idea básica es simple: simplemente combinamos alternancia con límites de palabras.\n\nstr_view(sentences, \"\\\\b(red|green|blue)\\\\b\")\n#&gt;   [2] │ Glue the sheet to the dark &lt;blue&gt; background.\n#&gt;  [26] │ Two &lt;blue&gt; fish swam in the tank.\n#&gt;  [92] │ A wisp of cloud hung in the &lt;blue&gt; air.\n#&gt; [148] │ The spot on the blotter was made by &lt;green&gt; ink.\n#&gt; [160] │ The sofa cushion is &lt;red&gt; and of light weight.\n#&gt; [174] │ The sky that morning was clear and bright &lt;blue&gt;.\n#&gt; ... and 20 more\n\nPero a medida que aumenta la cantidad de colores, rápidamente se vuelve tedioso construir este patrón a mano. ¿No sería bueno si pudiéramos almacenar los colores en un vector?\n\nrgb &lt;- c(\"red\", \"green\", \"blue\")\n\nBueno, ¡podemos! Solo necesitamos crear el patrón a partir del vector usando str_c() y str_flatten():\n\nstr_c(\"\\\\b(\", str_flatten(rgb, \"|\"), \")\\\\b\")\n#&gt; [1] \"\\\\b(red|green|blue)\\\\b\"\n\nPodríamos hacer este patrón más completo si tuviéramos una buena lista de colores. Un lugar desde el que podríamos comenzar es la lista de colores incorporados que R puede usar para los gráficos:\n\nstr_view(colors())\n#&gt; [1] │ white\n#&gt; [2] │ aliceblue\n#&gt; [3] │ antiquewhite\n#&gt; [4] │ antiquewhite1\n#&gt; [5] │ antiquewhite2\n#&gt; [6] │ antiquewhite3\n#&gt; ... and 651 more\n\nPero primero eliminemos las variantes numeradas:\n\ncols &lt;- colors()\ncols &lt;- cols[!str_detect(cols, \"\\\\d\")]\nstr_view(cols)\n#&gt; [1] │ white\n#&gt; [2] │ aliceblue\n#&gt; [3] │ antiquewhite\n#&gt; [4] │ aquamarine\n#&gt; [5] │ azure\n#&gt; [6] │ beige\n#&gt; ... and 137 more\n\nEntonces podemos convertir esto en un patrón gigante. No mostraremos el patrón aquí porque es enorme, pero puedes verlo funcionar:\n\npattern &lt;- str_c(\"\\\\b(\", str_flatten(cols, \"|\"), \")\\\\b\")\nstr_view(sentences, pattern)\n#&gt;   [2] │ Glue the sheet to the dark &lt;blue&gt; background.\n#&gt;  [12] │ A rod is used to catch &lt;pink&gt; &lt;salmon&gt;.\n#&gt;  [26] │ Two &lt;blue&gt; fish swam in the tank.\n#&gt;  [66] │ Cars and busses stalled in &lt;snow&gt; drifts.\n#&gt;  [92] │ A wisp of cloud hung in the &lt;blue&gt; air.\n#&gt; [112] │ Leaves turn &lt;brown&gt; and &lt;yellow&gt; in the fall.\n#&gt; ... and 57 more\n\nEn este ejemplo, cols solo contiene números y letras, por lo que no debe preocuparse por los metacaracteres. Pero, en general, siempre que cree patrones a partir de cadenas existentes, es aconsejable ejecutarlos a través de str_escape() para asegurarse de que coincidan literalmente.\n\n16.6.4 Ejercicios\n\n\nPara cada uno de los siguientes desafíos, intente resolverlos usando una sola expresión regular y una combinación de múltiples llamadas str_detect().\n\nEncuentra todas las palabras que comienzan o terminan con x.\nEncuentra todas las palabras que comienzan con una vocal y terminan con una consonante.\n¿Hay alguna palabra que contenga al menos una de cada vocal diferente?\n\n\n¿Construye patrones para encontrar evidencia a favor y en contra de la regla “i antes de e excepto después de c”?\ncolors() contiene una serie de modificadores como “lightgray” y “darkblue”. ¿Cómo podría identificar automáticamente estos modificadores? (Piense en cómo podría detectar y luego eliminar los colores que se modifican).\nCree una expresión regular que encuentre cualquier conjunto de datos base de R. Puede obtener una lista de estos conjuntos de datos mediante un uso especial de la función data(): data(package = \"datasets\")$results[, \"Item\"]. Tenga en cuenta que varios conjuntos de datos antiguos son vectores individuales; estos contienen el nombre del “data frame” de agrupación entre paréntesis, por lo que deberá eliminarlos.",
    "crumbs": [
      "Transformar",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Expresiones regulares</span>"
    ]
  },
  {
    "objectID": "regexps.html#expresiones-regulares-en-otros-lugares",
    "href": "regexps.html#expresiones-regulares-en-otros-lugares",
    "title": "16  Expresiones regulares",
    "section": "\n16.7 Expresiones regulares en otros lugares",
    "text": "16.7 Expresiones regulares en otros lugares\nAl igual que en las funciones stringr y tidyr, hay muchos otros lugares en R donde puede usar expresiones regulares. Las siguientes secciones describen algunas otras funciones útiles en el tidyverse más amplio y la base R.\n\n16.7.1 tidyverse\nHay otros tres lugares particularmente útiles en los que es posible que desee utilizar expresiones regulares\n\nmatches(pattern) seleccionará todas las variables cuyo nombre coincida con el patrón proporcionado. Es una función “tidyselect” que puede usar en cualquier lugar en cualquier función tidyverse que seleccione variables (p.ej., select(), rename_with() y across()).\npivot_longer()'s names_pattern aargumento toma un vector de expresiones regulares, al igual que separate_wider_regex(). Es útil cuando se extraen datos de nombres de variables con una estructura compleja.\nEl argumento delim en separate_longer_delim() y separate_wider_delim() generalmente coincide con una cadena fija, pero puede usar regex() para que coincida con un patrón. Esto es útil, por ejemplo, si desea hacer coincidir una coma seguida opcionalmente por un espacio, es decir, regex(\", ?\").\n\n16.7.2 R base\napropos(pattern) busca todos los objetos disponibles del entorno global que coincidan con el patrón dado. Esto es útil si no puede recordar el nombre de una función:\n\napropos(\"replace\")\n#&gt; [1] \"%+replace%\"       \"replace\"          \"replace_na\"      \n#&gt; [4] \"setReplaceMethod\" \"str_replace\"      \"str_replace_all\" \n#&gt; [7] \"str_replace_na\"   \"theme_replace\"\n\nlist.files(path, pattern) enumera todos los archivos en path que coinciden con una expresión regular pattern. Por ejemplo, puede encontrar todos los archivos R Markdown en el directorio actual con:\n\nhead(list.files(pattern = \"\\\\.Rmd$\"))\n#&gt; character(0)\n\nVale la pena señalar que el lenguaje de patrones usado por base R es ligeramente diferente al usado por stringr. Esto se debe a que stringr está construido sobre el paquete stringi, que a su vez está construido sobre el motor ICU, mientras que las funciones básicas de R usan el motor TRE o el motor PCRE, dependiendo de si ha establecido o no perl = TRUE. Afortunadamente, los conceptos básicos de las expresiones regulares están tan bien establecidos que encontrará pocas variaciones cuando trabaje con los patrones que aprenderá en este libro. Solo debe ser consciente de la diferencia cuando comience a confiar en funciones avanzadas como rangos de caracteres Unicode complejos o funciones especiales que usan la sintaxis (?…).",
    "crumbs": [
      "Transformar",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Expresiones regulares</span>"
    ]
  },
  {
    "objectID": "regexps.html#resumen",
    "href": "regexps.html#resumen",
    "title": "16  Expresiones regulares",
    "section": "\n16.8 Resumen",
    "text": "16.8 Resumen\nCon cada carácter de puntuación potencialmente sobrecargado de significado, las expresiones regulares son uno de los lenguajes más compactos que existen. Definitivamente son confusos al principio, pero a medida que entrenas tus ojos para leerlos y tu cerebro para entenderlos, desbloqueas una habilidad poderosa que puedes usar en R y en muchos otros lugares.\nEn este capítulo, ha comenzado su viaje para convertirse en un maestro de las expresiones regulares aprendiendo las funciones más útiles de stringr y los componentes más importantes del lenguaje de expresiones regulares. Y hay muchos recursos para aprender más.\nUn buen lugar para comenzar es vignette(\"regular-expressions\", package = \"stringr\"): documenta el conjunto completo de sintaxis compatible con stringr. Otra referencia útil es https://www.regular-expressions.info/. No es específico de R, pero puede usarlo para conocer las características más avanzadas de las expresiones regulares y cómo funcionan bajo el capó.\nTambién es bueno saber que stringr está implementado sobre el paquete stringi por Marek Gagolewski. Si tiene dificultades para encontrar una función que haga lo que necesita en stringr, no tenga miedo de buscar en stringi. Encontrará que stringi es muy fácil de aprender porque sigue muchas de las mismas convenciones que stringr.\nEn el próximo capítulo, hablaremos sobre una estructura de datos estrechamente relacionada con las cadenas: los factores. Los factores se utilizan para representar datos categóricos en R, es decir, datos con un conjunto fijo y conocido de valores posibles identificados por un vector de cadenas.",
    "crumbs": [
      "Transformar",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Expresiones regulares</span>"
    ]
  },
  {
    "objectID": "regexps.html#footnotes",
    "href": "regexps.html#footnotes",
    "title": "16  Expresiones regulares",
    "section": "",
    "text": "Puede pronunciarlo con una g dura (reg-x) o una g suave (rej-x).↩︎\nAprenderá cómo escapar de estos significados especiales en Sección 16.4.1.↩︎\nBueno, cualquier carácter aparte de \\n.↩︎\nEsto nos da la proporción de nombres que contienen una “x”; si quisiera la proporción de bebés con un nombre que contiene una x, necesitaría realizar una media ponderada.↩︎\nDesearíamos poder asegurarle que nunca verá algo tan extraño en la vida real, pero desafortunadamente en el transcurso de su carrera es probable que vea cosas mucho más extrañas.↩︎\nEl conjunto completo de metacaracteres es .^$\\|*+?{}[]()↩︎\nRecuerde, para crear una expresión regular que contenga \\d o \\s, deberá escapar del \\ para la cadena, por lo que escribirá \"\\\\d\" o \"\\\\s \".↩︎\ncomments = TRUE es particularmente efectivo en combinación con una cadena sin procesar, como la que usamos aquí.↩︎\ncomments = TRUE es particularmente efectivo en combinación con una cadena sin procesar, como la que usamos aquí.↩︎",
    "crumbs": [
      "Transformar",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Expresiones regulares</span>"
    ]
  },
  {
    "objectID": "datetimes.html#footnotes",
    "href": "datetimes.html#footnotes",
    "title": "18  Fechas y horas",
    "section": "",
    "text": "Un año es bisiesto si es divisible por 4, a menos que también sea divisible por 100, excepto si también es divisible por 400. En otras palabras, en cada conjunto de 400 años, hay 97 años bisiestos.↩︎\nhttps://xkcd.com/1179/↩︎\nQuizás se pregunte qué significa UTC. Es un compromiso entre el “Coordinated Universal Time” inglés y el “Temps Universel Coordonné” francés.↩︎\nNo hay premios por adivinar a qué país se le ocurrió el sistema de longitud.↩︎"
  },
  {
    "objectID": "joins.html#sec-non-equi-joins",
    "href": "joins.html#sec-non-equi-joins",
    "title": "20  Uniones",
    "section": "\n20.5 Non-equi joins",
    "text": "20.5 Non-equi joins\nHasta ahora solo has visto uniones de igualdad, uniones donde las filas coinciden si la tecla x es igual a la tecla y. Ahora relajaremos esa restricción y analizaremos otras formas de determinar si un par de filas coinciden.\nPero antes de que podamos hacer eso, debemos revisar una simplificación que hicimos anteriormente. En equi-joins, las teclas x e y son siempre iguales, por lo que solo necesitamos mostrar una en la salida. Podemos solicitar que dplyr mantenga ambas claves con keep = TRUE, lo que lleva al siguiente código y inner_join() redibujado en Figura 20.12.\n\nx |&gt; inner_join(y, join_by(key == key), keep = TRUE)\n#&gt; # A tibble: 2 × 4\n#&gt;   key.x val_x key.y val_y\n#&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;\n#&gt; 1     1 x1        1 y1   \n#&gt; 2     2 x2        2 y2\n\n\n\n\n\nFigura 20.12: Una combinación interna que muestra x e y en la salida.\n\n\n\nCuando nos alejamos de las combinaciones de igualdad, siempre mostraremos las claves, porque los valores de las claves a menudo serán diferentes. Por ejemplo, en lugar de hacer coincidir solo cuando la x$key y la y$key son iguales, podríamos hacer coincidir siempre que la x$key sea mayor o igual que la y$key, lo que lleva a Figura 20.13. Las funciones de combinación de dplyr entienden esta distinción entre combinaciones equi y no equi, por lo que siempre mostrará ambas teclas cuando realice una combinación no equi.\n\n\n\n\nFigura 20.13: Una combinación no equitativa en la que la tecla x debe ser mayor o igual que la tecla y. Muchas filas generan múltiples coincidencias.\n\n\n\nUnión no equitativa no es un término particularmente útil porque solo le dice qué no es la unión, no qué es. dplyr ayuda identificando cuatro tipos particularmente útiles de unión no equitativa:\n\n\nUniones cruzadas coinciden con cada par de filas.\n\nUniones de desigualdad use &lt;, &lt;=, &gt; y &gt;= en lugar de ==.\n\nLas uniones continuas son similares a las uniones de desigualdad, pero solo encuentran la coincidencia más cercana.\n\nLas uniones superpuestas son un tipo especial de unión de desigualdades diseñadas para trabajar con rangos.\n\nCada uno de estos se describe con más detalle en las siguientes secciones.\n\n20.5.1 Uniones cruzadas\nUna unión cruzada coincide con todo, como en Figura 20.14, generando el producto cartesiano de filas. Esto significa que la salida tendrá filas nrow(x) * nrow(y).\n\n\n\n\nFigura 20.14: Una combinación cruzada hace coincidir cada fila en x con cada fila en y.\n\n\n\nLas uniones cruzadas son útiles cuando se generan permutaciones. Por ejemplo, el siguiente código genera todos los pares de nombres posibles. Dado que estamos uniendo df a sí mismo, esto a veces se denomina autounión. Las uniones cruzadas usan una función de unión diferente porque no hay distinción entre inner/left/right/full cuando estás haciendo coincidir cada fila.\n\ndf &lt;- tibble(name = c(\"John\", \"Simon\", \"Tracy\", \"Max\"))\ndf |&gt; cross_join(df)\n#&gt; # A tibble: 16 × 2\n#&gt;   name.x name.y\n#&gt;   &lt;chr&gt;  &lt;chr&gt; \n#&gt; 1 John   John  \n#&gt; 2 John   Simon \n#&gt; 3 John   Tracy \n#&gt; 4 John   Max   \n#&gt; 5 Simon  John  \n#&gt; 6 Simon  Simon \n#&gt; # ℹ 10 more rows\n\n\n20.5.2 Uniones de desigualdad\nLas uniones de desigualdad usan &lt;, &lt;=, &gt;= o &gt; para restringir el conjunto de posibles coincidencias, como en Figura 20.13 y Figura 20.15.\n\n\n\n\nFigura 20.15: Una unión de desigualdad donde ‘x’ se une a ‘y’ en filas donde la clave de ‘x’ es menor que la clave de ‘y’. Esto crea una forma triangular en la esquina superior izquierda. fig-alt: | Un diagrama que representa una unión de desigualdad donde un marco de datos x se une a un marco de datos y donde la clave de x es menor que la clave de y, lo que da como resultado una forma triangular en la esquina superior izquierda.\n\n\n\nLas uniones de desigualdad son extremadamente generales, tan generales que es difícil encontrar casos de uso específicos significativos. Una pequeña técnica útil es usarlos para restringir la unión cruzada de modo que, en lugar de generar todas las permutaciones, generemos todas las combinaciones:\n\ndf &lt;- tibble(id = 1:4, name = c(\"John\", \"Simon\", \"Tracy\", \"Max\"))\n\ndf |&gt; inner_join(df, join_by(id &lt; id))\n#&gt; # A tibble: 6 × 4\n#&gt;    id.x name.x  id.y name.y\n#&gt;   &lt;int&gt; &lt;chr&gt;  &lt;int&gt; &lt;chr&gt; \n#&gt; 1     1 John       2 Simon \n#&gt; 2     1 John       3 Tracy \n#&gt; 3     1 John       4 Max   \n#&gt; 4     2 Simon      3 Tracy \n#&gt; 5     2 Simon      4 Max   \n#&gt; 6     3 Tracy      4 Max\n\n\n20.5.3 Uniones rodantes\nLas combinaciones rotativas son un tipo especial de combinación de desigualdad donde en lugar de obtener todas las filas que satisfacen la desigualdad, obtienes solo la fila más cercana, como en Figura 20.16. Puede convertir cualquier combinación de desigualdad en una combinación continua agregando closest(). Por ejemplo, join_by(closest(x &lt;= y)) coincide con la y más pequeña que es mayor o igual que x, y join_by(closest(x &gt; y)) coincide con la y más grande que es menor que x.\n\n\n\n\nFigura 20.16: Una unión continua es similar a una unión de desigualdad mayor o igual, pero solo coincide con el primer valor.\n\n\n\nLas uniones rotativas son particularmente útiles cuando tiene dos tablas de fechas que no se alinean perfectamente y desea encontrar (por ejemplo) la fecha más cercana en la tabla 1 que viene antes (o después) de alguna fecha en la tabla 2.\nPor ejemplo, imagina que estás a cargo de la comisión de planificación de fiestas de tu oficina. Su empresa es bastante barata, por lo que en lugar de tener fiestas individuales, solo tiene una fiesta una vez cada trimestre. Las reglas para determinar cuándo se realizará una fiesta son un poco complejas: las fiestas siempre son los lunes, te saltas la primera semana de enero porque mucha gente está de vacaciones y el primer lunes del tercer trimestre de 2022 es el 4 de julio, por lo que eso tiene que ser retrasado una semana. Eso lleva a los siguientes días de fiesta:\n\nparties &lt;- tibble(\n  q = 1:4,\n  party = ymd(c(\"2022-01-10\", \"2022-04-04\", \"2022-07-11\", \"2022-10-03\"))\n)\n\nAhora imagina que tienes una tabla de cumpleaños de los empleados:\n\nset.seed(123)\nemployees &lt;- tibble(\n  name = sample(babynames::babynames$name, 100),\n  birthday = ymd(\"2022-01-01\") + (sample(365, 100, replace = TRUE) - 1)\n)\nemployees\n#&gt; # A tibble: 100 × 2\n#&gt;   name     birthday  \n#&gt;   &lt;chr&gt;    &lt;date&gt;    \n#&gt; 1 Kemba    2022-01-22\n#&gt; 2 Orean    2022-06-26\n#&gt; 3 Kirstyn  2022-02-11\n#&gt; 4 Amparo   2022-11-11\n#&gt; 5 Belen    2022-03-25\n#&gt; 6 Rayshaun 2022-01-11\n#&gt; # ℹ 94 more rows\n\nY para cada empleado queremos encontrar la fecha de la primera fiesta que viene después (o en) su cumpleaños. Podemos expresar eso con una unión rodante:\n\nemployees |&gt; \n  left_join(parties, join_by(closest(birthday &gt;= party)))\n#&gt; # A tibble: 100 × 4\n#&gt;   name     birthday       q party     \n#&gt;   &lt;chr&gt;    &lt;date&gt;     &lt;int&gt; &lt;date&gt;    \n#&gt; 1 Kemba    2022-01-22     1 2022-01-10\n#&gt; 2 Orean    2022-06-26     2 2022-04-04\n#&gt; 3 Kirstyn  2022-02-11     1 2022-01-10\n#&gt; 4 Amparo   2022-11-11     4 2022-10-03\n#&gt; 5 Belen    2022-03-25     1 2022-01-10\n#&gt; 6 Rayshaun 2022-01-11     1 2022-01-10\n#&gt; # ℹ 94 more rows\n\nSin embargo, hay un problema con este enfoque: las personas que cumplen años antes del 10 de enero no organizan una fiesta:\n\nemployees |&gt; \n  anti_join(parties, join_by(closest(birthday &gt;= party)))\n#&gt; # A tibble: 2 × 2\n#&gt;   name   birthday  \n#&gt;   &lt;chr&gt;  &lt;date&gt;    \n#&gt; 1 Maks   2022-01-07\n#&gt; 2 Nalani 2022-01-04\n\nPara resolver ese problema, necesitaremos abordar el problema de una manera diferente, con uniones superpuestas.\n\n20.5.4 Uniones superpuestas\nLas uniones superpuestas proporcionan tres ayudantes que usan uniones de desigualdad para facilitar el trabajo con intervalos:\n\n\nbetween(x, y_lower, y_upper) es abreviatura para x &gt;= y_lower, x &lt;= y_upper.\n\nwithin(x_lower, x_upper, y_lower, y_upper) es abreviatura para x_lower &gt;= y_lower, x_upper &lt;= y_upper.\n\noverlaps(x_lower, x_upper, y_lower, y_upper) es abreviatura para x_lower &lt;= y_upper, x_upper &gt;= y_lower.\n\nSigamos con el ejemplo del cumpleaños para ver cómo podría usarlos. Hay un problema con la estrategia que usamos anteriormente: no hay fiesta antes de los cumpleaños del 1 al 9 de enero. Por lo tanto, sería mejor ser explícito sobre los rangos de fechas que abarca cada fiesta y hacer un caso especial para esos cumpleaños anticipados:\n\nparties &lt;- tibble(\n  q = 1:4,\n  party = ymd(c(\"2022-01-10\", \"2022-04-04\", \"2022-07-11\", \"2022-10-03\")),\n  start = ymd(c(\"2022-01-01\", \"2022-04-04\", \"2022-07-11\", \"2022-10-03\")),\n  end = ymd(c(\"2022-04-03\", \"2022-07-11\", \"2022-10-02\", \"2022-12-31\"))\n)\nparties\n#&gt; # A tibble: 4 × 4\n#&gt;       q party      start      end       \n#&gt;   &lt;int&gt; &lt;date&gt;     &lt;date&gt;     &lt;date&gt;    \n#&gt; 1     1 2022-01-10 2022-01-01 2022-04-03\n#&gt; 2     2 2022-04-04 2022-04-04 2022-07-11\n#&gt; 3     3 2022-07-11 2022-07-11 2022-10-02\n#&gt; 4     4 2022-10-03 2022-10-03 2022-12-31\n\nHadley es terriblemente malo ingresando datos, por lo que también quería verificar que los períodos de las fiestas no se superpusieran. Una forma de hacer esto es usar una autounión para verificar si algún intervalo de inicio-fin se superpone con otro:\n\nparties |&gt; \n  inner_join(parties, join_by(overlaps(start, end, start, end), q &lt; q)) |&gt; \n  select(start.x, end.x, start.y, end.y)\n#&gt; # A tibble: 1 × 4\n#&gt;   start.x    end.x      start.y    end.y     \n#&gt;   &lt;date&gt;     &lt;date&gt;     &lt;date&gt;     &lt;date&gt;    \n#&gt; 1 2022-04-04 2022-07-11 2022-07-11 2022-10-02\n\nVaya, hay una superposición, así que solucionemos ese problema y continuemos:\n\nparties &lt;- tibble(\n  q = 1:4,\n  party = ymd(c(\"2022-01-10\", \"2022-04-04\", \"2022-07-11\", \"2022-10-03\")),\n  start = ymd(c(\"2022-01-01\", \"2022-04-04\", \"2022-07-11\", \"2022-10-03\")),\n  end = ymd(c(\"2022-04-03\", \"2022-07-10\", \"2022-10-02\", \"2022-12-31\"))\n)\n\nAhora podemos emparejar a cada empleado con su partido. Este es un buen lugar para usar unmatched = \"error\" porque queremos averiguar rápidamente si a algún empleado no se le asignó una fiesta.\n\nemployees |&gt; \n  inner_join(parties, join_by(between(birthday, start, end)), unmatched = \"error\")\n#&gt; # A tibble: 100 × 6\n#&gt;   name     birthday       q party      start      end       \n#&gt;   &lt;chr&gt;    &lt;date&gt;     &lt;int&gt; &lt;date&gt;     &lt;date&gt;     &lt;date&gt;    \n#&gt; 1 Kemba    2022-01-22     1 2022-01-10 2022-01-01 2022-04-03\n#&gt; 2 Orean    2022-06-26     2 2022-04-04 2022-04-04 2022-07-10\n#&gt; 3 Kirstyn  2022-02-11     1 2022-01-10 2022-01-01 2022-04-03\n#&gt; 4 Amparo   2022-11-11     4 2022-10-03 2022-10-03 2022-12-31\n#&gt; 5 Belen    2022-03-25     1 2022-01-10 2022-01-01 2022-04-03\n#&gt; 6 Rayshaun 2022-01-11     1 2022-01-10 2022-01-01 2022-04-03\n#&gt; # ℹ 94 more rows\n\n\n20.5.5 Ejercicios\n\n\n¿Puedes explicar qué está pasando con las claves en esta unión equitativa? ¿Por qué son diferentes?\n\nx |&gt; full_join(y, join_by(key == key))\n#&gt; # A tibble: 4 × 3\n#&gt;     key val_x val_y\n#&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;\n#&gt; 1     1 x1    y1   \n#&gt; 2     2 x2    y2   \n#&gt; 3     3 x3    &lt;NA&gt; \n#&gt; 4     4 &lt;NA&gt;  y3\n\nx |&gt; full_join(y, join_by(key == key), keep = TRUE)\n#&gt; # A tibble: 4 × 4\n#&gt;   key.x val_x key.y val_y\n#&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;\n#&gt; 1     1 x1        1 y1   \n#&gt; 2     2 x2        2 y2   \n#&gt; 3     3 x3       NA &lt;NA&gt; \n#&gt; 4    NA &lt;NA&gt;      4 y3\n\n\nAl encontrar si algún período de fiesta se superponía con otro período de fiesta, usamos q &lt; q en join_by () ¿Por qué? ¿Qué pasa si eliminas esta desigualdad?"
  },
  {
    "objectID": "joins.html#footnotes",
    "href": "joins.html#footnotes",
    "title": "20  Uniones",
    "section": "",
    "text": "Recuerda que en RStudio también puedes usar View() para evitar este problema.↩︎\nEso no es 100% cierto, pero recibirás una advertencia cuando no lo sea.↩︎"
  },
  {
    "objectID": "databases.html#footnotes",
    "href": "databases.html#footnotes",
    "title": "22  Bases de datos",
    "section": "",
    "text": "SQL es pronunciado “s”-“q”-“l” o “sequel”.↩︎\nPor lo general, esta es la única función que usará del paquete del cliente, por lo que recomendamos usar :: para extraer esa función, en lugar de cargar el paquete completo con library().↩︎\nAl menos, todas las tablas que tiene permiso para ver.↩︎\nDe manera confusa, según el contexto, SELECT es una declaración o una cláusula. Para evitar esta confusión, generalmente usaremos la consulta SELECT en lugar de la instrucción SELECT.↩︎\nOk, técnicamente, solo se requiere SELECT, ya que puedes escribir consultas como SELECT 1+1 para realizar cálculos básicos. Pero si quieres trabajar con datos (¡como siempre lo haces!) también necesitarás una cláusula FROM.↩︎\nEsto no es coincidencia: el nombre de la función dplyr se inspiró en la cláusula SQL.↩︎",
    "crumbs": [
      "Importar",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Bases de datos</span>"
    ]
  },
  {
    "objectID": "functions.html#introducción",
    "href": "functions.html#introducción",
    "title": "26  Funciones",
    "section": "\n26.1 Introducción",
    "text": "26.1 Introducción\nUna de las mejores formas de mejorar su alcance como científico de datos es escribir funciones. Las funciones le permiten automatizar tareas comunes de una manera más potente y general que copiar y pegar. Escribir una función tiene cuatro grandes ventajas sobre el uso de copiar y pegar:\n\nPuede dar a una función un nombre sugerente que haga que su código sea más fácil de entender.\nA medida que cambian los requisitos, solo necesita actualizar el código en un lugar, en lugar de muchos.\nElimina la posibilidad de cometer errores incidentales al copiar y pegar (es decir, actualizar el nombre de una variable en un lugar, pero no en otro).\nHace que sea más fácil reutilizar el trabajo de un proyecto a otro, aumentando su productividad con el tiempo.\n\nUna buena regla general es considerar escribir una función siempre que haya copiado y pegado un bloque de código más de dos veces (es decir, ahora tiene tres copias del mismo código). En este capítulo, aprenderá acerca de tres tipos útiles de funciones:\n\nLas funciones vectoriales toman uno o más vectores como entrada y devuelven un vector como salida.\nLas funciones de marco de datos toman un marco de datos como entrada y devuelven un marco de datos como salida.\nFunciones gráficas que toman un marco de datos como entrada y devuelven un gráfico como salida.\n\nCada una de estas secciones incluye muchos ejemplos para ayudarlo a generalizar los patrones que ve. Estos ejemplos no serían posibles sin la ayuda de la gente de Twitter, y le recomendamos que siga los enlaces en el comentario para ver inspiraciones originales. También puede leer los tweets motivadores originales para funciones generales y funciones de gráficas para ver aún más funciones.\n\n26.1.1 Requisitos previos\nAgruparemos una variedad de funciones de todo el tidyverse. También usaremos nycflights13 como fuente de datos familiares para usar nuestras funciones.\n\nlibrary(tidyverse)\nlibrary(nycflights13)"
  },
  {
    "objectID": "functions.html#funciones-vectoriales",
    "href": "functions.html#funciones-vectoriales",
    "title": "26  Funciones",
    "section": "\n26.2 Funciones vectoriales",
    "text": "26.2 Funciones vectoriales\nComenzaremos con las funciones vectoriales: funciones que toman uno o más vectores y devuelven un resultado vectorial. Por ejemplo, eche un vistazo a este código. ¿Qué hace?\n\ndf &lt;- tibble(\n  a = rnorm(5),\n  b = rnorm(5),\n  c = rnorm(5),\n  d = rnorm(5),\n)\n\ndf |&gt; mutate(\n  a = (a - min(a, na.rm = TRUE)) / \n    (max(a, na.rm = TRUE) - min(a, na.rm = TRUE)),\n  b = (b - min(b, na.rm = TRUE)) / \n    (max(b, na.rm = TRUE) - min(a, na.rm = TRUE)),\n  c = (c - min(c, na.rm = TRUE)) / \n    (max(c, na.rm = TRUE) - min(c, na.rm = TRUE)),\n  d = (d - min(d, na.rm = TRUE)) / \n    (max(d, na.rm = TRUE) - min(d, na.rm = TRUE)),\n)\n#&gt; # A tibble: 5 × 4\n#&gt;       a     b     c     d\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 0.339  2.59 0.291 0    \n#&gt; 2 0.880  0    0.611 0.557\n#&gt; 3 0      1.37 1     0.752\n#&gt; 4 0.795  1.37 0     1    \n#&gt; 5 1      1.34 0.580 0.394\n\nEs posible que pueda descifrar que esto cambia la escala de cada columna para tener un rango de 0 a 1. Pero, ¿viste el error? Cuando Hadley escribió este código, cometió un error al copiar y pegar y olvidó cambiar una a por una b. Prevenir este tipo de error es una muy buena razón para aprender a escribir funciones.\n\n26.2.1 Escribiendo una función\nPara escribir una función, primero debe analizar su código repetido para determinar qué partes son constantes y qué partes varían. Si tomamos el código anterior y lo extraemos de mutate(), es un poco más fácil ver el patrón porque cada repetición ahora es una línea:\n\n(a - min(a, na.rm = TRUE)) / (max(a, na.rm = TRUE) - min(a, na.rm = TRUE))\n(b - min(b, na.rm = TRUE)) / (max(b, na.rm = TRUE) - min(b, na.rm = TRUE))\n(c - min(c, na.rm = TRUE)) / (max(c, na.rm = TRUE) - min(c, na.rm = TRUE))\n(d - min(d, na.rm = TRUE)) / (max(d, na.rm = TRUE) - min(d, na.rm = TRUE))  \n\nPara hacer esto un poco más claro, podemos reemplazar el bit que varía con █:\n\n(█ - min(█, na.rm = TRUE)) / (max(█, na.rm = TRUE) - min(█, na.rm = TRUE))\n\nPara convertir esto en una función necesitas tres cosas:\n\nUn nombre. Aquí usaremos rescale01 porque esta función cambia la escala de un vector para que esté entre 0 y 1.\nLos argumentos. Los argumentos son cosas que varían según las llamadas y nuestro análisis anterior nos dice que solo tenemos uno. Lo llamaremos x porque este es el nombre convencional para un vector numérico.\nEl cuerpo**. El cuerpo es el código que se repite en todas las llamadas.\n\nLuego creas una función siguiendo la plantilla:\n\nname &lt;- function(arguments) {\n  body\n}\n\nPara este caso que conduce a:\n\nrescale01 &lt;- function(x) {\n  (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))\n}\n\nEn este punto, puede probar con algunas entradas simples para asegurarse de haber capturado la lógica correctamente:\n\nrescale01(c(-10, 0, 10))\n#&gt; [1] 0.0 0.5 1.0\nrescale01(c(1, 2, 3, NA, 5))\n#&gt; [1] 0.00 0.25 0.50   NA 1.00\n\nEntonces puedes reescribir la llamada a mutate() como:\n\ndf |&gt; mutate(\n  a = rescale01(a),\n  b = rescale01(b),\n  c = rescale01(c),\n  d = rescale01(d),\n)\n#&gt; # A tibble: 5 × 4\n#&gt;       a     b     c     d\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 0.339 1     0.291 0    \n#&gt; 2 0.880 0     0.611 0.557\n#&gt; 3 0     0.530 1     0.752\n#&gt; 4 0.795 0.531 0     1    \n#&gt; 5 1     0.518 0.580 0.394\n\n(En Capítulo 27, aprenderá a usar across() para reducir aún más la duplicación, por lo que todo lo que necesita es df |&gt; mutate(across(a:d, rescale01))).\n\n26.2.2 Mejorando nuestra función\nPuede notar que la función rescale01() hace un trabajo innecesario — en lugar de calcular min() dos veces y max() una vez, podríamos calcular tanto el mínimo como el máximo en un solo paso con range( ):\n\nrescale01 &lt;- function(x) {\n  rng &lt;- range(x, na.rm = TRUE)\n  (x - rng[1]) / (rng[2] - rng[1])\n}\n\nO puede probar esta función en un vector que incluye un valor infinito:\n\nx &lt;- c(1:10, Inf)\nrescale01(x)\n#&gt;  [1]   0   0   0   0   0   0   0   0   0   0 NaN\n\nEse resultado no es particularmente útil, por lo que podríamos pedirle a range() que ignore valores infinitos:\n\nrescale01 &lt;- function(x) {\n  rng &lt;- range(x, na.rm = TRUE, finite = TRUE)\n  (x - rng[1]) / (rng[2] - rng[1])\n}\n\nrescale01(x)\n#&gt;  [1] 0.0000000 0.1111111 0.2222222 0.3333333 0.4444444 0.5555556 0.6666667\n#&gt;  [8] 0.7777778 0.8888889 1.0000000       Inf\n\nEstos cambios ilustran un beneficio importante de las funciones: debido a que hemos movido el código repetido a una función, solo necesitamos hacer el cambio en un lugar.\n\n26.2.3 Funciones mutate\nAhora que tienes la idea básica de las funciones, echemos un vistazo a un montón de ejemplos. Comenzaremos mirando las funciones de “mutate”, es decir, funciones que funcionan bien dentro de mutate() y filter() porque devuelven una salida de la misma longitud que la entrada.\nComencemos con una variación simple de rescale01(). Tal vez quiera calcular el puntaje Z, reescalar un vector para que tenga una media de cero y una desviación estándar de uno:\n\nz_score &lt;- function(x) {\n  (x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE)\n}\n\nO tal vez quieras terminar un case_when() sencillo y darle un nombre útil. Por ejemplo, esta función clamp() asegura que todos los valores de un vector se encuentran entre un mínimo o un máximo:\n\nclamp &lt;- function(x, min, max) {\n  case_when(\n    x &lt; min ~ min,\n    x &gt; max ~ max,\n    .default = x\n  )\n}\n\nclamp(1:10, min = 3, max = 7)\n#&gt;  [1] 3 3 3 4 5 6 7 7 7 7\n\nPor supuesto, las funciones no solo necesitan trabajar con variables numéricas. Es posible que desee realizar una manipulación repetida de cadenas. Tal vez necesites hacer el primer carácter en mayúsculas:\n\nfirst_upper &lt;- function(x) {\n  str_sub(x, 1, 1) &lt;- str_to_upper(str_sub(x, 1, 1))\n  x\n}\n\nfirst_upper(\"hello\")\n#&gt; [1] \"Hello\"\n\nO tal vez desee eliminar los signos de porcentaje, las comas y los signos de dólar de una cadena antes de convertirla en un número:\n\n# https://twitter.com/NVlabormarket/status/1571939851922198530\nclean_number &lt;- function(x) {\n  is_pct &lt;- str_detect(x, \"%\")\n  num &lt;- x |&gt; \n    str_remove_all(\"%\") |&gt; \n    str_remove_all(\",\") |&gt; \n    str_remove_all(fixed(\"$\")) |&gt; \n    as.numeric()\n  if_else(is_pct, num / 100, num)\n}\n\nclean_number(\"$12,300\")\n#&gt; [1] 12300\nclean_number(\"45%\")\n#&gt; [1] 0.45\n\nA veces, sus funciones estarán altamente especializadas para un paso de análisis de datos. Por ejemplo, si tiene un montón de variables que registran valores faltantes como 997, 998 o 999, puede escribir una función para reemplazarlos con NA:\n\nfix_na &lt;- function(x) {\n  if_else(x %in% c(997, 998, 999), NA, x)\n}\n\nNos hemos centrado en ejemplos que toman un solo vector porque creemos que son los más comunes. Pero no hay razón para que su función no pueda tomar múltiples entradas de vectores.\n\n26.2.4 Funciones summary\nOtra familia importante de funciones vectoriales son las funciones de resumen, funciones que devuelven un único valor para usar en summarize(). A veces, esto puede ser simplemente una cuestión de establecer uno o dos argumentos predeterminados:\n\ncommas &lt;- function(x) {\n  str_flatten(x, collapse = \", \", last = \" and \")\n}\n\ncommas(c(\"cat\", \"dog\", \"pigeon\"))\n#&gt; [1] \"cat, dog and pigeon\"\n\nO podría terminar un cálculo simple, como el coeficiente de variación, que divide la desviación estándar por la media:\n\ncv &lt;- function(x, na.rm = FALSE) {\n  sd(x, na.rm = na.rm) / mean(x, na.rm = na.rm)\n}\n\ncv(runif(100, min = 0, max = 50))\n#&gt; [1] 0.5196276\ncv(runif(100, min = 0, max = 500))\n#&gt; [1] 0.5652554\n\nO tal vez solo quiera hacer que un patrón común sea más fácil de recordar dándole un nombre fácil de recordar:\n\n# https://twitter.com/gbganalyst/status/1571619641390252033\nn_missing &lt;- function(x) {\n  sum(is.na(x))\n} \n\nTambién puede escribir funciones con múltiples entradas vectoriales. Por ejemplo, tal vez desee calcular el error de predicción absoluto medio para ayudarlo a comparar las predicciones del modelo con los valores reales:\n\n# https://twitter.com/neilgcurrie/status/1571607727255834625\nmape &lt;- function(actual, predicted) {\n  sum(abs((actual - predicted) / actual)) / length(actual)\n}\n\n\n\n\n\n\n\nRStudio\n\n\n\nUna vez que comience a escribir funciones, hay dos accesos directos de RStudio que son muy útiles:\n\nPara encontrar la definición de una función que hayas escrito, coloca el cursor sobre el nombre de la función y presiona F2.\nPara saltar rápidamente a una función, presione Ctrl + . para abrir el archivo difuso y el buscador de funciones y escriba las primeras letras del nombre de su función. También puede navegar a archivos, secciones en Quarto y más, lo que la convierte en una herramienta de navegación muy útil.\n\n\n\n\n26.2.5 Ejercicios\n\n\nPractique convertir los siguientes fragmentos de código en funciones. Piensa en lo que hace cada función. ¿Como lo llamarias? ¿Cuántos argumentos necesita?\n\nmean(is.na(x))\nmean(is.na(y))\nmean(is.na(z))\n\nx / sum(x, na.rm = TRUE)\ny / sum(y, na.rm = TRUE)\nz / sum(z, na.rm = TRUE)\n\nround(x / sum(x, na.rm = TRUE) * 100, 1)\nround(y / sum(y, na.rm = TRUE) * 100, 1)\nround(z / sum(z, na.rm = TRUE) * 100, 1)\n\n\nEn la segunda variante de rescale01(), los valores infinitos se dejan sin cambios. ¿Puedes reescribir rescale01() para que -Inf se asigne a 0 e Inf se asigne a 1?\nDado un vector de fechas de nacimiento, escribe una función para calcular la edad en años.\nEscriba sus propias funciones para calcular la varianza y la asimetría de un vector numérico. Puede buscar las definiciones en Wikipedia o en otro lugar.\nEscriba both_na(), una función de resumen que toma dos vectores de la misma longitud y devuelve el número de posiciones que tienen un NA en ambos vectores.\n\nLea la documentación para averiguar qué hacen las siguientes funciones. ¿Por qué son útiles a pesar de que son tan cortos?\n\nis_directory &lt;- function(x) {\n  file.info(x)$isdir\n}\nis_readable &lt;- function(x) {\n  file.access(x, 4) == 0\n}"
  },
  {
    "objectID": "functions.html#funciones-de-data-frame",
    "href": "functions.html#funciones-de-data-frame",
    "title": "26  Funciones",
    "section": "\n26.3 Funciones de data frame",
    "text": "26.3 Funciones de data frame\nLas funciones vectoriales son útiles para extraer código que se repite dentro de un verbo dplyr. Pero a menudo también repetirá los verbos, particularmente dentro de un pipe grande. Cuando se dé cuenta de que está copiando y pegando varios verbos varias veces, podría pensar en escribir una función de data frame. Las funciones de data frame funcionan como los verbos dplyr: toman un data frame como primer argumento, algunos argumentos adicionales que dicen qué hacer con él y devuelven un data frame o un vector.\nPara permitirle escribir una función que use verbos dplyr, primero le presentaremos el desafío de la indirección y cómo puede superarlo abrazando, {{ }}. Con esta teoría en su haber, le mostraremos un montón de ejemplos para ilustrar lo que podría hacer con ella.\n\n26.3.1 Evaluación indirecta y ordenada\nCuando comienza a escribir funciones que usan verbos dplyr, rápidamente se encuentra con el problema de la indirección. Ilustremos el problema con una función muy simple: grouped_mean(). El objetivo de esta función es calcular la media de mean_var agrupada por group_var:\n\ngrouped_mean &lt;- function(df, group_var, mean_var) {\n  df |&gt; \n    group_by(group_var) |&gt; \n    summarize(mean(mean_var))\n}\n\nSi lo intentamos y lo usamos, obtenemos un error:\n\ndiamonds |&gt; grouped_mean(cut, carat)\n#&gt; Error in `group_by()`:\n#&gt; ! Must group by variables found in `.data`.\n#&gt; ✖ Column `group_var` is not found.\n\nPara hacer el problema un poco más claro, podemos usar un marco de datos inventado:\n\ndf &lt;- tibble(\n  mean_var = 1,\n  group_var = \"g\",\n  group = 1,\n  x = 10,\n  y = 100\n)\n\ndf |&gt; grouped_mean(group, x)\n#&gt; # A tibble: 1 × 2\n#&gt;   group_var `mean(mean_var)`\n#&gt;   &lt;chr&gt;                &lt;dbl&gt;\n#&gt; 1 g                        1\ndf |&gt; grouped_mean(group, y)\n#&gt; # A tibble: 1 × 2\n#&gt;   group_var `mean(mean_var)`\n#&gt;   &lt;chr&gt;                &lt;dbl&gt;\n#&gt; 1 g                        1\n\nIndependientemente de cómo llamemos a grouped_mean(), siempre hace df |&gt; group_by(group_var) |&gt; resume(mean(mean_var)), en lugar de df |&gt; group_by(group) |&gt; resume(mean(x) ) o df |&gt; group_by(group) |&gt; resume(mean(y)). Este es un problema de direccionamiento indirecto, y surge porque dplyr usa evaluación ordenada para permitirle referirse a los nombres de las variables dentro de su marco de datos sin ningún tratamiento especial.\nLa evaluación ordenada es excelente el 95% de las veces porque hace que sus análisis de datos sean muy concisos, ya que nunca tiene que decir de qué marco de datos proviene una variable; es obvio por el contexto. La desventaja de la evaluación ordenada surge cuando queremos envolver el código tidyverse repetido en una función. Aquí necesitamos alguna forma de decirle a group_mean() y summarize() que no traten group_var y mean_var como el nombre de las variables, sino que busquen dentro de ellas la variable que realmente queremos usar.\nLa evaluación ordenada incluye una solución a este problema llamada abrazar 🤗. Abrazar una variable significa envolverla entre llaves para que (por ejemplo) var se convierta en {{ var }}. Abrazar una variable le dice a dplyr que use el valor almacenado dentro del argumento, no el argumento como el nombre literal de la variable. Una forma de recordar lo que está pasando es pensar en {{ }} como mirar hacia abajo en un túnel — {{ var }} hará que una función dplyr mire dentro de var en lugar de buscar una variable llamada var.\nEntonces, para hacer que grouped_mean() funcione, necesitamos rodear group_var y mean_var con {{ }}:\n\ngrouped_mean &lt;- function(df, group_var, mean_var) {\n  df |&gt; \n    group_by({{ group_var }}) |&gt; \n    summarize(mean({{ mean_var }}))\n}\n\ndf |&gt; grouped_mean(group, x)\n#&gt; # A tibble: 1 × 2\n#&gt;   group `mean(x)`\n#&gt;   &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1     1        10\n\n¡Éxito!\n\n26.3.2 ¿Cuándo abrazar?\nEntonces, el desafío clave al escribir funciones de data frame es descubrir qué argumentos deben adoptarse. Afortunadamente, esto es fácil porque puedes buscarlo en la documentación 😄. Hay dos términos para buscar en los documentos que corresponden a los dos subtipos más comunes de evaluación ordenada:\n\nData-masking (Enmascaramiento de datos): esto se usa en funciones como arrange(), filter() y summarize() que calculan con variables.\nTidy-selection (Selección ordenada): esto se usa para funciones como select(), relocate() y rename() que seleccionan variables.\n\nSu intuición sobre qué argumentos usan una evaluación ordenada debería ser buena para muchas funciones comunes — solo piense si puede calcular (por ejemplo, x + 1) o seleccionar (por ejemplo, a:x).\nEn las siguientes secciones, exploraremos los tipos de funciones útiles que podría escribir una vez que comprenda la adopción.\n\n26.3.3 Casos de uso comunes\nSi normalmente realiza el mismo conjunto de resúmenes cuando realiza la exploración inicial de datos, podría considerar incluirlos en una función de ayuda:\n\nsummary6 &lt;- function(data, var) {\n  data |&gt; summarize(\n    min = min({{ var }}, na.rm = TRUE),\n    mean = mean({{ var }}, na.rm = TRUE),\n    median = median({{ var }}, na.rm = TRUE),\n    max = max({{ var }}, na.rm = TRUE),\n    n = n(),\n    n_miss = sum(is.na({{ var }})),\n    .groups = \"drop\"\n  )\n}\n\ndiamonds |&gt; summary6(carat)\n#&gt; # A tibble: 1 × 6\n#&gt;     min  mean median   max     n n_miss\n#&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;  &lt;int&gt;\n#&gt; 1   0.2 0.798    0.7  5.01 53940      0\n\n(Cada vez que envuelve summarize() en un asistente, creemos que es una buena práctica configurar .groups = \"drop\" para evitar el mensaje y dejar los datos en un estado desagrupado).\nLo bueno de esta función es que, debido a que envuelve summarize(), puede usarla en datos agrupados:\n\ndiamonds |&gt; \n  group_by(cut) |&gt; \n  summary6(carat)\n#&gt; # A tibble: 5 × 7\n#&gt;   cut         min  mean median   max     n n_miss\n#&gt;   &lt;ord&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;  &lt;int&gt;\n#&gt; 1 Fair       0.22 1.05    1     5.01  1610      0\n#&gt; 2 Good       0.23 0.849   0.82  3.01  4906      0\n#&gt; 3 Very Good  0.2  0.806   0.71  4    12082      0\n#&gt; 4 Premium    0.2  0.892   0.86  4.01 13791      0\n#&gt; 5 Ideal      0.2  0.703   0.54  3.5  21551      0\n\nAdemás, dado que los argumentos para resumir son un enmascaramiento de datos, también significa que el argumento var para summary6() es un enmascaramiento de datos. Eso significa que también puede resumir las variables calculadas:\n\ndiamonds |&gt; \n  group_by(cut) |&gt; \n  summary6(log10(carat))\n#&gt; # A tibble: 5 × 7\n#&gt;   cut          min    mean  median   max     n n_miss\n#&gt;   &lt;ord&gt;      &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;  &lt;int&gt;\n#&gt; 1 Fair      -0.658 -0.0273  0      0.700  1610      0\n#&gt; 2 Good      -0.638 -0.133  -0.0862 0.479  4906      0\n#&gt; 3 Very Good -0.699 -0.164  -0.149  0.602 12082      0\n#&gt; 4 Premium   -0.699 -0.125  -0.0655 0.603 13791      0\n#&gt; 5 Ideal     -0.699 -0.225  -0.268  0.544 21551      0\n\nPara resumir varias variables, deberá esperar hasta Sección 27.2, donde aprenderá a usar across().\nOtra función auxiliar popular summarize() es una versión de count() que también calcula proporciones:\n\n# https://twitter.com/Diabb6/status/1571635146658402309\ncount_prop &lt;- function(df, var, sort = FALSE) {\n  df |&gt;\n    count({{ var }}, sort = sort) |&gt;\n    mutate(prop = n / sum(n))\n}\n\ndiamonds |&gt; count_prop(clarity)\n#&gt; # A tibble: 8 × 3\n#&gt;   clarity     n   prop\n#&gt;   &lt;ord&gt;   &lt;int&gt;  &lt;dbl&gt;\n#&gt; 1 I1        741 0.0137\n#&gt; 2 SI2      9194 0.170 \n#&gt; 3 SI1     13065 0.242 \n#&gt; 4 VS2     12258 0.227 \n#&gt; 5 VS1      8171 0.151 \n#&gt; 6 VVS2     5066 0.0939\n#&gt; # ℹ 2 more rows\n\nEsta función tiene tres argumentos: df, var y sort, y solo var debe aceptarse porque se pasa a count(), que utiliza el enmascaramiento de datos para todas las variables. Tenga en cuenta que usamos un valor predeterminado para sort, de modo que si el usuario no proporciona su propio valor, el valor predeterminado será FALSE.\nO tal vez quiera encontrar los valores únicos ordenados de una variable para un subconjunto de los datos. En lugar de proporcionar una variable y un valor para realizar el filtrado, permitiremos que el usuario proporcione una condición:\n\nunique_where &lt;- function(df, condition, var) {\n  df |&gt; \n    filter({{ condition }}) |&gt; \n    distinct({{ var }}) |&gt; \n    arrange({{ var }})\n}\n\n# Encuentra todos los destinos en diciembre\nflights |&gt; unique_where(month == 12, dest)\n#&gt; # A tibble: 96 × 1\n#&gt;   dest \n#&gt;   &lt;chr&gt;\n#&gt; 1 ABQ  \n#&gt; 2 ALB  \n#&gt; 3 ATL  \n#&gt; 4 AUS  \n#&gt; 5 AVL  \n#&gt; 6 BDL  \n#&gt; # ℹ 90 more rows\n\nAquí adoptamos condition porque se pasa a filter() y var porque se pasa a distinct() y arrange().\nHicimos todos estos ejemplos para tomar un data frame como el primer argumento, pero si está trabajando repetidamente con los mismos datos, puede tener sentido codificarlo. Por ejemplo, la siguiente función siempre funciona con el conjunto de datos de vuelos y siempre selecciona time_hour, carrier y flight, ya que forman la clave principal compuesta que le permite identificar una fila.\n\nsubset_flights &lt;- function(rows, cols) {\n  flights |&gt; \n    filter({{ rows }}) |&gt; \n    select(time_hour, carrier, flight, {{ cols }})\n}\n\n\n26.3.4 Enmascaramiento de datos vs selección ordenada\nA veces desea seleccionar variables dentro de una función que usa enmascaramiento de datos. Por ejemplo, imagina que quieres escribir un count_missing() que cuente el número de observaciones que faltan en las filas. Puedes intentar escribir algo como:\n\ncount_missing &lt;- function(df, group_vars, x_var) {\n  df |&gt; \n    group_by({{ group_vars }}) |&gt; \n    summarize(\n      n_miss = sum(is.na({{ x_var }})),\n      .groups = \"drop\"\n    )\n}\n\nflights |&gt; \n  count_missing(c(year, month, day), dep_time)\n#&gt; Error in `group_by()`:\n#&gt; ℹ In argument: `c(year, month, day)`.\n#&gt; Caused by error:\n#&gt; ! `c(year, month, day)` must be size 336776 or 1, not 1010328.\n\nEsto no funciona porque group_by() usa enmascaramiento de datos, no selección ordenada. Podemos solucionar ese problema usando la práctica función pick(), que le permite usar la selección ordenada dentro de las funciones de enmascaramiento de datos:\n\ncount_missing &lt;- function(df, group_vars, x_var) {\n  df |&gt; \n    group_by(pick({{ group_vars }})) |&gt; \n    summarize(\n      n_miss = sum(is.na({{ x_var }})),\n      .groups = \"drop\"\n  )\n}\n\nflights |&gt; \n  count_missing(c(year, month, day), dep_time)\n#&gt; # A tibble: 365 × 4\n#&gt;    year month   day n_miss\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;  &lt;int&gt;\n#&gt; 1  2013     1     1      4\n#&gt; 2  2013     1     2      8\n#&gt; 3  2013     1     3     10\n#&gt; 4  2013     1     4      6\n#&gt; 5  2013     1     5      3\n#&gt; 6  2013     1     6      1\n#&gt; # ℹ 359 more rows\n\nOtro uso conveniente de pick() es hacer una tabla de cuentas en 2D. Aquí contamos usando todas las variables en las filas y columnas, luego usamos pivot_wider() para reorganizar los conteos en una cuadrícula:\n\n# https://twitter.com/pollicipes/status/1571606508944719876\ncount_wide &lt;- function(data, rows, cols) {\n  data |&gt; \n    count(pick(c({{ rows }}, {{ cols }}))) |&gt; \n    pivot_wider(\n      names_from = {{ cols }}, \n      values_from = n,\n      names_sort = TRUE,\n      values_fill = 0\n    )\n}\n\ndiamonds |&gt; count_wide(c(clarity, color), cut)\n#&gt; # A tibble: 56 × 7\n#&gt;   clarity color  Fair  Good `Very Good` Premium Ideal\n#&gt;   &lt;ord&gt;   &lt;ord&gt; &lt;int&gt; &lt;int&gt;       &lt;int&gt;   &lt;int&gt; &lt;int&gt;\n#&gt; 1 I1      D         4     8           5      12    13\n#&gt; 2 I1      E         9    23          22      30    18\n#&gt; 3 I1      F        35    19          13      34    42\n#&gt; 4 I1      G        53    19          16      46    16\n#&gt; 5 I1      H        52    14          12      46    38\n#&gt; 6 I1      I        34     9           8      24    17\n#&gt; # ℹ 50 more rows\n\nSi bien nuestros ejemplos se han centrado principalmente en dplyr, la evaluación ordenada también respalda a tidyr, y si observa los documentos pivot_wider(), puede ver que names_from usa una selección ordenada.\n\n26.3.5 Ejercicios\n\n\nUsando los conjuntos de datos de nycflights13, escriba una función que:\n\n\nEncuentra todos los vuelos que fueron cancelados (es decir, is.na(arr_time)) o retrasados por más de una hora.\n\nflights |&gt; filter_severe()\n\n\n\nCuenta el número de vuelos cancelados y el número de vuelos retrasados por más de una hora.\n\nflights |&gt; group_by(dest) |&gt; summarize_severe()\n\n\n\nEncuentra todos los vuelos que fueron cancelados o retrasados por más de un número de horas proporcionado por el usuario:\n\nflights |&gt; filter_severe(hours = 2)\n\n\n\nResume el clima para calcular el mínimo, la media y el máximo de una variable proporcionada por el usuario:\n\nweather |&gt; summarize_weather(temp)\n\n\n\nConvierte la variable proporcionada por el usuario que utiliza la hora del reloj (por ejemplo, dep_time, arr_time, etc.) en una hora decimal (es decir, hours + (minutes/60)).\n\nflights |&gt; standardize_time(sched_dep_time)\n\n\n\n\nPara cada una de las siguientes funciones, enumere todos los argumentos que usan evaluación ordenada y describa si usan enmascaramiento de datos o selección ordenada: distinct(), count(), group_by(), rename_with(), slice_min(), slice_sample().\n\nGeneralice la siguiente función para que pueda proporcionar cualquier número de variables para contar.\n\ncount_prop &lt;- function(df, var, sort = FALSE) {\n  df |&gt;\n    count({{ var }}, sort = sort) |&gt;\n    mutate(prop = n / sum(n))\n}"
  },
  {
    "objectID": "functions.html#funciones-de-gráficas",
    "href": "functions.html#funciones-de-gráficas",
    "title": "26  Funciones",
    "section": "\n26.4 Funciones de gráficas",
    "text": "26.4 Funciones de gráficas\nEn lugar de devolver un data frame, es posible que desee devolver un gráfico. Afortunadamente, puedes usar las mismas técnicas con ggplot2, porque aes() es una función de enmascaramiento de datos. Por ejemplo, imagina que estás haciendo muchos histogramas:\n\ndiamonds |&gt; \n  ggplot(aes(x = carat)) +\n  geom_histogram(binwidth = 0.1)\n\ndiamonds |&gt; \n  ggplot(aes(x = carat)) +\n  geom_histogram(binwidth = 0.05)\n\n¿No sería bueno si pudieras envolver esto en una función de histograma? Esto es muy fácil una vez que sabe que aes () es una función de enmascaramiento de datos y debe adoptar:\n\nhistogram &lt;- function(df, var, binwidth = NULL) {\n  df |&gt; \n    ggplot(aes(x = {{ var }})) + \n    geom_histogram(binwidth = binwidth)\n}\n\ndiamonds |&gt; histogram(carat, 0.1)\n\n\n\n\nTenga en cuenta que histogram() devuelve un gráfico ggplot2, lo que significa que aún puede agregar componentes adicionales si lo desea. Solo recuerda cambiar de |&gt; a +:\n\ndiamonds |&gt; \n  histogram(carat, 0.1) +\n  labs(x = \"Size (in carats)\", y = \"Number of diamonds\")\n\n\n26.4.1 Más variables\nEs sencillo agregar más variables a la mezcla. Por ejemplo, tal vez desee una manera fácil de observar si un conjunto de datos es lineal o no al superponer una línea suave y una línea recta:\n\n# https://twitter.com/tyler_js_smith/status/1574377116988104704\nlinearity_check &lt;- function(df, x, y) {\n  df |&gt;\n    ggplot(aes(x = {{ x }}, y = {{ y }})) +\n    geom_point() +\n    geom_smooth(method = \"loess\", formula = y ~ x, color = \"red\", se = FALSE) +\n    geom_smooth(method = \"lm\", formula = y ~ x, color = \"blue\", se = FALSE) \n}\n\nstarwars |&gt; \n  filter(mass &lt; 1000) |&gt; \n  linearity_check(mass, height)\n\n\n\n\nO tal vez desee una alternativa a los diagramas de dispersión de colores para conjuntos de datos muy grandes en los que la superposición de gráficos es un problema:\n\n# https://twitter.com/ppaxisa/status/1574398423175921665\nhex_plot &lt;- function(df, x, y, z, bins = 20, fun = \"mean\") {\n  df |&gt; \n    ggplot(aes(x = {{ x }}, y = {{ y }}, z = {{ z }})) + \n    stat_summary_hex(\n      aes(color = after_scale(fill)), # make border same color as fill\n      bins = bins, \n      fun = fun,\n    )\n}\n\ndiamonds |&gt; hex_plot(carat, price, depth)\n\n\n\n\n\n26.4.2 Combinando con otros tidyverse\nAlgunos de los ayudantes más útiles combinan una pizca de manipulación de datos con ggplot2. Por ejemplo, si desea hacer un gráfico de barras verticales en el que ordene automáticamente las barras en orden de frecuencia usando fct_infreq(). Dado que el gráfico de barras es vertical, también debemos invertir el orden habitual para obtener los valores más altos en la parte superior:\n\nsorted_bars &lt;- function(df, var) {\n  df |&gt; \n    mutate({{ var }} := fct_rev(fct_infreq({{ var }})))  |&gt;\n    ggplot(aes(y = {{ var }})) +\n    geom_bar()\n}\n\ndiamonds |&gt; sorted_bars(clarity)\n\n\n\n\nTenemos que usar un nuevo operador aquí, := (comúnmente conocido como “operador morsa”), porque estamos generando el nombre de la variable en función de los datos proporcionados por el usuario. Los nombres de las variables van en el lado izquierdo de =, pero la sintaxis de R no permite nada a la izquierda de = excepto un solo nombre literal. Para solucionar este problema, usamos el operador especial := que la evaluación ordenada trata exactamente de la misma manera que =.\nO tal vez desee que sea más fácil dibujar un gráfico de barras solo para un subconjunto de los datos:\n\nconditional_bars &lt;- function(df, condition, var) {\n  df |&gt; \n    filter({{ condition }}) |&gt; \n    ggplot(aes(x = {{ var }})) + \n    geom_bar()\n}\n\ndiamonds |&gt; conditional_bars(cut == \"Good\", clarity)\n\n\n\n\nTambién puede ser creativo y mostrar resúmenes de datos de otras maneras. Puede encontrar una aplicación interesante en https://gist.github.com/Gshotwell/b19ef520b6d56f61a830fabb3454965b; utiliza las etiquetas de los ejes para mostrar el valor más alto. A medida que aprenda más sobre ggplot2, el poder de sus funciones seguirá aumentando.\nTerminaremos con un caso más complicado: etiquetar las parcelas que creas.\n\n26.4.3 Etiquetado\n¿Recuerdas la función de histograma que te mostramos antes?\n\nhistogram &lt;- function(df, var, binwidth = NULL) {\n  df |&gt; \n    ggplot(aes(x = {{ var }})) + \n    geom_histogram(binwidth = binwidth)\n}\n\n¿No sería bueno si pudiéramos etiquetar la salida con la variable y el ancho del contenedor que se usó? Para hacerlo, vamos a tener que pasar por debajo de las sábanas de la evaluación ordenada y usar una función del paquete del que aún no hemos hablado: rlang. rlang es un paquete de bajo nivel que es utilizado por casi todos los demás paquetes en el tidyverse porque implementa una evaluación ordenada (así como muchas otras herramientas útiles).\nPara resolver el problema de etiquetado podemos usar rlang::englue(). Esto funciona de manera similar a str_glue(), por lo que cualquier valor envuelto en { } se insertará en la cadena. Pero también entiende {{ }}, que inserta automáticamente el nombre de variable apropiado:\n\nhistogram &lt;- function(df, var, binwidth) {\n  label &lt;- rlang::englue(\"A histogram of {{var}} with binwidth {binwidth}\")\n  \n  df |&gt; \n    ggplot(aes(x = {{ var }})) + \n    geom_histogram(binwidth = binwidth) + \n    labs(title = label)\n}\n\ndiamonds |&gt; histogram(carat, 0.1)\n\n\n\n\nPuede usar el mismo enfoque en cualquier otro lugar donde desee proporcionar una cadena en un gráfico ggplot2.\n\n26.4.4 Ejercicios\nCree una función de trazado enriquecida implementando de forma incremental cada uno de los pasos a continuación:\n\nDibuje un diagrama de dispersión dado el conjunto de datos y las variables x e y.\nAgregue una línea de mejor ajuste (es decir, un modelo lineal sin errores estándar).\nAgregue un título."
  },
  {
    "objectID": "functions.html#estilo",
    "href": "functions.html#estilo",
    "title": "26  Funciones",
    "section": "\n26.5 Estilo",
    "text": "26.5 Estilo\nA R no le importa cómo se llamen sus funciones o argumentos, pero los nombres marcan una gran diferencia para los humanos. Idealmente, el nombre de su función será corto, pero evocará claramente lo que hace la función. ¡Eso es difícil! Pero es mejor ser claro que breve, ya que el autocompletado de RStudio facilita la escritura de nombres largos.\nGeneralmente, los nombres de las funciones deben ser verbos y los argumentos deben ser sustantivos. Hay algunas excepciones: los sustantivos están bien si la función calcula un sustantivo muy conocido (es decir, mean() es mejor que compute_mean()), o acceder a alguna propiedad de un objeto (es decir, coef() es mejor que obtener_coeficientes()). Use su mejor juicio y no tenga miedo de cambiar el nombre de una función si descubre un nombre mejor más tarde.\n\n# Demasiado corto\nf()\n\n# Ni verbo ni descriptivo\nmy_awesome_function()\n\n# Largo pero no claro\nimpute_missing()\ncollapse_years()\n\nA R tampoco le importa cómo usa el espacio en blanco en sus funciones, pero a los futuros lectores sí. Continúe siguiendo las reglas de Capítulo 5. Además, function() siempre debe ir seguida de corchetes ondulados ({}), y el contenido debe tener una sangría de dos espacios adicionales. Esto hace que sea más fácil ver la jerarquía en su código rozando el margen izquierdo.\n\n# Faltan los dos espacios extras\ndensity &lt;- function(color, facets, binwidth = 0.1) {\ndiamonds |&gt; \n  ggplot(aes(x = carat, y = after_stat(density), color = {{ color }})) +\n  geom_freqpoly(binwidth = binwidth) +\n  facet_wrap(vars({{ facets }}))\n}\n\n# Canalización con sangría incorrecta\ndensity &lt;- function(color, facets, binwidth = 0.1) {\n  diamonds |&gt; \n  ggplot(aes(x = carat, y = after_stat(density), color = {{ color }})) +\n  geom_freqpoly(binwidth = binwidth) +\n  facet_wrap(vars({{ facets }}))\n}\n\nComo puede ver, recomendamos poner espacios adicionales dentro de {{ }}. Esto hace que sea muy obvio que algo inusual está sucediendo.\n\n26.5.1 Ejercicios\n\n\nLea el código fuente de cada una de las siguientes dos funciones, averigüe lo que hacen y luego piense en mejores nombres.\n\nf1 &lt;- function(string, prefix) {\n  str_sub(string, 1, str_length(prefix)) == prefix\n}\n\nf3 &lt;- function(x, y) {\n  rep(y, length.out = length(x))\n}\n\n\nTome una función que haya escrito recientemente y dedique 5 minutos a pensar en un mejor nombre para ella y sus argumentos.\nExplique por qué norm_r(), norm_d() etc. sería mejor que rnorm(), dnorm(). Haga un caso para lo contrario. ¿Cómo podría hacer los nombres aún más claros?"
  },
  {
    "objectID": "functions.html#resumen",
    "href": "functions.html#resumen",
    "title": "26  Funciones",
    "section": "\n26.6 Resumen",
    "text": "26.6 Resumen\nEn este capítulo, aprendió a escribir funciones para tres escenarios útiles: crear un vector, crear data frame o crear un gráfico. En el camino, vio muchos ejemplos, que con suerte comenzaron a hacer fluir su creatividad y le dieron algunas ideas sobre dónde las funciones podrían ayudar a su código de análisis.\nSolo le hemos mostrado lo mínimo para comenzar con las funciones y hay mucho más que aprender. Algunos lugares para aprender más son:\n\nPara obtener más información sobre la programación con evaluación ordenada, consulte recetas útiles en programación con dplyr y programación con tidyr y obtenga más información sobre la teoría en ¿Qué es el enmascaramiento de datos y por qué necesito {{?.\nPara obtener más información sobre cómo reducir la duplicación en su código ggplot2, lea el capítulo Programación con ggplot2 del libro de ggplot2.\nPara obtener más consejos sobre el estilo de las funciones, consulta la guía de estilo de tidyverse.\n\nEn el próximo capítulo, nos sumergiremos en la iteración, que le brinda más herramientas para reducir la duplicación de código."
  },
  {
    "objectID": "iteration.html#introducción",
    "href": "iteration.html#introducción",
    "title": "27  Iteración",
    "section": "\n27.1 Introducción",
    "text": "27.1 Introducción\nEn este capítulo, aprenderá herramientas para la iteración, realizando repetidamente la misma acción en diferentes objetos. La iteración en R generalmente tiende a verse bastante diferente de otros lenguajes de programación porque gran parte de ella está implícita y la obtenemos de forma gratuita. Por ejemplo, si desea duplicar un vector numérico x en R, simplemente puede escribir 2 * x. En la mayoría de los otros idiomas, necesitaría duplicar explícitamente cada elemento de x usando algún tipo de bucle for.\nEste libro ya le ha brindado una pequeña pero poderosa cantidad de herramientas que realizan la misma acción para múltiples “cosas”:\n\n\nfacet_wrap() y facet_grid() dibuja una gráfica para cada subconjunto.\n\ngroup_by() más summarize() calcula un resumen de estadísticas para cada subconjunto.\n\nunnest_wider() y unnest_longer() crear nuevas filas y columnas para cada elemento de una lista-columna.\n\nAhora es el momento de aprender algunas herramientas más generales, a menudo llamadas herramientas de programación funcional porque están construidas alrededor de funciones que toman otras funciones como entradas. El aprendizaje de la programación funcional puede pasar fácilmente a lo abstracto, pero en este capítulo mantendremos las cosas concretas centrándonos en tres tareas comunes: modificar varias columnas, leer varios archivos y guardar varios objetos.\n\n27.1.1 Requisitos previos\nEn este capítulo, nos centraremos en las herramientas proporcionadas por dplyr y purrr, ambos miembros principales de tidyverse. Has visto dplyr antes, pero purrr es nuevo. Solo vamos a usar un par de funciones purrr en este capítulo, pero es un gran paquete para explorar a medida que mejora sus habilidades de programación.\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "iteration.html#leer-varios-archivos",
    "href": "iteration.html#leer-varios-archivos",
    "title": "27  Iteración",
    "section": "\n27.3 Leer varios archivos",
    "text": "27.3 Leer varios archivos\nEn la sección anterior, aprendiste a usar dplyr::across() para repetir una transformación en varias columnas. En esta sección, aprenderá cómo usar purrr::map() para hacer algo con cada archivo en un directorio. Empecemos con un poco de motivación: imagine que tiene un directorio lleno de hojas de cálculo de Excel[^iteración-4] que desea leer. Podrías hacerlo con copiar y pegar:\n\ndata2019 &lt;- readxl::read_excel(\"data/y2019.xlsx\")\ndata2020 &lt;- readxl::read_excel(\"data/y2020.xlsx\")\ndata2021 &lt;- readxl::read_excel(\"data/y2021.xlsx\")\ndata2022 &lt;- readxl::read_excel(\"data/y2022.xlsx\")\n\nY luego usa dplyr::bind_rows() para combinarlos todos juntos:\n\ndata &lt;- bind_rows(data2019, data2020, data2021, data2022)\n\nPuede imaginar que esto se volvería tedioso rápidamente, especialmente si tuviera cientos de archivos, no solo cuatro. Las siguientes secciones le muestran cómo automatizar este tipo de tareas. Hay tres pasos básicos: use list.files() para listar todos los archivos en un directorio, luego use purrr::map() para leer cada uno de ellos en una lista, luego use purrr::list_rbind( ) para combinarlos en un solo data frame. Luego, analizaremos cómo puede manejar situaciones de creciente heterogeneidad, en las que no puede hacer exactamente lo mismo con todos los archivos.\n\n27.3.1 Listado de archivos en un directorio\nComo sugiere el nombre, list.files() enumera los archivos en un directorio. Casi siempre usarás tres argumentos:\n\nEl primer argumento, path, es el directorio en el que buscar.\npattern es una expresión regular utilizada para filtrar los nombres de archivo. El patrón más común es algo como [.]xlsx$ o [.]csv$ para encontrar todos los archivos con una extensión específica.\nfull.names determina si el nombre del directorio debe incluirse o no en la salida. Casi siempre quieres que esto sea TRUE.\n\nPara concretar nuestro ejemplo motivador, este libro contiene una carpeta con 12 hojas de cálculo de Excel que contienen datos del paquete gapminder. Cada archivo contiene datos de un año para 142 países. Podemos listarlos todos con la llamada apropiada a list.files():\n\npaths &lt;- list.files(\"data/gapminder\", pattern = \"[.]xlsx$\", full.names = TRUE)\npaths\n#&gt;  [1] \"data/gapminder/1952.xlsx\" \"data/gapminder/1957.xlsx\"\n#&gt;  [3] \"data/gapminder/1962.xlsx\" \"data/gapminder/1967.xlsx\"\n#&gt;  [5] \"data/gapminder/1972.xlsx\" \"data/gapminder/1977.xlsx\"\n#&gt;  [7] \"data/gapminder/1982.xlsx\" \"data/gapminder/1987.xlsx\"\n#&gt;  [9] \"data/gapminder/1992.xlsx\" \"data/gapminder/1997.xlsx\"\n#&gt; [11] \"data/gapminder/2002.xlsx\" \"data/gapminder/2007.xlsx\"\n\n\n27.3.2 Lists\nAhora que tenemos estas 12 rutas, podríamos llamar a read_excel() 12 veces para obtener 12 data frames:\n\ngapminder_1952 &lt;- readxl::read_excel(\"data/gapminder/1952.xlsx\")\ngapminder_1957 &lt;- readxl::read_excel(\"data/gapminder/1957.xlsx\")\ngapminder_1962 &lt;- readxl::read_excel(\"data/gapminder/1962.xlsx\")\n ...,\ngapminder_2007 &lt;- readxl::read_excel(\"data/gapminder/2007.xlsx\")\n\nPero poner cada hoja en su propia variable hará que sea difícil trabajar con ellas unos pasos más adelante. En cambio, será más fácil trabajar con ellos si los ponemos en un solo objeto. Una lista es la herramienta perfecta para este trabajo:\n\nfiles &lt;- list(\n  readxl::read_excel(\"data/gapminder/1952.xlsx\"),\n  readxl::read_excel(\"data/gapminder/1957.xlsx\"),\n  readxl::read_excel(\"data/gapminder/1962.xlsx\"),\n  ...,\n  readxl::read_excel(\"data/gapminder/2007.xlsx\")\n)\n\nAhora que tiene estos data frames en una lista, ¿cómo obtiene uno? Puedes usar files[[i]] para extraer el i-ésimo elemento:\n\nfiles[[3]]\n#&gt; # A tibble: 142 × 5\n#&gt;   country     continent lifeExp      pop gdpPercap\n#&gt;   &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 Afghanistan Asia         32.0 10267083      853.\n#&gt; 2 Albania     Europe       64.8  1728137     2313.\n#&gt; 3 Algeria     Africa       48.3 11000948     2551.\n#&gt; 4 Angola      Africa       34    4826015     4269.\n#&gt; 5 Argentina   Americas     65.1 21283783     7133.\n#&gt; 6 Australia   Oceania      70.9 10794968    12217.\n#&gt; # ℹ 136 more rows\n\nVolveremos a [[ con más detalle en Sección 28.3.\n\n27.3.3 purrr::map() and list_rbind()\n\nEl código para recopilar esos data frames en una lista “a mano” es básicamente tan tedioso de escribir como el código que lee los archivos uno por uno. Felizmente, podemos usar purrr::map() para hacer un mejor uso de nuestro vector paths. map() es similar a across(), pero en lugar de hacer algo con cada columna en un data frame, hace algo con cada elemento de un vector. map(x, f) es una abreviatura de:\n\nlist(\n  f(x[[1]]),\n  f(x[[2]]),\n  ...,\n  f(x[[n]])\n)\n\nEntonces podemos usar map() para obtener una lista de 12 data frames:\n\nfiles &lt;- map(paths, readxl::read_excel)\nlength(files)\n#&gt; [1] 12\n\nfiles[[1]]\n#&gt; # A tibble: 142 × 5\n#&gt;   country     continent lifeExp      pop gdpPercap\n#&gt;   &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 Afghanistan Asia         28.8  8425333      779.\n#&gt; 2 Albania     Europe       55.2  1282697     1601.\n#&gt; 3 Algeria     Africa       43.1  9279525     2449.\n#&gt; 4 Angola      Africa       30.0  4232095     3521.\n#&gt; 5 Argentina   Americas     62.5 17876956     5911.\n#&gt; 6 Australia   Oceania      69.1  8691212    10040.\n#&gt; # ℹ 136 more rows\n\n(Esta es otra estructura de datos que no se muestra de manera particularmente compacta con str(), por lo que es posible que desee cargarla en RStudio e inspeccionarla con View()).\nAhora podemos usar purrr::list_rbind() para combinar esa lista de data frames en un solo data frame:\n\nlist_rbind(files)\n#&gt; # A tibble: 1,704 × 5\n#&gt;   country     continent lifeExp      pop gdpPercap\n#&gt;   &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 Afghanistan Asia         28.8  8425333      779.\n#&gt; 2 Albania     Europe       55.2  1282697     1601.\n#&gt; 3 Algeria     Africa       43.1  9279525     2449.\n#&gt; 4 Angola      Africa       30.0  4232095     3521.\n#&gt; 5 Argentina   Americas     62.5 17876956     5911.\n#&gt; 6 Australia   Oceania      69.1  8691212    10040.\n#&gt; # ℹ 1,698 more rows\n\nO podríamos hacer ambos pasos a la vez en una canalización:\n\npaths |&gt; \n  map(readxl::read_excel) |&gt; \n  list_rbind()\n\n¿Qué sucede si queremos pasar argumentos adicionales a read_excel()? Usamos la misma técnica que usamos con across(). Por ejemplo, suele ser útil alcanzar un máximo en las primeras filas de los datos con n_max = 1:\n\npaths |&gt; \n  map(\\(path) readxl::read_excel(path, n_max = 1)) |&gt; \n  list_rbind()\n#&gt; # A tibble: 12 × 5\n#&gt;   country     continent lifeExp      pop gdpPercap\n#&gt;   &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 Afghanistan Asia         28.8  8425333      779.\n#&gt; 2 Afghanistan Asia         30.3  9240934      821.\n#&gt; 3 Afghanistan Asia         32.0 10267083      853.\n#&gt; 4 Afghanistan Asia         34.0 11537966      836.\n#&gt; 5 Afghanistan Asia         36.1 13079460      740.\n#&gt; 6 Afghanistan Asia         38.4 14880372      786.\n#&gt; # ℹ 6 more rows\n\nEsto deja en claro que falta algo: no hay una columna year porque ese valor se registra en la ruta, no en los archivos individuales. Abordaremos ese problema a continuación.\n\n27.3.4 Datos en la ruta\nA veces, el nombre del archivo es el propio dato. En este ejemplo, el nombre del archivo contiene el año, que de otro modo no se registra en los archivos individuales. Para colocar esa columna en el data frame final, debemos hacer dos cosas:\nPrimero, nombramos el vector de rutas. La forma más fácil de hacer esto es con la función set_names(), que puede tomar una función. Aquí usamos basename() para extraer solo el nombre del archivo de la ruta completa:\n\npaths |&gt; set_names(basename) \n#&gt;                  1952.xlsx                  1957.xlsx \n#&gt; \"data/gapminder/1952.xlsx\" \"data/gapminder/1957.xlsx\" \n#&gt;                  1962.xlsx                  1967.xlsx \n#&gt; \"data/gapminder/1962.xlsx\" \"data/gapminder/1967.xlsx\" \n#&gt;                  1972.xlsx                  1977.xlsx \n#&gt; \"data/gapminder/1972.xlsx\" \"data/gapminder/1977.xlsx\" \n#&gt;                  1982.xlsx                  1987.xlsx \n#&gt; \"data/gapminder/1982.xlsx\" \"data/gapminder/1987.xlsx\" \n#&gt;                  1992.xlsx                  1997.xlsx \n#&gt; \"data/gapminder/1992.xlsx\" \"data/gapminder/1997.xlsx\" \n#&gt;                  2002.xlsx                  2007.xlsx \n#&gt; \"data/gapminder/2002.xlsx\" \"data/gapminder/2007.xlsx\"\n\nEsos nombres son llevados automáticamente por todas las funciones del mapa, por lo que la lista de data frames tendrá esos mismos nombres:\n\nfiles &lt;- paths |&gt; \n  set_names(basename) |&gt; \n  map(readxl::read_excel)\n\nEso hace que esta llamada a map() sea abreviada para:\n\nfiles &lt;- list(\n  \"1952.xlsx\" = readxl::read_excel(\"data/gapminder/1952.xlsx\"),\n  \"1957.xlsx\" = readxl::read_excel(\"data/gapminder/1957.xlsx\"),\n  \"1962.xlsx\" = readxl::read_excel(\"data/gapminder/1962.xlsx\"),\n  ...,\n  \"2007.xlsx\" = readxl::read_excel(\"data/gapminder/2007.xlsx\")\n)\n\nTambién puedes usar [[ para extraer elementos por nombre:\n\nfiles[[\"1962.xlsx\"]]\n#&gt; # A tibble: 142 × 5\n#&gt;   country     continent lifeExp      pop gdpPercap\n#&gt;   &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 Afghanistan Asia         32.0 10267083      853.\n#&gt; 2 Albania     Europe       64.8  1728137     2313.\n#&gt; 3 Algeria     Africa       48.3 11000948     2551.\n#&gt; 4 Angola      Africa       34    4826015     4269.\n#&gt; 5 Argentina   Americas     65.1 21283783     7133.\n#&gt; 6 Australia   Oceania      70.9 10794968    12217.\n#&gt; # ℹ 136 more rows\n\nLuego usamos el argumento names_to para list_rbind() para decirle que guarde los nombres en una nueva columna llamada year y luego usamos readr::parse_number() para extraer el número de la cadena.\n\npaths |&gt; \n  set_names(basename) |&gt; \n  map(readxl::read_excel) |&gt; \n  list_rbind(names_to = \"year\") |&gt; \n  mutate(year = parse_number(year))\n#&gt; # A tibble: 1,704 × 6\n#&gt;    year country     continent lifeExp      pop gdpPercap\n#&gt;   &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1  1952 Afghanistan Asia         28.8  8425333      779.\n#&gt; 2  1952 Albania     Europe       55.2  1282697     1601.\n#&gt; 3  1952 Algeria     Africa       43.1  9279525     2449.\n#&gt; 4  1952 Angola      Africa       30.0  4232095     3521.\n#&gt; 5  1952 Argentina   Americas     62.5 17876956     5911.\n#&gt; 6  1952 Australia   Oceania      69.1  8691212    10040.\n#&gt; # ℹ 1,698 more rows\n\nEn casos más complicados, puede haber otras variables almacenadas en el nombre del directorio, o tal vez el nombre del archivo contenga varios bits de datos. En ese caso, use set_names() (sin ningún argumento) para registrar la ruta completa y luego use tidyr::separate_wider_delim() y sus amigos para convertirlos en columnas útiles.\n\npaths |&gt; \n  set_names() |&gt; \n  map(readxl::read_excel) |&gt; \n  list_rbind(names_to = \"year\") |&gt; \n  separate_wider_delim(year, delim = \"/\", names = c(NA, \"dir\", \"file\")) |&gt; \n  separate_wider_delim(file, delim = \".\", names = c(\"file\", \"ext\"))\n#&gt; # A tibble: 1,704 × 8\n#&gt;   dir       file  ext   country     continent lifeExp      pop gdpPercap\n#&gt;   &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 gapminder 1952  xlsx  Afghanistan Asia         28.8  8425333      779.\n#&gt; 2 gapminder 1952  xlsx  Albania     Europe       55.2  1282697     1601.\n#&gt; 3 gapminder 1952  xlsx  Algeria     Africa       43.1  9279525     2449.\n#&gt; 4 gapminder 1952  xlsx  Angola      Africa       30.0  4232095     3521.\n#&gt; 5 gapminder 1952  xlsx  Argentina   Americas     62.5 17876956     5911.\n#&gt; 6 gapminder 1952  xlsx  Australia   Oceania      69.1  8691212    10040.\n#&gt; # ℹ 1,698 more rows\n\n\n27.3.5 Guarda tu trabajo\nAhora que ha hecho todo este arduo trabajo para llegar a un buen data frame ordenado, es un buen momento para guardar su trabajo:\n\ngapminder &lt;- paths |&gt; \n  set_names(basename) |&gt; \n  map(readxl::read_excel) |&gt; \n  list_rbind(names_to = \"year\") |&gt; \n  mutate(year = parse_number(year))\n\nwrite_csv(gapminder, \"gapminder.csv\")\n\nAhora, cuando regrese a este problema en el futuro, puede leer en un solo archivo csv. Para conjuntos de datos más grandes y ricos, usar parquet podría ser una mejor opción que .csv, como se explica en ?sec-parquet.\nSi está trabajando en un proyecto, le sugerimos llamar al archivo que hace este tipo de trabajo de preparación de datos algo así como 0-cleanup.R. El 0 en el nombre del archivo sugiere que esto debe ejecutarse antes que cualquier otra cosa.\nSi sus archivos de datos de entrada cambian con el tiempo, podría considerar aprender una herramienta como targets para configurar su código de limpieza de datos para que se vuelva a ejecutar automáticamente cada vez que una de las entradas se modifican los archivos.\n\n27.3.6 Muchas iteraciones simples\nAquí acabamos de cargar los datos directamente desde el disco y tuvimos la suerte de obtener un conjunto de datos ordenado. En la mayoría de los casos, deberá realizar algunas tareas de limpieza adicionales y tiene dos opciones básicas: puede realizar una ronda de iteración con una función compleja o realizar varias rondas de iteración con funciones simples. En nuestra experiencia, la mayoría de la gente llega primero a una iteración compleja, pero a menudo es mejor hacer varias iteraciones simples.\nPor ejemplo, imagine que desea leer un montón de archivos, filtrar los valores faltantes, pivotar y luego combinar. Una forma de abordar el problema es escribir una función que tome un archivo y realice todos esos pasos y luego llame a map() una vez:\n\nprocess_file &lt;- function(path) {\n  df &lt;- read_csv(path)\n  \n  df |&gt; \n    filter(!is.na(id)) |&gt; \n    mutate(id = tolower(id)) |&gt; \n    pivot_longer(jan:dec, names_to = \"month\")\n}\n\npaths |&gt; \n  map(process_file) |&gt; \n  list_rbind()\n\nAlternativamente, podría realizar cada paso de process_file() para cada archivo:\n\npaths |&gt; \n  map(read_csv) |&gt; \n  map(\\(df) df |&gt; filter(!is.na(id))) |&gt; \n  map(\\(df) df |&gt; mutate(id = tolower(id))) |&gt; \n  map(\\(df) df |&gt; pivot_longer(jan:dec, names_to = \"month\")) |&gt; \n  list_rbind()\n\nRecomendamos este enfoque porque evita que se obsesione con obtener el primer archivo correctamente antes de pasar al resto. Al considerar todos los datos al ordenar y limpiar, es más probable que piense de manera integral y termine con un resultado de mayor calidad.\nEn este ejemplo en particular, hay otra optimización que podría hacer al vincular todos los data frames antes. Entonces puede confiar en el comportamiento regular de dplyr:\n\npaths |&gt; \n  map(read_csv) |&gt; \n  list_rbind() |&gt; \n  filter(!is.na(id)) |&gt; \n  mutate(id = tolower(id)) |&gt; \n  pivot_longer(jan:dec, names_to = \"month\")\n\n\n27.3.7 Datos heterogéneos\nDesafortunadamente, a veces no es posible pasar directamente de map() a list_rbind() porque los data frames son tan heterogéneos que list_rbind() falla o produce un data frame que no es muy útil. En ese caso, sigue siendo útil comenzar cargando todos los archivos:\n\nfiles &lt;- paths |&gt; \n  map(readxl::read_excel) \n\nLuego, una estrategia muy útil es capturar la estructura de los data frames para que pueda explorarla usando sus habilidades de ciencia de datos. Una forma de hacerlo es con esta útil función df_types 4 que devuelve un tibble con una fila para cada columna:\n\ndf_types &lt;- function(df) {\n  tibble(\n    col_name = names(df), \n    col_type = map_chr(df, vctrs::vec_ptype_full),\n    n_miss = map_int(df, \\(x) sum(is.na(x)))\n  )\n}\n\ndf_types(gapminder)\n#&gt; # A tibble: 6 × 3\n#&gt;   col_name  col_type  n_miss\n#&gt;   &lt;chr&gt;     &lt;chr&gt;      &lt;int&gt;\n#&gt; 1 year      double         0\n#&gt; 2 country   character      0\n#&gt; 3 continent character      0\n#&gt; 4 lifeExp   double         0\n#&gt; 5 pop       double         0\n#&gt; 6 gdpPercap double         0\n\nLuego puede aplicar esta función a todos los archivos, y tal vez hacer algunos cambios para que sea más fácil ver dónde están las diferencias. Por ejemplo, esto facilita la verificación de que las hojas de cálculo de gapminder con las que hemos estado trabajando son bastante homogéneas:\n\nfiles |&gt; \n  map(df_types) |&gt; \n  list_rbind(names_to = \"file_name\") |&gt; \n  select(-n_miss) |&gt; \n  pivot_wider(names_from = col_name, values_from = col_type)\n#&gt; # A tibble: 12 × 6\n#&gt;   file_name country   continent lifeExp pop    gdpPercap\n#&gt;   &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;   &lt;chr&gt;  &lt;chr&gt;    \n#&gt; 1 1952.xlsx character character double  double double   \n#&gt; 2 1957.xlsx character character double  double double   \n#&gt; 3 1962.xlsx character character double  double double   \n#&gt; 4 1967.xlsx character character double  double double   \n#&gt; 5 1972.xlsx character character double  double double   \n#&gt; 6 1977.xlsx character character double  double double   \n#&gt; # ℹ 6 more rows\n\nSi los archivos tienen formatos heterogéneos, es posible que deba realizar más procesamiento antes de poder fusionarlos correctamente. Desafortunadamente, ahora vamos a dejar que lo averigües por tu cuenta, pero es posible que desees leer acerca de map_if() y map_at(). map_if() te permite modificar elementos de una lista de forma selectiva en función de sus valores; map_at() te permite modificar elementos de forma selectiva en función de sus nombres.\n\n27.3.8 Manejo de fallas\nA veces, la estructura de sus datos puede ser lo suficientemente salvaje como para que ni siquiera pueda leer todos los archivos con un solo comando. Y luego te encontrarás con una de las desventajas de map: tiene éxito o falla como un todo. map() leerá con éxito todos los archivos en un directorio o fallará con un error, leyendo cero archivos. Esto es molesto: ¿por qué una falla le impide acceder a todos los demás éxitos?\nAfortunadamente, purrr viene con un ayudante para abordar este problema: possibly(). possibly() es lo que se conoce como operador de función: toma una función y devuelve una función con comportamiento modificado. En particular, possibly() cambia una función de error a devolver un valor que especifique:\n\nfiles &lt;- paths |&gt; \n  map(possibly(\\(path) readxl::read_excel(path), NULL))\n\ndata &lt;- files |&gt; list_rbind()\n\nEsto funciona particularmente bien aquí porque list_rbind(), como muchas funciones de tidyverse, automáticamente ignora NULLs.\nAhora tiene todos los datos que se pueden leer fácilmente, y es hora de abordar la parte difícil de averiguar por qué algunos archivos no se cargaron y qué hacer al respecto. Comience por obtener las rutas que fallaron:\n\nfailed &lt;- map_vec(files, is.null)\npaths[failed]\n#&gt; character(0)\n\nLuego, vuelva a llamar a la función de importación para cada falla y descubra qué salió mal."
  },
  {
    "objectID": "iteration.html#guardar-múltiples-salidas",
    "href": "iteration.html#guardar-múltiples-salidas",
    "title": "27  Iteración",
    "section": "\n27.4 Guardar múltiples salidas",
    "text": "27.4 Guardar múltiples salidas\nEn la última sección, aprendiste sobre map(), que es útil para leer múltiples archivos en un solo objeto. En esta sección, ahora exploraremos una especie de problema opuesto: ¿cómo puede tomar uno o más objetos R y guardarlos en uno o más archivos? Exploraremos este desafío usando tres ejemplos:\n\nGuardar múltiples data frames en una base de datos.\nGuardar múltiples data frames en múltiples archivos .csv.\nGuardar varias gráficas en varios archivos .png.\n\n\n27.4.1 Escribir en una base de datos\nA veces, cuando se trabaja con muchos archivos a la vez, no es posible colocar todos los datos en la memoria a la vez y no se puede hacer map(files, read_csv). Un enfoque para lidiar con este problema es cargar sus datos en una base de datos para que pueda acceder solo a los bits que necesita con dbplyr.\nSi tiene suerte, el paquete de base de datos que está utilizando proporcionará una función útil que toma un vector de rutas y las carga todas en la base de datos. Este es el caso con duckdb_read_csv() de duckdb:\n\ncon &lt;- DBI::dbConnect(duckdb::duckdb())\nduckdb::duckdb_read_csv(con, \"gapminder\", paths)\n\nEsto funcionaría bien aquí, pero no tenemos archivos csv, sino hojas de cálculo de Excel. Así que vamos a tener que hacerlo “a mano”. Aprender a hacerlo a mano también te ayudará cuando tengas un montón de csvs y la base de datos con la que estás trabajando no tenga una función que los cargue todos.\nNecesitamos comenzar creando una tabla que se llene con datos. La forma más sencilla de hacerlo es creando una plantilla, un data frame ficticio que contiene todas las columnas que queremos, pero solo una muestra de los datos. Para los datos de gapminder, podemos hacer esa plantilla leyendo un solo archivo y añadiéndole el año:\n\ntemplate &lt;- readxl::read_excel(paths[[1]])\ntemplate$year &lt;- 1952\ntemplate\n#&gt; # A tibble: 142 × 6\n#&gt;   country     continent lifeExp      pop gdpPercap  year\n#&gt;   &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1 Afghanistan Asia         28.8  8425333      779.  1952\n#&gt; 2 Albania     Europe       55.2  1282697     1601.  1952\n#&gt; 3 Algeria     Africa       43.1  9279525     2449.  1952\n#&gt; 4 Angola      Africa       30.0  4232095     3521.  1952\n#&gt; 5 Argentina   Americas     62.5 17876956     5911.  1952\n#&gt; 6 Australia   Oceania      69.1  8691212    10040.  1952\n#&gt; # ℹ 136 more rows\n\nAhora podemos conectarnos a la base de datos y usar DBI::dbCreateTable() para convertir nuestra plantilla en una tabla de base de datos:\n\ncon &lt;- DBI::dbConnect(duckdb::duckdb())\nDBI::dbCreateTable(con, \"gapminder\", template)\n\ndbCreateTable() no usa los datos en template, solo los nombres y tipos de variables. Así que si inspeccionamos la tabla gapminder ahora verás que está vacía pero tiene las variables que necesitamos con los tipos que esperamos:\n\ncon |&gt; tbl(\"gapminder\")\n#&gt; # Source:   table&lt;gapminder&gt; [0 x 6]\n#&gt; # Database: DuckDB 0.8.1 [DDR@Windows 10 x64:R 4.3.1/:memory:]\n#&gt; # ℹ 6 variables: country &lt;chr&gt;, continent &lt;chr&gt;, lifeExp &lt;dbl&gt;, pop &lt;dbl&gt;,\n#&gt; #   gdpPercap &lt;dbl&gt;, year &lt;dbl&gt;\n\nA continuación, necesitamos una función que tome una única ruta de archivo, la lea en R y agregue el resultado a la tabla gapminder. Podemos hacerlo combinando read_excel() con DBI::dbAppendTable():\n\nappend_file &lt;- function(path) {\n  df &lt;- readxl::read_excel(path)\n  df$year &lt;- parse_number(basename(path))\n  \n  DBI::dbAppendTable(con, \"gapminder\", df)\n}\n\nAhora necesitamos llamar a append_file() una vez por cada elemento de paths. Eso es ciertamente posible con map():\n\npaths |&gt; map(append_file)\n\nPero no nos importa la salida de append_file(), así que en lugar de map() es un poco mejor usar walk(). walk() hace exactamente lo mismo que map() pero descarta el resultado:\n\npaths |&gt; walk(append_file)\n\nAhora podemos ver si tenemos todos los datos en nuestra tabla:\n\ncon |&gt; \n  tbl(\"gapminder\") |&gt; \n  count(year)\n#&gt; # Source:   SQL [?? x 2]\n#&gt; # Database: DuckDB 0.8.1 [DDR@Windows 10 x64:R 4.3.1/:memory:]\n#&gt;    year     n\n#&gt;   &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1  1952   142\n#&gt; 2  1957   142\n#&gt; 3  1962   142\n#&gt; 4  1967   142\n#&gt; 5  1972   142\n#&gt; 6  1977   142\n#&gt; # ℹ more rows\n\n\n27.4.2 Escribir archivos csv\nEl mismo principio básico se aplica si queremos escribir varios archivos csv, uno para cada grupo. Imaginemos que queremos tomar los datos ggplot2::diamonds y guardar un archivo csv para cada clarity. Primero necesitamos hacer esos conjuntos de datos individuales. Hay muchas formas de hacerlo, pero hay una que nos gusta especialmente: group_nest().\n\nby_clarity &lt;- diamonds |&gt; \n  group_nest(clarity)\n\nby_clarity\n#&gt; # A tibble: 8 × 2\n#&gt;   clarity               data\n#&gt;   &lt;ord&gt;   &lt;list&lt;tibble[,9]&gt;&gt;\n#&gt; 1 I1               [741 × 9]\n#&gt; 2 SI2            [9,194 × 9]\n#&gt; 3 SI1           [13,065 × 9]\n#&gt; 4 VS2           [12,258 × 9]\n#&gt; 5 VS1            [8,171 × 9]\n#&gt; 6 VVS2           [5,066 × 9]\n#&gt; # ℹ 2 more rows\n\nEsto nos da un nuevo tibble con ocho filas y dos columnas. clarity es nuestra variable de agrupación y data es una columna de lista que contiene un tibble para cada valor único de clarity:\n\nby_clarity$data[[1]]\n#&gt; # A tibble: 741 × 9\n#&gt;   carat cut       color depth table price     x     y     z\n#&gt;   &lt;dbl&gt; &lt;ord&gt;     &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1  0.32 Premium   E      60.9    58   345  4.38  4.42  2.68\n#&gt; 2  1.17 Very Good J      60.2    61  2774  6.83  6.9   4.13\n#&gt; 3  1.01 Premium   F      61.8    60  2781  6.39  6.36  3.94\n#&gt; 4  1.01 Fair      E      64.5    58  2788  6.29  6.21  4.03\n#&gt; 5  0.96 Ideal     F      60.7    55  2801  6.37  6.41  3.88\n#&gt; 6  1.04 Premium   G      62.2    58  2801  6.46  6.41  4   \n#&gt; # ℹ 735 more rows\n\nYa que estamos aquí, creemos una columna que dé el nombre del archivo de salida, usando mutate() y str_glue():\n\nby_clarity &lt;- by_clarity |&gt; \n  mutate(path = str_glue(\"diamonds-{clarity}.csv\"))\n\nby_clarity\n#&gt; # A tibble: 8 × 3\n#&gt;   clarity               data path             \n#&gt;   &lt;ord&gt;   &lt;list&lt;tibble[,9]&gt;&gt; &lt;glue&gt;           \n#&gt; 1 I1               [741 × 9] diamonds-I1.csv  \n#&gt; 2 SI2            [9,194 × 9] diamonds-SI2.csv \n#&gt; 3 SI1           [13,065 × 9] diamonds-SI1.csv \n#&gt; 4 VS2           [12,258 × 9] diamonds-VS2.csv \n#&gt; 5 VS1            [8,171 × 9] diamonds-VS1.csv \n#&gt; 6 VVS2           [5,066 × 9] diamonds-VVS2.csv\n#&gt; # ℹ 2 more rows\n\nEntonces, si fuéramos a guardar estos data frames a mano, podríamos escribir algo como:\n\nwrite_csv(by_clarity$data[[1]], by_clarity$path[[1]])\nwrite_csv(by_clarity$data[[2]], by_clarity$path[[2]])\nwrite_csv(by_clarity$data[[3]], by_clarity$path[[3]])\n...\nwrite_csv(by_clarity$by_clarity[[8]], by_clarity$path[[8]])\n\nEsto es un poco diferente a nuestros usos anteriores de map() porque hay dos argumentos que están cambiando, no solo uno. Eso significa que necesitamos una nueva función: map2(), que varía tanto el primer como el segundo argumento. Y como tampoco nos importa la salida, queremos walk2() en lugar de map2(). Eso nos da:\n\nwalk2(by_clarity$data, by_clarity$path, write_csv)\n\n\n27.4.3 Guardar gráficas\nPodemos tomar el mismo enfoque básico para crear muchas gráficas. Primero hagamos una función que dibuje la gráfica que queremos:\n\ncarat_histogram &lt;- function(df) {\n  ggplot(df, aes(x = carat)) + geom_histogram(binwidth = 0.1)  \n}\n\ncarat_histogram(by_clarity$data[[1]])\n\n\n\n\nAhora podemos usar map() para crear una lista de muchos gráficos[^iterationn-6] y sus posibles rutas de archivo:\n\nby_clarity &lt;- by_clarity |&gt; \n  mutate(\n    plot = map(data, carat_histogram),\n    path = str_glue(\"clarity-{clarity}.png\")\n  )\n\nLuego usa walk2() con ggsave() para guardar cada gráfico:\n\nwalk2(\n  by_clarity$path,\n  by_clarity$plot,\n  \\(path, plot) ggsave(path, plot, width = 6, height = 6)\n)\n\nEsta es la abreviatura de:\n\nggsave(by_clarity$path[[1]], by_clarity$plot[[1]], width = 6, height = 6)\nggsave(by_clarity$path[[2]], by_clarity$plot[[2]], width = 6, height = 6)\nggsave(by_clarity$path[[3]], by_clarity$plot[[3]], width = 6, height = 6)\n...\nggsave(by_clarity$path[[8]], by_clarity$plot[[8]], width = 6, height = 6)"
  },
  {
    "objectID": "iteration.html#resumen",
    "href": "iteration.html#resumen",
    "title": "27  Iteración",
    "section": "\n27.5 Resumen",
    "text": "27.5 Resumen\nEn este capítulo, ha visto cómo usar la iteración explícita para resolver tres problemas que surgen con frecuencia al hacer ciencia de datos: manipular múltiples columnas, leer múltiples archivos y guardar múltiples salidas. Pero, en general, la iteración es un superpoder: si conoce la técnica de iteración correcta, puede pasar fácilmente de solucionar un problema a solucionar todos los problemas. Una vez que haya dominado las técnicas de este capítulo, le recomendamos que aprenda más leyendo el capítulo Funcionales de Advanced R y consultando el sitio web de purrr.\nSi sabe mucho sobre la iteración en otros lenguajes, se sorprenderá de que no hayamos discutido el bucle for. Esto se debe a que la orientación de R hacia el análisis de datos cambia la forma en que iteramos: en la mayoría de los casos, puede confiar en un idioma existente para hacer algo con cada columna o cada grupo. Y cuando no puedas, a menudo puedes usar una herramienta de programación funcional como map() que hace algo con cada elemento de una lista. Sin embargo, verá bucles for en el código capturado de forma salvaje, por lo que aprenderá sobre ellos en el próximo capítulo, donde analizaremos algunas herramientas básicas importantes de R."
  },
  {
    "objectID": "iteration.html#footnotes",
    "href": "iteration.html#footnotes",
    "title": "27  Iteración",
    "section": "",
    "text": "Anónimo, porque nunca le dimos explícitamente un nombre con &lt;-. Otro término que usan los programadores para esto es “función lambda”.↩︎\nactualmente no puede cambiar el orden de las columnas, pero podría reordenarlas después usando relocate() o similar.↩︎\nTal vez habrá un día, pero actualmente no vemos cómo.↩︎\nno vamos a explicar cómo funciona, pero si miras los documentos de las funciones utilizadas, deberías poder descifrarlo.↩︎"
  },
  {
    "objectID": "quarto.html#introducción",
    "href": "quarto.html#introducción",
    "title": "29  Quarto",
    "section": "",
    "text": "Para comunicarse con los tomadores de decisiones, que quieren centrarse en las conclusiones, no en el código detrás del análisis.\nPara colaborar con otros científicos de datos (¡incluido el futuro usted!), que están interesados tanto en sus conclusiones como en cómo las alcanzó (es decir, el código).\nComo un entorno en el que hacer ciencia de datos, como un cuaderno de laboratorio moderno donde puede capturar no solo lo que hizo, sino también lo que estaba pensando.\n\n\n\n\n29.1.1 Requisitos previos\nNecesita la interfaz de línea de comandos de Quarto (Quarto CLI), pero no necesita instalarla o cargarla explícitamente, ya que RStudio hace ambas cosas automáticamente cuando es necesario.",
    "crumbs": [
      "Comunicar",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#editor-visual",
    "href": "quarto.html#editor-visual",
    "title": "29  Quarto",
    "section": "\n29.3 Editor Visual",
    "text": "29.3 Editor Visual\nEl editor visual de RStudio proporciona una interfaz WYSIWYM para crear documentos Quarto. En el fondo, la prosa de los documentos Quarto (archivos .qmd) está escrita en Markdown, un conjunto ligero de convenciones para formatear archivos de texto sin formato. De hecho, Quarto usa Pandoc Markdown (una versión ligeramente extendida de Markdown que Quarto entiende), que incluye tablas, citas, referencias cruzadas, notas al pie, divs/spans, listas de definiciones, atributos, HTML/TeX sin formato y más, así como soporte para ejecutar celdas de código y ver su salida en línea. Si bien Markdown está diseñado para que sea fácil de leer y escribir, como verá en Sección 29.4, aún requiere aprender una nueva sintaxis. Por lo tanto, si es nuevo en documentos computacionales como archivos .qmd pero tiene experiencia en el uso de herramientas como Google Docs o MS Word, la forma más fácil de comenzar con Quarto en RStudio es el editor visual.\nEn el editor visual, puede usar los botones en la barra de menú para insertar imágenes, tablas, referencias cruzadas, etc. o puede usar el atajo general ⌘ + / or Ctrl + / para insertar casi cualquier cosa. Si está al comienzo de una línea (como se muestra en Figura 29.5), también puede ingresar solo / para invocar el atajo.\n\n\n\n\n\n\n\nFigura 29.5: Editor visual de Quarto.\n\n\n\n\nLa inserción de imágenes y la personalización de cómo se muestran también se facilitan con el editor visual. Puede pegar una imagen de su portapapeles directamente en el editor visual (y RStudio colocará una copia de esa imagen en el directorio del proyecto y la vinculará) o puede usar el editor visual Insert &gt; Figure / Image menu para buscar la imagen que desea insertar o pegar su URL. Además, utilizando el mismo menú, puede cambiar el tamaño de la imagen y agregar un título, texto alternativo y un enlace.\nEl editor visual tiene muchas más funciones que no hemos enumerado aquí y que pueden resultarle útiles a medida que adquiera experiencia creando con él.\nLo que es más importante, mientras que el editor visual muestra su contenido con formato, debajo del capó, guarda su contenido en Markdown simple y puede alternar entre los editores visual y fuente para ver y editar su contenido usando cualquiera de las herramientas.\n\n29.3.1 Ejercicios\n\nVuelva a crear el documento en Figura 29.5 usando el editor visual.\nUsando el editor visual, inserte un fragmento de código usando el menú Insertar y luego la herramienta Insertar cualquier cosa.\nUsando el editor visual, descubra cómo:\n\nAñadir una nota al pie.\nAgregue una regla horizontal.\nAgregue una cita en bloque.\n\n\nEn el editor visual, vaya a Insert &gt; Citation e inserte una cita al artículo titulado Bienvenido a Tidyverse usando su DOI (objeto digital identificador), que es 10.21105/joss.01686. Renderice el documento y observe cómo aparece la referencia en el documento. ¿Qué cambio observa en el YAML de su documento?",
    "crumbs": [
      "Comunicar",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#fragmentos-de-código",
    "href": "quarto.html#fragmentos-de-código",
    "title": "29  Quarto",
    "section": "\n29.5 Fragmentos de código",
    "text": "29.5 Fragmentos de código\nPara ejecutar código dentro de un documento Quarto, debe insertar un fragmento. Hay tres formas de hacerlo:\n\nEl método abreviado de teclado Cmd + Opción + I / Ctrl + Alt + I.\nEl icono del botón “Insert” en la barra de herramientas del editor.\nAl escribir manualmente los delimitadores de fragmentos ```{r} y ```.\n\nLe recomendamos que aprenda el atajo de teclado. ¡Te ahorrará mucho tiempo a largo plazo!\nPuede continuar ejecutando el código usando el atajo de teclado que ahora (¡esperamos!) conoce y ama: Cmd/Ctrl + Enter. Sin embargo, los fragmentos obtienen un nuevo atajo de teclado: Cmd/Ctrl + Shift + Enter, que ejecuta todo el código en el fragmento. Piensa en un trozo como una función. Un fragmento debe ser relativamente independiente y centrarse en una sola tarea.\nLas siguientes secciones describen el encabezado del fragmento que consta de ```{r}, seguido de una etiqueta de fragmento opcional y varias otras opciones de fragmento, cada una en su propia línea, marcada por #|.\n\n29.5.1 Etiqueta de fragmento de código\nA los fragmento de código se les puede dar una etiqueta opcional, p.ej.\n\n```{r}\n#| label: simple-addition\n\n1 + 1\n```\n#&gt; [1] 2\n\nEsto tiene tres ventajas:\n\n\nPuede navegar más fácilmente a fragmentos específicos utilizando el navegador de código desplegable en la parte inferior izquierda del editor de secuencias de comandos:\n\n\n\n\n\n\n\n\n\nLos gráficos producidos por los fragmentos tendrán nombres útiles que los harán más fáciles de usar en otros lugares. Más sobre eso en Sección 29.6.\nPuede configurar redes de fragmentos almacenados en caché para evitar volver a realizar cálculos costosos en cada ejecución. Más sobre eso en Sección 29.8.\n\nLas etiquetas de fragmentos deben ser cortas pero sugerentes y no deben contener espacios. Recomendamos usar guiones (-) para separar palabras (en lugar de guiones bajos, _) y evitar otros caracteres especiales en las etiquetas de fragmentos.\nPor lo general, eres libre de etiquetar tu fragmento como quieras, pero hay un nombre de fragmento que imbuye un comportamiento especial: setup. Cuando esté en modo notebook, el fragmento denominado setup se ejecutará automáticamente una vez, antes de que se ejecute cualquier otro código.\nAdemás, las etiquetas de fragmentos no se pueden duplicar. Cada etiqueta de fragmento debe ser única.\n\n29.5.2 Opciones de fragmentos de código\nLa salida del fragmento se puede personalizar con opciones, campos proporcionados al encabezado del fragmento. Knitr proporciona casi 60 opciones que puede usar para personalizar sus fragmentos de código. Aquí cubriremos las opciones de fragmentos más importantes que usará con frecuencia. Puedes ver la lista completa en https://yihui.org/knitr/options.\nEl conjunto de opciones más importante controla si su bloque de código se ejecuta y qué resultados se insertan en el informe terminado:\n\neval: false impide que se evalúe el código. (Y obviamente si no se ejecuta el código, no se generarán resultados). Esto es útil para mostrar código de ejemplo o para deshabilitar un gran bloque de código sin comentar cada línea.\ninclude: false ejecuta el código, pero no muestra el código ni da como resultado el documento final. Úselo para el código de configuración que no desea que abarrote su informe.\necho: false evita que el código, pero no los resultados, aparezca en el archivo terminado. Use esto cuando escriba informes dirigidos a personas que no quieren ver el código R subyacente.\nmessage: false o warning: false evita que aparezcan mensajes o advertencias en el archivo terminado.\nresults: hide oculta la salida impresa; fig-show: hide oculta gráficas.\nerror: true hace que el procesamiento continúe incluso si el código devuelve un error. Esto rara vez es algo que desee incluir en la versión final de su informe, pero puede ser muy útil si necesita depurar exactamente lo que está sucediendo dentro de su .qmd. También es útil si está enseñando R y quiere incluir deliberadamente un error. El valor predeterminado error: false hace que la representación falle si hay un solo error en el documento.\n\nCada una de estas opciones de fragmento se agrega al encabezado del fragmento, después de #|, por ejemplo, en el siguiente fragmento, el resultado no se imprime ya que eval se establece en falso.\n\n```{r}\n#| label: simple-multiplication\n#| eval: false\n\n2 * 2\n```\n\nLa siguiente tabla resume qué tipos de salida suprime cada opción:\n\n\n\n\n\n\n\n\n\n\n\nOpción\nEjecutar código\nMostrar código\nSalida\nGráficas\nMensages\nAdvertencias\n\n\n\neval: false\nX\n\nX\nX\nX\nX\n\n\ninclude: false\n\nX\nX\nX\nX\nX\n\n\necho: false\n\nX\n\n\n\n\n\n\nresults: hide\n\n\nX\n\n\n\n\n\nfig-show: hide\n\n\n\nX\n\n\n\n\nmessage: false\n\n\n\n\nX\n\n\n\nwarning: false\n\n\n\n\n\nX\n\n\n\n29.5.3 Opciones globales\nA medida que trabaje más con knitr, descubrirá que algunas de las opciones de fragmentos predeterminadas no se ajustan a sus necesidades y querrá cambiarlas.\nPuede hacerlo agregando las opciones preferidas en el documento YAML, en execute. Por ejemplo, si está preparando un informe para una audiencia que no necesita ver su código sino solo sus resultados y narración, puede establecer echo: false en el nivel del documento. Eso ocultará el código de forma predeterminada, por lo que solo mostrará los fragmentos que elija mostrar deliberadamente (con echo: true). Podría considerar configurar message: false y warning: false, pero eso dificultaría la depuración de problemas porque no vería ningún mensaje en el documento final.\ntitle: \"My report\"\nexecute:\n  echo: false\nDado que Quarto está diseñado para ser multilingüe (funciona con R y otros lenguajes como Python, Julia, etc.), todas las opciones de knitr no están disponibles en el nivel de ejecución del documento, ya que algunas de ellas solo funcionan con knitr y no otros motores que usa Quarto para ejecutar código en otros lenguajes (por ejemplo, Jupyter). Sin embargo, aún puede configurarlas como opciones globales para su documento en el campo knitr, en opts_chunk. Por ejemplo, al escribir libros y tutoriales establecemos:\ntitle: \"Tutorial\"\nknitr:\n  opts_chunk:\n    comment: \"#&gt;\"\n    collapse: true\nEsto utiliza nuestro formato de comentario preferido y garantiza que el código y la salida se mantengan estrechamente entrelazados.\n\n29.5.4 código en línea\nHay otra forma de incrustar código R en un documento de Quarto: directamente en el texto, con: `r `. Esto puede ser muy útil si menciona propiedades de sus datos en el texto. Por ejemplo, el documento de ejemplo utilizado al comienzo del capítulo tenía:\n\nWe have data about `r nrow(diamonds)` diamonds. Only `r nrow(diamonds) - nrow(smaller)` are larger than 2.5 carats. The distribution of the remainder is shown below:\n\nCuando se presenta el informe, los resultados de estos cálculos se insertan en el texto:\n\nWe have data about 53940 diamonds. Only 126 are larger than 2.5 carats. The distribution of the remainder is shown below:\n\nAl insertar números en el texto, format() es tu amigo. Le permite configurar el número de digits para que no imprima con un grado ridículo de precisión, y una big.mark para que los números sean más fáciles de leer. Puede combinarlos en una función de ayuda:\n\ncomma &lt;- function(x) format(x, digits = 2, big.mark = \",\")\ncomma(3452345)\n#&gt; [1] \"3,452,345\"\ncomma(.12358124331)\n#&gt; [1] \"0.12\"\n\n\n29.5.5 Ejercicios\n\nAgregue una sección que explore cómo los tamaños de los diamantes varían según el corte, el color y la claridad. Suponga que está escribiendo un informe para alguien que no conoce R y, en lugar de establecer echo: false en cada fragmento, establezca una opción global.\nDescargue diamond-sizes.qmd desde https://github.com/hadley/r4ds/tree/main/quarto. Agregue una sección que describa los 20 diamantes más grandes, incluida una tabla que muestre sus atributos más importantes.\nModifique diamonds-sizes.qmd para usar label_comma() para producir una salida bien formateada. Incluya también el porcentaje de diamantes de más de 2,5 quilates.",
    "crumbs": [
      "Comunicar",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#tablas",
    "href": "quarto.html#tablas",
    "title": "29  Quarto",
    "section": "\n29.7 Tablas",
    "text": "29.7 Tablas\nAl igual que las figuras, puede incluir dos tipos de tablas en un documento Quarto. Pueden ser tablas de markdown que crea directamente en su documento Quarto (usando el menú Insert table) o pueden ser tablas generadas como resultado de un fragmento de código. En esta sección nos centraremos en las últimas, tablas generadas mediante computación.\nDe forma predeterminada, Quarto imprime data frames y matrices como los vería en la consola:\n\nmtcars[1:5, ]\n#&gt;                    mpg cyl disp  hp drat    wt  qsec vs am gear carb\n#&gt; Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\n#&gt; Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\n#&gt; Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\n#&gt; Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\n#&gt; Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\n\nSi prefiere que los datos se muestren con un formato adicional, puede usar la función knitr::kable(). El siguiente código genera Tabla 29.1.\n\nknitr::kable(mtcars[1:5, ], )\n\n\nTabla 29.1: A knitr kable.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmpg\ncyl\ndisp\nhp\ndrat\nwt\nqsec\nvs\nam\ngear\ncarb\n\n\n\nMazda RX4\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\nMazda RX4 Wag\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\nDatsun 710\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\nHornet 4 Drive\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\nHornet Sportabout\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\n\n\n\n\n\n\nLee la documentación de ?knitr::kable para ver otras formas en las que puedes personalizar la tabla. Para una personalización aún más profunda, considere gt, huxtable, reactable, kableExtra, xtable, stargazer, pander, * Paquetes *tables y ascii**. Cada uno proporciona un conjunto de herramientas para devolver tablas formateadas desde el código R.\n\n29.7.1 Ejercicios\n\nAbra diamond-sizes.qmd en el editor visual, inserte un fragmento de código y agregue una tabla con knitr::kable() que muestre las primeras 5 filas del data frame diamonds.\nMuestre la misma tabla con gt::gt() en su lugar.\nAgregue una etiqueta de fragmento que comience con el sufijo tbl- y agregue un título a la tabla con la opción de fragmento tbl-cap. Luego, edite el texto sobre el fragmento de código para agregar una referencia cruzada a la tabla con Insert &gt; Cross Reference.",
    "crumbs": [
      "Comunicar",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#solución-de-problemas",
    "href": "quarto.html#solución-de-problemas",
    "title": "29  Quarto",
    "section": "\n29.9 Solución de problemas",
    "text": "29.9 Solución de problemas\nLa solución de problemas de documentos Quarto puede ser un desafío porque ya no se encuentra en un entorno R interactivo y deberá aprender algunos trucos nuevos. Además, el error podría deberse a problemas con el propio documento Quarto o al código R en el documento Quarto.\nUn error común en los documentos con fragmentos de código son las etiquetas de fragmentos duplicados, que son especialmente frecuentes si su flujo de trabajo implica copiar y pegar fragmentos de código. Para solucionar este problema, todo lo que necesita hacer es cambiar una de sus etiquetas duplicadas.\nSi los errores se deben al código R del documento, lo primero que debes intentar siempre es recrear el problema en una sesión interactiva. Reinicie R, luego “Ejecute todos los fragmentos” ya sea desde el menú Código, en la región Ejecutar, o con el atajo de teclado Ctrl + Alt + R. Si tiene suerte, eso recreará el problema y podrá averiguar qué está pasando de forma interactiva.\nSi eso no ayuda, debe haber algo diferente entre su entorno interactivo y el entorno de Quarto. Vas a necesitar explorar sistemáticamente las opciones. La diferencia más común es el directorio de trabajo: el directorio de trabajo de Quarto es el directorio en el que vive. Comprueba que el directorio de trabajo es lo que esperas al incluir getwd() en un fragmento.\nA continuación, haga una lluvia de ideas sobre todas las cosas que podrían causar el error. Deberá verificar sistemáticamente que sean iguales en su sesión R y en su sesión Quarto. La forma más fácil de hacerlo es configurar error: true en el fragmento que causa el problema, luego usar print() y str() para verificar que la configuración sea la esperada.",
    "crumbs": [
      "Comunicar",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#encabezado-yaml",
    "href": "quarto.html#encabezado-yaml",
    "title": "29  Quarto",
    "section": "\n29.10 Encabezado YAML",
    "text": "29.10 Encabezado YAML\nPuede controlar muchas otras configuraciones de “documento completo” ajustando los parámetros del encabezado YAML. Quizás se pregunte qué significa YAML: es “YAML Ain’t Markup Language”, que está diseñado para representar datos jerárquicos de una manera que sea fácil de leer y escribir para los humanos. Quarto lo usa para controlar muchos detalles de la salida. Aquí discutiremos tres: documentos independientes, parámetros de documentos y bibliografías.\n\n29.10.1 Independientes\nLos documentos HTML suelen tener una serie de dependencias externas (por ejemplo, imágenes, hojas de estilo CSS, JavaScript, etc.) y, de forma predeterminada, Quarto coloca estas dependencias en una carpeta _files en el mismo directorio que su archivo .qmd. Si publica el archivo HTML en una plataforma de alojamiento (p. ej., QuartoPub, https://quartopub.com/), las dependencias de este directorio se publican con su documento y, por lo tanto, están disponibles en el informe publicado. Sin embargo, si desea enviar el informe por correo electrónico a un colega, es posible que prefiera tener un documento HTML único e independiente que incorpore todas sus dependencias. Puedes hacer esto especificando la opción embed-resources:\nformat:\n  html:\n    embed-resources: true\nEl archivo resultante será autónomo, por lo que no necesitará archivos externos ni acceso a Internet para que un navegador lo muestre correctamente.\n\n29.10.2 Parámetros\nLos documentos Quarto pueden incluir uno o más parámetros cuyos valores se pueden establecer al representar el informe. Los parámetros son útiles cuando desea volver a representar el mismo informe con valores distintos para varias entradas clave. Por ejemplo, podría generar informes de ventas por sucursal, resultados de exámenes por estudiante o resúmenes demográficos por país. Para declarar uno o más parámetros, utilice el campo params.\nEste ejemplo usa un parámetro my_class para determinar qué clase de autos mostrar:\n\n---\noutput: html\nparams:\n  my_class: \"suv\"\n---\n\n```{r}\n#| label: setup\n#| include: false\n\nlibrary(tidyverse)\n\nclass &lt;- mpg |&gt; filter(class == params$my_class)\n```\n\n# Fuel economy for `r params$my_class`s\n\n```{r}\n#| message: false\n\nggplot(class, aes(x = displ, y = hwy)) + \n  geom_point() + \n  geom_smooth(se = FALSE)\n```\n\nComo puede ver, los parámetros están disponibles dentro de los fragmentos de código como una lista de solo lectura llamada params.\nPuede escribir vectores atómicos directamente en el encabezado YAML. También puede ejecutar expresiones R arbitrarias anteponiendo el valor del parámetro con !expr. Esta es una buena forma de especificar parámetros de fecha/hora.\nparams:\n  start: !expr lubridate::ymd(\"2015-01-01\")\n  snapshot: !expr lubridate::ymd_hms(\"2015-01-01 12:30:00\")\n\n29.10.3 Bibliografías y citas\nQuarto puede generar automáticamente citas y una bibliografía en varios estilos. La forma más sencilla de agregar citas y bibliografías a un documento Quarto es usar el editor visual en RStudio.\nPara agregar una cita usando el editor visual, vaya a Insert &gt; Citation. Citations se puede insertar desde una variedad de fuentes:\n\nDOI (Identificador de objeto de documento) referencias.\nZotero bibliotecas personales o de grupo.\nBúsquedas de Crossref, DataCite, o PubMed.\nLa bibliografía de su documento (un archivo .bib en el directorio de su documento)\n\nDebajo del capó, el modo visual utiliza la representación de markdown estándar de Pandoc para las citas (por ejemplo, [@citation]).\nSi agrega una cita utilizando uno de los primeros tres métodos, el editor visual creará automáticamente un archivo bibliography.bib y le agregará la referencia. También agregará un campo bibliography al documento YAML. A medida que agregue más referencias, este archivo se completará con sus citas. También puede editar directamente este archivo utilizando muchos formatos de bibliografía comunes, incluidos BibLaTeX, BibTeX, EndNote, Medline.\nPara crear una cita dentro de su archivo .qmd en el editor de código fuente, use una clave compuesta por ‘@’ + el identificador de cita del archivo de bibliografía. Luego coloque la cita entre corchetes. Aquí hay unos ejemplos:\nSepare las citas múltiples con un `;`: Bla bla [@smith04; @doe99].\n\nPuede agregar comentarios arbitrarios dentro de los corchetes: \nBla bla [vea @doe99, pág. 33-35; también @smith04, cáp. 1].\n\nElimina los corchetes para crear una cita en el texto: @smith04 \ndice bla, o @smith04 [pág. 33] dice bla.\n\nAgregue un `-` antes de la cita para suprimir el nombre del autor: \n\nSmith dice bla [-@smith04].\nCuando Quarto renderice su archivo, creará y agregará una bibliografía al final de su documento. La bibliografía contendrá cada una de las referencias citadas de su archivo de bibliografía, pero no contendrá un encabezado de sección. Como resultado, es una práctica común terminar su archivo con un encabezado de sección para la bibliografía, como # Referencias o # Bibliografía.\nPuede cambiar el estilo de sus citas y bibliografía haciendo referencia a un archivo CSL (lenguaje de estilo de citas) en el campo csl:\nbibliography: rmarkdown.bib\ncsl: apa.csl\nAl igual que con el campo de bibliografía, su archivo csl debe contener una ruta al archivo. Aquí asumimos que el archivo csl está en el mismo directorio que el archivo .qmd. Un buen lugar para encontrar archivos de estilo CSL para estilos de bibliografía comunes es https://github.com/citation-style-language/styles.",
    "crumbs": [
      "Comunicar",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#flujo-de-trabajo",
    "href": "quarto.html#flujo-de-trabajo",
    "title": "29  Quarto",
    "section": "\n29.11 Flujo de trabajo",
    "text": "29.11 Flujo de trabajo\nAnteriormente, discutimos un flujo de trabajo básico para capturar su código R donde trabaja de forma interactiva en la consola, luego captura lo que funciona en el editor de scripts. Quarto reúne la consola y el editor de secuencias de comandos, desdibujando las líneas entre la exploración interactiva y la captura de código a largo plazo. Puede iterar rápidamente dentro de un fragmento, editar y volver a ejecutar con Cmd/Ctrl + Shift + Enter. Cuando estás feliz, sigues adelante y comienzas una nueva etapa.\nQuarto también es importante porque integra muy estrechamente la prosa y el código. Esto lo convierte en un excelente cuaderno de análisis porque le permite desarrollar código y registrar sus pensamientos. Un cuaderno de análisis comparte muchos de los mismos objetivos que un cuaderno de laboratorio clásico en las ciencias físicas. Quarto:\n\nRegistra lo que hiciste y por qué lo hiciste. Por muy buena que sea tu memoria, si no registras lo que haces, llegará un momento en que habrás olvidado detalles importantes. ¡Escríbelas para que no las olvides!\nApoya el pensamiento riguroso. Es más probable que obtenga un análisis sólido si registra sus pensamientos a medida que avanza y continúa reflexionando sobre ellos. Esto también le ahorra tiempo cuando eventualmente escribe su análisis para compartirlo con otros.\nAyuda a otros a entender su trabajo. Es raro que haga el análisis de datos usted mismo y, a menudo, trabajará como parte de un equipo. Un cuaderno de laboratorio lo ayuda a compartir no solo lo que ha hecho, sino también por qué lo hizo con sus colegas o compañeros de laboratorio.\n\nGran parte de los buenos consejos sobre el uso efectivo de los cuadernos de laboratorio también se pueden traducir en cuadernos de análisis. Nos hemos basado en nuestras propias experiencias y en los consejos de Colin Purrington sobre cuadernos de laboratorio (https://colinpurrington.com/tips/lab-notebooks) para llegar a los siguientes consejos:\n\nAsegúrese de que cada cuaderno tenga un título descriptivo, un nombre de archivo sugerente y un primer párrafo que describa brevemente los objetivos del análisis.\n\nUse el campo de fecha del encabezado YAML para registrar la fecha en que comenzó a trabajar en el cuaderno:\ndate: 2016-08-23\nUse ISO8601 YYYY-MM-DD formato para que no haya ambigüedad. ¡Úselo incluso si normalmente no escribe las fechas de esa manera!\n\nSi dedica mucho tiempo a una idea de análisis y resulta ser un callejón sin salida, ¡no la elimine! Escriba una breve nota sobre por qué falló y déjela en el cuaderno. Eso le ayudará a evitar caer en el mismo callejón sin salida cuando vuelva al análisis en el futuro.\nEn general, es mejor ingresar datos fuera de R. Pero si necesita registrar un pequeño fragmento de datos, expóngalo claramente usando tibble::tribble().\nSi descubre un error en un archivo de datos, nunca lo modifique directamente, sino que escriba código para corregir el valor. Explique por qué hizo la corrección.\nAntes de terminar el día, asegúrese de poder renderizar el cuaderno. Si está utilizando el almacenamiento en caché, asegúrese de borrar los cachés. Eso le permitirá solucionar cualquier problema mientras el código aún está fresco en su mente.\nSi desea que su código sea reproducible a largo plazo (es decir, para que pueda volver a ejecutarlo el próximo mes o el próximo año), deberá realizar un seguimiento de las versiones de los paquetes que utiliza su código. Un enfoque riguroso es usar renv, https://rstudio.github.io/renv/index.html, que almacena paquetes en el directorio de su proyecto. Un truco rápido y sucio es incluir un trozo que ejecute sessionInfo() — que no le permitirá recrear fácilmente sus paquetes como son hoy, pero al menos sabrá lo que eran.\nVas a crear muchos, muchos cuadernos de análisis a lo largo de tu carrera. ¿Cómo los va a organizar para poder encontrarlos nuevamente en el futuro? Recomendamos almacenarlos en proyectos individuales y crear un buen esquema de nombres.",
    "crumbs": [
      "Comunicar",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "quarto.html#resumen",
    "href": "quarto.html#resumen",
    "title": "29  Quarto",
    "section": "\n29.12 Resumen",
    "text": "29.12 Resumen\nEn este capítulo, le presentamos Quarto para crear y publicar documentos computacionales reproducibles que incluyen su código y su prosa en un solo lugar. Aprendió a escribir documentos de Quarto en RStudio con el editor visual o de código fuente, cómo funcionan los fragmentos de código y cómo personalizar las opciones para ellos, cómo incluir figuras y tablas en sus documentos de Quarto y opciones de almacenamiento en caché para cálculos. Además, aprendió a ajustar las opciones de encabezado YAML para crear documentos independientes o parametrizados, así como a incluir citas y bibliografía. También le hemos dado algunos consejos para la resolución de problemas y el flujo de trabajo.\nSi bien esta introducción debería ser suficiente para comenzar con Quarto, aún queda mucho por aprender. Quarto es todavía relativamente joven y sigue creciendo rápidamente. El mejor lugar para estar al tanto de las innovaciones es el sitio web oficial de Quarto: https://quarto.org.\nHay dos temas importantes que no hemos cubierto aquí: la colaboración y los detalles de comunicar con precisión sus ideas a otros humanos. La colaboración es una parte vital de la ciencia de datos moderna y puede hacer su vida mucho más fácil utilizando herramientas de control de versiones, como Git y GitHub. Recomendamos “Happy Git with R”, una introducción fácil de usar a Git y GitHub de usuarios de R, por Jenny Bryan. El libro está disponible gratuitamente en línea: https://happygitwithr.com.\nTampoco hemos mencionado lo que realmente debe escribir para comunicar claramente los resultados de su análisis. Para mejorar su escritura, recomendamos leer Style: Lessons in Clarity and Grace de Joseph M. Williams & Joseph Bizup, o The Sense of Structure: Writing from the Reader’s Perspective de George Gopen. Ambos libros lo ayudarán a comprender la estructura de oraciones y párrafos, y le brindarán las herramientas para que su escritura sea más clara. (Estos libros son bastante caros si se compran nuevos, pero muchas clases de inglés los usan, por lo que hay muchas copias baratas de segunda mano). George Gopen también tiene una serie de artículos breves sobre escritura en https://www.georgegopen.com/litigation-articles.html. Están dirigidos a abogados, pero casi todo se aplica también a los científicos de datos.",
    "crumbs": [
      "Comunicar",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "workflow-scripts.html",
    "href": "workflow-scripts.html",
    "title": "7  Flujo de trabajo: scripts y proyectos",
    "section": "",
    "text": "7.1 Scripts\nHasta ahora, ha utilizado la consola para ejecutar código. Ese es un excelente lugar para comenzar, pero encontrará que se atasca bastante rápido a medida que crea gráficos ggplot2 más complejos y canalizaciones dplyr más largas. Para disponer de más espacio para trabajar, utilice el editor de secuencias de comandos. Ábralo haciendo clic en el menú Archivo, seleccionando Nuevo archivo, luego R script, o usando el atajo de teclado Cmd/Ctrl + Shift + N. Ahora verá cuatro paneles, como en Figura 7.1. El editor de secuencias de comandos es un gran lugar para experimentar con su código. Cuando desee cambiar algo, no tiene que volver a escribirlo todo, simplemente puede editar el script y volver a ejecutarlo. Y una vez que haya escrito el código que funciona y hace lo que desea, puede guardarlo como un archivo de secuencia de comandos para volver fácilmente a él más tarde.\nFigura 7.1: Al abrir el editor de secuencias de comandos, se agrega un nuevo panel en la parte superior izquierda de la IDE.",
    "crumbs": [
      "El Juego Completo",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Flujo de trabajo: scripts y proyectos</span>"
    ]
  },
  {
    "objectID": "workflow-scripts.html#scripts",
    "href": "workflow-scripts.html#scripts",
    "title": "7  Flujo de trabajo: scripts y proyectos",
    "section": "",
    "text": "7.1.1 Código en ejecución\nEl editor de secuencias de comandos es un lugar excelente para crear gráficas de ggplot2 complejas o largas secuencias de manipulaciones de dplyr. La clave para usar el editor de secuencias de comandos de manera efectiva es memorizar uno de los atajos de teclado más importantes: Cmd/Ctrl + Enter. Esto ejecuta la expresión de R actual en la consola. Por ejemplo, tome el siguiente código.\n\nlibrary(dplyr)\nlibrary(nycflights13)\n\nnot_cancelled &lt;- flights |&gt; \n  filter(!is.na(dep_delay)█, !is.na(arr_delay))\n\nnot_cancelled |&gt; \n  group_by(year, month, day) |&gt; \n  summarize(mean = mean(dep_delay))\n\nSi su cursor está en █, al presionar Cmd/Ctrl + Enter se ejecutará el comando completo que genera not_cancelled. También moverá el cursor a la siguiente declaración (comenzando con not_cancelled |&gt;). Eso hace que sea más fácil recorrer el script completo presionando repetidamente Cmd/Ctrl + Enter.\nEn lugar de ejecutar su código expresión por expresión, también puede ejecutar el script completo en un solo paso con Cmd/Ctrl + Shift + S. Hacer esto regularmente es una excelente manera de asegurarse de haber capturado todas las partes importantes de su código en el script.\nLe recomendamos que siempre comience su script con los paquetes que necesita. De esa forma, si comparte su código con otras personas, pueden ver fácilmente qué paquetes necesitan instalar. Tenga en cuenta, sin embargo, que nunca debe incluir install.packages() en un script que comparta. ¡Es desconsiderado entregar un script que cambiará algo en su computadora si no tienen cuidado!\nCuando trabaje en capítulos futuros, le recomendamos que comience con el editor de scripts y practique los atajos de teclado. Con el tiempo, enviar código a la consola de esta manera se volverá tan natural que ni siquiera pensará en ello.\n\n7.1.2 Diagnósticos de RStudio\nEn el editor de secuencias de comandos, RStudio resaltará los errores de sintaxis con una línea ondulada roja y una cruz en la barra lateral:\n\n\n\n\n\n\n\n\nPase el cursor sobre la cruz para ver cuál es el problema:\n\n\n\n\n\n\n\n\nRStudio también le informará sobre posibles problemas:\n\n\n\n\n\n\n\n\n\n7.1.3 Guardar y nombrar\nRStudio guarda automáticamente el contenido del editor de secuencias de comandos cuando sale y lo vuelve a cargar automáticamente cuando lo vuelve a abrir. Sin embargo, es una buena idea evitar Untitled1, Untitled2, Untitled3, etc. y, en su lugar, guardar sus scripts y darles nombres informativos.\nPuede ser tentador nombrar sus archivos code.R o miscript.R, pero debe pensar un poco más antes de elegir un nombre para su archivo. Tres principios importantes para la denominación de archivos son los siguientes:\n\nLos nombres de los archivos deben ser legibles por máquina: evite espacios, símbolos y caracteres especiales. No confíe en la distinción entre mayúsculas y minúsculas para distinguir archivos.\nLos nombres de los archivos deben ser legibles por personas: use nombres de archivos para describir lo que hay en el archivo.\nLos nombres de archivo deberían funcionar bien con el orden predeterminado: comience los nombres de archivo con números para que la ordenación alfabética los coloque en el orden en que se usan.\n\nPor ejemplo, suponga que tiene los siguientes archivos en una carpeta de proyecto.\nalternative model.R\ncode for exploratory analysis.r\nfinalreport.qmd\nFinalReport.qmd\nfig 1.png\nFigure_02.png\nmodel_first_try.R\nrun-first.r\ntemp.txt\nHay una variedad de problemas aquí: es difícil encontrar qué archivo ejecutar primero, los nombres de los archivos contienen espacios, hay dos archivos con el mismo nombre pero con mayúsculas diferentes (finalreport vs. FinalReport[^workflow-scripts-1 ]), y algunos nombres no describen su contenido (run-first y temp).\nAquí hay una mejor manera de nombrar y organizar el mismo conjunto de archivos:\n01-load-data.R\n02-exploratory-analysis.R\n03-model-approach-1.R\n04-model-approach-2.R\nfig-01.png\nfig-02.png\nreport-2022-03-20.qmd\nreport-2022-04-02.qmd\nreport-draft-notes.txt\nLa numeración de los scripts clave hace que sea obvio en qué orden ejecutarlos y un esquema de nombres consistente hace que sea más fácil ver qué varía. Además, las cifras se etiquetan de manera similar, los informes se distinguen por las fechas incluidas en los nombres de los archivos y se cambia el nombre de temp a report-draft-notes para describir mejor su contenido. Si tiene muchos archivos en un directorio, se recomienda llevar la organización un paso más allá y colocar diferentes tipos de archivos (guiones, figuras, etc.) en diferentes directorios.",
    "crumbs": [
      "El Juego Completo",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Flujo de trabajo: scripts y proyectos</span>"
    ]
  },
  {
    "objectID": "workflow-scripts.html#proyectos",
    "href": "workflow-scripts.html#proyectos",
    "title": "7  Flujo de trabajo: scripts y proyectos",
    "section": "\n7.2 Proyectos",
    "text": "7.2 Proyectos\nUn día, deberá salir de R, hacer otra cosa y volver a su análisis más tarde. Un día, estará trabajando en múltiples análisis simultáneamente y querrá mantenerlos separados. Un día, deberá traer datos del mundo exterior a R y enviar resultados numéricos y cifras de R al mundo.\nPara manejar estas situaciones de la vida real, debe tomar dos decisiones:\n\n¿Cuál es la fuente de la verdad? ¿Qué guardará como registro duradero de lo que sucedió?\n¿Dónde vive su análisis?\n\n\n7.2.1 ¿Cuál es la fuente de la verdad?\nComo principiante, está bien confiar en su entorno actual para contener todos los objetos que ha creado a lo largo de su análisis. Sin embargo, para que sea más fácil trabajar en proyectos más grandes o colaborar con otros, su fuente de verdad deben ser los scripts R. Con sus scripts de R (y sus archivos de datos), puede recrear el entorno. Solo con su entorno, es mucho más difícil recrear sus scripts de R: tendrá que volver a escribir una gran cantidad de código de la memoria (inevitablemente cometiendo errores en el camino) o tendrá que extraer cuidadosamente su historial de R.\nPara ayudar a mantener sus scripts de R como la fuente de la verdad para su análisis, le recomendamos que indique a RStudio que no conserve su espacio de trabajo entre sesiones. Puede hacer esto ejecutando usethis::use_blank_slate()1 o imitando las opciones que se muestran en Figura 7.2. Esto le causará un poco de dolor a corto plazo, porque ahora, cuando reinicie RStudio, ya no recordará el código que ejecutó la última vez ni los objetos que creó o los conjuntos de datos que leyó estarán disponibles para su uso. Pero este dolor a corto plazo le ahorra una agonía a largo plazo porque lo obliga a capturar todas los procedimientos importantes en su código. No hay nada peor que descubrir tres meses después del hecho de que solo almacenó los resultados de un cálculo importante en su entorno, no el cálculo en sí mismo en su código.\n\n\n\n\n\n\n\nFigura 7.2: Copie estas opciones en sus opciones de RStudio para iniciar siempre su sesión de RStudio con borrón y cuenta nueva.\n\n\n\n\nHay un gran par de atajos de teclado que funcionarán juntos para asegurarse de que ha capturado las partes importantes de su código en el editor:\n\nPresione Cmd/Ctrl + Shift + 0/F10 para reiniciar R.\nPresione Cmd/Ctrl + Shift + S para volver a ejecutar el script actual.\n\nUsamos colectivamente este patrón cientos de veces a la semana.\nAlternativamente, si no usa atajos de teclado, puede ir a Sesión &gt; Reiniciar R y luego resaltar y volver a ejecutar su secuencia de comandos actual.\n\n\n\n\n\n\nServidor RStudio\n\n\n\nSi está utilizando el servidor RStudio, su sesión R nunca se reinicia de manera predeterminada. Cuando cierra la pestaña del servidor RStudio, puede parecer que está cerrando R, pero el servidor en realidad lo mantiene funcionando en segundo plano. La próxima vez que regrese, estará exactamente en el mismo lugar donde se fue. Esto hace que sea aún más importante reiniciar R regularmente para que comience con una lista de actualización.\n\n\n\n7.2.2 ¿Dónde vive su análisis?\nR tiene una poderosa noción del directorio de trabajo. Aquí es donde R busca los archivos que le pides que cargue, y donde colocará los archivos que le pides que guarde. RStudio muestra su directorio de trabajo actual en la parte superior de la consola:\n\n\n\n\n\n\n\n\nY puede imprimir esto en código de R ejecutando getwd():\n\ngetwd()\n#&gt; [1] \"/Users/hadley/Documents/r4ds\"\n\nEn esta sesión de R, el directorio de trabajo actual (piense en él como “inicio”) está en la carpeta Documentos de hadley, en una subcarpeta llamada r4ds. Este código devolverá un resultado diferente cuando lo ejecute, porque su computadora tiene una estructura de directorio diferente a la de Hadley.\nComo usuario principiante de R, está bien dejar que su directorio de trabajo sea su directorio de inicio, directorio de documentos o cualquier otro directorio extraño en su computadora. Pero llevas varios capítulos en este libro y ya no eres un principiante. Muy pronto debería evolucionar para organizar sus proyectos en directorios y, cuando trabaje en un proyecto, establecer el directorio de trabajo de R en el directorio asociado.\nPuede configurar el directorio de trabajo desde R pero nosotros no lo recomendamos:\n\nsetwd(\"/path/to/my/CoolProject\")\n\nHay una mejor manera; una manera que también lo coloca en el camino para administrar su trabajo de R como un experto. Así es el proyecto de RStudio.\n\n7.2.3 Proyectos de RStudio\nMantener todos los archivos asociados con un proyecto determinado (datos de entrada, scripts R, resultados analíticos y figuras) juntos en un directorio es una práctica tan sabia y común que RStudio tiene soporte incorporado para esto a través de proyectos. Hagamos un proyecto para que lo use mientras trabaja en el resto de este libro. Haga clic en Archivo &gt; Nuevo proyecto, luego siga los pasos que se muestran en Figura 7.3.\n\n\n\n\n\n\n\nFigura 7.3: Para crear un nuevo proyecto: (arriba) primero haga clic en Nuevo directorio, luego (en el medio) haga clic en Nuevo proyecto, luego (abajo) complete el nombre del directorio (proyecto), elija un buen subdirectorio para su inicio y haga clic en Crear proyecto.\n\n\n\n\nLlame a su proyecto r4ds y piense detenidamente en qué subdirectorio coloca el proyecto. Si no lo guarda en un lugar sensato, ¡será difícil encontrarlo en el futuro!\nUna vez que se complete este proceso, obtendrá un nuevo proyecto de RStudio solo para este libro. Verifique que el “hogar” de su proyecto sea el directorio de trabajo actual:\n\ngetwd()\n#&gt; [1] /Users/hadley/Documents/r4ds\n\nAhora ingrese los siguientes comandos en el editor de secuencias de comandos y guarde el archivo, llamándolo “diamantes.R”. Luego, cree una nueva carpeta llamada “datos”. Puede hacerlo haciendo clic en el botón “Nueva carpeta” en el panel Archivos en RStudio. Finalmente, ejecute el script completo que guardará un archivo PNG y CSV en el directorio de su proyecto. No se preocupe por los detalles, los aprenderá más adelante en el libro.\n\nlibrary(tidyverse)\n\nggplot(diamonds, aes(x = carat, y = price)) + \n  geom_hex()\nggsave(\"diamonds.png\")\n\nwrite_csv(diamonds, \"datos/diamonds.csv\")\n\nSalga de RStudio. Inspeccione la carpeta asociada con su proyecto — observe el archivo .Rproj. Haga doble clic en ese archivo para volver a abrir el proyecto. Observe que vuelve a donde lo dejó: es el mismo directorio de trabajo e historial de comandos, y todos los archivos en los que estaba trabajando todavía están abiertos. Sin embargo, debido a que siguió nuestras instrucciones anteriores, tendrá un entorno completamente nuevo, lo que garantiza que está comenzando desde cero.\nDe la forma específica de su sistema operativo favorito, busque diamonds.png en su computadora y encontrará el PNG (no es de extrañar), pero también el script que lo creó (diamonds.R). ¡Esta es una gran victoria! Un día querrás rehacer una figura o simplemente entender de dónde vino. Si guarda rigurosamente las figuras en archivos con código de R y nunca con el mouse o el portapapeles, ¡podrá reproducir trabajos antiguos con facilidad!\n\n7.2.4 Rutas relativas y absolutas\nUna vez que esté dentro de un proyecto, solo debe usar rutas relativas, no rutas absolutas. ¿Cual es la diferencia? Una ruta relativa es relativa al directorio de trabajo, es decir, el hogar del proyecto. Cuando Hadley escribió data/diamonds.csv arriba, era un atajo para /Users/hadley/Documents/r4ds/data/diamonds.csv. Pero lo que es más importante, si Mine ejecutara este código en su computadora, apuntaría a /Users/Mine/Documents/r4ds/data/diamonds.csv. Esta es la razón por la que las rutas relativas son importantes: funcionarán independientemente de dónde termine la carpeta del proyecto R.\nLas rutas absolutas apuntan al mismo lugar independientemente de su directorio de trabajo. Se ven un poco diferentes dependiendo de su sistema operativo. En Windows, comienzan con una letra de unidad (por ejemplo, C:) o dos barras invertidas (por ejemplo, \\\\servername) y en Mac/Linux comienzan con una barra inclinada “/” (por ejemplo, /users/hadley). Nunca debe usar rutas absolutas en sus scripts, porque dificultan el uso compartido: nadie más tendrá exactamente la misma configuración de directorio que usted.\nHay otra diferencia importante entre los sistemas operativos: cómo se separan los componentes de la ruta. Mac y Linux usan barras inclinadas (por ejemplo, data/diamonds.csv) y Windows usa barras invertidas (por ejemplo, data\\diamonds.csv). R puede funcionar con cualquier tipo (sin importar qué plataforma esté usando actualmente), pero desafortunadamente, las barras invertidas significan algo especial para R, y para obtener una sola barra invertida en la ruta, ¡debe escribir dos barras invertidas! Eso hace que la vida sea frustrante, por lo que recomendamos usar siempre el estilo Linux/Mac con barras diagonales.",
    "crumbs": [
      "El Juego Completo",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Flujo de trabajo: scripts y proyectos</span>"
    ]
  },
  {
    "objectID": "workflow-scripts.html#ejercicios",
    "href": "workflow-scripts.html#ejercicios",
    "title": "7  Flujo de trabajo: scripts y proyectos",
    "section": "\n7.3 Ejercicios",
    "text": "7.3 Ejercicios\n\nVaya a la cuenta de Twitter RStudio Tips, https://twitter.com/rstudiotips y encuentre un consejo que parezca interesante. ¡Practica usarlo!\n¿Qué otros errores comunes informará el diagnóstico de RStudio? Lea https://support.posit.co/hc/en-us/articles/205753617-Code-Diagnostics para averiguarlo.",
    "crumbs": [
      "El Juego Completo",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Flujo de trabajo: scripts y proyectos</span>"
    ]
  },
  {
    "objectID": "workflow-scripts.html#resumen",
    "href": "workflow-scripts.html#resumen",
    "title": "7  Flujo de trabajo: scripts y proyectos",
    "section": "\n7.4 Resumen",
    "text": "7.4 Resumen\nEn este capítulo, ha aprendido a organizar su código R en scripts (archivos) y proyectos (directorios). Al igual que el estilo de código, esto puede parecer un trabajo pesado al principio. Pero a medida que acumule más código en múltiples proyectos, aprenderá a apreciar cómo un poco de organización inicial puede ahorrarle mucho tiempo en el futuro.\nEn resumen, los guiones y los proyectos le brindan un flujo de trabajo sólido que le será útil en el futuro:\n\nCree un proyecto de RStudio para cada proyecto de análisis de datos.\nGuarde sus scripts (con nombres informativos) en el proyecto, edítelos, ejecútelos en bits o como un todo. Reinicie R con frecuencia para asegurarse de haber capturado todo en sus scripts.\nSolo use rutas relativas, no rutas absolutas.\n\nEntonces todo lo que necesita está en un solo lugar y claramente separado de todos los demás proyectos en los que está trabajando.\nHasta ahora, hemos trabajado con conjuntos de datos incluidos en paquetes de R. Esto hace que sea más fácil obtener algo de práctica con datos preparados previamente, pero obviamente sus datos no estarán disponibles de esta manera. Entonces, en el próximo capítulo, aprenderá cómo cargar datos desde el disco en su sesión R usando el paquete readr.",
    "crumbs": [
      "El Juego Completo",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Flujo de trabajo: scripts y proyectos</span>"
    ]
  },
  {
    "objectID": "workflow-scripts.html#footnotes",
    "href": "workflow-scripts.html#footnotes",
    "title": "7  Flujo de trabajo: scripts y proyectos",
    "section": "",
    "text": "Si no tiene instalado usethis, puede instalarlo con install.packages(\"usethis\").↩︎",
    "crumbs": [
      "El Juego Completo",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Flujo de trabajo: scripts y proyectos</span>"
    ]
  },
  {
    "objectID": "logicals.html",
    "href": "logicals.html",
    "title": "13  Vectores lógicos",
    "section": "",
    "text": "13.1 Introducción\nEn este capítulo, aprenderá herramientas para trabajar con vectores lógicos. Los vectores lógicos son el tipo de vector más simple porque cada elemento solo puede tener uno de tres valores posibles: TRUE, TRUE, FALSE, FALSE y faltante, NA. Es relativamente raro encontrar vectores lógicos en sus datos sin procesar, pero los creará y manipulará en el curso de casi todos los análisis.\nComenzaremos discutiendo la forma más común de crear vectores lógicos: con comparaciones numéricas. Luego, aprenderá cómo puede usar el álgebra booleana para combinar diferentes vectores lógicos, así como algunos resúmenes útiles. Terminaremos con if_else() y case_when(), dos funciones útiles para realizar cambios condicionales impulsados por vectores lógicos.",
    "crumbs": [
      "Transformar",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Vectores lógicos</span>"
    ]
  },
  {
    "objectID": "numbers.html",
    "href": "numbers.html",
    "title": "14  Números",
    "section": "",
    "text": "14.1 Introducción\nLos vectores numéricos son la columna vertebral de la ciencia de datos y ya los ha usado varias veces anteriormente en el libro. Ahora es el momento de examinar sistemáticamente lo que puede hacer con ellos en R, asegurándose de estar bien situado para abordar cualquier problema futuro que involucre vectores numéricos.\nComenzaremos brindándole un par de herramientas para hacer números si tiene cadenas, y luego entraremos en un poco más de detalle de count(). Luego nos sumergiremos en varias transformaciones numéricas que combinan bien con mutate(), incluidas transformaciones más generales que se pueden aplicar a otros tipos de vectores, pero que a menudo se usan con vectores numéricos. Terminaremos cubriendo las funciones de resumen que combinan bien con summarize() y le mostraremos cómo también se pueden usar con mutate().",
    "crumbs": [
      "Transformar",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Números</span>"
    ]
  },
  {
    "objectID": "numbers.html#resúmenes-numéricos",
    "href": "numbers.html#resúmenes-numéricos",
    "title": "14  Números",
    "section": "\n14.6 Resúmenes numéricos",
    "text": "14.6 Resúmenes numéricos\nEl solo uso de los recuentos, medios y sumas que ya hemos presentado puede ayudarlo mucho, pero R proporciona muchas otras funciones de resumen útiles. Aquí hay una selección que puede resultarle útil.\n\n14.6.1 Centrar\nHasta ahora, hemos usado principalmente mean() para resumir el centro de un vector de valores. Como hemos visto en Sección 4.6, debido a que la media es la suma dividida por el recuento, es sensible incluso a unos pocos valores inusualmente altos o bajos. Una alternativa es usar median(), que encuentra un valor que se encuentra en el “medio” del vector, es decir, el 50 % de los valores está por encima y el 50 % por debajo. Dependiendo de la forma de la distribución de la variable que le interese, la media o la mediana pueden ser una mejor medida del centro. Por ejemplo, para distribuciones simétricas generalmente informamos la media, mientras que para distribuciones asimétricas generalmente informamos la mediana.\nFigura 14.2 compara la media con la mediana del retraso de salida (en minutos) para cada destino. El retraso mediano siempre es menor que el retraso medio porque los vuelos a veces salen varias horas tarde, pero nunca salen varias horas antes.\n\nflights |&gt;\n  group_by(year, month, day) |&gt;\n  summarize(\n    mean = mean(dep_delay, na.rm = TRUE),\n    median = median(dep_delay, na.rm = TRUE),\n    n = n(),\n    .groups = \"drop\"\n  ) |&gt; \n  ggplot(aes(x = mean, y = median)) + \n  geom_abline(slope = 1, intercept = 0, color = \"white\", linewidth = 2) +\n  geom_point()\n\n\n\n\n\n\nFigura 14.2: Un diagrama de dispersión que muestra las diferencias de resumir el retraso de salida por día con la mediana en lugar de la media.\n\n\n\n\nTambién puede preguntarse sobre la moda o el valor más común. Este es un resumen que solo funciona bien para casos muy simples (por eso es posible que lo hayas aprendido en la escuela secundaria), pero no funciona bien para muchos conjuntos de datos reales. Si los datos son discretos, puede haber varios valores más comunes, y si los datos son continuos, es posible que no haya un valor más común porque cada valor es ligeramente diferente. Por estas razones, la moda tiende a no ser utilizada por los estadísticos y no hay una función de moda incluida en la base R2.\n\n14.6.2 Mínimo, máximo y cuantiles\n¿Qué pasa si estás interesado en lugares que no sean el centro? min() y max() le darán los valores más grandes y más pequeños. Otra herramienta poderosa es quantile(), que es una generalización de la mediana: quantile(x, 0.25) encontrará el valor de x que es mayor que el 25% de los valores, quantile(x, 0.5) es equivalente a la mediana, y quantile(x, 0.95) encontrará el valor que es mayor que el 95% de los valores.\nPara los datos de flights, es posible que desee observar el cuantil del 95 % de los retrasos en lugar del máximo, ya que ignorará el 5 % de la mayoría de los vuelos retrasados, lo que puede ser bastante extremo.\n\nflights |&gt;\n  group_by(year, month, day) |&gt;\n  summarize(\n    max = max(dep_delay, na.rm = TRUE),\n    q95 = quantile(dep_delay, 0.95, na.rm = TRUE),\n    .groups = \"drop\"\n  )\n#&gt; # A tibble: 365 × 5\n#&gt;    year month   day   max   q95\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1  2013     1     1   853  70.1\n#&gt; 2  2013     1     2   379  85  \n#&gt; 3  2013     1     3   291  68  \n#&gt; 4  2013     1     4   288  60  \n#&gt; 5  2013     1     5   327  41  \n#&gt; 6  2013     1     6   202  51  \n#&gt; # ℹ 359 more rows\n\n\n14.6.3 Dispersión\nA veces, no está tan interesado en dónde se encuentra la mayor parte de los datos, sino en cómo se distribuyen. Dos resúmenes de uso común son la desviación estándar, sd(x), y el rango intercuartílico, IQR(). No explicaremos sd() aquí porque probablemente ya estés familiarizado con él, pero IQR() podría ser nuevo — es quantile(x, 0.75) - quantile(x, 0.25) y le da el rango que contiene el 50% medio de los datos.\nPodemos usar esto para revelar una pequeña rareza en los datos de vuelos. Es de esperar que la dispersión de la distancia entre el origen y el destino sea cero, ya que los aeropuertos siempre están en el mismo lugar. Pero el siguiente código hace que parezca que un aeropuerto, EGE, podría haberse mudado.\n\nflights |&gt; \n  group_by(origin, dest) |&gt; \n  summarize(\n    distance_iqr = IQR(distance), \n    n = n(),\n    .groups = \"drop\"\n  ) |&gt; \n  filter(distance_iqr &gt; 0)\n#&gt; # A tibble: 2 × 4\n#&gt;   origin dest  distance_iqr     n\n#&gt;   &lt;chr&gt;  &lt;chr&gt;        &lt;dbl&gt; &lt;int&gt;\n#&gt; 1 EWR    EGE              1   110\n#&gt; 2 JFK    EGE              1   103\n\n\n14.6.4 Distribuciones\nVale la pena recordar que todas las estadísticas de resumen descritas anteriormente son una forma de reducir la distribución a un solo número. Esto significa que son fundamentalmente reductivos, y si elige el resumen incorrecto, fácilmente puede pasar por alto diferencias importantes entre los grupos. Es por eso que siempre es una buena idea visualizar la distribución antes de comprometerse con sus estadísticas de resumen.\nFigura 14.3 muestra la distribución general de los retrasos en las salidas. La distribución está tan sesgada que tenemos que acercarnos para ver la mayor parte de los datos. Esto sugiere que es poco probable que la media sea un buen resumen y que preferiríamos la mediana en su lugar.\n\n\n\n\n\n\n\nFigura 14.3: (Izquierda) El histograma de los datos completos está extremadamente sesgado, lo que lo hace difícil obtener algún detalle. (Derecha) Acercamiento a retrasos de menos de dos horas hace posible ver lo que sucede con la mayor parte de la observaciones.\n\n\n\n\nTambién es una buena idea verificar que las distribuciones de los subgrupos se parezcan al todo. En el gráfico siguiente se superponen 365 polígonos de frecuencia de dep_delay, uno para cada día. Las distribuciones parecen seguir un patrón común, lo que sugiere que está bien usar el mismo resumen para cada día.\n\nflights |&gt;\n  filter(dep_delay &lt; 120) |&gt; \n  ggplot(aes(x = dep_delay, group = interaction(day, month))) + \n  geom_freqpoly(binwidth = 5, alpha = 1/5)\n\n\n\n\n\n\n\nNo tenga miedo de explorar sus propios resúmenes personalizados específicamente diseñados para los datos con los que está trabajando. En este caso, eso podría significar resumir por separado los vuelos que salieron temprano frente a los vuelos que salieron tarde, o dado que los valores están muy sesgados, puede intentar una transformación logarítmica. Finalmente, no olvide lo que aprendió en Sección 4.6: siempre que cree resúmenes numéricos, es una buena idea incluir el número de observaciones en cada grupo.\n\n14.6.5 Posiciones\nHay un último tipo de resumen que es útil para los vectores numéricos, pero también funciona con cualquier otro tipo de valor: extraer un valor en una posición específica: primero(x), último(x) y nth(x, n).\nPor ejemplo, podemos encontrar la primera, quinta y la última salida de cada día:\n\nflights |&gt; \n  group_by(year, month, day) |&gt; \n  summarize(\n    first_dep = first(dep_time, na_rm = TRUE), \n    fifth_dep = nth(dep_time, 5, na_rm = TRUE),\n    last_dep = last(dep_time, na_rm = TRUE)\n  )\n#&gt; `summarise()` has grouped output by 'year', 'month'. You can override using\n#&gt; the `.groups` argument.\n#&gt; # A tibble: 365 × 6\n#&gt; # Groups:   year, month [12]\n#&gt;    year month   day first_dep fifth_dep last_dep\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;     &lt;int&gt;     &lt;int&gt;    &lt;int&gt;\n#&gt; 1  2013     1     1       517       554     2356\n#&gt; 2  2013     1     2        42       535     2354\n#&gt; 3  2013     1     3        32       520     2349\n#&gt; 4  2013     1     4        25       531     2358\n#&gt; 5  2013     1     5        14       534     2357\n#&gt; 6  2013     1     6        16       555     2355\n#&gt; # ℹ 359 more rows\n\n(NB: Debido a que las funciones dplyr usan _ para separar los componentes de la función y los nombres de los argumentos, estas funciones usan na_rm en lugar de na.rm.)\nSi está familiarizado con [, al que volveremos en Sección 28.2, es posible que se pregunte si alguna vez necesitará estas funciones. Hay tres razones: el argumento default le permite proporcionar un valor predeterminado si la posición especificada no existe, el argumento order_by le permite anular localmente el orden de las filas y el argumento na_rm le permite eliminar los valores perdidos.\nLa extracción de valores en posiciones es complementaria al filtrado en rangos. El filtrado le brinda todas las variables, con cada observación en una fila separada:\n\nflights |&gt; \n  group_by(year, month, day) |&gt; \n  mutate(r = min_rank(sched_dep_time)) |&gt; \n  filter(r %in% c(1, max(r)))\n#&gt; # A tibble: 1,195 × 20\n#&gt; # Groups:   year, month, day [365]\n#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n#&gt; 1  2013     1     1      517            515         2      830            819\n#&gt; 2  2013     1     1     2353           2359        -6      425            445\n#&gt; 3  2013     1     1     2353           2359        -6      418            442\n#&gt; 4  2013     1     1     2356           2359        -3      425            437\n#&gt; 5  2013     1     2       42           2359        43      518            442\n#&gt; 6  2013     1     2      458            500        -2      703            650\n#&gt; # ℹ 1,189 more rows\n#&gt; # ℹ 12 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, …\n\n\n14.6.6 Con mutate()\n\nComo sugieren los nombres, las funciones de resumen normalmente se combinan con summarize(). Sin embargo, debido a las reglas de reciclaje que discutimos en Sección 14.4.1, también se pueden combinar de manera útil con mutate(), particularmente cuando desea realizar algún tipo de estandarización de grupo. Por ejemplo:\n\n\nx / sum(x) calcula la proporción de un total.\n\n(x - mean(x)) / sd(x) calcula una puntuación Z (estandarizada a media 0 y sd 1).\n\n(x - min(x)) / (max(x) - min(x)) se estandariza al rango [0, 1].\n\nx / first(x) calcula un índice basado en la primera observación.\n\n14.6.7 Ejercicios\n\nHaga una lluvia de ideas sobre al menos 5 formas diferentes de evaluar las características típicas de retraso de un grupo de vuelos. ¿Cuándo es útil mean()? ¿Cuándo es útil median()? ¿Cuándo podría querer usar otra cosa? ¿Debe utilizar el retraso de llegada o el retraso de salida? ¿Por qué querrías usar datos de aviones?\n¿Qué destinos muestran la mayor variación en la velocidad del aire?\nCrea una gráfica para explorar más a fondo las aventuras de EGE. ¿Puedes encontrar alguna evidencia de que el aeropuerto cambió de ubicación? ¿Puedes encontrar otra variable que pueda explicar la diferencia?",
    "crumbs": [
      "Transformar",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Números</span>"
    ]
  },
  {
    "objectID": "numbers.html#resumen",
    "href": "numbers.html#resumen",
    "title": "14  Números",
    "section": "\n14.7 Resumen",
    "text": "14.7 Resumen\nYa está familiarizado con muchas herramientas para trabajar con números y, después de leer este capítulo, ahora sabe cómo usarlas en R. También aprendió un puñado de transformaciones generales útiles que se aplican comúnmente, pero no exclusivamente, a vectores numéricos como rangos y compensaciones. Finalmente, trabajó en una serie de resúmenes numéricos y discutió algunos de los desafíos estadísticos que debe considerar.\nEn los próximos dos capítulos, nos sumergiremos en el trabajo con cadenas con el paquete stringr. Las cadenas son un gran tema, por lo que tienen dos capítulos, uno sobre los fundamentos de las cadenas y otro sobre las expresiones regulares.",
    "crumbs": [
      "Transformar",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Números</span>"
    ]
  },
  {
    "objectID": "numbers.html#footnotes",
    "href": "numbers.html#footnotes",
    "title": "14  Números",
    "section": "",
    "text": "ggplot2 proporciona algunos ayudantes para casos comunes en cut_interval(), cut_number() y cut_width(). ggplot2 es un lugar ciertamente extraño para que vivan estas funciones, pero son útiles como parte del cálculo del histograma y se escribieron antes de que existieran otras partes del tidyverse.↩︎\n¡La función mode() hace algo muy diferente!↩︎",
    "crumbs": [
      "Transformar",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Números</span>"
    ]
  },
  {
    "objectID": "regexps.html",
    "href": "regexps.html",
    "title": "16  Expresiones regulares",
    "section": "",
    "text": "16.1 Introducción\nEn Capítulo 15, aprendió un montón de funciones útiles para trabajar con cadenas. Este capítulo se centrará en funciones que usan expresiones regulares, un lenguaje conciso y poderoso para describir patrones dentro de cadenas. El término “expresión regular” es un poco complicado, por lo que la mayoría de la gente lo abrevia como “regex”1 (del inglés, “regular expressions”) o “regexp”.\nEl capítulo comienza con los conceptos básicos de las expresiones regulares y las funciones stringr más útiles para el análisis de datos. Luego, ampliaremos su conocimiento de los patrones y cubriremos siete temas nuevos e importantes (escape, anclaje, clases de caracteres, clases de taquigrafía, cuantificadores, precedencia y agrupación). A continuación, hablaremos sobre algunos de los otros tipos de patrones con los que pueden trabajar las funciones stringr y las diversas “banderas” que le permiten modificar el funcionamiento de las expresiones regulares. Terminaremos con una encuesta de otros lugares en el tidyverse y base R donde podría usar expresiones regulares.",
    "crumbs": [
      "Transformar",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Expresiones regulares</span>"
    ]
  },
  {
    "objectID": "factors.html",
    "href": "factors.html",
    "title": "17  Factores",
    "section": "",
    "text": "17.1 Introducción\nLos factores se utilizan para variables categóricas, variables que tienen un conjunto fijo y conocido de valores posibles. También son útiles cuando desea mostrar vectores de caracteres en un orden no alfabético.\nComenzaremos explicando por qué se necesitan factores para el análisis de datos1 y cómo puede crearlos con factor(). Luego le presentaremos el conjunto de datos gss_cat que contiene un montón de variables categóricas para experimentar. Luego usará ese conjunto de datos para practicar la modificación del orden y los valores de los factores, antes de que terminemos con una discusión sobre los factores ordenados.",
    "crumbs": [
      "Transformar",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Factores</span>"
    ]
  },
  {
    "objectID": "factors.html#footnotes",
    "href": "factors.html#footnotes",
    "title": "17  Factores",
    "section": "",
    "text": "También son muy importantes para el modelado.↩︎",
    "crumbs": [
      "Transformar",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Factores</span>"
    ]
  },
  {
    "objectID": "databases.html",
    "href": "databases.html",
    "title": "22  Bases de datos",
    "section": "",
    "text": "22.1 Introducción\nUna gran cantidad de datos reside en las bases de datos, por lo que es esencial que sepa cómo acceder a ellos. A veces, puede pedirle a alguien que descargue una instantánea en un .csv para usted, pero esto se vuelve doloroso rápidamente: cada vez que necesite hacer un cambio, tendrá que comunicarse con otro ser humano. Desea poder acceder directamente a la base de datos para obtener los datos que necesita, cuando los necesita.\nEn este capítulo, primero aprenderá los conceptos básicos del paquete DBI: cómo usarlo para conectarse a una base de datos y luego recuperar datos con una consulta SQL1. SQL, abreviatura de structured query llanguage, es la lingua franca de las bases de datos y es un lenguaje importante que deben aprender todos los científicos de datos. Dicho esto, no vamos a comenzar con SQL, sino que le enseñaremos dbplyr, que puede traducir su código dplyr a SQL. Usaremos eso como una forma de enseñarle algunas de las características más importantes de SQL. No se convertirá en un maestro de SQL al final del capítulo, pero podrá identificar los componentes más importantes y entender lo que hacen.",
    "crumbs": [
      "Importar",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Bases de datos</span>"
    ]
  },
  {
    "objectID": "quarto.html",
    "href": "quarto.html",
    "title": "29  Quarto",
    "section": "",
    "text": "29.1 Introducción\nQuarto proporciona un marco de creación unificado para la ciencia de datos, combinando su código, sus resultados y su prosa. Los documentos Quarto son totalmente reproducibles y admiten docenas de formatos de salida, como PDF, archivos de Word, presentaciones y más.\nLos archivos Quarto están diseñados para usarse de tres maneras:\nQuarto es una herramienta de interfaz de línea de comandos, no un paquete R. Esto significa que la ayuda, en general, no está disponible a través de ?. En cambio, mientras trabaja en este capítulo y usa Quarto en el futuro, debe consultar la documentación de Quarto.\nSi es un usuario de R Markdown, podría estar pensando “Quarto se parece mucho a R Markdown”. ¡Tu no estas equivocado! Quarto unifica la funcionalidad de muchos paquetes del ecosistema R Markdown (rmarkdown, bookdown, destilar, xaringan, etc.) en un solo sistema consistente y lo amplía con soporte nativo para múltiples lenguajes de programación como Python y Julia además de R. En cierto modo, Quarto refleja todo lo que se aprendió al expandir y respaldar el ecosistema R Markdown durante una década.",
    "crumbs": [
      "Comunicar",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Quarto</span>"
    ]
  },
  {
    "objectID": "quarto-formats.html",
    "href": "quarto-formats.html",
    "title": "30  Formatos Quarto",
    "section": "",
    "text": "30.1 Introducción\nHasta ahora, ha visto que Quarto se usa para producir documentos HTML. Este capítulo ofrece una breve descripción general de algunos de los muchos otros tipos de salida que puede producir con Quarto.\nHay dos formas de configurar la salida de un documento:",
    "crumbs": [
      "Comunicar",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Formatos Quarto</span>"
    ]
  }
]