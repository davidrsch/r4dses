# Iteración {#sec-iteration}

```{r}
#| results: "asis"
#| echo: false

source("_common.R")
status("complete")
```

## Introducción

En este capítulo, aprenderá herramientas para la iteración, realizando repetidamente la misma acción en diferentes objetos.
La iteración en R generalmente tiende a verse bastante diferente de otros lenguajes de programación porque gran parte de ella está implícita y la obtenemos de forma gratuita.
Por ejemplo, si desea duplicar un vector numérico `x` en R, simplemente puede escribir `2 * x`.
En la mayoría de los otros idiomas, necesitaría duplicar explícitamente cada elemento de `x` usando algún tipo de bucle for.

Este libro ya le ha brindado una pequeña pero poderosa cantidad de herramientas que realizan la misma acción para múltiples "cosas":

-   `facet_wrap()` y `facet_grid()` dibuja una gráfica para cada subconjunto.
-   `group_by()` más `summarize()` calcula un resumen de estadísticas para cada subconjunto.
-   `unnest_wider()` y `unnest_longer()` crear nuevas filas y columnas para cada elemento de una lista-columna.

Ahora es el momento de aprender algunas herramientas más generales, a menudo llamadas herramientas de **programación funcional** porque están construidas alrededor de funciones que toman otras funciones como entradas.
El aprendizaje de la programación funcional puede pasar fácilmente a lo abstracto, pero en este capítulo mantendremos las cosas concretas centrándonos en tres tareas comunes: modificar varias columnas, leer varios archivos y guardar varios objetos.

### Requisitos previos

En este capítulo, nos centraremos en las herramientas proporcionadas por dplyr y purrr, ambos miembros principales de tidyverse.
Has visto dplyr antes, pero [purrr](http://purrr.tidyverse.org/) es nuevo.
Solo vamos a usar un par de funciones purrr en este capítulo, pero es un gran paquete para explorar a medida que mejora sus habilidades de programación.

```{r}
#| label: setup
#| message: false

library(tidyverse)
```

## Modificar varias columnas {#sec-across}

Imagina que tienes este tibble simple y quieres contar el número de observaciones y calcular la mediana de cada columna.

```{r}
df <- tibble(
  a = rnorm(10),
  b = rnorm(10),
  c = rnorm(10),
  d = rnorm(10)
)
```

Podrías hacerlo con copiar y pegar:

```{r}
df |> summarize(
  n = n(),
  a = median(a),
  b = median(b),
  c = median(c),
  d = median(d),
)
```

Eso rompe nuestra regla general de nunca copiar y pegar más de dos veces, y puedes imaginar que esto se volverá muy tedioso si tienes decenas o incluso cientos de columnas.
En su lugar, puedes usar `across()`:

```{r}
df |> summarize(
  n = n(),
  across(a:d, median),
)
```

`across()` tiene tres argumentos particularmente importantes, que discutiremos en detalle en las siguientes secciones.
Usará los dos primeros cada vez que use `across()`: el primer argumento, `.cols`, especifica sobre qué columnas desea iterar, y el segundo argumento, `.fns`, especifica qué hacer con cada columna Puedes usar el argumento `.names` cuando necesites un control adicional sobre los nombres de las columnas de salida, lo cual es particularmente importante cuando usas `across()` con `mutate()`.
También discutiremos dos variaciones importantes, `if_any()` y `if_all()`, que funcionan con `filter()`.

### Selección de columnas con `.cols`

El primer argumento de `across()`, `.cols`, selecciona las columnas para transformar.
Esto usa las mismas especificaciones que `select()`, @sec-select, por lo que puede usar funciones como `starts_with()` y `ends_with()` para seleccionar columnas según su nombre.

Hay dos técnicas de selección adicionales que son particularmente útiles para `across()`: `everything()` y `where()`.
`everything()` es sencillo: selecciona todas las columnas (no agrupadas):

```{r}
df <- tibble(
  grp = sample(2, 10, replace = TRUE),
  a = rnorm(10),
  b = rnorm(10),
  c = rnorm(10),
  d = rnorm(10)
)

df |> 
  group_by(grp) |> 
  summarize(across(everything(), median))
```

Tenga en cuenta que las columnas de agrupación (`grp` aquí) no se incluyen en `across()`, porque `summarize()` las conserva automáticamente.

`where()` le permite seleccionar columnas según su tipo:

-   `where(is.numeric)` selecciona todas las columnas numéricas.
-   `where(is.character)` selecciona todas las columnas de cadena.
-   `where(is.Date)` selecciona todas las columnas de fecha.
-   `where(is.POSIXct)` selecciona todas las columnas de fecha y hora.
-   `where(is.logical)` selecciona todas las columnas lógicas.

Al igual que otros selectores, puede combinarlos con álgebra booleana.
Por ejemplo, `!where(is.numeric)` selecciona todas las columnas no numéricas, y `starts_with("a") & where(is.logical)` selecciona todas las columnas lógicas cuyo nombre comienza con "a".

### Llamar a una sola función

El segundo argumento de `across()` define cómo se transformará cada columna.
En casos simples, como el anterior, esta será una sola función existente.
Esta es una característica bastante especial de R: estamos pasando una función (`median`, `mean`, `str_flatten`, ...) a otra función (`across`).
Esta es una de las características que hace de R un lenguaje de programación funcional.

Es importante tener en cuenta que estamos pasando esta función a `across()`, por lo que `across()` puede llamarla; no lo estamos llamando nosotros mismos.
Eso significa que el nombre de la función nunca debe ir seguido de `()`.
Si lo olvida, obtendrá un error:

```{r}
#| error: true
df |> 
  group_by(grp) |> 
  summarize(across(everything(), median()))
```

Este error surge porque está llamando a la función sin entrada, por ejemplo:

```{r}
#| error: true
median()
```

### Llamar a múltiples funciones

En casos más complejos, es posible que desee proporcionar argumentos adicionales o realizar varias transformaciones.
Motivemos este problema con un ejemplo simple: ¿qué sucede si tenemos algunos valores faltantes en nuestros datos?
`median()` propaga esos valores perdidos, dándonos un resultado subóptimo:

```{r}
rnorm_na <- function(n, n_na, mean = 0, sd = 1) {
  sample(c(rnorm(n - n_na, mean = mean, sd = sd), rep(NA, n_na)))
}

df_miss <- tibble(
  a = rnorm_na(5, 1),
  b = rnorm_na(5, 1),
  c = rnorm_na(5, 2),
  d = rnorm(5)
)
df_miss |> 
  summarize(
    across(a:d, median),
    n = n()
  )
```

Sería bueno si pudiéramos pasar `na.rm = TRUE` a `median()` para eliminar estos valores faltantes.
Para hacerlo, en lugar de llamar a `median()` directamente, necesitamos crear una nueva función que llame a `median()` con los argumentos deseados:

```{r}
df_miss |> 
  summarize(
    across(a:d, function(x) median(x, na.rm = TRUE)),
    n = n()
  )
```

Esto es un poco detallado, por lo que R viene con un atajo útil: para este tipo de función desechable, o **anónima**[^iteration-1], puede reemplazar `función` con `\`\[\^iteration-2 \]:

[^iteration-1]: Anónimo, porque nunca le dimos explícitamente un nombre con `<-`.
    Otro término que usan los programadores para esto es "función lambda".

```{r}
#| results: false
df_miss |> 
  summarize(
    across(a:d, \(x) median(x, na.rm = TRUE)),
    n = n()
  )
```

En cualquier caso, `across()` se expande efectivamente al siguiente código:

```{r}
#| eval: false

df_miss |> 
  summarize(
    a = median(a, na.rm = TRUE),
    b = median(b, na.rm = TRUE),
    c = median(c, na.rm = TRUE),
    d = median(d, na.rm = TRUE),
    n = n()
  )
```

Cuando eliminamos los valores que faltan de la mediana, `median()`, sería bueno saber cuántos valores se eliminaron.
Podemos averiguarlo proporcionando dos funciones a `across()`: una para calcular la mediana y la otra para contar los valores que faltan.
Proporciona múltiples funciones usando una lista con nombre para `.fns`:

```{r}
df_miss |> 
  summarize(
    across(a:d, list(
      median = \(x) median(x, na.rm = TRUE),
      n_miss = \(x) sum(is.na(x))
    )),
    n = n()
  )
```

Si observa detenidamente, puede intuir que las columnas se nombran utilizando una especificación de pegamento (@sec-glue) como `{.col}_{.fn}` donde `.col` es el nombre de la columna original y `. fn` es el nombre de la función.
¡Eso no es una coincidencia!
Como aprenderá en la siguiente sección, puede usar el argumento `.names` para proporcionar su propia especificación de pegamento.

### Nombres de columna

El resultado de `across()` se nombra de acuerdo con la especificación provista en el argumento `.names`.
Podríamos especificar el nuestro si quisiéramos que el nombre de la función fuera primero [^iteration-2]:

[^iteration-2]: actualmente no puede cambiar el orden de las columnas, pero podría reordenarlas después usando `relocate()` o similar.

```{r}
df_miss |> 
  summarize(
    across(
      a:d,
      list(
        median = \(x) median(x, na.rm = TRUE),
        n_miss = \(x) sum(is.na(x))
      ),
      .names = "{.fn}_{.col}"
    ),
    n = n(),
  )
```

El argumento `.names` es particularmente importante cuando usas `across()` con `mutate()`.
Por defecto, la salida de `across()` recibe los mismos nombres que las entradas.
Esto significa que `across()` dentro de `mutate()` reemplazará las columnas existentes.
Por ejemplo, aquí usamos `coalesce()` para reemplazar `NA`s con `0`:

```{r}
df_miss |> 
  mutate(
    across(a:d, \(x) coalesce(x, 0))
  )
```

Si desea crear nuevas columnas, puede usar el argumento `.names` para dar nuevos nombres a la salida:

```{r}
df_miss |> 
  mutate(
    across(a:d, \(x) abs(x), .names = "{.col}_abs")
  )
```

### Filtrando

`across()` es una gran combinación para `summarize()` y `mutate()`, pero es más incómodo de usar con `filter()`, porque generalmente combina varias condiciones con `|` o `&`.
Está claro que `across()` puede ayudar a crear varias columnas lógicas, pero ¿entonces qué?
Así que dplyr proporciona dos variantes de `across()` llamadas `if_any()` y `if_all()`:

```{r}
# igual que df_miss |> filter(is.na(a) | is.na(b) | is.na(c) | is.na(d))
df_miss |> filter(if_any(a:d, is.na))

# igual que df_miss |> filter(is.na(a) & is.na(b) & is.na(c) & is.na(d))
df_miss |> filter(if_all(a:d, is.na))
```

### `across()` en funciones

`across()` es particularmente útil para programar porque te permite operar en múltiples columnas.
Por ejemplo, [Jacob Scott](https://twitter.com/_wurli/status/1571836746899283969) usa este pequeño ayudante que envuelve un montón de funciones de lubridate para expandir todas las columnas de fecha en columnas de año, mes y día:

```{r}
expand_dates <- function(df) {
  df |> 
    mutate(
      across(where(is.Date), list(year = year, month = month, day = mday))
    )
}

df_date <- tibble(
  name = c("Amy", "Bob"),
  date = ymd(c("2009-08-03", "2010-01-16"))
)

df_date |> 
  expand_dates()
```

`across()` también facilita el suministro de múltiples columnas en un solo argumento porque el primer argumento usa tidy-select; solo necesita recordar abrazar ese argumento, como discutimos en @sec-embracing.
Por ejemplo, esta función calculará las medias de las columnas numéricas de forma predeterminada.
Pero al proporcionar el segundo argumento, puede optar por resumir solo las columnas seleccionadas:

```{r}
summarize_means <- function(df, summary_vars = where(is.numeric)) {
  df |> 
    summarize(
      across({{ summary_vars }}, \(x) mean(x, na.rm = TRUE)),
      n = n()
    )
}
diamonds |> 
  group_by(cut) |> 
  summarize_means()

diamonds |> 
  group_by(cut) |> 
  summarize_means(c(carat, x:z))
```

### Vs `pivot_longer()`

Antes de continuar, vale la pena señalar una conexión interesante entre `across()` y `pivot_longer()` (@sec-pivoting).
En muchos casos, usted realiza los mismos cálculos girando primero los datos y luego realizando las operaciones por grupo en lugar de por columna.
Por ejemplo, tome este resumen multifunción:

```{r}
df |> 
  summarize(across(a:d, list(median = median, mean = mean)))
```

Podríamos calcular los mismos valores girando más y luego resumiendo:

```{r}
long <- df |> 
  pivot_longer(a:d) |> 
  group_by(name) |> 
  summarize(
    median = median(value),
    mean = mean(value)
  )
long
```

Y si quisieras la misma estructura que `across()`, podrías pivotar de nuevo:

```{r}
long |> 
  pivot_wider(
    names_from = name,
    values_from = c(median, mean),
    names_vary = "slowest",
    names_glue = "{name}_{.value}"
  )
```

Esta es una técnica útil para conocer porque a veces te encontrarás con un problema que actualmente no es posible resolver con `across()`: cuando tienes grupos de columnas con las que quieres calcular simultáneamente.
Por ejemplo, imagine que nuestro data frame contiene valores y pesos y queremos calcular una media ponderada:

```{r}
df_paired <- tibble(
  a_val = rnorm(10),
  a_wts = runif(10),
  b_val = rnorm(10),
  b_wts = runif(10),
  c_val = rnorm(10),
  c_wts = runif(10),
  d_val = rnorm(10),
  d_wts = runif(10)
)
```

Actualmente no hay forma de hacer esto con `across()`[^iteration-3], pero es relativamente sencillo con `pivot_longer()`:

[^iteration-3]: Tal vez habrá un día, pero actualmente no vemos cómo.

```{r}
df_long <- df_paired |> 
  pivot_longer(
    everything(), 
    names_to = c("group", ".value"), 
    names_sep = "_"
  )
df_long

df_long |> 
  group_by(group) |> 
  summarize(mean = weighted.mean(val, wts))
```

Si es necesario, puede `pivot_wider()` para devolverlo a la forma original.

### Ejercicios

1.  Practica tus habilidades `across()` al:

    1.  Calcular el número de valores únicos en cada columna de `palmerpenguins::penguins`.

    2.  Calcular la media de cada columna en `mtcars`.

    3.  Agrupar 'diamantes' por 'corte', 'claridad' y 'color' y luego contar el número de observaciones y calcular la media de cada columna numérica.

2.  ¿Qué pasa si usas una lista de funciones en `across()`, pero no las nombras?
    ¿Cómo se llama la salida?

3.  Ajuste `expand_dates()` para eliminar automáticamente las columnas de fecha después de que se hayan expandido.
    ¿Necesitas aceptar algún argumento?

4.  Explique qué hace cada paso de la tubería en esta función.
    ¿Qué característica especial de `where()` estamos aprovechando?

    ```{r}
    #| results: false

    show_missing <- function(df, group_vars, summary_vars = everything()) {
      df |> 
        group_by(pick({{ group_vars }})) |> 
        summarize(
          across({{ summary_vars }}, \(x) sum(is.na(x))),
          .groups = "drop"
        ) |>
        select(where(\(x) any(x > 0)))
    }
    nycflights13::flights |> show_missing(c(year, month, day))
    ```

## Leer varios archivos

En la sección anterior, aprendiste a usar `dplyr::across()` para repetir una transformación en varias columnas.
En esta sección, aprenderá cómo usar `purrr::map()` para hacer algo con cada archivo en un directorio.
Empecemos con un poco de motivación: imagine que tiene un directorio lleno de hojas de cálculo de Excel\[\^iteración-4\] que desea leer.
Podrías hacerlo con copiar y pegar:

```{r}
#| eval: false
data2019 <- readxl::read_excel("data/y2019.xlsx")
data2020 <- readxl::read_excel("data/y2020.xlsx")
data2021 <- readxl::read_excel("data/y2021.xlsx")
data2022 <- readxl::read_excel("data/y2022.xlsx")
```

Y luego usa `dplyr::bind_rows()` para combinarlos todos juntos:

```{r}
#| eval: false
data <- bind_rows(data2019, data2020, data2021, data2022)
```

Puede imaginar que esto se volvería tedioso rápidamente, especialmente si tuviera cientos de archivos, no solo cuatro.
Las siguientes secciones le muestran cómo automatizar este tipo de tareas.
Hay tres pasos básicos: use `list.files()` para listar todos los archivos en un directorio, luego use `purrr::map()` para leer cada uno de ellos en una lista, luego use `purrr::list_rbind( )` para combinarlos en un solo data frame.
Luego, analizaremos cómo puede manejar situaciones de creciente heterogeneidad, en las que no puede hacer exactamente lo mismo con todos los archivos.

### Listado de archivos en un directorio

Como sugiere el nombre, `list.files()` enumera los archivos en un directorio.
Casi siempre usarás tres argumentos:

-   El primer argumento, `path`, es el directorio en el que buscar.

-   `pattern` es una expresión regular utilizada para filtrar los nombres de archivo.
    El patrón más común es algo como `[.]xlsx$` o `[.]csv$` para encontrar todos los archivos con una extensión específica.

-   `full.names` determina si el nombre del directorio debe incluirse o no en la salida.
    Casi siempre quieres que esto sea `TRUE`.

Para concretar nuestro ejemplo motivador, este libro contiene una carpeta con 12 hojas de cálculo de Excel que contienen datos del paquete gapminder.
Cada archivo contiene datos de un año para 142 países.
Podemos listarlos todos con la llamada apropiada a `list.files()`:

```{r}
paths <- list.files("data/gapminder", pattern = "[.]xlsx$", full.names = TRUE)
paths
```

### Lists

Ahora que tenemos estas 12 rutas, podríamos llamar a `read_excel()` 12 veces para obtener 12 data frames:

```{r}
#| eval: false
gapminder_1952 <- readxl::read_excel("data/gapminder/1952.xlsx")
gapminder_1957 <- readxl::read_excel("data/gapminder/1957.xlsx")
gapminder_1962 <- readxl::read_excel("data/gapminder/1962.xlsx")
 ...,
gapminder_2007 <- readxl::read_excel("data/gapminder/2007.xlsx")
```

Pero poner cada hoja en su propia variable hará que sea difícil trabajar con ellas unos pasos más adelante.
En cambio, será más fácil trabajar con ellos si los ponemos en un solo objeto.
Una lista es la herramienta perfecta para este trabajo:

```{r}
#| eval: false
files <- list(
  readxl::read_excel("data/gapminder/1952.xlsx"),
  readxl::read_excel("data/gapminder/1957.xlsx"),
  readxl::read_excel("data/gapminder/1962.xlsx"),
  ...,
  readxl::read_excel("data/gapminder/2007.xlsx")
)
```

```{r}
#| include: false
files <- map(paths, readxl::read_excel)
```

Ahora que tiene estos data frames en una lista, ¿cómo obtiene uno?
Puedes usar `files[[i]]` para extraer el i-ésimo elemento:

```{r}
files[[3]]
```

Volveremos a `[[` con más detalle en @sec-subset-one.

### `purrr::map()` and `list_rbind()`

El código para recopilar esos data frames en una lista "a mano" es básicamente tan tedioso de escribir como el código que lee los archivos uno por uno.
Felizmente, podemos usar `purrr::map()` para hacer un mejor uso de nuestro vector `paths`.
`map()` es similar a `across()`, pero en lugar de hacer algo con cada columna en un data frame, hace algo con cada elemento de un vector.
`map(x, f)` es una abreviatura de:

```{r}
#| eval: false
list(
  f(x[[1]]),
  f(x[[2]]),
  ...,
  f(x[[n]])
)
```

Entonces podemos usar `map()` para obtener una lista de 12 data frames:

```{r}
files <- map(paths, readxl::read_excel)
length(files)

files[[1]]
```

(Esta es otra estructura de datos que no se muestra de manera particularmente compacta con `str()`, por lo que es posible que desee cargarla en RStudio e inspeccionarla con `View()`).

Ahora podemos usar `purrr::list_rbind()` para combinar esa lista de data frames en un solo data frame:

```{r}
list_rbind(files)
```

O podríamos hacer ambos pasos a la vez en una canalización:

```{r}
#| results: false
paths |> 
  map(readxl::read_excel) |> 
  list_rbind()
```

¿Qué sucede si queremos pasar argumentos adicionales a `read_excel()`?
Usamos la misma técnica que usamos con `across()`.
Por ejemplo, suele ser útil alcanzar un máximo en las primeras filas de los datos con `n_max = 1`:

```{r}
paths |> 
  map(\(path) readxl::read_excel(path, n_max = 1)) |> 
  list_rbind()
```

Esto deja en claro que falta algo: no hay una columna `year` porque ese valor se registra en la ruta, no en los archivos individuales.
Abordaremos ese problema a continuación.

### Datos en la ruta {#sec-data-in-the-path}

A veces, el nombre del archivo es el propio dato.
En este ejemplo, el nombre del archivo contiene el año, que de otro modo no se registra en los archivos individuales.
Para colocar esa columna en el data frame final, debemos hacer dos cosas:

Primero, nombramos el vector de rutas.
La forma más fácil de hacer esto es con la función `set_names()`, que puede tomar una función.
Aquí usamos `basename()` para extraer solo el nombre del archivo de la ruta completa:

```{r}
paths |> set_names(basename) 
```

Esos nombres son llevados automáticamente por todas las funciones del mapa, por lo que la lista de data frames tendrá esos mismos nombres:

```{r}
files <- paths |> 
  set_names(basename) |> 
  map(readxl::read_excel)
```

Eso hace que esta llamada a `map()` sea abreviada para:

```{r}
#| eval: false
files <- list(
  "1952.xlsx" = readxl::read_excel("data/gapminder/1952.xlsx"),
  "1957.xlsx" = readxl::read_excel("data/gapminder/1957.xlsx"),
  "1962.xlsx" = readxl::read_excel("data/gapminder/1962.xlsx"),
  ...,
  "2007.xlsx" = readxl::read_excel("data/gapminder/2007.xlsx")
)
```

También puedes usar `[[` para extraer elementos por nombre:

```{r}
files[["1962.xlsx"]]
```

Luego usamos el argumento `names_to` para `list_rbind()` para decirle que guarde los nombres en una nueva columna llamada `year` y luego usamos `readr::parse_number()` para extraer el número de la cadena.

```{r}
paths |> 
  set_names(basename) |> 
  map(readxl::read_excel) |> 
  list_rbind(names_to = "year") |> 
  mutate(year = parse_number(year))
```

En casos más complicados, puede haber otras variables almacenadas en el nombre del directorio, o tal vez el nombre del archivo contenga varios bits de datos.
En ese caso, use `set_names()` (sin ningún argumento) para registrar la ruta completa y luego use `tidyr::separate_wider_delim()` y sus amigos para convertirlos en columnas útiles.

```{r}
paths |> 
  set_names() |> 
  map(readxl::read_excel) |> 
  list_rbind(names_to = "year") |> 
  separate_wider_delim(year, delim = "/", names = c(NA, "dir", "file")) |> 
  separate_wider_delim(file, delim = ".", names = c("file", "ext"))
```

### Guarda tu trabajo

Ahora que ha hecho todo este arduo trabajo para llegar a un buen data frame ordenado, es un buen momento para guardar su trabajo:

```{r}
gapminder <- paths |> 
  set_names(basename) |> 
  map(readxl::read_excel) |> 
  list_rbind(names_to = "year") |> 
  mutate(year = parse_number(year))

write_csv(gapminder, "gapminder.csv")
```

Ahora, cuando regrese a este problema en el futuro, puede leer en un solo archivo csv.
Para conjuntos de datos más grandes y ricos, usar parquet podría ser una mejor opción que `.csv`, como se explica en @sec-parquet.

```{r}
#| include: false
unlink("gapminder.csv")
```

Si está trabajando en un proyecto, le sugerimos llamar al archivo que hace este tipo de trabajo de preparación de datos algo así como `0-cleanup.R`.
El `0` en el nombre del archivo sugiere que esto debe ejecutarse antes que cualquier otra cosa.

Si sus archivos de datos de entrada cambian con el tiempo, podría considerar aprender una herramienta como [targets](https://docs.ropensci.org/targets/) para configurar su código de limpieza de datos para que se vuelva a ejecutar automáticamente cada vez que una de las entradas se modifican los archivos.

### Muchas iteraciones simples

Aquí acabamos de cargar los datos directamente desde el disco y tuvimos la suerte de obtener un conjunto de datos ordenado.
En la mayoría de los casos, deberá realizar algunas tareas de limpieza adicionales y tiene dos opciones básicas: puede realizar una ronda de iteración con una función compleja o realizar varias rondas de iteración con funciones simples.
En nuestra experiencia, la mayoría de la gente llega primero a una iteración compleja, pero a menudo es mejor hacer varias iteraciones simples.

Por ejemplo, imagine que desea leer un montón de archivos, filtrar los valores faltantes, pivotar y luego combinar.
Una forma de abordar el problema es escribir una función que tome un archivo y realice todos esos pasos y luego llame a `map()` una vez:

```{r}
#| eval: false
process_file <- function(path) {
  df <- read_csv(path)
  
  df |> 
    filter(!is.na(id)) |> 
    mutate(id = tolower(id)) |> 
    pivot_longer(jan:dec, names_to = "month")
}

paths |> 
  map(process_file) |> 
  list_rbind()
```

Alternativamente, podría realizar cada paso de `process_file()` para cada archivo:

```{r}
#| eval: false

paths |> 
  map(read_csv) |> 
  map(\(df) df |> filter(!is.na(id))) |> 
  map(\(df) df |> mutate(id = tolower(id))) |> 
  map(\(df) df |> pivot_longer(jan:dec, names_to = "month")) |> 
  list_rbind()
```

Recomendamos este enfoque porque evita que se obsesione con obtener el primer archivo correctamente antes de pasar al resto.
Al considerar todos los datos al ordenar y limpiar, es más probable que piense de manera integral y termine con un resultado de mayor calidad.

En este ejemplo en particular, hay otra optimización que podría hacer al vincular todos los data frames antes.
Entonces puede confiar en el comportamiento regular de dplyr:

```{r}
#| eval: false
paths |> 
  map(read_csv) |> 
  list_rbind() |> 
  filter(!is.na(id)) |> 
  mutate(id = tolower(id)) |> 
  pivot_longer(jan:dec, names_to = "month")
```

### Datos heterogéneos

Desafortunadamente, a veces no es posible pasar directamente de `map()` a `list_rbind()` porque los data frames son tan heterogéneos que `list_rbind()` falla o produce un data frame que no es muy útil.
En ese caso, sigue siendo útil comenzar cargando todos los archivos:

```{r}
#| eval: false
files <- paths |> 
  map(readxl::read_excel) 
```

Luego, una estrategia muy útil es capturar la estructura de los data frames para que pueda explorarla usando sus habilidades de ciencia de datos.
Una forma de hacerlo es con esta útil función `df_types` [^iteration-4] que devuelve un tibble con una fila para cada columna:

[^iteration-4]: no vamos a explicar cómo funciona, pero si miras los documentos de las funciones utilizadas, deberías poder descifrarlo.

```{r}
df_types <- function(df) {
  tibble(
    col_name = names(df), 
    col_type = map_chr(df, vctrs::vec_ptype_full),
    n_miss = map_int(df, \(x) sum(is.na(x)))
  )
}

df_types(gapminder)
```

Luego puede aplicar esta función a todos los archivos, y tal vez hacer algunos cambios para que sea más fácil ver dónde están las diferencias.
Por ejemplo, esto facilita la verificación de que las hojas de cálculo de gapminder con las que hemos estado trabajando son bastante homogéneas:

```{r}
files |> 
  map(df_types) |> 
  list_rbind(names_to = "file_name") |> 
  select(-n_miss) |> 
  pivot_wider(names_from = col_name, values_from = col_type)
```

Si los archivos tienen formatos heterogéneos, es posible que deba realizar más procesamiento antes de poder fusionarlos correctamente.
Desafortunadamente, ahora vamos a dejar que lo averigües por tu cuenta, pero es posible que desees leer acerca de `map_if()` y `map_at()`.
`map_if()` te permite modificar elementos de una lista de forma selectiva en función de sus valores; `map_at()` te permite modificar elementos de forma selectiva en función de sus nombres.

### Manejo de fallas

A veces, la estructura de sus datos puede ser lo suficientemente salvaje como para que ni siquiera pueda leer todos los archivos con un solo comando.
Y luego te encontrarás con una de las desventajas de map: tiene éxito o falla como un todo.
`map()` leerá con éxito todos los archivos en un directorio o fallará con un error, leyendo cero archivos.
Esto es molesto: ¿por qué una falla le impide acceder a todos los demás éxitos?

Afortunadamente, purrr viene con un ayudante para abordar este problema: `possibly()`.
`possibly()` es lo que se conoce como operador de función: toma una función y devuelve una función con comportamiento modificado.
En particular, `possibly()` cambia una función de error a devolver un valor que especifique:

```{r}
files <- paths |> 
  map(possibly(\(path) readxl::read_excel(path), NULL))

data <- files |> list_rbind()
```

Esto funciona particularmente bien aquí porque `list_rbind()`, como muchas funciones de tidyverse, automáticamente ignora `NULL`s.

Ahora tiene todos los datos que se pueden leer fácilmente, y es hora de abordar la parte difícil de averiguar por qué algunos archivos no se cargaron y qué hacer al respecto.
Comience por obtener las rutas que fallaron:

```{r}
failed <- map_vec(files, is.null)
paths[failed]
```

Luego, vuelva a llamar a la función de importación para cada falla y descubra qué salió mal.

## Guardar múltiples salidas

En la última sección, aprendiste sobre `map()`, que es útil para leer múltiples archivos en un solo objeto.
En esta sección, ahora exploraremos una especie de problema opuesto: ¿cómo puede tomar uno o más objetos R y guardarlos en uno o más archivos?
Exploraremos este desafío usando tres ejemplos:

-   Guardar múltiples data frames en una base de datos.
-   Guardar múltiples data frames en múltiples archivos `.csv`.
-   Guardar varias gráficas en varios archivos `.png`.

### Escribir en una base de datos {#sec-save-database}

A veces, cuando se trabaja con muchos archivos a la vez, no es posible colocar todos los datos en la memoria a la vez y no se puede hacer `map(files, read_csv)`.
Un enfoque para lidiar con este problema es cargar sus datos en una base de datos para que pueda acceder solo a los bits que necesita con dbplyr.

Si tiene suerte, el paquete de base de datos que está utilizando proporcionará una función útil que toma un vector de rutas y las carga todas en la base de datos.
Este es el caso con `duckdb_read_csv()` de duckdb:

```{r}
#| eval: false
con <- DBI::dbConnect(duckdb::duckdb())
duckdb::duckdb_read_csv(con, "gapminder", paths)
```

Esto funcionaría bien aquí, pero no tenemos archivos csv, sino hojas de cálculo de Excel.
Así que vamos a tener que hacerlo "a mano".
Aprender a hacerlo a mano también te ayudará cuando tengas un montón de csvs y la base de datos con la que estás trabajando no tenga una función que los cargue todos.

Necesitamos comenzar creando una tabla que se llene con datos.
La forma más sencilla de hacerlo es creando una plantilla, un data frame ficticio que contiene todas las columnas que queremos, pero solo una muestra de los datos.
Para los datos de gapminder, podemos hacer esa plantilla leyendo un solo archivo y añadiéndole el año:

```{r}
template <- readxl::read_excel(paths[[1]])
template$year <- 1952
template
```

Ahora podemos conectarnos a la base de datos y usar `DBI::dbCreateTable()` para convertir nuestra plantilla en una tabla de base de datos:

```{r}
con <- DBI::dbConnect(duckdb::duckdb())
DBI::dbCreateTable(con, "gapminder", template)
```

`dbCreateTable()` no usa los datos en `template`, solo los nombres y tipos de variables.
Así que si inspeccionamos la tabla `gapminder` ahora verás que está vacía pero tiene las variables que necesitamos con los tipos que esperamos:

```{r}
con |> tbl("gapminder")
```

A continuación, necesitamos una función que tome una única ruta de archivo, la lea en R y agregue el resultado a la tabla `gapminder`.
Podemos hacerlo combinando `read_excel()` con `DBI::dbAppendTable()`:

```{r}
append_file <- function(path) {
  df <- readxl::read_excel(path)
  df$year <- parse_number(basename(path))
  
  DBI::dbAppendTable(con, "gapminder", df)
}
```

Ahora necesitamos llamar a `append_file()` una vez por cada elemento de `paths`.
Eso es ciertamente posible con `map()`:

```{r}
#| eval: false
paths |> map(append_file)
```

Pero no nos importa la salida de `append_file()`, así que en lugar de `map()` es un poco mejor usar `walk()`.
`walk()` hace exactamente lo mismo que `map()` pero descarta el resultado:

```{r}
paths |> walk(append_file)
```

Ahora podemos ver si tenemos todos los datos en nuestra tabla:

```{r}
con |> 
  tbl("gapminder") |> 
  count(year)
```

```{r}
#| include: false
DBI::dbDisconnect(con, shutdown = TRUE)
```

### Escribir archivos csv

El mismo principio básico se aplica si queremos escribir varios archivos csv, uno para cada grupo.
Imaginemos que queremos tomar los datos `ggplot2::diamonds` y guardar un archivo csv para cada `clarity`.
Primero necesitamos hacer esos conjuntos de datos individuales.
Hay muchas formas de hacerlo, pero hay una que nos gusta especialmente: `group_nest()`.

```{r}
by_clarity <- diamonds |> 
  group_nest(clarity)

by_clarity
```

Esto nos da un nuevo tibble con ocho filas y dos columnas.
`clarity` es nuestra variable de agrupación y `data` es una columna de lista que contiene un tibble para cada valor único de `clarity`:

```{r}
by_clarity$data[[1]]
```

Ya que estamos aquí, creemos una columna que dé el nombre del archivo de salida, usando `mutate()` y `str_glue()`:

```{r}
by_clarity <- by_clarity |> 
  mutate(path = str_glue("diamonds-{clarity}.csv"))

by_clarity
```

Entonces, si fuéramos a guardar estos data frames a mano, podríamos escribir algo como:

```{r}
#| eval: false
write_csv(by_clarity$data[[1]], by_clarity$path[[1]])
write_csv(by_clarity$data[[2]], by_clarity$path[[2]])
write_csv(by_clarity$data[[3]], by_clarity$path[[3]])
...
write_csv(by_clarity$by_clarity[[8]], by_clarity$path[[8]])
```

Esto es un poco diferente a nuestros usos anteriores de `map()` porque hay dos argumentos que están cambiando, no solo uno.
Eso significa que necesitamos una nueva función: `map2()`, que varía tanto el primer como el segundo argumento.
Y como tampoco nos importa la salida, queremos `walk2()` en lugar de `map2()`.
Eso nos da:

```{r}
walk2(by_clarity$data, by_clarity$path, write_csv)
```

```{r}
#| include: false
unlink(by_clarity$path)
```

### Guardar gráficas

Podemos tomar el mismo enfoque básico para crear muchas gráficas.
Primero hagamos una función que dibuje la gráfica que queremos:

```{r}
carat_histogram <- function(df) {
  ggplot(df, aes(x = carat)) + geom_histogram(binwidth = 0.1)  
}

carat_histogram(by_clarity$data[[1]])
```

Ahora podemos usar `map()` para crear una lista de muchos gráficos\[\^iterationn-6\] y sus posibles rutas de archivo:

```{r}
by_clarity <- by_clarity |> 
  mutate(
    plot = map(data, carat_histogram),
    path = str_glue("clarity-{clarity}.png")
  )
```

Luego usa `walk2()` con `ggsave()` para guardar cada gráfico:

```{r}
walk2(
  by_clarity$path,
  by_clarity$plot,
  \(path, plot) ggsave(path, plot, width = 6, height = 6)
)
```

Esta es la abreviatura de:

```{r}
#| eval: false
ggsave(by_clarity$path[[1]], by_clarity$plot[[1]], width = 6, height = 6)
ggsave(by_clarity$path[[2]], by_clarity$plot[[2]], width = 6, height = 6)
ggsave(by_clarity$path[[3]], by_clarity$plot[[3]], width = 6, height = 6)
...
ggsave(by_clarity$path[[8]], by_clarity$plot[[8]], width = 6, height = 6)
```

```{r}
#| include: false
unlink(by_clarity$path)
```

```{=html}
<!-- 
### Exercises

1.  Imagine you have a table of student data containing (amongst other variables) `school_name` and `student_id`. Sketch out what code you'd write if you want to save all the information for each student in file called `{student_id}.csv` in the `{school}` directory.
-->
```
## Resumen

En este capítulo, ha visto cómo usar la iteración explícita para resolver tres problemas que surgen con frecuencia al hacer ciencia de datos: manipular múltiples columnas, leer múltiples archivos y guardar múltiples salidas.
Pero, en general, la iteración es un superpoder: si conoce la técnica de iteración correcta, puede pasar fácilmente de solucionar un problema a solucionar todos los problemas.
Una vez que haya dominado las técnicas de este capítulo, le recomendamos que aprenda más leyendo el [capítulo Funcionales](https://adv-r.hadley.nz/functions.html) de *Advanced R* y consultando el [sitio web de purrr](https://purrr.tidyverse.org).

Si sabe mucho sobre la iteración en otros lenguajes, se sorprenderá de que no hayamos discutido el bucle `for`.
Esto se debe a que la orientación de R hacia el análisis de datos cambia la forma en que iteramos: en la mayoría de los casos, puede confiar en un idioma existente para hacer algo con cada columna o cada grupo.
Y cuando no puedas, a menudo puedes usar una herramienta de programación funcional como `map()` que hace algo con cada elemento de una lista.
Sin embargo, verá bucles `for` en el código capturado de forma salvaje, por lo que aprenderá sobre ellos en el próximo capítulo, donde analizaremos algunas herramientas básicas importantes de R.
