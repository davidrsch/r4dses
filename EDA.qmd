# Análisis exploratorio de datos {#sec-exploratory-data-analysis}

```{r}
#| results: "asis"
#| echo: false
source("_common.R")
status("complete")
```

## Introducción

Este capítulo le mostrará cómo usar la visualización y la transformación para explorar sus datos de manera sistemática, una tarea que los estadísticos llaman análisis exploratorio de datos, o EDA para abreviar, *Exploratory Data Analysis*.
EDA es un ciclo iterativo.
Tú:

1.  Genera preguntas sobre tus datos.

2.  Busque respuestas visualizando, transformando y modelando sus datos.

3.  Use lo que aprendió para refinar sus preguntas y/o generar nuevas preguntas.

EDA no es un proceso formal con un conjunto estricto de reglas.
Más que nada, EDA es un estado de ánimo.
Durante las fases iniciales de EDA, debe sentirse libre de investigar cada idea que se le ocurra.
Algunas de estas ideas funcionarán y otras serán callejones sin salida.
A medida que continúe su exploración, se centrará en algunas áreas particularmente productivas que eventualmente escribirá y comunicará a otros.

EDA es una parte importante de cualquier análisis de datos, incluso si las preguntas se le entregan en bandeja, porque siempre necesita investigar la calidad de sus datos.
La limpieza de datos es solo una aplicación de EDA: hace preguntas sobre si sus datos cumplen con sus expectativas o no.
Para realizar la limpieza de datos, deberá implementar todas las herramientas de EDA: visualización, transformación y modelado.

### Requisitos previos

En este capítulo, combinaremos lo que ha aprendido sobre dplyr y ggplot2 para hacer preguntas de forma interactiva, responderlas con datos y luego hacer nuevas preguntas.

```{r}
#| label: setup
#| message: false

library(tidyverse)
```

## Preguntas

> "No hay preguntas estadísticas rutinarias, solo rutinas estadísticas cuestionables." --- Sir David Cox

> "Es mucho mejor una respuesta aproximada a la pregunta correcta, que a menudo es vaga, que una respuesta exacta a la pregunta equivocada, que siempre se puede precisar." --- John Tukey

Su objetivo durante EDA es desarrollar una comprensión de sus datos.
La forma más fácil de hacer esto es usar preguntas como herramientas para guiar su investigación.
Cuando hace una pregunta, la pregunta enfoca su atención en una parte específica de su conjunto de datos y lo ayuda a decidir qué gráficos, modelos o transformaciones hacer.

EDA es fundamentalmente un proceso creativo.
Y como la mayoría de los procesos creativos, la clave para hacer preguntas de *calidad* es generar una gran *cantidad* de preguntas.
Es difícil hacer preguntas reveladoras al comienzo de su análisis porque no sabe qué información se puede obtener de su conjunto de datos.
Por otro lado, cada nueva pregunta que haga lo expondrá a un nuevo aspecto de sus datos y aumentará sus posibilidades de hacer un descubrimiento.
Puede profundizar rápidamente en las partes más interesantes de sus datos, y desarrollar un conjunto de preguntas que invitan a la reflexión, si hace un seguimiento de cada pregunta con una nueva pregunta basada en lo que encuentre.

No hay una regla sobre qué preguntas debe hacer para guiar su investigación.
Sin embargo, dos tipos de preguntas siempre serán útiles para hacer descubrimientos dentro de sus datos.
Puede redactar libremente estas preguntas como:

1.  ¿Qué tipo de variación ocurre dentro de mis variables?

2.  ¿Qué tipo de covariación ocurre entre mis variables?

El resto de este capítulo analizará estas dos preguntas.
Explicaremos qué son la variación y la covariación, y le mostraremos varias formas de responder cada pregunta.
Para facilitar la discusión, definamos algunos términos:

-   Una **variable** es una cantidad, calidad o propiedad que puede medir.

-   Un **valor** es el estado de una variable cuando la mides.
    El valor de una variable puede cambiar de una medida a otra.

-   Una **observación** es un conjunto de mediciones realizadas en condiciones similares (usualmente realiza todas las mediciones en una observación al mismo tiempo y en el mismo objeto).
    Una observación contendrá varios valores, cada uno asociado con una variable diferente.
    A veces nos referiremos a una observación como un punto de datos.

-   **Datos tabulares** es un conjunto de valores, cada uno asociado con una variable y una observación.
    Los datos tabulares están *ordenados* si cada valor se coloca en su propia "celda", cada variable en su propia columna y cada observación en su propia fila.

Hasta ahora, todos los datos que ha visto han estado ordenados.
En la vida real, la mayoría de los datos no están ordenados, por lo que volveremos a estas ideas nuevamente en @sec-rectangling.

## Variación

**Variación** es la tendencia de los valores de una variable a cambiar de una medida a otra.
Puedes ver la variación fácilmente en la vida real; si mide cualquier variable continua dos veces, obtendrá dos resultados diferentes.
Esto es cierto incluso si mide cantidades que son constantes, como la velocidad de la luz.
Cada una de sus medidas incluirá una pequeña cantidad de error que varía de una medida a otra.
Las variables también pueden variar si mide diferentes temas (p. ej., los colores de ojos de diferentes personas) o diferentes momentos (p. ej., los niveles de energía de un electrón en diferentes momentos).
Cada variable tiene su propio patrón de variación, que puede revelar información interesante sobre cómo varía esa variable entre mediciones en la misma observación, así como entre observaciones.
La mejor forma de comprender ese patrón es visualizar la distribución de los valores de la variable, que aprendiste en @sec-data-visualization.

Comenzaremos nuestra exploración visualizando la distribución de pesos (quilates `carat`) de \~54,000 diamantes del conjunto de datos `diamonds`.
Dado que `carat` es una variable numérica, podemos usar un histograma:

```{r}
#| fig-alt: >
#|   Un histograma de quilates de diamantes, con el eje x que va de 0 a 4,5
#|   y el eje y que va de 0 a 30000. La distribución está sesgada a la derecha
#|   con muy pocos diamantes en el contenedor centrado en 0, casi 30000 diamantes en
#|   el contenedor centrado en 0.5, aproximadamente 15000 diamantes en el contenedor centrado
#|   en 1, y mucho menos, aproximadamente 5000 diamantes en el contenedor centrado en
#|   1.5. Más allá de esto, hay una cola que se arrastra.

ggplot(diamonds, aes(x = carat)) +
  geom_histogram(binwidth = 0.5)
```

Ahora que puede visualizar la variación, ¿qué debe buscar en sus gráficos?
¿Y qué tipo de preguntas de seguimiento debe hacer?
Hemos reunido una lista a continuación de los tipos de información más útiles que encontrará en sus gráficos, junto con algunas preguntas de seguimiento para cada tipo de información.
La clave para hacer buenas preguntas de seguimiento será confiar en su curiosidad (¿Sobre qué quiere aprender más?) así como en su escepticismo (¿Cómo podría ser engañoso?).

### Valores típicos

Tanto en los gráficos de barras como en los histogramas, las barras altas muestran los valores comunes de una variable y las barras más cortas muestran los valores menos comunes.
Los lugares que no tienen barras revelan valores que no se vieron en sus datos.
Para convertir esta información en preguntas útiles, busque cualquier cosa inesperada:

-   ¿Qué valores son los más comunes?
    ¿Por qué?

-   ¿Qué valores son raros?
    ¿Por qué?
    ¿Eso coincide con sus expectativas?

-   ¿Puedes ver algún patrón inusual?
    ¿Qué podría explicarlos?

Como ejemplo, el siguiente histograma sugiere varias preguntas interesantes:

-   ¿Por qué hay más diamantes en quilates enteros y fracciones comunes de quilates?

-   ¿Por qué hay más diamantes ligeramente a la derecha de cada pico que ligeramente a la izquierda de cada pico?

```{r}
#| fig-alt: >
#|   Un histograma de quilates de diamantes, con el eje x que va de 0 a 3 y
#|   el eje y que va de 0 a aproximadamente 2500. El ancho del contenedor es bastante estrecho
#|   (0,01), lo que da como resultado una gran cantidad de barras delgadas. La distribución
#|   está sesgado a la derecha, con muchos picos seguidos de barras en alturas decrecientes,
#|   hasta un fuerte aumento en el siguiente pico.

smaller <- diamonds |> 
  filter(carat < 3)

ggplot(smaller, aes(x = carat)) +
  geom_histogram(binwidth = 0.01)
```

Los grupos de valores similares sugieren que existen subgrupos en sus datos.
Para comprender los subgrupos, pregunte:

-   ¿En qué se parecen las observaciones dentro de cada grupo?

-   ¿En qué se diferencian entre sí las observaciones en grupos separados?

-   ¿Cómo puedes explicar o describir los clusters?

-   ¿Por qué la apariencia de los clústeres podría ser engañosa?

El siguiente histograma muestra la duración (en minutos) de 272 erupciones del géiser Old Faithful en el Parque Nacional de Yellowstone.
Los tiempos de erupción parecen estar agrupados en dos grupos: hay erupciones cortas (de alrededor de 2 minutos) y erupciones largas (4-5 minutos), pero poco en el medio.

```{r}
#| fig-alt: >
#|   Un histograma de tiempos de erupción. El eje x va desde aproximadamente 1,5 a 5,
#|   y el eje y varía de 0 a aproximadamente 40. La distribución es bimodal
#|   con picos alrededor de 1.75 y 4.5.

ggplot(faithful, aes(x = eruptions)) + 
  geom_histogram(binwidth = 0.25)
```

Muchas de las preguntas anteriores lo llevarán a explorar una relación *entre* variables, por ejemplo, para ver si los valores de una variable pueden explicar el comportamiento de otra variable.
Llegaremos a eso en breve.

### Valores inusuales

Los valores atípicos son observaciones que son inusuales; puntos de datos que no parecen ajustarse al patrón.
A veces, los valores atípicos son errores de entrada de datos; otras veces, los valores atípicos sugieren nueva ciencia importante.
Cuando tiene muchos datos, los valores atípicos a veces son difíciles de ver en un histograma.
Por ejemplo, tome la distribución de la variable `y` del conjunto de datos de diamantes.
La única evidencia de valores atípicos son los límites inusualmente amplios en el eje x.

```{r}
#| fig-alt: >
#|   Un histograma de longitudes de diamantes. El eje x va de 0 a 60 y el
#|   eje y varía de 0 a 12000. Hay un pico alrededor de 5, y los datos
#|   parecen estar completamente agrupados alrededor del pico.

ggplot(diamonds, aes(x = y)) + 
  geom_histogram(binwidth = 0.5)
```

Hay tantas observaciones en los contenedores comunes que los contenedores raros son muy cortos, por lo que es muy difícil verlos (aunque tal vez si miras fijamente a 0 verás algo).
Para que sea más fácil ver los valores inusuales, necesitamos ampliar los valores pequeños del eje y con `coord_cartesian()`:

```{r}
#| fig-alt: >
#|   Un histograma de longitudes de diamantes. El eje x va de 0 a 60 y el
#|   eje y va de 0 a 50. Hay un pico alrededor de 5 y los datos
#|   parecen estar completamente agrupados alrededor del pico. Aparte de esos datos,
#|   hay un contenedor en 0 con una altura de aproximadamente 8, uno un poco más de 30 con
#|   una altura de 1 y otra un poco por debajo de 60 con una altura de 1.

ggplot(diamonds, aes(x = y)) + 
  geom_histogram(binwidth = 0.5) +
  coord_cartesian(ylim = c(0, 50))
```

`coord_cartesian()` también tiene un argumento `xlim()` para cuando necesite hacer zoom en el eje x.
ggplot2 también tiene funciones `xlim()` y `ylim()` que funcionan de forma ligeramente diferente: desechan los datos fuera de los límites.

Esto nos permite ver que hay tres valores inusuales: 0, \~30 y \~60.
Los sacamos con dplyr:

```{r}
#| include: false

old <- options(tibble.print_max = 10, tibble.print_min = 10)
```

```{r}
unusual <- diamonds |> 
  filter(y < 3 | y > 20) |> 
  select(price, x, y, z) |>
  arrange(y)
unusual
```

```{r}
#| include: false

options(old)
```

La variable `y` mide una de las tres dimensiones de estos diamantes, en mm.
Sabemos que los diamantes no pueden tener un ancho de 0 mm, por lo que estos valores deben ser incorrectos.
También podemos sospechar que las medidas de 32 mm y 59 mm son inverosímiles: esos diamantes miden más de una pulgada de largo, ¡pero no cuestan cientos de miles de dólares!

Es una buena práctica repetir su análisis con y sin los valores atípicos.
Si tienen un efecto mínimo en los resultados y no puede averiguar por qué están ahí, es razonable omitirlos y continuar.
Sin embargo, si tienen un efecto sustancial en sus resultados, no debe dejarlos sin justificación.
Deberá averiguar qué los causó (por ejemplo, un error de ingreso de datos) y revelar que los eliminó en su informe.

### Ejercicios

1.  Explore la distribución de cada una de las variables `x`, `y` y `z` en `diamantes`.
    ¿Qué aprendes?
    Piensa en un diamante y en cómo podrías decidir qué dimensión es la longitud, el ancho y la profundidad.

2.  Explora la distribución del precio `price`.
    ¿Descubriste algo inusual o sorprendente?
    (Sugerencia: piense detenidamente en el `binwidth` y asegúrese de probar una amplia gama de valores).

3.  ¿Cuántos diamantes son de 0,99 quilates?
    ¿Cuántos son de 1 quilate?
    ¿Cuál crees que es la causa de la diferencia?

4.  Compare y contraste `coord_cartesian()` frente a `xlim()` o `ylim()` al hacer zoom en un histograma.
    ¿Qué sucede si dejas `binwidth` sin configurar?
    ¿Qué sucede si intenta hacer zoom para que solo se muestre la mitad de una barra?

## Valores inusuales {#sec-missing-values-eda}

Si ha encontrado valores inusuales en su conjunto de datos y simplemente desea continuar con el resto de su análisis, tiene dos opciones.

1.  Suelta toda la fila con los valores extraños:

    ```{r}
    #| eval: false

    diamonds2 <- diamonds |> 
      filter(between(y, 3, 20))
    ```

    No recomendamos esta opción porque el hecho de que una medida no sea válida no significa que todas las medidas lo sean.
    Además, si tiene datos de baja calidad, en el momento en que haya aplicado este enfoque a cada variable, es posible que no le queden datos.

2.  En su lugar, recomendamos reemplazar los valores inusuales con valores faltantes.
    La forma más fácil de hacer esto es usar `mutate()` para reemplazar la variable con una copia modificada.
    Puedes usar la función `if_else()` para reemplazar valores inusuales con `NA`:

    ```{r}
    diamonds2 <- diamonds |> 
      mutate(y = if_else(y < 3 | y > 20, NA, y))
    ```

`if_else()` tiene tres argumentos.
El primer argumento `test` debe ser un vector lógico.
El resultado contendrá el valor del segundo argumento, `yes`, cuando `test` es `TRUE`, y el valor del tercer argumento, `no`, cuando es falso.
Como alternativa a `if_else()`, utilice `case_when()`.
`case_when()` es particularmente útil dentro de mutate cuando desea crear una nueva variable que se basa en una combinación compleja de variables existentes o que de otro modo requeriría múltiples declaraciones `if_else()` anidadas una dentro de otra.
Aprenderá más sobre vectores lógicos en @sec-logicals.

It's not obvious where you should plot missing values, so ggplot2 doesn't include them in the plot, but it does warn that they've been removed:

```{r}
#| dev: "png"
#| fig-alt: >
#|   Un diagrama de dispersión de anchos frente a longitudes de diamantes. Hay un fuerte,
#|   asociación lineal entre las dos variables. Todos menos uno de los diamantes
#|   tiene una longitud mayor que 3. El único valor atípico tiene una longitud de 0 y un ancho
#|   de unos 6,5. 

ggplot(diamonds2, aes(x = x, y = y)) + 
  geom_point()
```

Para suprimir esa advertencia, configure `na.rm = TRUE`:

```{r}
#| eval: false

ggplot(diamonds2, aes(x = x, y = y)) + 
  geom_point(na.rm = TRUE)
```

Otras veces, desea comprender qué hace que las observaciones con valores faltantes sean diferentes a las observaciones con valores registrados.
Por ejemplo, en `nycflights13::flights`[^eda-1], los valores faltantes en la variable `dep_time` indican que el vuelo fue cancelado.
Por lo tanto, es posible que desee comparar los horarios de salida programados para los horarios cancelados y no cancelados.
Puedes hacer esto creando una nueva variable con `is.na()`.

[^eda-1]: Recuerda que cuando necesites ser explícito sobre el origen de una función (o conjunto de datos), usaremos la forma especial `package::funcion()` o `package::conjuntodedatos`.

```{r}
#| fig-alt: >
#|   Un polígono de frecuencia de horas de salida programadas de vuelos. Dos lineas
#|   representan vuelos cancelados y no cancelados. Los rangos del eje x
#|   van de 0 a 25 minutos y el eje y va de 0 a 10000. El número de
#|   los vuelos no cancelados son muy superiores a los cancelados.

nycflights13::flights |> 
  mutate(
    cancelled = is.na(dep_time),
    sched_hour = sched_dep_time %/% 100,
    sched_min = sched_dep_time %% 100,
    sched_dep_time = sched_hour + (sched_min / 60)
  ) |> 
  ggplot(aes(x = sched_dep_time)) + 
  geom_freqpoly(aes(color = cancelled), binwidth = 1/4)
```

Sin embargo, esta gráfica no es muy buena porque hay muchos más vuelos no cancelados que vuelos cancelados.
En la siguiente sección exploraremos algunas técnicas para mejorar esta comparación.

### Ejercicios

1.  ¿Qué sucede con los valores faltantes en un histograma?
    ¿Qué sucede con los valores faltantes en un gráfico de barras?
    ¿Por qué hay una diferencia en cómo se manejan los valores perdidos en histogramas y gráficos de barras?

2.  ¿Qué hace `na.rm = TRUE` en `mean()` y `sum()`?

## Covariación

Si la variación describe el comportamiento *dentro* de una variable, la covariación describe el comportamiento *entre* variables.
**Covariación** es la tendencia de los valores de dos o más variables a variar juntos de manera relacionada.
La mejor manera de detectar la covariación es visualizar la relación entre dos o más variables.

### Una variable categórica y una numérica {#sec-cat-num}

Por ejemplo, exploremos cómo varía el precio de un diamante con su calidad (medida por su corte `cut`) usando `geom_freqpoly()`:

```{r}
#| fig-alt: >
#|   Un polígono de frecuencia de precios de diamantes donde cada corte de quilate (Regular,
#|   Bueno, Muy bueno, Premium e Ideal) se representa con una linea de color
#|   diferente. El eje x va de 0 a 30000 y el eje y va de 0 a
#|   5000. Las líneas se superponen mucho, lo que sugiere una frecuencia similar
#|   en las distribuciones de precios de diamantes. Una característica notable es que
#|   los diamantes ideales tienen el pico más alto alrededor de 1500.

ggplot(diamonds, aes(x = price)) + 
  geom_freqpoly(aes(color = cut), binwidth = 500, linewidth = 0.75)
```

La apariencia predeterminada de `geom_freqpoly()` no es tan útil para ese tipo de comparación porque la altura viene dada por el conteo y los conteos generales de `cut` difieren mucho, lo que dificulta ver las diferencias en las formas de sus distribuciones:

```{r}
#| fig-alt: >
#|   Gráfico de barras de cortes de diamantes que muestra una gran variabilidad entre los
#|   frecuencias de varios cortes. Los diamantes Regulares tienen la frecuencia más baja,
#|   luego Bueno, luego Muy Bueno, luego Premium y luego Ideal.

ggplot(diamonds, aes(x = cut)) + 
  geom_bar()
```

Para facilitar la comparación, necesitamos intercambiar lo que se muestra en el eje y.
En lugar de mostrar el conteo, mostraremos la **densidad**, que es el conteo estandarizado para que el área debajo de cada polígono de frecuencia sea uno.

```{r}
#| fig-alt: >
#|   Un polígono de frecuencias de densidades de precios de diamantes donde cada corte de
#|   quilate (Regular, Bueno, Muy bueno, Premium e Ideal) se representa con un
#|   línea de color diferente. El eje x va de 0 a 20000. Las líneas se superponen
#|   mucho, lo que sugiere distribuciones de densidad similares de precios de
#|   diamantes. Una característica notable es que todos, excepto los diamantes Regulares, tienen picos altos.
#|   alrededor de un precio de 1500 y los diamantes Regulares tienen un promedio más alto que otros.

ggplot(diamonds, aes(x = price, y = after_stat(density))) + 
  geom_freqpoly(aes(color = cut), binwidth = 500, linewidth = 0.75)
```

Tenga en cuenta que estamos asignando la densidad a `y`, pero dado que `density` no es una variable en el conjunto de datos `diamonds`, primero debemos calcularla.
Usamos la función `after_stat()` para hacerlo.

Hay algo bastante sorprendente en esta gráfica: ¡parece que los diamantes justos (la calidad más baja) tienen el precio promedio más alto!
Pero tal vez eso se deba a que los polígonos de frecuencia son un poco difíciles de interpretar: están sucediendo muchas cosas en este gráfico.

Una gráfica visualmente más simple para explorar esta relación es usar diagramas de caja uno al lado del otro.

```{r}
#| fig-height: 3
#| fig-alt: >
#|   Gráficos de caja uno al lado del otro de los precios de los diamantes por corte. La distribución de
#|   los precios están sesgados a la derecha para cada corte (Regular, Bueno, Muy bueno, Premium y
#|   Ideal). Las medianas están cerca una de la otra, con la mediana para diamantes
#|   Ideal más baja y la de Regular más alta.

ggplot(diamonds, aes(x = cut, y = price)) +
  geom_boxplot()
```

Vemos mucha menos información sobre la distribución, pero los diagramas de caja son mucho más compactos, por lo que podemos compararlos más fácilmente (y encajar más en un diagrama).
¡Es compatible con el hallazgo contrario a la intuición de que los diamantes de mejor calidad son más baratos en promedio!
En los ejercicios, se le desafiará a averiguar por qué.

`cut` es un factor ordenado: regular es peor que bueno, que es peor que muy bueno y así sucesivamente.
Muchas variables categóricas no tienen ese orden intrínseco, por lo que es posible que desee reordenarlas para que la visualización sea más informativa.
Una forma de hacerlo es con la función `fct_reorder()`.

Por ejemplo, tome la variable `class` en el conjunto de datos `mpg`.
Puede que le interese saber cómo varía el kilometraje en carretera según las clases:

```{r}
#| fig-alt: >
#|   Gráficas de caja. uno al lado de otro, de kilometraje en carretera de automóviles por clase. Las clases son
#|   en el eje x (2 plazas, compacto, mediano, minivan, camioneta, subcompacto,
#|   y todoterreno).

ggplot(mpg, aes(x = class, y = hwy)) +
  geom_boxplot()
```

Para que la tendencia sea más fácil de ver, podemos reordenar `class` en función del valor medio de carretera `hwy`:

```{r}
#| fig-height: 3
#| fig-alt: >
#|   Gráficas de caja, uno al lado del otro, de kilometraje en carretera de automóviles por clase. Las clases son
#|   en el eje x y ordenadas por kilometraje medio creciente en carretera (recogida,
#|   todoterreno, monovolumen, biplaza, subcompacto, compacto y mediano).

ggplot(mpg, aes(x = fct_reorder(class, hwy, median), y = hwy)) +
  geom_boxplot()
```

Si tiene nombres de variables largos, `geom_boxplot()` funcionará mejor si lo gira 90°.
Puede hacerlo intercambiando las asignaciones estéticas x e y.

```{r}
#| fig-alt: >
#|   Gráficas de caja, una al lado de la otra, de kilometraje en carretera de automóviles por clase. Las clases son
#|   en el eje y y ordenadas por kilometraje promedio creciente en carretera.

ggplot(mpg, aes(x = hwy, y = fct_reorder(class, hwy, median))) +
  geom_boxplot()
```

#### Ejercicios

1.  Utilice lo que ha aprendido para mejorar la visualización de las horas de salida de los vuelos cancelados frente a los no cancelados.

2.  ¿Qué variable en el conjunto de datos de diamantes es más importante para predecir el precio de un diamante?
    ¿Cómo se correlaciona esa variable con el corte?
    ¿Por qué la combinación de esas dos relaciones hace que los diamantes de menor calidad sean más caros?

3.  En lugar de intercambiar las variables x e y, agregue `coord_flip()` como una nueva capa al diagrama de caja vertical para crear uno horizontal.
    ¿Cómo se compara esto con el uso de intercambiar las variables?

4.  Un problema con los diagramas de caja es que se desarrollaron en una era de conjuntos de datos mucho más pequeños y tienden a mostrar una cantidad prohibitivamente grande de "valores atípicos".
    Un enfoque para remediar este problema es la gráfica de valores de letras.
    Instale el paquete lvplot e intente usar `geom_lv()` para mostrar la distribución del precio frente al corte.
    ¿Qué aprendes?
    ¿Cómo interpretas las gráficas?

5.  Compara y contrasta `geom_violin()` con un `geom_histogram()` facetado, o un `geom_freqpoly()` coloreado.
    ¿Cuáles son los pros y los contras de cada método?

6.  Si tiene un conjunto de datos pequeño, a veces es útil usar `geom_jitter()` para ver la relación entre una variable continua y categórica.
    El paquete ggbeeswarm proporciona una serie de métodos similares a `geom_jitter()`.
    Enumérelos y describa brevemente lo que hace cada uno.

### Dos variables categóricas

To visualize the covariation between categorical variables, you'll need to count the number of observations for each combination of levels of these categorical variables.
One way to do that is to rely on the built-in `geom_count()`:

```{r}
#| fig-alt: >
#|   A scatterplot of color vs. cut of diamonds. There is one point for each
#|   combination of levels of cut (Fair, Good, Very Good, Premium, and Ideal) 
#|   abd color (D, E, F, G, G, I, and J). The sizes of the points represent 
#|   the number of observations for that combination. The legend indicates 
#|   that these sizes range between 1000 and 4000.

ggplot(diamonds, aes(x = cut, y = color)) +
  geom_count()
```

The size of each circle in the plot displays how many observations occurred at each combination of values.
Covariation will appear as a strong correlation between specific x values and specific y values.

Another approach for exploring the relationship between these variables is computing the counts with dplyr:

```{r}
diamonds |> 
  count(color, cut)
```

Then visualize with `geom_tile()` and the fill aesthetic:

```{r}
#| fig-alt: >
#|   A tile plot of cut vs. color of diamonds. Each tile represents a 
#|   cut/color combination and tiles are colored according to the number of 
#|   observations in each tile. There are more Ideal diamonds than other cuts, 
#|   with the highest number being Ideal diamonds with color G. Fair diamonds 
#|   and diamonds with color I are the lowest in frequency.

diamonds |> 
  count(color, cut) |>  
  ggplot(aes(x = color, y = cut)) +
  geom_tile(aes(fill = n))
```

If the categorical variables are unordered, you might want to use the seriation package to simultaneously reorder the rows and columns in order to more clearly reveal interesting patterns.
For larger plots, you might want to try the heatmaply package, which creates interactive plots.

#### Exercises

1.  How could you rescale the count dataset above to more clearly show the distribution of cut within color, or color within cut?

2.  How does the segmented bar chart change if color is mapped to the `x` aesthetic and `cut` is mapped to the `fill` aesthetic?
    Calculate the counts that fall into each of the segments.

3.  Use `geom_tile()` together with dplyr to explore how average flight delays vary by destination and month of year.
    What makes the plot difficult to read?
    How could you improve it?

4.  Why is it slightly better to use `aes(x = color, y = cut)` rather than `aes(x = cut, y = color)` in the example above?

### Two numerical variables

You've already seen one great way to visualize the covariation between two numerical variables: draw a scatterplot with `geom_point()`.
You can see covariation as a pattern in the points.
For example, you can see an exponential relationship between the carat size and price of a diamond:

```{r}
#| dev: "png"
#| fig-alt: >
#|   A scatterplot of price vs. carat. The relationship is positive, somewhat 
#|   strong, and exponential.

ggplot(smaller, aes(x = carat, y = price)) +
  geom_point()
```

(In this section we'll use the `smaller` dataset to stay focused on the bulk of the diamonds that are smaller than 3 carats)

Scatterplots become less useful as the size of your dataset grows, because points begin to overplot, and pile up into areas of uniform black (as above).
You've already seen one way to fix the problem: using the `alpha` aesthetic to add transparency.

```{r}
#| dev: "png"
#| fig-alt: >
#|   A scatterplot of price vs. carat. The relationship is positive, somewhat 
#|   strong, and exponential. The points are transparent, showing clusters where 
#|   the number of points is higher than other areas, The most obvious clusters 
#|   are for diamonds with 1, 1.5, and 2 carats.

ggplot(smaller, aes(x = carat, y = price)) + 
  geom_point(alpha = 1 / 100)
```

But using transparency can be challenging for very large datasets.
Another solution is to use bin.
Previously you used `geom_histogram()` and `geom_freqpoly()` to bin in one dimension.
Now you'll learn how to use `geom_bin2d()` and `geom_hex()` to bin in two dimensions.

`geom_bin2d()` and `geom_hex()` divide the coordinate plane into 2d bins and then use a fill color to display how many points fall into each bin.
`geom_bin2d()` creates rectangular bins.
`geom_hex()` creates hexagonal bins.
You will need to install the hexbin package to use `geom_hex()`.

```{r}
#| layout-ncol: 2
#| eval: false
#| fig-alt: >
#|   Plot 1: A binned density plot of price vs. carat. Plot 2: A hexagonal bin 
#|   plot of price vs. carat. Both plots show that the highest density of 
#|   diamonds have low carats and low prices.

ggplot(smaller, aes(x = carat, y = price)) +
  geom_bin2d()

# install.packages("hexbin")
ggplot(smaller, aes(x = carat, y = price)) +
  geom_hex()
```

Another option is to bin one continuous variable so it acts like a categorical variable.
Then you can use one of the techniques for visualizing the combination of a categorical and a continuous variable that you learned about.
For example, you could bin `carat` and then for each group, display a boxplot:

```{r}
#| fig-alt: >
#|   Side-by-side box plots of price by carat. Each box plot represents diamonds 
#|   that are 0.1 carats apart in weight. The box plots show that as carat 
#|   increases the median price increases as well. Additionally, diamonds with 
#|   1.5 carats or lower have right skewed price distributions, 1.5 to 2 have 
#|   roughly symmetric price distributions, and diamonds that weigh more have 
#|   left skewed distributions. Cheaper, smaller diamonds have outliers on the 
#|   higher end, more expensive, bigger diamonds have outliers on the lower end.

ggplot(smaller, aes(x = carat, y = price)) + 
  geom_boxplot(aes(group = cut_width(carat, 0.1)))
```

`cut_width(x, width)`, as used above, divides `x` into bins of width `width`.
By default, boxplots look roughly the same (apart from number of outliers) regardless of how many observations there are, so it's difficult to tell that each boxplot summaries a different number of points.
One way to show that is to make the width of the boxplot proportional to the number of points with `varwidth = TRUE`.

#### Exercises

1.  Instead of summarizing the conditional distribution with a boxplot, you could use a frequency polygon.
    What do you need to consider when using `cut_width()` vs. `cut_number()`?
    How does that impact a visualization of the 2d distribution of `carat` and `price`?

2.  Visualize the distribution of `carat`, partitioned by `price`.

3.  How does the price distribution of very large diamonds compare to small diamonds?
    Is it as you expect, or does it surprise you?

4.  Combine two of the techniques you've learned to visualize the combined distribution of cut, carat, and price.

5.  Two dimensional plots reveal outliers that are not visible in one dimensional plots.
    For example, some points in the following plot have an unusual combination of `x` and `y` values, which makes the points outliers even though their `x` and `y` values appear normal when examined separately.
    Why is a scatterplot a better display than a binned plot for this case?

    ```{r}
    #| eval: false
    diamonds |> 
      filter(x >= 4) |>
      ggplot(aes(x = x, y = y)) +
      geom_point() +
      coord_cartesian(xlim = c(4, 11), ylim = c(4, 11))
    ```

6.  Instead of creating boxes of equal width with `cut_width()`, we could create boxes that contain roughly equal number of points with `cut_number()`.
    What are the advantages and disadvantages of this approach?

    ```{r}
    #| eval: false
    ggplot(smaller, aes(x = carat, y = price)) +
      geom_boxplot(aes(group = cut_number(carat, 20)))
    ```

## Patterns and models

Patterns in your data provide clues about relationships.
If a systematic relationship exists between two variables it will appear as a pattern in the data.
If you spot a pattern, ask yourself:

-   Could this pattern be due to coincidence (i.e. random chance)?

-   How can you describe the relationship implied by the pattern?

-   How strong is the relationship implied by the pattern?

-   What other variables might affect the relationship?

-   Does the relationship change if you look at individual subgroups of the data?

A scatterplot of Old Faithful eruption lengths versus the wait time between eruptions shows a pattern: longer wait times are associated with longer eruptions.
The scatterplot also displays the two clusters that we noticed above.

```{r}
#| fig-height: 2
#| fig-alt: >
#|   A scatterplot of eruption time vs. waiting time to next eruption of the 
#|   Old Faithful geyser. There are two clusters of points: one with low 
#|   eruption times and short waiting times and one with long eruption times and 
#|   long waiting times.

ggplot(faithful, aes(x = eruptions, y = waiting)) + 
  geom_point()
```

Patterns provide one of the most useful tools for data scientists because they reveal covariation.
If you think of variation as a phenomenon that creates uncertainty, covariation is a phenomenon that reduces it.
If two variables covary, you can use the values of one variable to make better predictions about the values of the second.
If the covariation is due to a causal relationship (a special case), then you can use the value of one variable to control the value of the second.

Models are a tool for extracting patterns out of data.
For example, consider the diamonds data.
It's hard to understand the relationship between cut and price, because cut and carat, and carat and price are tightly related.
It's possible to use a model to remove the very strong relationship between price and carat so we can explore the subtleties that remain.
The following code fits a model that predicts `price` from `carat` and then computes the residuals (the difference between the predicted value and the actual value).
The residuals give us a view of the price of the diamond, once the effect of carat has been removed.
Note that instead of using the raw values of `price` and `carat`, we log transform them first, and fit a model to the log-transformed values.
Then, we exponentiate the residuals to put them back in the scale of raw prices.

```{r}
#| message: false
#| dev: "png"
#| fig-alt: >
#|   A scatter plot of residuals vs. carat of diamonds. The x-axis ranges from 0 
#|   to 5, the y-axis ranges from 0 to almost 4. Much of the data are clustered 
#|   around low values of carat and residuals. There is a clear, curved pattern 
#|   showing decrease in residuals as carat increases.

library(tidymodels)

diamonds <- diamonds |>
  mutate(
    log_price = log(price),
    log_carat = log(carat)
  )

diamonds_fit <- linear_reg() |>
  fit(log_price ~ log_carat, data = diamonds)

diamonds_aug <- augment(diamonds_fit, new_data = diamonds) |>
  mutate(.resid = exp(.resid))

ggplot(diamonds_aug, aes(x = carat, y = .resid)) + 
  geom_point()
```

Once you've removed the strong relationship between carat and price, you can see what you expect in the relationship between cut and price: relative to their size, better quality diamonds are more expensive.

```{r}
#| fig-alt: >
#|   Side-by-side box plots of residuals by cut. The x-axis displays the various 
#|   cuts (Fair to Ideal), the y-axis ranges from 0 to almost 5. The medians are 
#|   quite similar, between roughly 0.75 to 1.25. Each of the distributions of 
#|   residuals is right skewed, with many outliers on the higher end.

ggplot(diamonds_aug, aes(x = cut, y = .resid)) + 
  geom_boxplot()
```

We're not discussing modelling in this book because understanding what models are and how they work is easiest once you have tools of data wrangling and programming in hand.

## Summary

In this chapter you've learned a variety of tools to help you understand the variation within your data.
You've seen technique that work with a single variable at a time and with a pair of variables.
This might seem painful restrictive if you have tens or hundreds of variables in your data, but they're foundation upon which all other techniques are built.

In the next chapter, we'll tackle our final piece of workflow advice: how to get help when you're stuck.
